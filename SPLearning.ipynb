{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Useful SPs from Wikipedia Text\n",
    "\n",
    "We can use a stream of articles from wikipedia as a corpus for learning useful semantic pointers that capture various relationships between words. First, we'll set up the corpus, build a vocabulary of words to model, and check the size of this vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  14924\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from embeddings import RandomIndexing\n",
    "from corpora import Wikipedia\n",
    "\n",
    "wiki = Wikipedia(path=os.getcwd()+'/wikipedia/', article_limit=100)\n",
    "wiki.load_vocab('tutorial_words')\n",
    "\n",
    "print('Vocab size: ', len(wiki.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Encoding\n",
    "\n",
    "Now, we can build a basic random indexing model to encode the word co-occurence patterns in these articles into a set of high-dimensional vectors. This method is related to well-known algorithms such as LSA, Word2Vec (i.e. CBOW + skip-gram encoding), and GloVe. One benefit of random indexing is that it is easy to parallelize, and hence efficient to run on large corpora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time:  12.955912113189697\n"
     ]
    }
   ],
   "source": [
    "dim = 512\n",
    "\n",
    "model = RandomIndexing(wiki)\n",
    "model.train(dim=dim, wordlist=wiki.vocab, flags=['context'], batchsize=100)\n",
    "print('Computation time: ', model.runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the nearest neighbors to any word in the resulting 'semantic space' with just a few lines of code. Note that with this small amount of training data, the results will be specific to the topics of the wikipedia articles that have been chosen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors to \"brain\":\n",
      "brain 1.0\n",
      "autism 0.482719270829\n",
      "disorders 0.431223462006\n",
      "hypothesizes 0.421037821424\n",
      "diffusion 0.406571107305\n",
      "\n",
      "Nearest neighbors to \"movie\":\n",
      "movie 1.0\n",
      "oscars 0.388022533051\n",
      "picture 0.386882381116\n",
      "conferred 0.37202252053\n",
      "chances 0.364864475903\n",
      "\n",
      "Nearest neighbors to \"philosophy\":\n",
      "philosophy 1.0\n",
      "metaphysics 0.61318627448\n",
      "poetical 0.548708071504\n",
      "logic 0.545480437691\n",
      "theoretical 0.504074031182\n",
      "\n",
      "Nearest neighbors to \"political\":\n",
      "political 1.0\n",
      "social 0.547131407219\n",
      "economic 0.54543491821\n",
      "government 0.539706920881\n",
      "power 0.520555591159\n",
      "\n",
      "Nearest neighbors to \"oil\":\n",
      "oil 1.0\n",
      "crude 0.804677235039\n",
      "reserves 0.696746126835\n",
      "sands 0.689746302217\n",
      "petroleum 0.682390158621\n",
      "\n",
      "Nearest neighbors to \"president\":\n",
      "president 1.0\n",
      "government 0.619202080505\n",
      "presidential 0.580545854702\n",
      "power 0.565907232342\n",
      "lincoln 0.561240526704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_list = ['brain','movie','philosophy','political','oil','president']\n",
    "\n",
    "for word in word_list:\n",
    "    print('Nearest neighbors to \"%s\":' % word)\n",
    "    model.get_nearest(word)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Encoding\n",
    "\n",
    "To make the model a bit more interesting, we can encode positional information about the words that tend to occur around each target word in our voabulary. This amounts to adding information about ngrams in the corpus to each semantic vector. Computation is a bit more costly in this case, due to the need to compute several circular convolutions per word occurence. Again, though, this computation can be parallelized, so it's not too bad to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time:  44.344762086868286\n"
     ]
    }
   ],
   "source": [
    "model.train(dim=dim, wordlist=wiki.vocab, flags=['order'], batchsize=100)\n",
    "print('Computation time: ', model.runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting vectors can be queried for likely words occuring in positions to left and right of a target word. We can also find words that tend to occur in the same 'order contexts' as a target word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likely words next to \"king\":\n",
      "of 0.57443948913\n",
      "diatomic 0.160800123097\n",
      "driven 0.15608508356\n",
      "goto 0.155153476234\n",
      "rupture 0.154560077595\n",
      "\n",
      "Likely words next to \"abraham\":\n",
      "lincoln 0.635985749054\n",
      "became 0.228987218933\n",
      "was 0.175729638394\n",
      "freedom 0.172380710857\n",
      "karl 0.169741238861\n",
      "\n",
      "Likely words next to \"of\":\n",
      "the 0.55075464884\n",
      "retained 0.171044524436\n",
      "yearend 0.170602723443\n",
      "gills 0.155525676624\n",
      "nationalism 0.153929979113\n",
      "\n",
      "Likely words next to \"academy\":\n",
      "awards 0.483823646548\n",
      "of 0.319674694827\n",
      "fusion 0.167788028739\n",
      "purposes 0.162761848232\n",
      "discretion 0.160095686802\n",
      "\n",
      "Likely words next to \"argued\":\n",
      "that 0.882071931377\n",
      "hanson 0.196121308755\n",
      "bonds 0.173961963386\n",
      "behaves 0.167207538577\n",
      "morocco 0.160188908936\n",
      "\n",
      "Likely words next to \"give\":\n",
      "the 0.273766341149\n",
      "up 0.186127414351\n",
      "pair 0.172831825054\n",
      "venting 0.17098575083\n",
      "meaningless 0.169791329506\n",
      "\n",
      "Likely words next to \"each\":\n",
      "other 0.456362070757\n",
      "of 0.28614683538\n",
      "concerns 0.173493371328\n",
      "contradictory 0.165255655526\n",
      "limbs 0.156787903135\n",
      "\n",
      "Likely words next to \"smallest\":\n",
      "amphibian 0.239718738765\n",
      "distributed 0.178837771669\n",
      "reconstructed 0.170500166705\n",
      "alkali 0.156669330731\n",
      "santa 0.155726105414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_list = ['king','abraham','of','academy','argued','give','each','smallest']\n",
    "\n",
    "for word in word_list:\n",
    "    print('Likely words next to \"%s\":' % word)\n",
    "    model.get_order_completions(word, position=1)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a more accurate way to find preceding and subsequent words - we simply look for order vectors that tend to encode the target word in particular positions.(It's helpful to consider why this is more accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase completion for promoted __ rights\n",
      "womens 0.262810141569\n",
      "voting 0.262042164951\n",
      "lacked 0.171768277508\n",
      "nothing 0.168861043148\n",
      "rounded 0.167518179177\n",
      "\n",
      "Phrase completion for which lincoln promoted __ rights for\n",
      "voting 0.278843281101\n",
      "asks 0.249397675761\n",
      "descriptive 0.24782792937\n",
      "desperate 0.240031331288\n",
      "warrants 0.234872507407\n",
      "\n",
      "Phrase completion for president __\n",
      "abdelaziz 0.434404086616\n",
      "sali 0.407114279307\n",
      "barack 0.401388428771\n",
      "stephens 0.378002219932\n",
      "nicolas 0.347773673543\n",
      "\n",
      "Phrase completion for  __ civil war\n",
      "horrific 0.459219754447\n",
      "spanish 0.247091510776\n",
      "condemning 0.224804799034\n",
      "devastating 0.217499235849\n",
      "aversion 0.209073883859\n",
      "\n",
      "Phrase completion for aristotle held more __ theories\n",
      "accurate 0.408222379894\n",
      "recently 0.341959338532\n",
      "than 0.330895569306\n",
      "efficient 0.307709706472\n",
      "complex 0.30739589076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "phrase_list = [ 'promoted __ rights', 'which lincoln promoted __ rights for', 'president __', \n",
    "               ' __ civil war', 'aristotle held more __ theories']\n",
    "\n",
    "for phrase in phrase_list:\n",
    "    print('Phrase completion for %s' % phrase)\n",
    "    model.get_resonants(phrase)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntax Encoding\n",
    "\n",
    "It is possible to extend the methods used for encoding order information to encode information about the syntactic structure of the sentences a word typically occurs in. We'll use dependency structures to model this information, primarily because they are simpler than constituency structures and thus easier to encode in vectors with a limited capacity for storing structured information (all the usual facts about HRR capacity apply here). Instead of encoding words to the left or right of a target word, we'll encode words that occur as parents or children of a target word in a dependency tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://taweb.aichi-u.ac.jp/tmgross/pix/PSG-DG.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"http://taweb.aichi-u.ac.jp/tmgross/pix/PSG-DG.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting vectors can be used to query a target word for words that are commonly linked to it by a given dependency relation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time:  21.879013061523438\n"
     ]
    }
   ],
   "source": [
    "model.train(dim=dim, wordlist=wiki.vocab, flags=['syntax'], batchsize=100)\n",
    "print('Computation time: ', model.runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common nsubj for \"notice\":\n",
      "parents 0.534678252456\n",
      "one 0.489546129555\n",
      "broadcasting 0.170170041982\n",
      "elder 0.157420893005\n",
      "tried 0.155045247614\n",
      "\n",
      "Common nsubj for \"give\":\n",
      "he 0.19300148185\n",
      "which 0.192824225911\n",
      "forces 0.187580831608\n",
      "none 0.185935319357\n",
      "yuryevets 0.178073951621\n",
      "\n",
      "Common nsubj for \"emphasized\":\n",
      "he 0.31377949721\n",
      "douglas 0.311736258305\n",
      "change 0.29532005205\n",
      "anthropology 0.278888407662\n",
      "historians 0.266938271992\n",
      "\n",
      "Common nsubj for \"presented\":\n",
      "aruba 0.371237062549\n",
      "they 0.230624238136\n",
      "statuettes 0.214007281377\n",
      "rand 0.20840321304\n",
      "idealism 0.203376587666\n",
      "\n",
      "Common nsubj for \"invited\":\n",
      "leaders 0.282923280864\n",
      "legislature 0.24892190193\n",
      "they 0.242622722039\n",
      "massoud 0.237031806475\n",
      "government 0.225154786406\n",
      "\n",
      "Common nsubj for \"appeals\":\n",
      "who 0.426105574645\n",
      "defendant 0.410865369367\n",
      "party 0.371509988426\n",
      "dagny 0.167833555625\n",
      "staterun 0.163422007327\n",
      "\n",
      "Common dobj for \"notice\":\n",
      "colors 0.511212477806\n",
      "signs 0.473584516216\n",
      "kinship 0.203159554886\n",
      "forts 0.17947452356\n",
      "teaching 0.1691675435\n",
      "\n",
      "Common dobj for \"give\":\n",
      "name 0.394793414302\n",
      "rise 0.259344078632\n",
      "thanks 0.251893119498\n",
      "birth 0.230810179141\n",
      "thought 0.209915591702\n",
      "\n",
      "Common dobj for \"emphasized\":\n",
      "aspects 0.296877534042\n",
      "shock 0.273741635383\n",
      "rights 0.252949839892\n",
      "opposition 0.23681315918\n",
      "independence 0.232428970936\n",
      "\n",
      "Common dobj for \"presented\":\n",
      "theory 0.362145583899\n",
      "meaning 0.276628672898\n",
      "hazard 0.264994363397\n",
      "mutualism 0.246344007618\n",
      "figures 0.209600418378\n",
      "\n",
      "Common dobj for \"invited\":\n",
      "departments 0.29665465581\n",
      "lincoln 0.290398169777\n",
      "huxley 0.257282612623\n",
      "einstein 0.256031834767\n",
      "leaders 0.249485575439\n",
      "\n",
      "Common dobj for \"appeals\":\n",
      "conviction 0.477775481361\n",
      "it 0.460688773142\n",
      "scotland 0.169792399161\n",
      "guineabissau 0.159570600199\n",
      "refusal 0.154943157933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_list = ['notice','give','emphasized','presented','invited','appeals']\n",
    "\n",
    "for word in word_list:\n",
    "    print('Common nsubj for \"%s\":' % word)\n",
    "    model.get_verb_completions(word, 'nsubj')\n",
    "    print('')\n",
    "\n",
    "for word in word_list:\n",
    "    print('Common dobj for \"%s\":' % word)\n",
    "    model.get_verb_completions(word, 'dobj')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likely counterparts to \"notice\":\n",
      "notice 1.0\n",
      "class 0.363665562229\n",
      "grazed 0.35715918596\n",
      "remembers 0.355812480473\n",
      "touched 0.341009433454\n",
      "\n",
      "Likely counterparts to \"give\":\n",
      "give 1.0\n",
      "gave 0.40778233999\n",
      "recalled 0.307071259807\n",
      "fought 0.293124204471\n",
      "giving 0.280921546521\n",
      "\n",
      "Likely counterparts to \"emphasized\":\n",
      "emphasized 1.0\n",
      "preserved 0.38192874388\n",
      "adhered 0.335296547149\n",
      "stated 0.33081216497\n",
      "said 0.327748539451\n",
      "\n",
      "Likely counterparts to \"presented\":\n",
      "presented 1.0\n",
      "extinguishing 0.280717568308\n",
      "influenced 0.278342177993\n",
      "gather 0.275606504481\n",
      "reveal 0.258146316738\n",
      "\n",
      "Likely counterparts to \"invited\":\n",
      "invited 1.0\n",
      "inviting 0.298846385815\n",
      "perish 0.28797554879\n",
      "eat 0.244524503383\n",
      "invested 0.242880905063\n",
      "\n",
      "Likely counterparts to \"appeals\":\n",
      "appeals 1.0\n",
      "grabbing 0.535491293784\n",
      "grasping 0.463539748069\n",
      "mounted 0.463539748069\n",
      "narrow 0.463539748069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in word_list:\n",
    "    print('Likely counterparts to \"%s\":' % word)\n",
    "    model.get_verb_neighbors(word)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using Learned SPs in a Nengo Model\n",
    "\n",
    "When using the SPA system, we often specify vocabularies that contain various semantic pointers that the components in a SPA model then become aware of. Because we can specify the elements in these vocabularies directly, we can use the vectors we just learned from wikipedia to produce vocabularies that possess SPs with interesting semantic properties. This is a nice alterative to using the default, random SPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nengo\n",
    "import nengo.spa as spa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "words = ['go','abraham','was','a','the','to','race','politician','agreement','also','test','walked','chase','related',\n",
    "        'ants','alone','heidegger','light','water','disorders','resumed','refuse','anger','just','help','trade','court',\n",
    "        'commonly','lincoln','moment','wine','hamlet','aardvark','differently','materials','occurring','surface',\n",
    "        'phrase','car','dirt','at','trust','brain','physiology','house','martin','womens','voting','accurate']\n",
    "\n",
    "context_vocab = spa.Vocabulary(dim)\n",
    "order_vocab = spa.Vocabulary(dim)\n",
    "syntax_vocab = spa.Vocabulary(dim)\n",
    "\n",
    "for word in words:\n",
    "    context_vocab.add(word.upper(), model.context_vectors[model.word_to_index[word], :])\n",
    "    order_vocab.add(word.upper(), model.order_vectors[model.word_to_index[word], :])\n",
    "    syntax_vocab.add(word.upper(), model.syntax_vectors[model.word_to_index[word], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As an initial illustration, we can build a simple SPA model that estimates how related two words are. This takes just a few lines of code to implement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation finished in 0:00:33.                                                                                                                                                                             \n"
     ]
    }
   ],
   "source": [
    "def first_word(t):\n",
    "    return 'AARDVARK'\n",
    "\n",
    "def second_word(t):\n",
    "    return 'ANTS'\n",
    "    \n",
    "with spa.SPA() as simple_model:\n",
    "    simple_model.word_1 = spa.State(dimensions=dim, vocab=context_vocab)\n",
    "    simple_model.word_2 = spa.State(dimensions=dim, vocab=context_vocab)\n",
    "    simple_model.relate = spa.Compare(dimensions=dim, vocab=context_vocab)\n",
    "    \n",
    "    nengo.Connection(simple_model.word_1.output, simple_model.relate.inputA)\n",
    "    nengo.Connection(simple_model.word_2.output, simple_model.relate.inputB)\n",
    "    \n",
    "    simple_model.inputs = spa.Input(word_1=first_word, word_2=second_word)\n",
    "    \n",
    "    word_1_probe = nengo.Probe(simple_model.word_1.output, synapse=0.03)\n",
    "    word_2_probe = nengo.Probe(simple_model.word_2.output, synapse=0.03)\n",
    "    relate_probe = nengo.Probe(simple_model.relate.output, synapse=0.1)\n",
    "\n",
    "sim = nengo.Simulator(simple_model)\n",
    "sim.run(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotting_vocab = context_vocab.create_subset(['AARDVARK','ANTS','HOUSE','TEST','PHRASE','CAR','DIRT'])\n",
    "\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "n = 3\n",
    "p1 = fig.add_subplot(n,1,1)\n",
    "p1.plot(sim.trange(), simple_model.similarity(sim.data, word_1_probe, vocab=plotting_vocab))\n",
    "p1.legend(plotting_vocab.keys, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=8)\n",
    "p1.set_ylabel('First Word', fontsize=14)\n",
    "\n",
    "p2 = fig.add_subplot(n,1,2)\n",
    "p2.plot(sim.trange(), simple_model.similarity(sim.data, word_2_probe, vocab=plotting_vocab))\n",
    "p2.legend(plotting_vocab.keys, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=8)\n",
    "p2.set_ylabel('Second Word', fontsize=14)\n",
    "\n",
    "p3 = fig.add_subplot(n,1,3)\n",
    "p3.plot(sim.trange(), sim.data[relate_probe])\n",
    "p3.set_ylabel('Word Relatedness', fontsize=14)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how well this nengo model is measuring the relatedness of these two terms by showing the true dot product of the underlying vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.get_nearest('aardvark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a slightly more complicated model, let's build a network that predicts the next word given some sequence of words. To do so, we'll match vectors that encode a sequence of n words to the vectors corresponding to the next word using an associative memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order_vocab.add('TEST_PHRASE_1', model.get_vector_encoding('promoted __ rights'))\n",
    "order_vocab.add('TEST_PHRASE_2', model.get_vector_encoding( 'which lincoln promoted __ rights for'))\n",
    "order_vocab.add('TEST_PHRASE_3', model.get_vector_encoding('aristotle held more __ theories'))\n",
    "\n",
    "uppercase_words = [w.upper() for w in words]\n",
    "\n",
    "def built_phrase(t):\n",
    "    if t < 0.35:\n",
    "        return 'TEST_PHRASE_1'\n",
    "    elif 0.45 < t < 0.7:\n",
    "        return 'TEST_PHRASE_2'\n",
    "    elif 0.75 < t:\n",
    "        return 'TEST_PHRASE_3'\n",
    "    else:\n",
    "        return '0'\n",
    "    \n",
    "with spa.SPA() as ngram_model:\n",
    "    ngram_model.ngram = spa.State(dimensions=dim, vocab=order_vocab)\n",
    "    ngram_model.match = spa.AssociativeMemory(order_vocab, input_keys=uppercase_words, output_keys=uppercase_words,\n",
    "                                              threshold=0.2)\n",
    "    \n",
    "    nengo.Connection(ngram_model.ngram.output, ngram_model.match.input)\n",
    "    \n",
    "    ngram_model.input = spa.Input(ngram=built_phrase)\n",
    "    \n",
    "    ngram_probe = nengo.Probe(ngram_model.ngram.output, synapse=0.03)\n",
    "    match_probe = nengo.Probe(ngram_model.match.output, synapse=0.1)\n",
    "    \n",
    "sim = nengo.Simulator(ngram_model)\n",
    "sim.run(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,8))\n",
    "p1 = fig.add_subplot(2,1,1)\n",
    "p1.plot(sim.trange(), simple_model.similarity(sim.data, ngram_probe, vocab=order_vocab))\n",
    "p1.legend(words, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=12)\n",
    "p1.set_ylabel('Phrase', fontsize=14)\n",
    "\n",
    "p2 = fig.add_subplot(2,1,2)\n",
    "p2.plot(sim.trange(), simple_model.similarity(sim.data, match_probe, vocab=order_vocab))\n",
    "p2.legend(words, fontsize='medium', bbox_to_anchor=(1, -0.15), ncol=12)\n",
    "p2.set_ylabel('Predicted Word', fontsize=14)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
