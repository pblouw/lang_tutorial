<doc id="2216" url="http://en.wikipedia.org/wiki?curid=2216" title="Abu Sayyaf">
Abu Sayyaf

Abu Sayyaf (   ;[] Arabic: جماعة أبو سياف‎; Jamāʿah Abū Sayyāf, ASG, Filipino: "Grupong Abu Sayyaf") is a militant Islamist group based in and around Jolo and Basilan islands in the southwestern part of the Philippines, where for more than four decades, Moro groups have been engaged in an insurgency for an independent province in the country. The group is considered very violent, and was responsible for the Philippines' worst terrorist attack, the bombing of Superferry 14 in 2004, which killed 116 people.
The name of the group is derived from the Arabic ابو, "abu" ("father of") and "sayyaf" ("swordsmith"). As of 2012, the group was estimated to have between 200 and 400 members, down from 1250 in 2000. They use mostly improvised explosive devices, mortars, and automatic rifles.
Since its inception in 1991, the group has carried out bombings, kidnappings, assassinations, and extortion 
in what they describe as their fight for an independent Islamic province in the Philippines, They have also been involved in criminal activities, including kidnapping, rape, child sexual assault, drive-by shootings, extortion, and drug trafficking,
and the goals of the group "appear to have vacillated over time between criminal objectives and a more ideological intent".
The group has been designated as a terrorist organization by the United Nations, Australia, Canada, the UAE, the United Kingdom and the United States. In 2002, fighting Abu Sayyaf became a mission of the American military's Operation Enduring Freedom and part of the Global War on Terrorism. Several hundred United States soldiers are also stationed in the area to mainly train local forces in counter terror and counter guerrilla operations, but as a status of forces agreement and under Philippine law are not allowed to engage in direct combat.
The group was founded by Abdurajik Abubakar Janjalani, and led after his death in 1998 by his younger brother Khadaffy Janjalani wjho was killed in 2007. 
On July 23, 2014, Abu Sayyaf leader Isnilon Totoni Hapilon swore an oath of loyalty to Abu Bakr al-Baghdadi, the leader of ISIL. In September 2014, the group began kidnapping people to ransom, in the name of ISIL.
History.
In the early 1970s, the Moro National Liberation Front (M.N.L.F.) was the main Muslim rebel groups fighting in Basilan and Mindanao in the southern Philippines.
Abdurajik Abubakar Janjalani, the older brother of Khadaffy Janjalani, had been a teacher from Basilan, who later studied Islamic theology and Arabic in Libya, Syria and Saudi Arabia during the 1980s. Abdurajik then went to Afghanistan to fight against the Soviet Union and the Afghan government during the Soviet war in Afghanistan in the 1980s. During that period, he is alleged to have met Osama Bin Laden and been given $6 million to establish a more Islamic group with the M.N.L.F. in the southern Philippines, made up of members of the extant M.N.L.F.
By then, as a political solution in the southern Philippines, ARMM had been established in 1989.
Both Abdurajik Abubakar and his younger brother who succeeded him were natives of Isabela City, currently one of the poorest cities of the Philippines. Located on the North-Western part of the island of Basilan, Isabela is also the capital of Basilan province, across the Isabela Channel from the Malamwi Island. But Isabela City is administered under the Zamboanga Peninsula political region north of the island of Basilan, while the rest of the island province of Basilan is now (since 1996) governed as part of the Autonomous Region in Muslim Mindanao (ARMM) to the east.
Abdurajik Abubakar Janjalani leadership (1989–1998).
M.N.L.F. had moderated into an established political government, the ARMM. It was established in 1989, fully institutionalized by 1996 and which eventually became the ruling government in southern Mindanao.
When Abdurajik Abubakar Janjalani returned home to Basilan island in 1990, he gathered radical members of the old M.N.L.F. who wanted to resume armed struggle for an independent Islamic state and in 1991 established the Abu Sayyaf.
Janjalani was provided some funding by a Saudi Islamist, Mohammed Jamal Khalifa, who came to the Philippines in 1987 or 1988 and was head of the Philippine branch of the International Islamic Relief Organization foundation. A defector from Abu Sayyaf told Filipino authorities, "The IIRO was behind the construction of Mosques, school buildings and other livelihood projects" but only "in areas penetrated, highly influenced and controlled by the Abu Sayyaf." According to the defector "Only 10 to 30% of the foreign funding goes to the legitimate relief and livelihood projects and the rest go to terrorist operations." 
Khalifa had married a local woman, Alice "Jameelah" Yabo,
By 1995 Abu Sayyaf was active in large scale bombings and attacks in the Philippines. The Abu Sayyaf's first attack was the assault on the town of Ipil in Mindanao in April 1995. This year also marked the escape of 20 year old Khadaffy Janjalani from Camp Crame in Manila along with another member named Jovenal Bruno.
On December 18, 1998, Abdurajik Abubakar Janjalani was killed in a gun battle with the Philippine National Police on Basilan Island. He is thought to have been about age 39 at the time of his death. The death of Aburajik Abubakar Janjalani marked a turning point in Abu Sayyaf operations, shifting from its ideological focus to more general kidnappings, murders and robberies, as the younger brother Khadaffy Janjalani succeeded Abdurajak.
Consequently, being on the social or political division line, Basilan, Jolo and Sulu have seen some of the fiercest fighting between government troops and the Muslim separatist group Abu Sayyaf through the early 1990s. The Abu Sayyaf primarily operates in the southern Philippines with members traveling to Manila and other provinces in the country. It was reported that Abu Sayyaf had begun expanding into neighbouring Malaysia and Indonesia by the early 1990s.
The Abu Sayyaf is one of the smallest, but strongest of the Islamist separatist groups in the Philippines. Some Abu Sayyaf members have studied or worked in Saudi Arabia and developed ties to mujahadeen while fighting and training in the war against the Soviet invasion of Afghanistan. Abu Sayyaf proclaimed themselves as mujahideen and freedom fighters but are not supported by many people in the Philippines including its Muslim clerics.
Khadaffy Janjalani leadership (1999–2007).
Until his death in a gunbattle on September 4, 2006, Khaddafy Janjalani was considered the nominal leader of the group by the Armed Forces of the Philippines.
The 23 year-old Khadaffy Janjalani then took leadership of one of Abu Sayyaf's factions in an internecine struggle. He then worked to consolidate his leadership of the Abu Sayyaf, causing the group to appear inactive for a period. After Janjalani's leadership was secured, the Abu Sayyaf began a new strategy, as they proceeded to take hostages.
The group's motive for kidnapping became more financial than religious during the period of Khadaffy's leadership, according to locals in the areas associated with Abu Sayyaf. The hostage money is probably the method of financing of the group.
The group expanded its operations to Malaysia in 2000 when it abducted foreigners from two resorts. This action was condemned by most leaders in the Islamic world.
It was also responsible for the kidnapping and murder of more than 30 foreigners and Christian clerics and workers, including Martin and Gracia Burnham.
A commander named Abu Sabaya was killed in 2002 while trying to evade forces.
Galib Andang, one of the leaders of the group, was captured in Sulu in December 2003.
An explosion at a military base in Jolo on February 18, 2006 was blamed on Abu Sayyaf by Brig. General Alexander Aleo, an Army officer.
Khadaffy Janjalani was indicted in the United States District Court for the District of Columbia for his alleged involvement in terrorist attacks, including hostage taking by Abu Sayyaf and murder, against United States nationals and other foreign nationals in and around the Republic of the Philippines.
Consequently on February 24, 2006, Janjalani was among six fugitives in the second and most recent group of indicted fugitives to be added to the FBI Most Wanted Terrorists list along with two fellow members of the Abu Sayyaf, including Isnilon Totoni Hapilon and Jainal Antel Sali, Jr.
On December 13, 2006, it was reported that Abu Sayyaf members may have been planning attacks during the ASEAN summit in the Philippines. The group was reported to have been training alongside Jemaah Islamiyah militants. The plot was reported to have involved detonating a car bomb in Cebu City where the summit was scheduled to take place.
On December 27, 2006, the Philippine military reported that Janjalani's remains had been recovered near Patikul, in Jolo in the southern Philippines and that DNA tests had been ordered to confirm the discovery. He was allegedly shot in the neck in an encounter with government troops on September on Luba Hills, Patikul town in Sulu.
Present time (2010-2014).
In a video published in the summer of 2014, senior Abu Sayyaf leader Isnilon Hapilon and other masked men swear their allegiance or “bay'ah” to the "Islamic State" (ISIS) caliph. “We pledge to obey him on anything which our hearts desire or not and to value him more than anyone else. We will not take any emir (leader) other than him unless we see in him any obvious act of disbelief that could be questioned by Allah in the hereafter.” For many years prior to this Islamic State's competitor, Al Qaeda, had the support of Abu Sayyaf "through various connections." 
Observers were skeptical of whether the pledge would lead to Abu Sayyaf becoming an ISIS outpost in Southeast Asia, or was simply a way for the group to taking advantage of the international publicity Islamic State is getting.
Motivation, beliefs, targets.
Filipino Islamist guerillas such as Abu Sayyaf, have been described as “rooted in a distinct class made up of closely knit networks built through marriage of important families through socioeconomic backgrounds and family structures," according to Michael Buehler, a lecturer in comparative politics at the University of London’s School of Oriental and African Studies. This tight-knit, familial structure provides resilience but also limits their ability to expand. The commander of the Philippines military’s Western Mindanao Command Lieutenant General Rustico Guerrero, also describes Abu Sayyaf as "a local group with a local agenda."
Two kidnapping victims, (Martin and Gracia Burnham) who were kept in captivity by ASG for over a year, "gently engaged their captors in theological discussion" and found Abu Sayyaf fighters to be unfamiliar with the Qur'an. They had only "a sketchy" notion of Islam, which they saw as "a set of behavioral rules, to be violated when it suited them", according to author Mark Bowden. As "holy warriors, they were justified in kidnapping, killing and stealing. Having sex with women captives was justified by their claiming them as "wives".
Unlike the Moro Islamic Liberation Front or Moro National Liberation Front, the group is not recognized by the Organisation of Islamic Cooperation, and according to author Robert East, was seen as "nothing more than a criminal operation" at least prior to 2001.
A Center for Strategic and International Studies report by Jack Fellman notes the political rather than religious motivation of ASG. He quotes ASG leader Khadaffy Janjalain's statement that his brother (the former leader of ASG) was right to split from the more moderate NMLF because "up to now, nothing came out" of attempts to gain more autonomy for Moro Muslims. This suggests, Fellman believes, that ASG "is merely the latest, albeit most violent, iteration of Moro political dissatisfaction that has existed for the last several decades."
Targets.
Most of the Abu Sayyaf victims have been Filipinos. However, non-Filipinos have also been taken hostage for large ransom payment demands. Westerners, especially Americans, have been targeted for political and racial reasons.
In 1993, Abu Sayyaf kidnapped an American Bible translator in the southern Philippines. In 2000, Abu Sayyaf captured an American Muslim visiting Jolo and demanded that the United States release Sheikh Omar Abdel Rahman and Ramzi Yousef, who were jailed for their involvement in the World Trade Center bombing of 1993.
A spokesman for the Abu Sayyaf has stated that, "We have been trying hard to get an American because they may think we are afraid of them." He added, "We want to fight the American people."
British, Canadian, Australian, French, and German tourists have been kidnapped as well.
Crimes.
Kidnappings.
2000 Sipadan kidnappings.
On May 3, 2000, Abu Sayyaf guerillas occupied the Malaysian dive resort island Sipadan and took 21 hostages, including 10 tourists and 11 resort workers – 19 non-Filipino nationals in total. The hostages were taken to an Abu Sayyaf base in Jolo, Sulu.
Two Muslim Malaysians were released soon after, however Abu Sayyaf made various demands for the release of several prisoners, including 1993 World Trade Center bomber Ramzi Yousef and $2.4 million. In July, a Filipino television evangelist and 12 of his crew offered their help and went as mediators for the relief of other hostages. They, three French television crew members and a German journalist, all visiting Abu Sayyaf on Jolo, were also taken hostage. Most hostages were released in August and September 2000, partly due to mediation by Libyan leader Muammar Gaddafi and an offer of $25 million in "development aid".
Abu Sayyaf conducted a second raid on the island of Pandanan near Sipadan on September 10 and seized three more Malaysians. The Philippine army launched a major offensive on September 16, 2000, rescuing all remaining hostages, except Filipino dive instructor Roland Ullah. He was eventually freed in 2003.
Abu Sayyaf coordinated with the Chinese 14K Triad gang in carrying out the kidnappings. The 14K Triad has militarily supported Abu Sayyaf.
Jeffrey Schilling.
Jeffrey Schilling, an American citizen and Muslim convert, was held by Abu Sayyaf for 8 months after being captured while visiting a terrorist camp with his wife, Ivy Osani. Abu Sayyaf demanded a $10 million ransom for his release, but Schilling escaped after more than 7 months and was picked up by the Philippine Marine Corps on April 12, 2001.
Many commentators have been critical of Schilling, who had reportedly walked into the camp. Schilling claims to have been invited by his wife's distant cousin who was a member of Abu Sayyaf.
Martin and Gracia Burnham.
On May 27, 2001, an Abu Sayyaf raid kidnapped about 20 people from Dos Palmas, an expensive resort in Honda Bay, to the north of Puerto Princesa City on the island of Palawan, which had been "considered completely safe". The most "valuable" of the hostages were three North Americans, Martin and Gracia Burnham, a missionary couple, and Guillermo Sobero, a Peruvian-American tourist who was later beheaded by Abu Sayyaf, for whom Abu Sayyaf demanded $1 million in ransom. The hostages and hostage-takers then returned hundreds of kilometres back across the Sulu Sea to the Abu Sayyaf's territories in Mindanao.
According to author Mark Bowden, the leader of the raid was Abu Sabaya. According to Gracia Burnham, she told her husband "to identify his kidnappers" to authorities "as 'the Osama bin Laden Group,' but Burnham was unfamiliar with that name and stuck with" Abu Sayyaf. After returning to Mindanao, Abu Sayyaf operatives conducted numerous raids, "including one at a coconut plantation called Golden Harvest; they took about 15 people captive there and later used bolo knives to hack the heads off two men. The number of hostages waxed and waned as some were ransomed and released, new ones were taken and others were killed."
On June 7, 2002, about a year after the raid, Philippine army troops conducted a rescue operation in which two of the three hostages held, Martin Burnham and Filipino nurse, Ediborah Yap, were killed. The remaining hostage was wounded and the hostage takers escaped.
In July 2004, Gracia Burnham testified at a trial of eight Abu Sayyaf members and identified six of the suspects as being her erstwhile captors, including Alhamzer Limbong, Abdul Azan Diamla, Abu Khari Moctar, Bas Ishmael, Alzen Jandul, and Dazid Baize.
"The eight suspects sat silently during her three-hour testimony, separated from her by a wooden grill. They face the death sentence if found guilty of kidnapping for ransom. The trial began this year and is not expected to end for several months."
Alhamzer Limbong was later killed in a prison uprising.
Gracia Burnham has claimed that Philippine military officials were colluding with her captors, saying that the Armed Forces of the Philippines "didn't pursue us...As time went on, we noticed that they never pursued us".
Journalists abducted since 2000.
ABS-CBN's "Newsbreak" reported that Abu Sayyaf abducted at least 20 journalists since 2000 (mostly foreign journalists) and all of them were eventually released upon payment of ransom.
Ces Drilon and cameramen Jimmy Encarnacion and Angelo Valderama were the latest of its kidnap victims. The journalists held captive were
2009 Red Cross kidnapping.
On January 15, 2009, Abu Sayyaf kidnapped International Committee of the Red Cross (ICRC) volunteers in Patikul, Sulu province, Philippines. The three ICRC workers had finished conducting field work in Sulu province, located in the southwest of the country, when they were abducted by an unknown group, later confirmed as Abu Sayyaf leader Albader Parad's group. Parad himself was said to be involved in the kidnapping. All three workers were eventually released. According to a CNN story, Parad was reportedly killed, along with five other militants, in an assault raid by Philippine marines in Sulu province on Sunday, February 21, 2010.
Warren Rodwell.
Warren Richard Rodwell (born June 16, 1958 Homebush NSW) a former soldier in the Australian Army, and university English teacher, grew up in Tamworth NSW He was shot through the right hand when seized from his home at Ipil, Zamboanga Sibugay on the island of Mindanao in the southern Philippines on December 5, 2011 by Abu Sayyaf (ASG) militants. Rodwell later had to have a finger amputated.
The ASG threatened to behead Rodwell if the original ransom demand for $US2 million was not paid. Both the Philippine and Australian governments had strict policies of refusing to pay ransoms. Australia formed a multi-agency task force to assist the Philippine authorities, and liaise with Rodwell's family. A news blackout was imposed. Filipino politicians helped negotiate the release. After the payment of $AUD94,000 for "board and lodging" expenses by his siblings, Rodwell was released 472 days later on March 23, 2013. The incumbent Australian prime minister praised the Philippines government for securing Rodwell's release. Tribute was also made to Australian officials from the Department of Foreign Affairs, the Australian Federal Police and Defence. Rodwell subsequently returned to Australia.
As part of the 2015 Australia Day Honours, Australian Army Lieutenant Colonel Paul Joseph Barta was awarded the Conspicuous Service Cross (CSC) for outstanding devotion to duty as the Assistant Defence Attaché Manila during the Australian whole of government response to the Rodwell kidnap for ransom "(and immediately following, the devastation of Typhoon Haiyan)." At the 2015 Australian Federal Police Foundation Day award ceremony in Canberra, fourteen AFP members received the Commissioners’ Group Citation for Conspicuous Conduct for their work in support of the Philippine National Police and Australian Government efforts to release Australian man Warren Rodwell.
By the end of his 15 months as a hostage in the Autonomous Region in Muslim Mindanao, Rodwell had lost about 30 kilograms in weight due to starvation, His biography "472 Days Captive of the Abu Sayyaf - The Survival of Australian Warren Rodwell" by independent researcher Dr Robert (Bob) East was published by Cambridge Scholars Publishing, United Kingdom (2015) ISBN 1-4438-7058-7 
In January 2015, Mindanao Examiner newspaper reported the arrest of Barahama Ali kidnap gang sub-leaders linked to the kidnapping of Warren Rodwell, who was seized by at least 5 gunmen (disguised as policemen), and eventually handed over or sold by the kidnappers to the Abu Sayyaf in Basilan province.
In May 2015, ex-Philippine National Police (PNP) officer Jun A. Malban was arrested in Kota Kinabalu Malaysia for the crime of "Kidnapping for Ransom" after Rodwell identified him as the negotiator/spokesperson of the Abu Sayyaf Group during his captivity. Further PNP investigation revealed that Malban is the cousin of Abu Sayyaf leaders Khair Mundos and Borhan Mundos. The director of the Anti-Kidnapping Group (AKG) stated that Malban's arrest resulted from close coordination by the PNP, National Bureau of Investigation (Philippines) and Presidential Anti-Organized Crime Commission with the Malaysian counterparts and through Interpol.
2013 Pom Pom kidnappings.
On November 15, 2013, Abu Sayyaf militants raided a resort on a Malaysian island of Pom Pom in Semporna, Sabah. During the ambush, Taiwanese citizen Chang An-wei was kidnapped and her husband, Hsu Li-min, was killed. Chang was taken to the Sulu Archipelago in the southern Philippines. Gene Yu, an American and former US Army Special Forces captain was instrumental in negotiating, locating and working to free Taiwanese citizen Chang An-wei from Abu Sayyaf militants with Filipino special forces and private security contractors in 2013. Chang was freed in Sulu Province and returned to Taiwan on December 21.
2014 Singamata resort, Baik Island and Kampung Air Sapang fish farm kidnappings.
On April 2, 2014, a group believed to originate from Abu Sayyaf militants raided a resort off Semporna, Sabah. During the raid, Gao Huayun, a Chinese tourist from Shanghai and Marcy Dayawan, a Filipino resort worker who was on the resort were kidnapped and taken to the Sulu Archipelago. The two hostages were later rescued after a collaboration between the Malaysian and the Philippines security forces.
On May 6, 2014, a group comprising five Abu Sayyaf gunmen raided a Malaysian fish farm in Baik Island, Sabah and kidnapped the fish farm manager, after which the hostage was brought to Jolo island. He was later freed on July with the help of Malaysian negotiators.
On June 16, 2014, two gunmen believed to be from the Abu Sayyaf group kidnapped another Chinese fish farm manager and one Filipino in Kampung Air Sapang, Kunak, Sabah. One of the kidnap victims, a Filipino fish farm worker, managed to escape and went missing. Meanwhile the fish farm manager was taken to Jolo.
The Malaysian authorities have identified five Filipinos, the "Muktadir brothers", as behind all of the kidnapping cases. They then sell their hostages to the Abu Sayyaf group.
Superferry 14 Bombing.
Superferry 14 was a large ferry destroyed by a bomb on February 27, 2004, killing 116 people in the Philippines' worst terrorist attack and the world's deadliest terrorist attack at sea.
On that day, the 10,192 ton ferry sailed out of Manila with about 900 passengers and crew on board. A television set filled with 8 lb. (4 kilograms) of TNT had been placed on board. 90 minutes out of port, the bomb exploded. 63 people were killed instantly and 53 went missing and presumed dead.
Despite claims from terrorist groups, the blast was initially thought to have been an accident caused by a gas explosion. However, after divers righted the ferry five months after it had sunk, they found evidence of a bomb blast. A man called Redendo Cain Dellosa also admitted to planting the bomb on board for Abu Sayyaf.
Philippine president Gloria Macapagal-Arroyo announced on October 11, 2004 that investigators had concluded the explosion was caused by a bomb. She said six suspects had been arrested in connection with the bombing and that the masterminds, Khadaffy Janjalani and Abu Sulaiman, have been killed. But the ASG continues to pose a threat to Philippine security.
Supporters and funding.
Abdurajik Abubakar Janjalani’s first recruits were soldiers of the Moro National Liberation Front (M.N.L.F.) and the Moro Islamic Liberation Front (M.I.L.F.). However, the M.I.L.F. and M.N.L.F. deny having links with Abu Sayyaf. Both officially distance themselves from Abu Sayyaf because of its attacks on civilians and its supposed profiteering. The Philippine military, however, has claimed that elements of both groups provide support to the Abu Sayyaf.
The group was originally not thought to receive funding from outside sources, but intelligence reports from the United States, Indonesia and Australia have found intermittent ties to the Indonesian Jemaah Islamiyah terrorist group, and the Philippine government considers the Abu Sayyaf as a part of Jemaah Islamiyah. The government also notes that initial funding for ASG in the 1990s came from al-Qaeda through the brother-in-law of Osama bin Laden, Mohammed Jamal Khalifa, through Islamic charities in the region.
Al-Qaeda-affiliated terrorist Ramzi Yousef operated in the Philippines in the mid-1990s and trained Abu Sayyaf soldiers. The 2002 edition of the United State Department’s Patterns of Global Terrorism mention links to Al-Qaeda.
Continuing ties to Islamist groups in the Middle East indicate that al-Qaeda may be continuing support.
As of mid 2005, Jemaah Islamiyah personnel reportedly had trained about 60 Abu Sayyarf cadre in bomb assembling and detonations.
Funding.
The group obtains most of its financing through ransom and extortion. One report estimated its revenues from ransom payments in 2000 alone between $10 and $25 million. According to the State Department, it may also receive funding from radical Islamic benefactors in the Middle East and South Asia.
It was reported that Libya facilitated ransom payments to Abu Sayyaf. Libya was also suggested that Libyan money could possibly be channeled to Abu Sayyaf.
Russian intelligence agencies connected with Victor Bout's planes have reportedly provided Abu Sayyaf with arms.
Military action against.
The military has intensified its intelligence operation against the Abu Sayyaf following the arrest of a Filipino-American allegedly selling illegal weapons to the Al-Qaeda linked group. Security forces have arrested Victor Moore Infante in Zamboanga for selling weapons to the extremist group. The 34-year-old man was tagged by authorities as "one of the United States most wanted fugitives."
His arrest was made secret and announced by the Bureau of Immigration and Deportation. Infante, who was reported to have traveled to Basilan, a stronghold of the Abu Sayyaf, had been deported to Guam. Federal agents escorted the Filipino-American, who was also suspected of planning to smuggle illegal drugs to the Philippines. United States authorities have issued a warrant for the arrest of Infante in New York after Customs men in July 2003 seized one of his package from Oakland containing weapons’ parts addressed to his safehouse in Zamboanga City.
"His arrest and deportation is another big step in our campaign against terrorism because this man is known to have aided the Abu Sayyaf in acquiring weapons used by the group in committing atrocities against our soldiers and civilians," Philippine immigration chief Andrea Domingo said in a statement.
Criticism.
The Libyan envoy accused the group of inhumanity and violating the tenets of Islam by holding innocent people. Abdul Rajab Azzarouq, former ambassador to the Philippines, criticised the kidnappers for holding people who have nothing to do with the conflict. The hostage-takers should not use religion as a reason to keep the hostages isolated from their families, he said.
Sheikh Yusuf al-Qaradawi in Qatar has denounced the kidnapping and killings committed by the Abu Sayyaf towards civilians and foreigners, asserting that they are not part of the dispute between the Abu Sayyaf and the Philippines government. He stated that it is shameful to commit such acts in the name of the Islamic faith, saying that such acts produce backlashes against Islam and Muslims worldwide. It is known that Qaradawi supports the rights of Muslims in Philippines. Qaradawi spoke of the importance of education in the life of Muslims, stating that educational institutions in the Muslim world should review their educational philosophy in order that it may reflect Islamic values aiming to create pious Muslims good to themselves and non-Muslims as well.
The Organisation of the Islamic Conference (OIC) condemned the Sipadan kidnapping and offered to help secure their release. OIC Secretary General Azeddine Laraki who represents the world's largest Islamic body, told the Philippine government he was prepared to send an envoy to help save the hostages and issued a statement condemning the rebels. "The Secretary General has pointed out that this operation and the like are rejected by divine laws and that they are neither the appropriate nor correct means to resolve conflicts," the statement said.

</doc>
<doc id="2217" url="http://en.wikipedia.org/wiki?curid=2217" title="Armenian language">
Armenian language

The Armenian language (classical: հայերէն; reformed: հայերեն ] "hayeren") is an Indo-European language spoken by the Armenians. It is the official language of the Republic of Armenia and the self-proclaimed Nagorno-Karabakh Republic. It has historically been spoken throughout the Armenian Highlands and today is widely spoken in the Armenian diaspora. Armenian has its own unique script, the Armenian alphabet, invented in 405 AD by Mesrop Mashtots.
Linguists classify Armenian as an independent branch of the Indo-European language family. It is of interest to linguists for its distinctive phonological developments within the Indo-European languages. Armenian shares a number of major innovations with Greek, and some linguists group these two languages with Phrygian and the Indo-Iranian family into a higher-level subgroup of Indo-European, which is defined by such shared innovations as the augment. More recently, others have proposed a Balkan grouping including Greek, Phrygian, Armenian, and Albanian.
Armenia was a monolingual country by the second century BC at the latest. Its language has a long literary history, with a fifth-century Bible translation as its oldest surviving text. There are two standardized modern literary forms, Eastern Armenian and Western Armenian, with which most contemporary dialects are mutually intelligible.
Classification and origins.
While the Armenians were known to history much earlier (for example, they were mentioned in the 6th century BC Behistun Inscription and Xenophon's 4th century BC history, "The Anabasis"), the oldest surviving Armenian-language text is the 5th-century AD Bible translation of Mesrop Mashtots, who created the Armenian alphabet in 405 AD, at which time it had 36 letters. He is also credited by some with the creation of the Georgian alphabet.
Early contacts.
The loans from Iranian languages initially led linguists to erroneously classify Armenian as an Iranian language. The distinctness of Armenian was only recognized when Hübschmann (1875) used the comparative method to distinguish two layers of Iranian loans from the older Armenian vocabulary.
W. M. Austin (1942) concluded that there was an early contact between Armenian and Anatolian languages, based on what he considered common archaisms, such as the lack of a feminine and the absence of inherited long vowels. However, unlike shared innovations (or "synapomorphies"), the common retention of archaisms (or "symplesiomorphy") is not necessarily considered evidence of a period of common isolated development.
Soviet linguist Igor Diakonov (1985) noted the presence in Old Armenian of what he calls a Caucasian substratum, identified by earlier scholars, consisting of loans from the Kartvelian and Northeast Caucasian languages. Noting that the Hurro-Urartian peoples inhabited the Armenian homeland in the second millennium b.c., Diakonov identifies in Armenian a Hurro-Urartian substratum of social, cultural, and animal and plant terms such as "ałaxin" "slave girl" ( ← Hurr. "al(l)a(e)ḫḫenne"), "cov" "sea" ( ← Urart. "ṣûǝ" "(inland) sea"), "ułt" "camel" ( ← Hurr. "uḷtu"), and "xnjor" "apple(tree)" ( ← Hurr. "ḫinzuri"). Some of the terms he gives admittedly have an Akkadian or Sumerian provenance, but he suggests they were borrowed through Hurrian or Urartian. Given that these borrowings do not undergo sound changes characteristic of the development of Armenian from Proto-Indo-European, he dates their borrowing to a time before the written record but after the Proto-Armenian language stage.
Graeco-Armenian hypothesis.
The hypothesis that Greek is Armenian's closest living relative originates with Pedersen (1924), who noted that the number of Greek-Armenian lexical cognates is greater than that of agreements between Armenian and any other Indo-European language. Meillet (1925, 1927) further investigated morphological and phonological agreement, postulating that the parent languages of Greek and Armenian were dialects in immediate geographical proximity in the parent language. Meillet's hypothesis became popular in the wake of his "Esquisse" (1936). Solta (1960) does not go as far as postulating a Proto-Graeco-Armenian stage, but he concludes that considering both the lexicon and morphology, Greek is clearly the dialect most closely related to Armenian. Hamp (1976, 91) supports the Graeco-Armenian thesis, anticipating even a time "when we should speak of Helleno-Armenian" (meaning the postulate of a Graeco-Armenian proto-language). Armenian shares the augment, and a negator derived from the set phrase PIE *"ne h2oiu kwid" ("never anything" or "always nothing"), and the representation of word-initial laryngeals by prothetic vowels, and other phonological and morphological peculiarities with Greek. The closeness of the relationship between Armenian and Greek sheds light on the paraphyletic nature of the Centum-Satem isogloss. Nevertheless, linguists, including Fortson (2004), comment "by the time we reach our earliest Armenian records in the 5th century AD, the evidence of any such early kinship has been reduced to a few tantalizing pieces."
Evolution.
Classical Armenian, or Grabar, imported numerous words from Middle Iranian languages, primarily Parthian, and contains smaller inventories of borrowings from Greek, Syriac, Latin, and autochthonous languages such as Urartian. In the period that followed the invention of the alphabet and up to the threshold of the modern era, Grabar lived on. An effort to modernize the language in Greater Armenia and the Armenian Kingdom of Cilicia (11–14th centuries) resulted in the addition of two more characters to the alphabet, bringing the total number to 38.
The Book of Lamentations by Gregory of Narek (951–1003) is an example of the development of a literature and writing style in Middle Armenian. In addition to elevating the literary style of the Armenian language, Gregory of Nareg paved the way for his successors to include secular themes in their writings. The thematic shift from mainly religious texts to writings with secular outlooks further enhanced and enriched the vocabulary. “A Word of Wisdom”, a poem by Hovhannes Sargavak devoted to a starling, legitimizes poetry devoted to nature, love, or female beauty. Gradually, the interests of the population at large were reflected in other literary works as well. Konsdantin Yerzinkatsi and several others even take the unusual step of criticizing the ecclesiastic establishment and addressing the social issues of the Armenian homeland. Not surprisingly, these changes altered the nature of the literary style and syntax, but they did not constitute radical changes to the fundamentals of the grammar or the morphology of the language.
The Treaty of Turkmenchay of 1828 once again divided the traditional Armenian homeland. This time, two thirds of historical Armenia fell under Ottoman control, while the remaining territories were divided between the Russian and Persian empires. The antagonistic relationship between the Russian and Ottoman Empires led to creation of two separate and different environments under which Armenians lived and suffered. Halfway through the 19th century, two important concentrations of Armenian communities were constituted.
Because of persecutions or the search for better economic opportunities, many Armenians living under Ottoman rule gradually moved to Constantinople, the capital of the Ottoman Empire, while Tiflis (Tbilisi) in Georgia became the center of Armenians living under Russian rule. These two cosmopolitan cities very soon became the primary poles of Armenian intellectual and cultural life.
The introduction of new literary forms and styles, as well as many new ideas sweeping Europe, reached Armenians living in both regions. This created an ever-growing need to elevate the vernacular, Ašxarhabar, to the dignity of a modern literary language, in contrast to the now-anachronistic Grabar. Numerous dialects developed in the traditional Armenian regions, which, different as they were, had certain morphological and phonetic features in common. On the basis of these features two major variants emerged:
Both centers vigorously pursued the promotion of Ašxarhabar. The proliferation of newspapers in both versions (Eastern & Western) and the development of a network of schools where modern Armenian was taught, dramatically increased the rate of literacy (in spite of the obstacles by the colonial administrators), even in remote rural areas. The emergence of literary works entirely written in the modern versions increasingly legitimized the language’s existence. By the turn of the 20th century both varieties of the one modern Armenian language prevailed over Grabar and opened the path to a new and simplified grammatical structure of the language in the two different cultural spheres. Apart from minor morphological, phonetic, and grammatical differences, the largely common vocabulary and identical rules of grammatical fundamentals allows users of one variant to understand the other easily.
After the First World War, the existence of the two modern versions of the same language was sanctioned even more clearly. The Armenian Soviet Socialist Republic (1920–1990) used Eastern Armenian as its official language, whereas the diaspora created after the Genocide of 1915 preserved the Western Armenian dialect.
Modern changes.
The two modern literary dialects, Western (originally associated with writers in the Ottoman Empire) and Eastern (originally associated with writers in the Russian Empire), removed almost all of their Turkish lexical influences in the 20th century, primarily following the Armenian Genocide.
Phonology.
Proto-Indo-European voiceless occlusives are aspirated in Proto-Armenian, one of the circumstances that is often linked to the Glottalic theory, a version of which postulated that the voiceless occlusives of Proto-Indo-European were aspirated.
Stress.
In Armenian the stress falls on the last syllable unless the last syllable contains [ə], in which case it falls on the penultimate one. For instance, [ɑχoɾˈʒɑk], [mɑʁɑdɑˈnos], [giˈni] but [vɑˈhɑgən] and [ˈdɑʃtə]. Exceptions to this rule are some words with the final letter է (ե in the reformed orthography) (մի՛թէ, մի՛գուցե, ո՛րեւէ) and sometimes the ordinal numerals (վե՛ցերորդ, տա՛սներորդ, etc.).
Vowels.
Modern Armenian has six monophthongs. Each vowel phoneme in the table is represented by three symbols. The first indicates the phoneme's pronunciation in the International Phonetic Alphabet (IPA). After that appears the corresponding letter of the Armenian alphabet. The last symbol is its Latin transliteration (according to ISO 9985).
Consonants.
The following table lists the Eastern Armenian consonantal system. The occlusives and affricates have a special aspirated series (transcribed with an "apostrophe" after the letter): "p’", "t’", "c’", "k’" (but "č"). Each phoneme in the table is represented by three symbols. The first indicates the phoneme's pronunciation in the (IPA), after that appears the corresponding letter of the Armenian alphabet, and the last symbol is its Latin transliteration according to ISO 9985.
The major phonetic difference between dialects is in the reflexes of Classical Armenian voice-onset time. The seven dialect types have the following correspondences, illustrated with the t–d series:
The consonants transcribed ⟨dʱ⟩ are breathy voiced.
Morphology.
Armenian corresponds with other Indo-European languages in its structure, but it shares distinctive sounds and features of its grammar with neighboring languages of the Caucasus region. Armenian is agglutinative, one of only two Indo-European languages with this characteristic, the other one being Persian. Armenian is rich in combinations of consonants. Both classical Armenian and the modern spoken and literary dialects have a complicated system of declining nouns, with six or seven noun cases but no gender. In modern Armenian the use of auxiliary verbs to show tense (comparable to will in "he will go") has generally supplemented the inflected verbs of Classical Armenian. Negative verbs are conjugated differently from positive ones (as in English "he goes" and "he does not go"). Grammatically, early forms of Armenian had much in common with classical Greek and Latin, but the modern language, like modern Greek, has undergone many transformations. With time the Armenian language made a transition from a synthetic language (Old Armenian or Grabar) to a typical analytic language (Modern Armenian) with Middle Armenian as a midpoint in this transition.
Noun.
Classical Armenian has no grammatical gender, not even in the pronoun, but there is a feminine suffix (-ուհի "-uhi"). For example, ուսուցիչ ("usuts'ich", "teacher") becomes ուսուցչուհի ("usuts'chuhi", female teacher). This suffix, however, does not have a grammatical effect on the sentence. The nominal inflection, however, preserves several types of inherited stem classes. Nouns are declined for one of seven cases: nominative, accusative, locative, genitive, dative, ablative, or instrumental.
Examples of nouns' declension
Հեռախոս (Telephone):
Մայր (Mother)
Animated nouns don't decline for locative case.
Հանրապետություն (Republic)
Verb.
Verbs in Armenian have an expansive system of conjugation with two main verb types (three in Western Armenian) changing form based on tense, mood and aspect.
Dialects.
Armenian is a pluricentric language, having two modern standardized forms: Eastern Armenian and Western Armenian. The most distinctive feature of Western Armenian is that it has undergone several phonetic mergers; these may be due to proximity to Arabic- and Turkish-speaking communities.
For example, Eastern Armenian speakers pronounce (թ) as an aspirated "t" as in "tiger", (դ) like the "d" in "develop", and (տ) as a tenuis occlusive, sounding somewhere between the two as in "stop." Western Armenian has simplified the occlusive system into a simple division between voiced occlusives and aspirated ones; the first series corresponds to the tenuis series of Eastern Armenian, and the second corresponds to the Eastern voiced and aspirated series. Thus, the Western dialect pronounces both (թ) and (դ) as an aspirated "t" as in "tiger", and the (տ) letter is pronounced like the letter "d" as in "develop".
There is no precise linguistic border between one dialect and another because there is nearly always a dialect transition zone of some size between pairs of geographically identified dialects.
Armenian can be divided into two major dialectal blocks and those blocks into individual dialects, though many of the Western Armenian dialects have become extinct due to the effects of the Armenian Genocide. In addition, neither dialect is completely homogeneous: any dialect can be subdivided into several subdialects. Although Western and Eastern Armenian are often described as different dialects of the same language, some subdialects are not readily mutually intelligible. Nevertheless, a fluent speaker of one of two greatly varying dialects who is exposed to the other dialect for even a short period of time will be able to understand the other with relative ease.
Other distinct dialects include the Homshetsi language of the Hemshin people and the divergent and almost extinct Lomavren language of the Bosha people, both of which are categorized as belonging to the Armenian language family.
Writing system.
The Armenian alphabet (Armenian: Հայոց գրեր "Hayots grer" or Հայոց այբուբեն "Hayots aybuben") is a graphically unique alphabetical writing system that is used to write the Armenian language. It was introduced around 405 AD by Mesrop Mashtots, an Armenian linguist and ecclesiastical leader, and originally contained 36 letters. Two more letters, օ (o) and ֆ (f), were added in the Middle Ages. 
During the 1920s orthography reform, a new letter և (capital ԵՎ) was added, which was a ligature before ե+ւ, while the letter Ւ ւ was discarded and reintroduced as part of a new letter ՈՒ ու (which was a digraph before).
Indo-European cognates.
Armenian is an Indo-European language, so many of its Proto-Indo-European-descended words are cognates of words in other Indo-European languages such as English, Latin, Greek, and Sanskrit. This table lists only some of the more recognizable cognates that Armenian shares with English (more specifically, with English words descended from the Old English (Anglo-Saxon) language). (Source: Online Etymology Dictionary.)
References.
</dl>
Further reading.
</dl>
External links.
Armenian Online Dictionaries

</doc>
<doc id="2218" url="http://en.wikipedia.org/wiki?curid=2218" title="Additive synthesis">
Additive synthesis

Additive synthesis is a sound synthesis technique that creates timbre by adding sine waves together.
The timbre of musical instruments can be considered in the light of Fourier theory to consist of multiple harmonic or inharmonic "partials" or overtones. Each partial is a sine wave of different frequency and amplitude that swells and decays over time.
Additive synthesis most directly generates sound by adding the output of multiple sine wave generators. Alternative implementations may use pre-computed wavetables or the inverse Fast Fourier transform.
Definitions.
Harmonic additive synthesis is closely related to the concept of a Fourier series which is a way of expressing a periodic function as the sum of sinusoidal functions with frequencies equal to integer multiples of a common fundamental frequency. These sinusoids are called harmonics, overtones, or generally, partials. In general, a Fourier series contains an infinite number of sinusoidal components, with no upper limit to the frequency of the sinusoidal functions and includes a DC component (one with frequency of 0 Hz). Frequencies outside of the human audible range can be omitted in additive synthesis. As a result only a finite number of sinusoidal terms with frequencies that lie within the audible range are modeled in additive synthesis.
A waveform or function is said to be periodic if
for all formula_2 and for some period formula_3.
The Fourier series of a periodic function is mathematically expressed as:
where
Being inaudible, the DC component, formula_12, and all components with frequencies higher than some finite limit, formula_13, are omitted in the following expressions of additive synthesis.
Harmonic form.
The simplest harmonic additive synthesis can be mathematically expressed as:
where formula_14 is the synthesis output, formula_15, formula_16, and formula_17 are the amplitude, frequency, and the phase offset, respectively, of the formula_9th harmonic partial of a total of formula_19 harmonic partials, and formula_20 is the fundamental frequency of the waveform and the frequency of the musical note.
Time-dependent amplitudes.
More generally, the amplitude of each harmonic can be prescribed as a function of time, formula_21, in which case the synthesis output is
Each envelope formula_21 should vary slowly relative to the frequency spacing between adjacent sinusoids. The bandwidth of formula_21 should be significantly less than formula_20.
Inharmonic form.
Additive synthesis can also produce inharmonic sounds (which are aperiodic waveforms) in which the individual overtones need not have frequencies that are integer multiples of some common fundamental frequency. While many conventional musical instruments have harmonic partials (e.g. an oboe), some have inharmonic partials (e.g. bells). Inharmonic additive synthesis can be described as
where formula_26 is the constant frequency of formula_9th partial.
Time-dependent frequencies.
In the general case, the instantaneous frequency of a sinusoid is the derivative (with respect to time) of the argument of the sine or cosine function. If this frequency is represented in hertz, rather than in angular frequency form, then this derivative is divided by formula_28. This is the case whether the partial is harmonic or inharmonic and whether its frequency is constant or time-varying.
In the most general form, the frequency of each non-harmonic partial is a non-negative function of time, formula_29, yielding
Broader definitions.
"Additive synthesis" more broadly may mean sound synthesis techniques that sum simple elements to create more complex timbres, even when the elements are not sine waves. For example, F. Richard Moore listed additive synthesis as one of the "four basic categories" of sound synthesis alongside subtractive synthesis, nonlinear synthesis, and physical modelling. In this broad sense, pipe organs, which also have pipes producing non-sinusoidal waveforms, can be considered as additive synthesizers. Summation of principal components and Walsh functions have also been classified as additive synthesis.
Implementation methods.
Modern-day implementations of additive synthesis are mainly digital. (See section "Discrete-time equations" for the underlying discrete-time theory)
Oscillator bank synthesis.
Additive synthesis can be implemented using a bank of sinusoidal oscillators, one for each partial.
Wavetable synthesis.
In the case of harmonic, quasi-periodic musical tones, wavetable synthesis can be as general as time-varying additive synthesis, but requires less computation during synthesis. As a result, an efficient implementation of time-varying additive synthesis of harmonic tones can be accomplished by use of "wavetable synthesis".
Group additive synthesis.
Group additive synthesis is a method to group partials into harmonic groups (of differing fundamental frequencies) and synthesize each group separately with "wavetable synthesis" before mixing the results.
Inverse FFT synthesis.
An inverse Fast Fourier transform can be used to efficiently synthesize frequencies that evenly divide the transform period or "frame". By careful consideration of the DFT frequency-domain representation it is also possible to efficiently synthesize sinusoids of arbitrary frequencies using a series of overlapping frames and the inverse Fast Fourier transform.
Additive analysis/resynthesis.
It is possible to analyze the frequency components of a recorded sound giving a "sum of sinusoids" representation. This representation can be re-synthesized using additive synthesis. One method of decomposing a sound into time varying sinusoidal partials is Fourier Transform-based McAulay-Quatieri Analysis.
By modifying the sum of sinusoids representation, timbral alterations can be made prior to resynthesis. For example, a harmonic sound could be restructured to sound inharmonic, and vice versa. Sound hybridisation or "morphing" has been implemented by additive resynthesis.
Additive analysis/resynthesis has been employed in a number of techniques including Sinusoidal Modelling, Spectral Modelling Synthesis (SMS), and the Reassigned Bandwidth-Enhanced Additive Sound Model. Software that implements additive analysis/resynthesis includes: SPEAR, LEMUR, LORIS, SMSTools, ARSS.
Products.
New England Digital Synclavier had a resynthesis feature where samples could be analyzed and converted into ”timbre frames” which were part of its additive synthesis engine. Technos acxel, launched in 1987, utilized the additive analysis/resynthesis model, in an FFT implementation.
Also a vocal synthesizer, Vocaloid have been implemented on the basis of additive analysis/resynthesis: its spectral voice model called Excitation plus Resonances (EpR) model is extended based on Spectral Modeling Synthesis (SMS),
and its diphone concatenative synthesis is processed using
"spectral peak processing" (SPP) technique similar to modified phase-locked vocoder (an improved phase vocoder for formant processing). Using these techniques, spectral components ("formants") consisting of purely harmonic partials can be appropriately transformed into desired form for sound modeling, and sequence of short samples ("diphones" or "phonemes") constituting desired phrase, can be smoothly connected by interpolating matched partials and formant peaks, respectively, in the inserted transition region between different samples.
Applications.
Musical instruments.
Additive synthesis is used in electronic musical instruments.
Speech synthesis.
In linguistics research, harmonic additive synthesis was used in 1950s to play back modified and synthetic speech spectrograms.
Later, in early 1980s, listening tests were carried out on synthetic speech stripped of acoustic cues to assess their significance. Time-varying formant frequencies and amplitudes derived by linear predictive coding were synthesized additively as pure tone whistles. This method is called sinewave synthesis. Also the composite sinusoidal modeling (CSM) used on a singing speech synthesis feature on Yamaha CX5M (1984), is known to use a similar approach which was independently developed during 1966–1979. These methods are characterized by extraction and recomposition of a set of significant spectral peaks corresponding to the several resonance modes occurred in the oral cavity and nasal cavity, in a viewpoint of acoustics. This principle was also utilized on a physical modeling synthesis method, called modal synthesis.
History.
Harmonic analysis was discovered by Joseph Fourier, who published an extensive treatise of his research in the context of heat transfer in 1822. The theory found an early application in prediction of tides. Around 1876, Lord Kelvin constructed a mechanical tide predictor. It consisted of a "harmonic analyzer" and a "harmonic synthesizer", as they were called already in the 19th century. The analysis of tide measurements was done using James Thomson's "integrating machine". The resulting Fourier coefficients were input into the synthesizer, which then used a system of cords and pulleys to generate and sum harmonic sinusoidal partials for prediction of future tides. In 1910, a similar machine was built for the analysis of periodic waveforms of sound. The synthesizer drew a graph of the combination waveform, which was used chiefly for visual validation of the analysis.
Georg Ohm applied Fourier's theory to sound in 1843. The line of work was greatly advanced by Hermann von Helmholtz, who published his eight years worth of research in 1863. Helmholtz believed that the psychological perception of tone color is subject to learning, while hearing in the sensory sense is purely physiological. He supported the idea that perception of sound derives from signals from nerve cells of the basilar membrane and that the elastic appendages of these cells are sympathetically vibrated by pure sinusoidal tones of appropriate frequencies. Helmholtz agreed with the finding of Ernst Chladni from 1787 that certain sound sources have inharmonic vibration modes.
In Helmholtz's time, electronic amplification was unavailable. For synthesis of tones with harmonic partials, Helmholtz built an electrically excited array of tuning forks and acoustic resonance chambers that allowed adjustment of the amplitudes of the partials. Built at least as early as in 1862, these were in turn refined by Rudolph Koenig, who demonstrated his own setup in 1872. For harmonic synthesis, Koenig also built a large apparatus based on his "wave siren". It was pneumatic and utilized cut-out tonewheels, and was criticized for low purity of its partial tones. Also tibia pipes of pipe organs have nearly sinusoidal waveforms and can be combined in the manner of additive synthesis.
In 1938, with significant new supporting evidence, it was reported on the pages of Popular Science Monthly that the human vocal cords function like a fire siren to produce a harmonic-rich tone, which is then filtered by the vocal tract to produce different vowel tones. By the time, the additive Hammond organ was already on market. Most early electronic organ makers thought it too expensive to manufacture the plurality of oscillators required by additive organs, and began instead to built subtractive ones. In a 1940 Institute of Radio Engineers meeting, the head field engineer of Hammond elaborated on the company's new "Novachord" as having a "“subtractive system”" in contrast to the original Hammond organ in which "“the final tones were built up by combining sound waves”". Alan Douglas used the qualifiers "additive" and "subtractive" to describe different types of electronic organs in a 1948 paper presented to the Royal Musical Association. The contemporary wording "additive synthesis" and "subtractive synthesis" can be found in his 1957 book "The electrical production of music", in which he categorically lists three methods of forming of musical tone-colours, in sections titled "Additive synthesis", "Subtractive synthesis", and "Other forms of combinations".
A typical modern additive synthesizer produces its output as an electrical, analog signal, or as digital audio, such as in the case of software synthesizers, which became popular around year 2000.
Timeline.
The following is a timeline of historically and technologically notable analog and digital synthesizers and devices implementing additive synthesis.
Discrete-time equations.
In digital implementations of additive synthesis, discrete-time equations are used in place of the continuous-time synthesis equations. A notational convention for discrete-time signals uses brackets i.e. formula_30 and the argument formula_31 can only be integer values. If the continuous-time synthesis output formula_14 is expected to be sufficiently bandlimited; below half the sampling rate or formula_33, it suffices to directly sample the continuous-time expression to get the discrete synthesis equation. The continuous synthesis output can later be reconstructed from the samples using a digital-to-analog converter. The sampling period is formula_34.
Beginning with (3),
and sampling at discrete times formula_36 results in
where
This is equivalent to
where
and

</doc>
<doc id="2219" url="http://en.wikipedia.org/wiki?curid=2219" title="Aircraft carrier">
Aircraft carrier

An aircraft carrier is a warship that serves as a seagoing airbase, equipped with a full-length flight deck and facilities for carrying, arming, deploying, and recovering aircraft. Typically, it is the capital ship of a fleet, as it allows a naval force to project air power worldwide without depending on local bases for staging aircraft operations. It is extremely expensive to build and important to protect. Aircraft carriers have evolved from converted cruisers to nuclear-powered warships that carry numerous fighter planes, strike aircraft, helicopters, and other types of aircraft.
There is no single definition of an "aircraft carrier", and modern navies use several variants of the type. These variants are sometimes categorized as sub-types of aircraft carriers, and sometimes as distinct types of naval aviation-capable ships. Aircraft carriers may be classified according to the type of aircraft they carry and their operational assignments. Admiral Sir Mark Stanhope, former head of the Royal Navy, has said that "To put it simply, countries that aspire to strategic international influence have aircraft carriers".
Carriers have evolved since their inception in the early twentieth century from wooden vessels used to deploy balloons to nuclear-powered warships that carry dozens of aircraft, including fighter jets and helicopters. As of none }}, there are thirty-seven active aircraft carriers in the world within twelve navies. The United States Navy has ten large nuclear-powered carriers, known as supercarriers, carrying up to ninety aircraft each, the largest carriers in the world. As well as the supercarrier fleet, the US Navy has nine amphibious assault ships used primarily for helicopters (sometimes called helicopter carriers); these can also carry up to twenty-five fighter jets, and in some cases, are as large as some other nations' fixed-wing carriers.
Types of carrier.
By role.
A "fleet carrier" is intended to operate with the main fleet and usually provides an offensive capability. These are the largest carriers capable of fast speeds. By comparison, "escort carriers" were developed to provide defense for convoys of ships. They were smaller and slower with lower numbers of aircraft carried. Most were built from mercantile hulls or, in the case of merchant aircraft carriers, were bulk cargo ships with a flight deck added on top. "Light aircraft carriers" were carriers that were fast enough to operate with the fleet but of smaller size with reduced aircraft capacity. Soviet aircraft carriers now in use by Russia are actually called "heavy aviation cruisers", these ships while sized in the range of large fleet carriers were designed to deploy alone or with escorts and provide both strong defensive weaponry and heavy offensive missiles equivalent to a guided missile cruiser in addition to supporting fighters and helicopters.
By configuration.
There are four main configurations of aircraft carrier in service in the world's navies, divided by the way that aircraft take off and land:
Hull type identification symbols.
Several systems of identification symbol for aircraft carriers and related types of ship have been used. These include the pennant numbers used by the British Royal Navy and some Commonwealth countries, the US hull classification symbols also used by NATO and some other countries, and the Canadian hull classification symbols.
History.
Origins.
The 1903 advent of heavier-than-air fixed-wing aircraft was closely followed in 1910 by the first experimental take-off of an airplane, made from the deck of a United States Navy vessel (cruiser USS "Birmingham"), and the first experimental landings were conducted in 1911. On 9 May 1912 the first airplane take-off from a ship underway was made from the deck of the British Royal Navy's HMS "Hibernia". Seaplane tender support ships came next, with the French "Foudre" of 1911. In September 1914 the Imperial Japanese Navy "Wakamiya" conducted the world's first successful ship-launched air raid: on 6 September 1914 a Farman aircraft launched by "Wakamiya" attacked the Austro-Hungarian cruiser "Kaiserin Elisabeth" and the German gunboat "Jaguar" in Kiaochow Bay off Tsingtao; neither was hit.
The development of flattop vessels produced the first large fleet ships. In 1918, HMS "Argus" became the world's first carrier capable of launching and recovering naval aircraft. As a result of the Washington Naval Treaty of 1922, which limited the construction of new heavy surface combat ships, most early aircraft carriers were conversions of ships that were laid down (or had served) as different ship types: cargo ships, cruisers, battle cruisers, or battleships. These conversions gave rise to "Lexington"-class aircraft carriers (1927), "Akagi" and "Courageous"-class. Specialist carrier evolution was well underway, with several navies ordering and building warships that were purposefully designed to function as aircraft carriers by the mid-1920s, resulting in the commissioning of ships such as "Hōshō" (1922), HMS "Hermes" (1924), and "Béarn" (1927). During World War II, these ships would become the backbone of the carrier forces of the United States, British, and Japanese navies, known as fleet carriers.
World War II.
The aircraft carrier dramatically changed naval combat in World War II, because air power was becoming a significant factor in warfare. The advent of aircraft as focal weapons was driven by the superior range, flexibility and effectiveness of carrier-launched aircraft. They had higher range and precision than naval guns, making them highly effective. The versatility of the carrier was demonstrated in November 1940 when HMS "Illustrious" launched a long-range strike on the Italian fleet at their base in Taranto, signalling the beginning of the effective and highly mobile aircraft strikes. This operation incapacitated three of the six battleships at a cost of two torpedo bombers. World War II in the Pacific Ocean involved clashes between aircraft carrier fleets. The 1941 Japanese surprise attack on Pearl Harbor was a clear illustration of the power projection capability afforded by a large force of modern carriers. Concentrating six carriers in a single unit turned naval history about, as no other nation had fielded anything comparable. However, the vulnerability of carriers compared to traditional battleships when forced into a gun-range encounter was quickly illustrated by the sinking of HMS "Glorious" by German battle cruisers during the Norwegian campaign in 1940.
This new-found importance of naval aviation forced nations to create a number of carriers, in efforts to provide air superiority cover for every major fleet in order to ward off enemy aircraft. This extensive usage required the construction of several new 'light' carriers. Escort aircraft carriers, such as USS "Bogue", were sometimes purpose-built, but most were converted from merchant ships as a stop-gap measure to provide anti-submarine air support for convoys and amphibious invasions. Following this concept, Light aircraft carriers built by the US, such as USS "Independence", represented a larger, more "militarized" version of the escort carrier. Although with similar complement to Escort carriers, they had the advantage of speed from their converted cruiser hulls. The UK 1942 Design Light Fleet Carrier was designed for building quickly by civilian shipyards and with an expected service life of about 3 years. They served the Royal Navy during the war and was the hull design chosen for nearly all aircraft carrier equipped navies after the war until the 1980s. Emergencies also spurred the creation or conversion of highly unconventional aircraft carriers. CAM ships, were cargo-carrying merchant ships that could launch (but not retrieve) a single fighter aircraft from a catapult to defend the convoy from long range German aircraft.
Postwar era.
Before World War II, international naval treaties of 1922, 1930 and 1936 limited the size of capital ships including carriers.
Since World War II, aircraft carrier designs have increased in size to accommodate a steady increase in aircraft size. The large, modern "Nimitz" class of US carriers has a displacement nearly four times that of the World War II–era USS "Enterprise", yet its complement of aircraft is roughly the same—a consequence of the steadily increasing size and weight of military aircraft over the years. Today's aircraft carriers are so expensive that nations which operate them risk significant political, economic, and military impact if a carrier is lost, or even used in conflict.
Modern navies that operate such aircraft carriers treat them as the capital ship of the fleet, a role previously held by the battleship. This change took place during World War II in response to air power becoming a significant factor in warfare, driven by the superior range, flexibility and effectiveness of carrier-launched aircraft. Following the war, carrier operations continued to increase in size and importance. Supercarriers, displacing 75,000 tonnes or greater, have become the pinnacle of carrier development. Some are powered by nuclear reactors and form the core of a fleet designed to operate far from home. Amphibious assault ships, such as USS "Tarawa" and HMS "Ocean", serve the purpose of carrying and landing Marines, and operate a large contingent of helicopters for that purpose. Also known as "commando carriers" or "helicopter carriers", many have the capability to operate VSTOL aircraft.
Lacking the firepower of other warships, carriers by themselves are considered vulnerable to attack by other ships, aircraft, submarines, or missiles. Therefore, an aircraft carrier is generally accompanied by a number of other ships to provide protection for the relatively unwieldy carrier, to carry supplies and perform other support services, and to provide additional offensive capabilities. The resulting group of ships is often termed a battle group, carrier group, or carrier battle group.
There is a view that modern anti-ship weapons systems, such as torpedoes and missiles, have made aircraft carriers obsolete as too vulnerable for modern combat. On the other hand, the threatening role of aircraft carriers has a place in modern asymmetric warfare, like the gunboat diplomacy of the past. Furthermore, aircraft carriers facilitate quick and precise projections of overwhelming military power into such local and regional conflicts.
Aircraft carriers in service.
Most navies operate only one or two aircraft carriers, if any. The USA is a notable exception, with 10 super carriers and 9 amphibious assault ships in service.
A total of 20 fleet carriers are in active service with ten navies. Additionally, the navies of Australia, Brazil, China, France, India, Italy, Japan, Russia, South Korea, Spain, Thailand and the United States also operate ships capable of carrying and operating multiple helicopters and STOVL aircraft.
Among helicopter-only types:
The future of aircraft carriers.
A good many aircraft carriers and related types are planned, under construction or undergoing commissioning activity.
The Royal Australian Navy is in the process of procuring two Canberra-class LHD's expected to enter service in 2014 and 2016 respectively. The ships will be the largest in Australian naval history. Their primary roles are to embark, transport and deploy an embarked force and to carry out or support humanitarian assistance missions. The LHD is capable of launching multiple helicopters at one time while maintaining an amphibious capability of 1,000 troops and their supporting vehicles (tanks, armoured personnel carriers etc.). The Australian Defence Minister has publically raised the possibility of procuring F-35B STOVL aircraft for the carrier, stating that it "has been on the table since day one. Stating the LHD's are "STOVL capable".
In December 2009, then Indian Navy chief Admiral Nirmal Kumar Verma said at his maiden navy week press conference that concepts currently being examined by the Directorate of Naval Design for the second indigenous aircraft carrier (IAC-2), are for a conventionally powered carrier displacing over 50,000 tons and equipped with steam catapults (rather than the ski-jump on the "Gorshkov"/"Vikramaditya" and the IAC) to launch fourth-generation aircraft. Later on in August 2013 Vice Admiral RK Dhowan, while talking about the detailed study underway on the IAC-II project, said that nuclear propulsion was also being considered. The navy also evaluated the Electromagnetic Aircraft Launch System (EMALS), which is being used by the US Navy in their latest "Gerald R. Ford"-class aircraft carriers. General Atomics, the developer of the EMALS, was cleared by the US government to give a technical demonstration to Indian Navy officers, who were impressed by the new capabilities of the system. The EMALS enables launching varied aircraft including unmanned combat air vehicles (UCAV). The aim is to have a total of three aircraft carriers in service, with two fully operational carriers and the third in refit.
In August 2013, a launching ceremony for Japan's largest military ship since World War II was held in Yokohama. The 820-foot-long, 19,500-ton flattop destroyer Izumo will be deployed in March 2015. The ship will be able to carry up to 14 helicopters; however, only 7 ASW helicopters and 2 SAR helicopters are planned for the initial aircraft complement. For other operations, 400 troops and 50 3.5t trucks (or equivalent equipment) can also be carried. The flight deck has 5 helicopter landing spots that allow simultaneous landings or take-offs. The ship is equipped with 2 Phalanx CIWS and 2 SeaRAM for its defense. The destroyers of this class were initially intended to replace the two ships of the "Shirane" class, which were originally scheduled to begin decommissioning in FY2014.
Speaking in St. Petersburg, Russia on 30 June 2011, the head of Russia's United Shipbuilding Corporation said his company expected to begin design work for a new carrier in 2016, with a goal of beginning construction in 2018 and having the carrier achieve initial operational capability by 2023. Several months later, on 3 November 2011 the Russian newspaper "Izvestiya" reported that the naval building plan now included (first) the construction of a new shipyard capable of building large hull ships, after which Moscow will build two(80 000 tons full load each) nuclear-powered aircraft carriers by 2027. The spokesperson said one carrier would be assigned to the Russian Navy's Northern Fleet at Murmansk, and the second would be stationed with the Pacific Fleet at Vladivostok.
The Republic of Korea Navy believes it can deploy two light aircraft carriers by 2036 and expand its blue-water force to cope with the rapid naval buildups of China and Japan, according to a Navy source.
The British Royal Navy is constructing two new larger STOVL aircraft carriers, the "Queen Elizabeth" class, to replace the three "Invincible"-class carriers. The ships will be named HMS "Queen Elizabeth" and HMS "Prince of Wales". They will be able to operate up to 40 aircraft in peace time with a tailored group of up to 50, and will have a displacement of 70,600 tonnes. The ships are due to become operational from 2020. Their primary aircraft complement will be made up of F-35B Lightning IIs, and their ship's company will number around 680 with the total complement rising to about 1600 when the air group is embarked. Defensive weapons will include the Phalanx Close-In Weapons System for anti-aircraft and anti-missile defence; also 30mm Automated Small Calibre Guns and Miniguns for use against fast attack craft. The two ships will be the largest warships ever built for the Royal Navy.
The current US fleet of "Nimitz"-class carriers will be followed into service (and in some cases replaced) by the "Gerald R. Ford" class. It is expected that the ships will be more automated in an effort to reduce the amount of funding required to maintain and operate its supercarriers. The main new features are implementation of Electromagnetic Aircraft Launch System (EMALS) (which replace the old steam catapults) and unmanned aerial vehicles. With the deactivation of the USS "Enterprise" in December 2012 (decommissioning scheduled for 2013), the U.S. fleet comprises 10 supercarriers. On 24 July 2007, the House Armed Services Seapower subcommittee recommended seven or eight new carriers (one every four years). However, the debate has deepened over budgeting for the $12–14.5 billion (plus $12 billion for development and research) for the 100,000 ton "Gerald R. Ford"-class carrier (estimated service 2015) compared to the smaller $2 billion 45,000 ton "America"-class amphibious assault ships able to deploy squadrons of F-35B of which two are already under construction and twelve are planned.
Description.
Structure.
Carriers are large and long ships, although there is a high degree of variation depending on their intended role and aircraft complement. The size of the carrier has varied over history and among navies, to cater to the various roles that global climates have demanded from naval aviation.
Regardless of size, the ship itself must house their complement of aircraft, with space for launching, storing, and maintaining them. Space is also required for the large crew, supplies (food, munitions, fuel, engineering parts), and propulsion. US supercarriers are notable for having nuclear reactors powering their systems and propulsion. This makes the carrier reasonably tall.
The top of the carrier is the flight deck, where aircraft are launched and recovered. On the starboard side of this is the island, where air-traffic control and the bridge are located.
The constraints of constructing a flight deck affect the role of a given carrier strongly, as they influence the weight, type, and configuration of the aircraft that may be launched. For example, assisted launch mechanisms are used primarily for heavy aircraft, especially those loaded with air-to-ground weapons. CATOBAR is most commonly used on USN supercarriers as it allows the deployment of heavy jets with full loadouts, especially on ground-attack missions. STOVL is used by other navies because it is cheaper to operate and still provides good deployment capability for fighter aircraft.
Due to the busy nature of the flight deck, only 20 or so aircraft may be on it at any one time. A hangar storage several decks below the flight deck is where most aircraft are kept, and aircraft are taken from the lower storage decks to the flight deck through the use of an elevator. The hangar is usually quite large and can take up several decks of vertical space.
Munitions are commonly stored on the lower decks because they are highly explosive should the compartment they are in be breached. Usually this is below the water line so that the area can be flooded in case of emergency.
Flight deck.
As "runways at sea", aircraft carriers have a flat-top flight deck, which launches and recovers aircraft. Aircraft launch forward, into the wind, and are recovered from astern. The flight deck is where the most notable differences between a carrier and a land runway are found. Creating such a surface at sea poses constraints on the carrier – for example, the fact that it is a ship means that a full-length runway would be costly to construct and maintain. This affects take-off procedure, as a shorter runway length of the deck requires that aircraft accelerate more quickly to gain lift. This either requires a thrust boost, a vertical component to its velocity, or a reduced take-off load (to lower mass). The differing types of deck configuration, as above, influence the structure of the flight deck. The form of launch assistance a carrier provides is strongly related to the types of aircraft embarked and the design of the carrier itself.
There are two main philosophies in order to keep the deck short: add thrust to the aircraft, such as using a Catapult Assisted Take-Off (CATO-); and changing the direction of the airplanes' thrust, as in Vertical and/or Short Take-Off (V/STO-). Each method has advantages and disadvantages of its own:
On the recovery side of the flight deck, the adaptation to the aircraft loadout is mirrored. Non-VTOL or conventional aircraft cannot decelerate on their own, and almost all carriers using them must have arrested-recovery systems (-BAR, e.g. CATO"BAR" or STO"BAR") to recover their aircraft. Aircraft that are landing extend a tailhook that catches on arrestor wires stretched across the deck to bring themselves to a stop in a short distance. Post-WWII Royal Navy research on safer CATOBAR recovery eventually lead to universal adoption of a landing area angled off axis to allow aircraft who missed the arresting wires to "bolt" and safely return to flight for another landing attempt rather than crashing into aircraft on the forward deck.
If the aircraft are VTOL-capable or helicopters, they do not need to decelerate and hence there is no such need. The arrested-recovery system has used an angled deck since the 1950s because, in case the aircraft does not catch the arresting wire, the short deck allows easier take off by reducing the number of objects between the aircraft and the end of the runway. It also has the advantage of separating the recovery operation area from the launch area. Helicopters and aircraft capable of vertical or short take-off and landing (V/STOL) usually recover by coming abreast the carrier on the port side and then using their hover capability to move over the flight deck and land vertically without the need for arresting gear.
Staff and Deck Operations.
Carriers steam at speed, up to 35 knots (65 km/h) into the wind during flight deck operations to increase wind speed over the deck to a safe minimum. This increase in effective wind speed provides a higher launch airspeed for aircraft at the end of the catapult stroke or ski-jump, as well as making recovery safer by reducing the difference between the relative speeds of the aircraft and ship.
Since the early 1950s on conventional carriers it has been the practice to recover aircraft at an angle to port of the axial line of the ship. The primary function of this angled deck is to allow aircraft that miss the arresting wires, referred to as a bolter, to become airborne again without the risk of hitting aircraft parked forward. The angled deck allows the installation of one or two "waist" catapults in addition to the two bow cats. An angled deck also improves launch and recovery cycle flexibility with the option of simultaneous launching and recovery of aircraft.
Conventional ("tailhook") aircraft rely upon a landing signal officer (LSO, sometimes called "paddles") to monitor the aircraft's approach, visually gauge glideslope, attitude, and airspeed, and transmit that data to the pilot. Before the angled deck emerged in the 1950s, LSOs used colored paddles to signal corrections to the pilot (hence the nickname). From the late 1950s onward, visual landing aids such as Optical Landing System have provided information on proper glide slope, but LSOs still transmit voice calls to approaching pilots by radio.
Key personnel involved in the flight deck include the shooters, the handler, and the air boss. Shooters are naval aviators or Naval Flight Officers and are responsible for launching aircraft. The handler works just inside the island from the flight deck and is responsible for the movement of aircraft before launching and after recovery. The "air boss" (usually a commander) occupies the top bridge (Primary Flight Control, also called "primary" or "the tower") and has the overall responsibility for controlling launch, recovery and "those aircraft in the air near the ship, and the movement of planes on the flight deck, which itself resembles a well-choreographed ballet." The captain of the ship spends most of his time one level below primary on the Navigation Bridge. Below this is the Flag Bridge, designated for the embarked admiral and his staff.
To facilitate working on the flight deck of a U.S. aircraft carrier, the sailors wear colored shirts that designate their responsibilities. There are at least seven different colors worn by flight deck personnel for modern United States Navy carrier air operations. Carrier operations of other nations use similar color schemes.
Deck structures.
The superstructure of a carrier (such as the bridge, flight control tower) are concentrated in a relatively small area called an "island", a feature pioneered on the HMS "Hermes" in 1923. While the island is usually built on the starboard side of the fight deck, the Japanese aircraft carriers "Akagi" and "Hiryū" had their islands built on the port side. Very few carriers have been designed or built without an island. The "flush deck" configuration proved to have significant drawbacks, primary of which was management of the exhaust from the power plant. Fumes coming across the deck were a major issue in the . In addition, lack of an island meant difficulties managing the flight deck, performing air traffic control, a lack of radar housing placements and problems with navigating and controlling the ship itself.
Another deck structure that can be seen is a ski-jump ramp at the forward end of the flight deck. This was first developed to help launch STOVL aircraft take off at far higher weights than is possible with a vertical or rolling takeoff on flat decks. Originally developed by the Royal Navy, it since has been adopted by many navies for smaller carriers. A ski-jump ramp works by converting some of the forward rolling movement of the aircraft into vertical velocity and is sometimes combined with the aiming of jet thrust partly downwards. This allows heavily loaded and fueled aircraft a few more precious seconds to attain sufficient air velocity and lift to sustain normal flight. Without a ski-jump launching fully loaded and fueled aircraft such as the Harrier would not be possible on a smaller flat deck ship before either stalling out or crashing directly into the sea.
Although STOVL aircraft are capable of taking off vertically from a spot on the deck, using the ramp and a running start is far more fuel efficient and permits a heavier launch weight. As catapults are unnecessary, carriers with this arrangement reduce weight, complexity, and space needed for complex steam or electromagnetic launching equipment, vertical landing aircraft also remove the need for arresting cables and related hardware. Russian, Chinese, and future Indian carriers include a ski-jump ramp for launching lightly loaded conventional fighter aircraft but recover using traditional carrier arresting cables and a tailhook on their aircraft.
The disadvantage of the ski-jump is the penalty it exacts on aircraft size, payload, and fuel load (and thus range); heavily laden aircraft can not launch using a ski-jump because their high loaded weight requires either a longer takeoff roll than is possible on a carrier deck, or assistance from a catapult or JATO rocket. For example the Russian Su-33 is only able to launch from the carrier "Kuznetsov" with a minimal armament and fuel load. Another disadvantage is on mixed flight deck operations where helicopters are also present such as a US Landing Helicopter Dock or Landing Helicopter Assault amphibious assault ship a ski jump is not included as this would eliminate one or more helicopter landing areas, this flat deck limits the loading of Harriers but is somewhat mitigated by the longer rolling start provided by a long flight deck compared to many STOVL carriers.
National fleets.
A total of 20 fleet carriers are in active service with ten navies. Additionally, the navies of Australia, Brazil, China, France, India, Italy, Japan, South Korea, Spain, Thailand and the United States also operate ships capable of carrying and operating multiple helicopters and STOVL aircraft.
Australia.
Future.
The "Canberra" class of landing helicopter docks, based on the Spanish vessel "Juan Carlos I", is composed of two ships one of which has just entered service. The class is being built by Navantia and BAE Systems Australia; and HMAS "Canberra" is the largest ship ever built for the Royal Australian Navy. "Canberra" underwent sea trials in late 2013 and has been commissioned in 2014, while HMAS "Adelaide" is expected to enter service in 2016. The Australian version retains the ski-ramp from the "Juan Carlos I" design, although the RAN has not acquired carrier based fixed-wing aircraft.
Brazil.
Current.
1 CATOBAR carrier: NAe "São Paulo" (A12) is a Clemenceau-class aircraft carrier currently in service with the Brazilian Navy. The São Paulo was first commissioned in 1963 by the French Navy as the Foch and was transferred in 2000 to Brazil, where she became the new flagship of the Brazilian Navy. During the period from 2005–2010, the "São Paulo" underwent extensive modernization. At the end of 2010, sea trials began, and as of 2011[ [update]] the "São Paulo" had been evaluated by the CIASA (Inspection Commission and Training Advisory). She was expected to rejoin the fleet in late 2013, but suffered another major fire in 2012.
China.
Current.
1 STOBAR carrier: "Liaoning" was originally built as the 57,000 tonne Soviet "Kuznetsov"-class carrier "Varyag" and was later purchased as a stripped hulk by China in 1998 on the pretext of use as a floating casino, then partially rebuilt and towed to China for completion. The "Liaoning" was commissioned on 25 September 2012, and began service for testing and training. On 24 or 25 November 2012, "Liaoning" successfully launched and recovered several Shenyang J-15 jet fighter aircraft. She is classified as a training ship, intended to allow the Navy to practice with carrier usage. On 26 December 2012, the People's Daily reported that it will take 4 to 5 years for "Liaoning" to reach full capacity, mainly due to training and coordination which will take significant amount of time for Chinese PLA Navy to complete as this is the first aircraft carrier in their possession. As it is a training ship, "Liaoning" is not assigned to any of China's operation fleets.
France.
Current.
1 CATOBAR carrier: "Charles de Gaulle" (R91) is a 42,000 tonne nuclear-powered aircraft carrier, commissioned in 2001 and is the flagship of the French Navy (Marine Nationale). The ship carries a complement of Dassault-Breguet Super Étendard, Dassault Rafale M and E‑2C Hawkeye aircraft, EC725 Caracal and AS532 Cougar helicopter for combat search and rescue, as well as modern electronics and Aster missiles. It is a CATOBAR-type carrier that uses two 75 m C13‑3 steam catapults of a shorter version of the catapult system installed on the U.S. "Nimitz" class carriers, one catapult at the bow and one across the front of the landing area.
3 Amphibious assault ships: "Mistral"-class, 21,500 tonne full deck amphibious assault ships with hospital and well deck.
India.
Current.
1 STOBAR carrier: , 45,400 tonnes, modified "Kiev"-class. The carrier was purchased by India on 20 January 2004 after years of negotiations at a final price of $2.35 billion. The ship successfully completed her sea trials in July 2013 and aviation trials in September 2013. She was formally commissioned on 16 November 2013 at a ceremony held at Severodvinsk, Russia.
1 STOVL carrier: : 28,700 tonne ex-British STOVL converted carrier HMS "Hermes" (launched 1953), purchased in 1986 and commissioned in 1987, scheduled to be decommissioned by 2016.
Future.
India started the construction of a 40,000-tonne, 260-metre-long "Vikrant"-class aircraft carrier in 2009. The new carrier will operate MiG-29K and naval HAL Tejas aircraft along with the Indian-made helicopter HAL Dhruv. The ship will be powered by four gas-turbine engines and will have a range of 8,000 nmi, carrying 160 officers, 1,400 sailors, and 30 aircraft. The carrier is being constructed by Cochin Shipyard. The ship was launched in August 2013 and is scheduled for commissioning in 2018.
A second "Vikrant"-class carrier INS Vishal with a displacement of over 65,000 tons is planned and likely to be nuclear-powered with CATOBAR system to launch heavier and unmanned combat aircrafts . The project was in design phase as of April 2015.
Italy.
Current.
2 STOVL carriers: 
Japan.
Current.
2 helicopter carrier ships:"Hyūga"-class helicopter destroyer 19,000 tons (full load) anti-submarine warfare carrier with enhanced command-and-control capabilities allowing them to serve as fleet flagships.
Future.
In August 2013, A launching ceremony for Japan's largest military ship since World War II was held in Yokohama on Tuesday, 6 August. The 820-foot-long, 19,500 tons (27,000 tons full load) flattop destroyer Izumo will be deployed in March 2015.
Russia.
Current.
1 STOBAR carrier: "Admiral Flota Sovetskovo Soyuza Kuznetsov": 55,000 tonne "Kuznetsov"-class STOBAR aircraft carrier. Launched in 1985 as "Tbilisi", renamed and operational from 1995. Without catapults she can launch and recover lightly fueled naval fighters for air defense or anti-ship missions but not heavy conventional bombing strikes. Officially designated an aircraft carrying cruiser, she is unique in carrying a heavy cruiser's complement of defensive weapons and large P-700 Granit offensive missiles. The P-700 systems will be removed in the coming refit to enlarge her below decks aviation facilities as well as upgrading her defensive systems.
Spain.
Current.
1 STOVL carrier: "Juan Carlos I" (L61): 27,000 tonne, Specially designed multipurpose strategic projection ship which can operate as an amphibious assault ship or STOVL carrier depending on mission requirement, has full facilities for both functions including a ski jump ramp, well deck, and vehicle storage area which can be used as additional hangar space, launched in 2008, commissioned 30 September 2010.
South Korea.
Current.
One Dokdo-class amphibious assault ship 18,860 ton full deck amphibious assault ship with hospital and well deck and facilities to serve as fleet flagship.
Future.
South Korea believes it can procure 2 light aircraft carriers by 2036, which will help make the ROKN a blue water navy.
Thailand.
Current.
1 Offshore helicopter support ship: HTMS "Chakri Naruebet" helicopter carrier: 11,400 tonne STOVL carrier based on Spanish "Príncipe de Asturias" design. Commissioned in 1997. The AV-8S Matador/Harrier STOVL fighter wing, mostly inoperable by 1999, was retired from service without replacement in 2006. Ship now used for royal transport, helicopter operations, and as a disaster relief platform.
United Kingdom.
Current.
One amphibious assault ship: HMS "Ocean". A 21,750 ton full deck amphibious assault ship based on the Invincible-class aircraft carrier hull but without facilities for fixed wing aviation.
Future.
The Royal Navy is constructing two new larger STOVL aircraft carriers, the "Queen Elizabeth" class, to replace the three "Invincible"-class carriers. The ships are HMS "Queen Elizabeth" and HMS "Prince of Wales". They will be able to operate up to 40 aircraft on peace time operations with a tailored group of up to 50, and will have a displacement of 70,600 tonnes. The ships are due to become operational from 2020. Their primary aircraft complement will be made up of F-35B Lightning IIs, and their ship's company will number around 680 with the total complement rising to about 1600 when the air group is embarked. The two ships will be the largest warships ever built for the Royal Navy.
United States.
Current.
10 CATOBAR carriers: "Nimitz" class: ten 101,000 ton nuclear-powered supercarriers, the first of which was commissioned in 1975. A "Nimitz"-class carrier is powered by two nuclear reactors and four steam turbines and is 1,092 ft long.
9 Amphibious assault ships:
Future.
The current US fleet of "Nimitz"-class carriers will be followed into service (and in some cases replaced) by the "Gerald R. Ford" class. It is expected that the ships will be more automated in an effort to reduce the amount of funding required to maintain and operate its supercarriers. The main new features are implementation of Electromagnetic Aircraft Launch System (EMALS) (which replace the old steam catapults) and unmanned aerial vehicles.
With the deactivation of the USS "Enterprise" in December 2012 (decommissioning scheduled for 2013), the U.S. fleet comprises 10 supercarriers. The House Armed Services Seapower subcommittee on 24 July 2007, recommended seven or maybe eight new carriers (one every four years). However, the debate has deepened over budgeting for the $12–14.5 billion (plus $12 billion for development and research) for the 100,000 ton "Gerald R. Ford"-class carrier (estimated service 2016) compared to the smaller $2 billion 45,000 ton "America"-class amphibious assault ships able to deploy squadrons of F-35Bs, of which two are already under construction and twelve are planned.
Further reading.
</dl>

</doc>
<doc id="2221" url="http://en.wikipedia.org/wiki?curid=2221" title="Apicomplexa">
Apicomplexa

The Apicomplexa (also called Apicomplexia) are a large phylum of parasitic protists. Most of them possess a unique form of organelle that comprises a type of plastid called an apicoplast, and an "apical complex" structure. The organelle is an adaptation that the organism applies in penetration of a host cell.
The Apicomplexa are unicellular and spore-forming. All species are obligate endoparasites of animals, except "Nephromyces", a symbiont in marine animals, originally classified as a chytrid fungus. Motile structures such as flagella or pseudopods are present only in certain gamete stages.
The Apicomplexa are a diverse group that includes organisms such as the coccidia, gregarines, piroplasms, haemogregarines, and plasmodia. The various members of the superphylum Apicomplexa cause a range of diseases, including:
and
The name of the taxon Apicomplexa derives from two Latin words — "apex" (top) and "complexus" (infolds) — and refers to a set of organelles in the sporozoite. The Apicomplexa comprise the bulk of what used to be called the Sporozoa, a group of parasitic protozoans, in general without flagella, cilia, or pseudopods. Most of the Apicomplexa are motile however, by use of a gliding mechanism
that uses adhesions and small static myosin motors.The other main lines were the Ascetosporea (now in Rhizaria), the Myxozoa (now known to be derived from animals), and the Microsporidia (now known to be derived from fungi). Sometimes, the name Sporozoa is taken as a synonym for the Apicomplexa, or occasionally as a subset.
General features of the Apicomplexa.
All members of this phylum have an infectious stage — the sporozoite — which possesses three distinct structures in an apical complex. The apical complex consists of a set of spirally arranged microtubules (the conoid), a secretory body (the rhoptry) and one or more polar rings. Additional slender electron-dense secretory bodies (micronemes) surrounded by one or two polar rings may also be present. This structure gives the phylum its name.
A further group of spherical organelles is distributed throughout the cell rather than being localized at the apical complex and are known as the dense granules. These typically have a mean diameter of about 0.7 μm. Secretion of the dense-granule content takes place after parasite invasion and localization within the parasitophorous vacuole and persists for several minutes.
Other morphological findings that are common to all members of this phylum include:
Replication:
Mobility:
Apicomplexans have a unique gliding capability which enables them to cross through tissues and enter and leave their host cells. This gliding ability is made possible by the use of adhesions and small static myosin motors.
Other features common to this phylum are a lack of cilia, sexual reproduction, use of micropores for feeding, and the production of oocysts containing sporozoites as the infective form.
Most apicomplexans have an apicoplast, (a nonphotosynthetic plastid) and mitochondrial and nuclear genomes, although "Cryptosporidium" species and gregarines are possible exceptions, as they are thought to have lost their plastids after the diverging last common ancestor of apicomplexans.
General features of the subgroups.
Within this phylum are three groups — coccidians, gregarines, and haemosporidians. The coccidians and gregarines appear to be relatively closely related.
"Perkinsus ", while once considered a member of this phylum, has been moved to a new phylum —Perkinsozoa.
Gregarines.
The gregarines are generally parasites of annelids, arthropods, and mollusks. They are often found in the guts of their hosts, but may invade the other tissues. In the typical gregarine lifecycle, a trophozoite develops within a host cell into a schizont. This then divides into a number of merozoites by schizogony. The merozoites are released by lysing the host cell, which in turn invade other cells. At some point in the apicomplexan lifecycle, gametocytes are formed. These are released by lysis of the host cells, which group together. Each gametocyte forms multiple gametes. The gametes fuse with another to form oocysts. The oocysts leave the host to be taken up by a new host.
Coccidians.
In general, coccidians are parasites of vertebrates. Like gregarines, they are commonly parasites of the epithelial cells of the gut, but may infect other tissues.
The coccidian lifecycle involves merogony, gametogony, and sporogony. While similar to that of the gregarines it differs in zygote formation. Some trophozoites enlarge and become macrogamete, whereas others divide repeatedly to form microgametes (anisogamy). The microgametes are motile and must reach the macrogamete to fertilize it. The fertilized macrogamete forms a zygote that in its turn forms an oocyst that is normally released from the body. Syzygy, when it occurs, involves markedly anisogamous gametes. The lifecycle is typically haploid, with the only diploid stage occurring in the zygote, which is normally short-lived.
The main difference between the coccidians and the gregarines is in the gamonts. In the coccida these are small, intracellular and without epimerites or mucrons. In the gregarines, these are large, extracellular, and possess epimerites or mucrons. A second difference between the coccidia and the gregarines also lies in the gamonts. In the coccidian, a single gamont becomes a macrogametocyte, whereas in the gregarines, the gamonts give rise to multiple gametocytes.
Haemosporidia.
The Haemosporidia have more complex lifecycles that alternate between an arthropod and a vertebrate host. The trophozoite parasitises erythrocytes or other tissues in the vertebrate host. Microgametes and macrogametes are always found in the blood. The gametes are taken up by the insect vector during a blood meal. The microgametes migrate within the gut of the insect vector and fuse with the macrogametes. The fertilized macrogamete now becomes an ookinete, which penetrates the body of the vector. The ookinete then transforms into an oocyst and divides initially by meiosis and then by mitosis (haplontic lifecycle) to give rise to the sporozoites. The sporozoites escape from the oocyst and migrate within the body of the vector to the salivary glands where they are injected into the new vertebrate host when the insect vector feeds again.
Reproduction and lifecycle.
Most members have a complex lifecycle, involving both asexual and sexual reproduction. Typically, a host is infected via an active invasion by the parasites (similar to entosis), which divide to produce sporozoites that enter its cells. Eventually, the cells burst, releasing merozoites, which infect new cells. This may occur several times, until gamonts are produced, forming gametes that fuse to create new cysts. Many variations occur on this basic pattern, however, and many Apicomplexa have more than one host.
The apical complex includes vesicles called rhoptries and micronemes, which open at the anterior of the cell. These secrete enzymes that allow the parasite to enter other cells. The tip is surrounded by a band of microtubules, called the polar ring, and among the Conoidasida is also a funnel of tubulin proteins called the conoid. Over the rest of the cell, except for a diminished mouth called the micropore, the membrane is supported by vesicles called alveoli, forming a semirigid pellicle.
The presence of alveoli and other traits place the Apicomplexa among a group called the alveolates. Several related flagellates, such as "Perkinsus" and "Colpodella", have structures similar to the polar ring and were formerly included here, but most appear to be closer relatives of the dinoflagellates. They are probably similar to the common ancestor of the two groups.
Another similarity is that many apicomplexan cells contain a single plastid, called the apicoplast, surrounded by either three or four membranes. Its functions are thought to include tasks such as lipid and heme biosynthesis, and it appears to be necessary for survival. In general, plastids are considered to have a common origin with the chloroplasts of dinoflagellates, and evidence points to an origin from red algae rather than green.
Parasitology and genomics.
Many of the apicomplexan parasites are important pathogens of human and domestic animals. In contrast to bacterial pathogens, these apicomplexan parasites are eukaryotic and share many metabolic pathways with their animal hosts. This makes therapeutic target development extremely difficult – a drug that harms an apicomplexan parasite is also likely to harm its human host. At present, no effective vaccines are available for most diseases caused by these parasites. Biomedical research on these parasites is challenging because it is often difficult, if not impossible, to maintain live parasite cultures in the laboratory and to genetically manipulate these organisms. In recent years, several of the apicomplexan species have been selected for genome sequencing. The availability of genome sequences provides a new opportunity for scientists to learn more about the evolution and biochemical capacity of these parasites. The predominant source of this genomic information is the EuPathDB family of websites, which currently provides specialised services for "Plasmodium" species (PlasmoDB), coccidians (ToxoDB), piroplasms (PiroplasmaDB), and "Cryptosporidium" species (CryptoDB). One possible target for drugs is the plastid, and in fact existing drugs such as tetracyclines, which are effective against apicomplexans, seem to operate against the plastid.
Blood-borne genera.
Within the Apicomplexa are three suborders of parasites: 
Within the Adelorina are species that infect invertebrates and others that infect vertebrates. The Eimeriorina — the largest suborder in this phylum — the lifecycle involves both sexual and asexual stages. The asexual stages reproduce by schizogony. The male gametocyte produces a large number of gametes and the zygote gives rise to an oocyst, which is the infective stage. The majority are monoxenous (infect one host only), but a few are heteroxenous (lifecycle involves two or more hosts).
The number of families in this later suborder is debated, with the number of families being between one and 20 depending on the authority and the number of genera being between 19 and 25.
Evolution.
All members of this phylum are parasitic and evolved from a free-living ancestor. This lifestyle is presumed to have evolved at the time of the divergence of dinoﬂagellates and apicomplexans. Further evolution of this phylum has been estimated to have occurred about million years ago. The oldest extant clade is thought to be the archigregarines.
Many Coccidiomorpha have an intermediate host, as well as a primary host, and the evolution of hosts proceeded in different ways and at different times in these groups. For some coccidiomorphs, the original host has become the intermediate host, whereas in others it has become the definitive host. In the genera "Aggregata", "Atoxoplasma", "Cystoisospora", "Schellackia", and "Toxoplasma", the original is now definitive, whereas in "Akiba", "Babesiosoma", "Babesia", "Haemogregarina", "Haemoproteus", "Hepatozoon", "Karyolysus", "Leucocytozoon", "Plasmodium", "Sarcocystis", and "Theileria", the original hosts are now intermediate.
Similar strategies to increase the likelihood of transmission have evolved in multiple genera. Polyenergid oocysts and tissue cysts are found in representatives of the orders Protococcidiorida and Eimeriida. Hypnozoites are found in "Karyolysus lacerate" and most species of "Plasmodium"; transovarial transmission of parasites occurs in lifecycles of "Karyolysus" and "Babesia".
Horizontal gene transfer appears to have occurred early on in this phylum's evolution with the transfer of a histone H4 lysine 20 (H4K20) modifier, Set8, from an animal host to the ancestor of apicomplexans. A second gene — H3K36 methyltransferase (Ashr3 in plants) — may have also be horizontally transferred.
Phylogenetic relations.
This has rarely been studied at the subclass level. The Haemosporidia are related to the gregarines and the piroplasms and coccidians are sister groups. The Haemosporidia and the Piroplasma appear to be sister clades and are more closely related to the coccidians than to the gregarines.
Transposons appear to be rare in this phylum, but have been identified in the genera "Ascogregarina" and "Eimeria".
Taxonomy.
History.
The first Apicomplexa protozoan was seen by Antonie van Leeuwenhoek, who in 1674 saw oocysts of "Eimeria stiedae" in the gall bladder of a rabbit. The first member of the phylum to be named (by Dufour in 1828) was "Gregarina ovata" in earwigs. Since then, many more have been identified and named. During 1826–1850, 41 species and six genera of Apicomplexa were named. In 1951–1975, 1873 new species and 83 new genera were added.
The older taxon Sporozoa was created by Leuckart in 1879 and adopted by Bütschli in 1880. Through history, it grouped with the current Apicomplexa many unrelated groups. For example, Kudo (1954) included in the Sporozoa species of the Ascetosporea (Rhizaria), Microsporidia (Fungi), Myxozoa (Animalia) and "Helicosporidium" (Chlorophyta), while Zierdt (1978) included the genus "Blastocystis" (Stramenopiles). Sporozoa is no longer regarded as biologically valid and its use is discouraged, although some authors still use it as a synonym for the Apicomplexa. More recently, other groups were excluded from Apicomplexa, e.g., "Perkinsus" and "Colpodella" (now in Protalveolata).
The field of classifying Apicomplexa is in flux and classification has changed throughout the years since it was formally named in 1970.
By 1987, a comprehensive survey of the phylum was completed: in all, 4516 species and 339 genera had been named. They consisted of:
Although considerable revision of this phylum has been done (the order Haemosporidia now has 17 genera rather than 9), these numbers seems likely to be still approximately correct.
Jacques Euzéby (1988).
Jacques Euzéby in 1988 created a new class Haemosporidiasina by merging subclass Piroplasmasina and suborder Haemospororina.
The division into Achromatorida and Chromatorida, although proposed on morphological grounds, may have a biological basis, as the ability to store haemozoin appears to have evolved only once.
Roberts and Janovy (1996).
Roberts and Janovy in 1996 divided the phylum into the following subclasses and suborders (omitting classes and orders):
These form the following five taxonomic groups:
Perkins (2000).
This scheme is taken from Perkins et al. It is outdated as the Perkinsidae have since been recognised as a sister group to the dinoflagellates rather that the Apicomplexia. The remainder of the scheme appears to be valid: 
The name Protospiromonadida has been proposed for the common ancestor of the Gregarinomorpha and Coccidiomorpha.

</doc>
<doc id="2222" url="http://en.wikipedia.org/wiki?curid=2222" title="Argentine cuisine">
Argentine cuisine

Argentine cuisine may be described as a cultural blending of Indigenous, Mediterranean influences (such as those created by Italian and Spanish populations) within the wide scope of livestock and agricultural products that are abundant in the country. Argentine annual consumption of beef has averaged 100 kg (220 lbs) per capita, approaching 180 kg (396 lbs) per capita during the 19th century; consumption averaged 67.7 kg (149 lbs) in 2007. Beyond "asado" (the Argentine barbecue), no other dish more genuinely matches the national identity. Nevertheless, the country's vast area, and its cultural diversity, have led to a local cuisine of various dishes. The great immigratory waves consequently imprinted a large influence in the Argentine cuisine, after all Argentina was the second country in the world with the most immigrants with 6.6 million, only second to the United States with 27 million, and ahead of other immigratory receptor countries such as Canada, Brazil, Australia, etc.
Argentine people have a reputation for their love of eating. Social gatherings are commonly centered on sharing a meal. Invitations to have dinner at home is generally viewed as a symbol of friendship, warmth, and integration. Sunday family dinner is considered the most significant meal of the week, whose highlights often include asado or pasta.
Another feature of Argentine cuisine is the preparation of homemade food such as french fries, patties, and pasta to celebrate a special occasion, to meet friends, or to honor someone. The tradition of locally preparing food is passed down from generation to generation, and homemade food is also seen as a way to show affection.
Argentine restaurants include a great variety of cuisines, prices, and flavors. Large cities tend to host everything from high-end international cuisine, to "bodegones" (inexpensive traditional hidden taverns), less stylish restaurants, and bars and canteens offering a range of dishes at affordable prices.
History.
Native Americans lived in Argentina thousands of years before the European explorers arrived. Members of an Indian tribe in the southern part of Argentina were farmers who grew squash, melons, and sweet potatoes. Spanish settlers came to Argentina in 1536. Between 1853 and 1955, 6.6 million immigrants came to live in Argentina from diverse sources such as Europe, the Near and Middle East, Russia and Japan, contributing to the development of Argentine cuisine and making Argentina the second country with most immigrants only second to the United States. Most of the immigrants were from Italy and Spain. The Italians introduced pizza, as well as a variety of pasta dishes, including spaghetti and lasagna. British, German, Jewish, and other immigrants also settled in Argentina, all bringing their styles of cooking and favorite foods with them. The British brought tea, starting the tradition of teatime. All of these cultures influenced the dishes of Argentina.
Typical foods.
Most regions of Argentina are known for their beef-oriented diet. In Argentina the Spanish term,""Carne", which means meat, is assumed to be beef in Argentina. In other Spanish-speaking countries—such as Spain—the term is usually qualified with the type of animal, such as "carne de vaca" (beef), "carne de cordero"" (lamb), etc.
Grilled meat from the "asado" (barbecue) is a staple, with steak and beef ribs especially common. The term asado itself refers to long strips of flank-cut beef ribs. Popular items such as "Chorizo" (pork sausage), "morcilla" (blood sausage), "chinchulines" (chitterlings), "mollejas" (sweetbread), and other parts of the animal are also enjoyed. In Patagonia, however, lamb and chivito (goat) are eaten more frequently than beef. Whole lambs and goats are traditionally cooked over an open fire in a technique known as asado a la estaca.
The most common condiment for asado is "Chimichurri", a sauce of herbs, garlic and vinegar. Unlike other preparations, Argentines do not include chili in their version of chimichurri.
Breaded and fried meats — "milanesas" — are used as snacks, in sandwiches, or eaten warm with mashed potatoes — "purée". "Empanadas" — small pastries of meat, cheese, sweet corn, and a hundred other fillings — are a common sight at parties and picnics, or as starters to a meal. A variation, the "empanada gallega" (Galician empanada), is a big, round meat pie made most commonly with tuna and mackerel ("caballa" in Spanish). Vegetables and salads are also eaten by Argentines; tomatoes, onions, lettuce, eggplants, squashes, and zucchini are common side dishes.
Italian staples, such as pizza and pasta, are eaten as commonly as beef. "Fideos" (noodles), "tallarines" ("fettucine" and "tagliatelle"), "ñoquis" (gnocchi), "ravioles", and "canelones" (cannelloni) can be bought freshly made in many establishments in the larger cities. Italian-style ice cream is served in large parlours and even drive-through businesses.
In Chubut, the Welsh community is known for its teahouses, offering scones and "torta galesa", which is rather like "torta negra".
"Sandwiches de miga" are delicate sandwiches made with crustless buttered white bread, very thinly sliced cured meat, cheese, and lettuce. They are often purchased from entrepreneurial home cooks and may be eaten for a light evening meal.
A sweet paste, "dulce de leche" is another treasured national food, used to fill cakes and pancakes, spread over toasted bread for breakfast, or served with ice cream. "Alfajores" are shortbread cookies sandwiched together with chocolate and "dulce de leche" or a fruit paste. The "policeman's" or "truck driver's" sweet is cheese with quince paste or "dulce de membrillo". "Dulce de batata" is made of sweet potato/yam: this with cheese is the "Martín Fierro"'s sweet. Apples, pears, peaches, kiwifruits, avocados, and plums are major exports.
A traditional drink of Argentina is an infusion called mate (in Spanish, "mate", with the accent on the first syllable [MAH-teh]). The name comes from the hollow gourd from which it is traditionally drunk. The mate (gourd) or other small cup is filled about three-quarters full with "yerba mate", the dried leaves and twigs of the "Ilex paraguariensis". The drink, which is rather bitter, is sipped through a metal or cane straw called a "bombilla". Mate can be sweetened with sugar, or flavored with aromatic herbs or dried orange peel. Hot but not boiling water is poured into the gourd, drunk, then the mate is refilled. The mate is nearly full of leaves, so each refill only makes a small drink, but many refills are possible before the yerba is spent. In small gatherings it is traditional for one "mate" to be passed from person to person, filled by whoever has the kettle. It is customary not to thank the refiller routinely; a final "gracias" (thank you) implies that the drinker has had enough. Drinking mate together is an important social ritual. "Mate cocido" is the same leaf, which rather than brewed is boiled and served, like tea, with milk and sugar to taste.
Other typical drinks include wine (sometimes with soda water added); tea and coffee are equally important. Quilmes is the national brand of pale lager, named after the town of Quilmes, Buenos Aires, where it was first produced.
Regional differences.
Argentine cuisine is heavily influenced by its European roots and has regional variations. "Asado", "dulce de leche", "empanadas", and "yerba mate" are found throughout Argentina. In many parts of the country, food is prepared differently and different kinds of foods are made; this includes to a smaller degree food from pre-Columbian times, as in the Northwest.
Central region and las Pampas.
For long periods, urban areas such as Buenos Aires, Rosario, and Córdoba welcomed European immigrants, including, above all, those of Italian and Spanish descent. Nevertheless, there was also a migratory flow of German, Swiss, and Middle-Eastern immigrants arriving in Argentina. Among the countless changes this melting pot brought was the enrichment of the culinary art. Dishes such as pasta, pizza, pucheros (stews), croquetas (fritter)s, sauces, embutidos (sausages), and chicken and meat courses brought a wider scope of options to daily menus. Furthermore, the bread-making, dessert, pastry, and dairy industries have achieved considerable development in this region.
The above-mentioned dishes have developed a distinctively Argentine nuance. That is why, for example, Argentine pasta includes a wide variety of dishes ranging from spaghetti, fusiles (fusilli), ñoquis (gnocchi), ravioli, cintas (pasta ribbons), and lasagne to the Argentine-made sorrentinos, agnolottis (agnolotti), canelones (cannelloni), and fetuchines (fetuchini).
Pizza—made with very thin, and sometimes thick, high-rising doughs, with or without cheese, cooked in the oven or "a la piedra" (on a stone oven), and stuffed with numerous ingredients -— is a dish which can be found in nearly every corner of the country. Buenos Aires, Rosario, and Córdoba also serve it with fainá, which is a chick pea-flour dough placed over the piece of pizza. People say that what makes the Argentine pizza unique is the blending of Italian and Spanish cultures. At the turn of the 19th century, immigrants from Naples and Genoa opened the first pizza bars, though Spanish residents subsequently owned most of the pizza businesses.
Bread products are consumed all around the country. The deeply rooted bread, pastry, and dessert-making tradition derives from blending the above nationalities' products. Bakeries sell not only a wide scope of breads, cookies, and cakes, but also pastries. The latter resembles a sort of roll pastry whose main dough ingredient is either butter or fat and which may be simple or stuffed with dulce de leche, milk, jam, crema pastelera, or quince or apple jelly, among other fillings. The most popular type of pastry is said to be that of "medialunas", based upon French croissants. Furthermore, sandwiches de miga are another type of bread products; they are made only with thin layers of white bread (generally referred to as crustless bread) and stuffed with food items ranging from ham and cheese to other more sophisticated combinations such as raw ham, tomatoes, olives, hard boiled eggs, tuna, lettuce, red pepper, and the like.
Desserts and sweets are usually stuffed or covered with dulce de leche. The latter can be eaten alone or on top of cakes, alfajores, panqueques (creppes), and pastries, or as a topping spread over flan. Chantilly cream is widely consumed and used in preparing sweets and desserts. Additionally, cakes, sponge cakes, and puddings are very popular dishes. Italian ice-creams in this region also achieved a significant degree of development by adding local flavors that somehow preserved the local spirit involved in their preparation.
Although asado is eaten all over the country, its origin may be traced back to the Pampas. It entails manifold types of meat, which are generally eaten as follows: achuras (offal, or the cow's inner parts), morcilla (blood sausage), and sometimes also a provoleta (a piece of provolone cheese cooked on the grill with oregano) are eaten first. Then comes the choripán (a kind of spiced sausage made with pork or lamb and placed between two slices of bread), and lastly meat such as asado de tira, vacío (hindquarter), lomo (tenderloin), colita de cuadril (rump), matambre (rolled stuffed steak cut into slices and served cold), entraña (innards); the list is never-ending. It is quite common to eat and enjoy a dish known as "cabrito al asador" (roast kid or goat) in the province of Córdoba.
Northwest and Cuyo.
This region is regarded as perhaps the one most influenced by native Indians, and its foods are closely linked to the Andean-Incan tradition. When preparing regional dishes, potatoes and corn or wheat are almost always used, including quinoa (a cereal typically used in Incan cuisine), peppers, squashes and tomatoes. The most celebrated dishes are humita and tamal, in which the corn husk is stuffed with the corn filling itself, seasonings or meat.
This region is the most suitable to taste empanadas, particularly those stuffed with meat and offering different types of tempting varieties such as the "meat empanada", salteña also filled with potatoes, or the "empanada tucumana", which is stuffed with matambre and cut with a knife, or empanadas made with cheese. Empanadas are indibn sized and closed savoury pastries which may be fried or baked in the oven and are generally eaten with the hands.
Stews such as locro, carbonada and cazuelas (casseroles) are also typical dishes characterizing this region, which also include pumpkin or potato pudding stuffed with meat.
Many of the sweets produced in this region, such as quince, sweet potato, molasses and cayote jams, have given rise to a very well known and easily made dessert referred to as "vigilante", or to so-called "queso y dulce" (where a piece of fresh cheese is served with one of the sweets mentioned above).
Mesopotamia.
The humid and verdant area of north-east Argentina known as Mesopotamia, comprising the provinces of Misiones, Entre Ríos and Corrientes. is another area influenced by native Indians, particularly by the Guaraní tribe. Abounding in rivers and shores, it offers a wide diversity of fish species, such as dorado, pacú, surubi, boga and silverside.
Widely grown in this area, cassava is typically included in the region's dishes, as are other components of meals, such as the chipá (a cassava and cheese bread), which originally came from Paraguay. Sopa Paraguaya and Chipá Guazu are also commonly eaten. As regards products made with sugar, Papaya (mamón in Argentine Spanish) jam is typical of the province of Corrientes.
The principal product of this region is certainly yerba mate. Consumed countrywide, this product features a peculiarity of its own in this area: it is not only prepared with hot water, but, driven by the region's high temperatures, it is common to see it prepared with cold water as well, in which case the beverage is known as tereré.
Patagonia.
Foods produced in the large southern region of Patagonia include fish and seafood from the sea and rivers, and the products of the sheep widely farmed there.
Marine species such as salmon, spider crabs, squid and other shellfish and molluscs may be caught in the Atlantic Ocean. There are trout in the rivers.
The many berries grown in the area include cherries, bilberries, strawberries, rosa mosqueta and elders, which are made into jams.
The Northern and Central European settlements in this region have built up large-scale production of chocolate and its by-products. Viennese and German cuisine and pastries are also typically associated with this region.
Mutton and lamb, together with wild boar and venison tend to make up the region's meat-based dishes. Also typical of southern region are smoked products, including salmon, stag, wild boar, and pheasant.
Patagonia has been profound influenced by the tribes living there since long before Europeans arrived, in particular, the Mapuches and the Araucanos. A typical dish prepared by the latter is the curanto (a term meaning "hot stone"). Its preparation involves making a fire in a hole about 150 cm deep in the ground, and heating stones in it. A bed of nalca or maqui leaves is arranged on top of the stones, and ingredients are added in turn on top. Ingredients vary, but may include beef, lamb, pork, chicken, Argentine chorizos (pork sausages), potatoes, sweet potatoes, apples and holed squashes filled with cheese, cream and peas. The food is covered with leaves and damp pieces of cloth to keep the heat in, and covered with plenty of soil.
Alcoholic beverages.
Though wine ("vino") has traditionally been the most popular alcoholic beverage in Argentina, beer ("cerveza"; the Italian "birra" is frequently used) in recent decades has competed with wine in popularity. Breweries appeared in Argentina at the end of the 1860s, started by Alsatian colonists. The first were nearly all in the downtown of Buenos Aires ("el égido de la Ciudad Autónoma de Buenos Aires"), and soon Polish brewers began industrial production of beer: San Carlos in the province of Santa Fe, Río Segundo and Córdoba in the province of Córdoba, Quilmes and Lavallol on the outskirts of La Plata (in Buenos Aires Province), San Miguel de Tucumán in the province of Tucumán and on the outskirts of the cities of Mendoza and Salta.
The local consumption of beer has risen dramatically in the last generation: Argentines consumed 233 million liters in 1980 and 1.57 billion in 2007 (40 liters per capita). Outpacing that of wine since 2001, the growing production and consumption of beer has supported the existence of related events, for example beer festivals called "Oktoberfests" or "Fiestas de la Cerveza" in locations that have a significant German population (Villa General Belgrano in Córdoba, San Carlos and Esperanza in the province of Santa Fe, etc.). Such celebrations copy, in an Argentine manner, Munich's "Oktoberfest", and similarly are tourist attractions. However, the presence of a vigorous population of Celtic lineage, principally of Irish origin, has supported the creation of other celebrations of beer, often for marketing purposes, such as Saint Patrick's Day ("Día de San Patricio"), patron of Ireland, which is celebrated with abundant libations.
The consumption of alcoholic beverages in Argentina is similar to that of the United States and somewhat lower than the Western European average. Argentines enjoy a variety of alcoholic beverages and Argentina can boast a varied array of "elaboraciones", whether industrial or artisanal. Besides beer and wine, Argentines frequently drink cider (here again, the heritage comes from Spain and Italy, more precisely from Asturias and Campania). Cider is the most popular beverage of the middle and lower economic classes at Christmas and New Year (the upper classes proverbially preferring to celebrate with locally produced champagne, although real old-line "creole" aristocrats will still drink cider, which is much more traditional).
Other widely consumed spirits are "aguardiente" (firewater) made from sugar cane, known as "caña quemada" ("burnt cane") or, simply, 'caña' ("cane"). A folkloric note about "caña quemada": until June 21 it is traditional to drink "caña quemada" with "ruda macho" (a variant of common rue), it is supposed that this mixture prevents the flu and other illnesses. "Caña" competes, mainly in rural areas, with gin ("ginebra"—as in the Dutch kind of gin.)
There are many artisanally produced liqueurs (distilled, flavored alcoholic beverages) in Argentina, for example those flavored with orange, egg, anise, coffee, cherry and, inevitably, "dulce de leche". The "Hesperidina" is a type of liqueur made from orange peels, invented in Argentina around 1890. One may also encounter "chitronchelo" or (in Italian) "citroncello", based on lemon. This beverage arrived with immigrants from the Mezzogiorno, and is produced both artisanally and industrially (for example, at Mar del Plata).
Non-alcoholic specialties.
Argentines enjoy a wide variety of non-alcoholic infusions (although now and then both "families" are mixed; the "yerbiao" for example, is mate mixed with "caña" or gin). Among these, "mate" has long been the most widely enjoyed; in 2006, over 700,000 metric tons were harvested in Argentina, mostly for domestic consumption.
The fact that mate is so prevalent in the "Southern Cone", however, should not necessarily make visitors think that other infusions are rare in the region; in Argentina especially, given the strong European cultural imprint, the consumption of coffee is very common (141 cups per capita, annually). Chocolate infusions are also popular (the eating of chocolate is a Spanish influence, although the plant originated in Mesoamerica). This consumption grows during autumn and winter, or in the cold regions of the country; there are two dates where consumption of chocolate infusions is traditional in the primary educational centres: 25 May and 9 July, that is, the two national dates of Argentina.
English cultural influence (reinforced at the end of the 19th century and beginnings of the 20th by British contacts with the Far East) has also made the consumption of tea very common.
Medicinal herbs are common in the whole country; among the most popular are: chamomile, lanceleaf, "boldo", "poleo", "peperina", "carqueja", thyme, "canchalagua", rue ("macho" and "hembra", that is, "male" and "female"), mallow, rosemary, passion flower, "bira bira", "palán palán", "muña muña", to mention only the main ones. Many of these herbs are also used in apéritifs and bitters, whether alcoholic or not.
Popular short-order dishes.
Common "restoranes" or "restaurantes" and "rotiserias" (grill restaurants) nearly anywhere in Argentina today serve (into the small hours) quickly prepared meals that in the course of the 20th century came to be known as "minutas", "short-order dishes." Some of the dishes included in the category of "minutas" are "milanesas", "churrascos", "bifes" (beefsteaks), "escalopes", "tallarines", "ravioles" (ravioli), "ñoquis" (gnocchi), although some are very typical of locations that sell food: ""bifes" and "milanesas" are served "a caballo"" ("on horseback", with fried egg on top), ""milanesa completa" (a "milanesa" with two fried eggs and French fries), "revuelto Gramajo", "colchón de arvejas" (an omelette made with peas), "suprema de pollo" (chicken supreme, usually breaded as a "milanesa"), "matambres", "lengua a la vinagreta"" (pickled tongue), and "sandwiches" (sandwiches de miga) are made with sliced white bread, rather than, say, rolls).
The most common sandwiches are those made of "milanesa", baked ham and cheese, 'pan de miga", toast, "pebetes", "panchos" (hot dogs), "choripanes", "morcipanes", etc.; from Montevideo comes a different species of sandwich called the "chivito", even though it contains no goat meat.
"Picadas", which are consumed at home or in bars, cafés, ""cafetines" and "bodegones" are also popular; they consist of an ensemble of plates containing cubes of cheese (typically from Mar del Plata or Chubut), pieces of salame, olives in brine, french fries, "maníes" (peanuts), etc.; "picada"s are eaten accompanied by an alcoholic beverage ("fernet"", beer, wine with soda, to give some common examples).
The people of Argentina greatly enjoy "helado" (ice cream or sorbet). In Spanish colonial times a type of sorbet was made from hail or snow.
Eating habits.
In most parts of Argentina, lunch is the largest meal of the day. Excluding the largest cities, such as Buenos Aires, most towns close for lunch time. This is when most people return home to enjoy a large meal. Traditional lunches in Argentina are long and well developed. As such, it's common to not eat dinner until 10 at night.

</doc>
<doc id="2224" url="http://en.wikipedia.org/wiki?curid=2224" title="April 8">
April 8

April 8 is the day of the year in the Gregorian calendar.

</doc>
<doc id="2226" url="http://en.wikipedia.org/wiki?curid=2226" title="Ad hominem">
Ad hominem

An ad hominem (Latin for "to the man" or "to the person"), short for argumentum ad hominem, means responding to arguments by attacking a person's character, rather than to the content of their arguments. When used inappropriately, it is a fallacy in which a claim or argument is dismissed on the basis of some irrelevant fact or supposition about the author or the person being criticized. "Ad hominem" reasoning is not always fallacious, for example, when it relates to the credibility of statements of fact or when used in certain kinds of moral and practical reasoning.
Fallacious "ad hominem" reasoning is normally categorized as an informal fallacy, more precisely as a genetic fallacy, a subcategory of fallacies of irrelevance.
"Ad hominem" arguments are the converse of appeals to authority, and may be used in response to such appeals, for example, by pointing to the feet of clay of the authority being pointed to.
Types.
Abusive.
Abusive "ad hominem" usually involves attacking the traits of an opponent as a means to invalidate their arguments. Equating someone's character with the soundness of their argument is a logical fallacy.
"Ad hominem" abuse is not to be confused with slander or libel, which employ falsehoods and are not necessarily leveled to undermine otherwise sound stands with character attacks.
Tu quoque.
"Ad hominem tu quoque" (literally: "You also") refers to a claim that the source making the argument has spoken or acted in a way inconsistent with the argument. In particular, if Source A criticizes the actions of Source B, a "tu quoque" response is that Source A has acted in the same way. This argument is false because it does not disprove the premise; if the premise is true then Source A may be a hypocrite, but this does not make the statement less credible from a logical perspective. Indeed, Source B may be in a position to provide personal testimony to support the argument.
For example, a father may tell his son not to start smoking as he will regret it when he is older, and the son may point out that his father is or was a smoker. This does not alter the fact that his son may regret smoking when he is older.
Circumstantial.
"Ad hominem circumstantial" points out that someone is in circumstances such that they are disposed to take a particular position. "Ad hominem" circumstantial constitutes an attack on the bias of a source. This is fallacious because a disposition to make a certain argument does not make the argument false; this overlaps with the genetic fallacy (an argument that a claim is incorrect due to its source).
The circumstantial fallacy applies only where the source taking a position is only making a logical argument from premises that are generally accepted. Where the source seeks to convince an audience of the truth of a premise by a claim of authority or by personal observation, observation of their circumstances may reduce the evidentiary weight of the claims, sometimes to zero.
Examples:
1. Mandy Rice-Davies's famous testimony during the Profumo Affair, "He would [say that], wouldn't he?", is an example of a valid circumstantial argument. Her point was that a man in a prominent position, accused of an affair with a callgirl, would deny the claim whether it was true or false. His denial, in itself, provides little evidence against the claim of an affair. Note, however, that this argument is valid only insofar as it devalues the denial; it does "not" bolster the original claim. To construe invalid evidence of the denial as valid evidence of the original claim is fallacious (on several different bases, including that of "argumentum ad hominem"); however likely the man in question would be to deny an affair that did in fact happen, he is no less likely to deny an affair that never happened.
2. Glassner suggests that Bennett is somehow unqualified to criticize rap music because of positions Bennett has taken on other issues. However wrong Bennett may have been on other issues, such as the funding of public television or illegitimacy, that does not mean that his criticisms of rap were mistaken.
3. Consider the following circumstance as a clear case of an "ad hominem" argument: "David Duke says that white people are victims of police brutality just as often as black people... but honestly, would you believe a claim made by a racist?"
Guilt by association.
Guilt by association can sometimes also be a type of "ad hominem" fallacy if the argument attacks a source because of the similarity between the views of someone making an argument and other proponents of the argument.
This form of the argument is as follows:
An example of this fallacy could be "My opponent for office just received an endorsement from the Puppy Haters Association. Is that the sort of person you would want to vote for?"
Ad feminam.
"Ad feminam" is defined as appealing to irrelevant considerations about women, in particular, prejudices against them or stereotypes about them, rather than giving an answer to the contentions they made. Merriam-Webster attests the usage of the term since 1963.
Types of "ad hominem" reasoning.
When an "ad hominem" argument is made against a statement, it is important to draw a distinction whether the statement in question was "an argument" or "a statement of fact" ("testimony"). In the latter case the issues of the credibility of the person making the statement may be crucial.
Doug Walton, Canadian academic and author, has argued that "ad hominem" reasoning is not always fallacious, and that in some instances, questions of personal conduct, character, motives, etc., are legitimate and relevant to the issue, as when it directly involves hypocrisy, or actions contradicting the subject's words.
The philosopher Charles Taylor has argued that "ad hominem" reasoning is essential to understanding certain moral issues, and contrasts this sort of reasoning with the apodictic reasoning of philosophical naturalism.
External links.
Today, your boobs are pink!
What the fuckin' bitch you are!

</doc>
<doc id="2230" url="http://en.wikipedia.org/wiki?curid=2230" title="Analysis of algorithms">
Analysis of algorithms

In computer science, the analysis of algorithms is the determination of the amount of resources (such as time and storage) necessary to execute them. Most algorithms are designed to work with inputs of arbitrary length. Usually, the efficiency or running time of an algorithm is stated as a function relating the input length to the number of steps (time complexity) or storage locations (space complexity).
Algorithm analysis is an important part of a broader computational complexity theory, which provides theoretical estimates for the resources needed by any algorithm which solves a given computational problem. These estimates provide an insight into reasonable directions of search for efficient algorithms.
In theoretical analysis of algorithms it is common to estimate their complexity in the asymptotic sense, i.e., to estimate the complexity function for arbitrarily large input. Big O notation, Big-omega notation and Big-theta notation are used to this end. For instance, binary search is said to run in a number of steps proportional to the logarithm of the length of the list being searched, or in O(log(n)), colloquially "in logarithmic time". Usually asymptotic estimates are used because different implementations of the same algorithm may differ in efficiency. However the efficiencies of any two "reasonable" implementations of a given algorithm are related by a constant multiplicative factor called a "hidden constant".
Exact (not asymptotic) measures of efficiency can sometimes be computed but they usually require certain assumptions concerning the particular implementation of the algorithm, called model of computation. A model of computation may be defined in terms of an abstract computer, e.g., Turing machine, and/or by postulating that certain operations are executed in unit time.
For example, if the sorted list to which we apply binary search has "n" elements, and we can guarantee that each lookup of an element in the list can be done in unit time, then at most log2 "n" + 1 time units are needed to return an answer.
Cost models.
Time efficiency estimates depend on what we define to be a step. For the analysis to correspond usefully to the actual execution time, the time required to perform a step must be guaranteed to be bounded above by a constant. One must be careful here; for instance, some analyses count an addition of two numbers as one step. This assumption may not be warranted in certain contexts. For example, if the numbers involved in a computation may be arbitrarily large, the time required by a single addition can no longer be assumed to be constant.
Two cost models are generally used:
The latter is more cumbersome to use, so it's only employed when necessary, for example in the analysis of arbitrary-precision arithmetic algorithms, like those used in cryptography.
A key point which is often overlooked is that published lower bounds for problems are often given for a model of computation that is more restricted than the set of operations that you could use in practice and therefore there are algorithms that are faster than what would naively be thought possible.
Run-time analysis.
Run-time analysis is a theoretical classification that estimates and anticipates the increase in "running time" (or run-time) of an algorithm as its "input size" (usually denoted as "n") increases. Run-time efficiency is a topic of great interest in computer science: A program can take seconds, hours or even years to finish executing, depending on which algorithm it implements (see also performance analysis, which is the analysis of an algorithm's run-time in practice).
Shortcomings of empirical metrics.
Since algorithms are platform-independent (i.e. a given algorithm can be implemented in an arbitrary programming language on an arbitrary computer running an arbitrary operating system), there are significant drawbacks to using an empirical approach to gauge the comparative performance of a given set of algorithms.
Take as an example a program that looks up a specific entry in a sorted list of size "n". Suppose this program were implemented on Computer A, a state-of-the-art machine, using a linear search algorithm, and on Computer B, a much slower machine, using a binary search algorithm. Benchmark testing on the two computers running their respective programs might look something like the following:
Based on these metrics, it would be easy to jump to the conclusion that "Computer A" is running an algorithm that is far superior in efficiency to that of "Computer B". However, if the size of the input-list is increased to a sufficient number, that conclusion is dramatically demonstrated to be in error:
Computer A, running the linear search program, exhibits a linear growth rate. The program's run-time is directly proportional to its input size. Doubling the input size doubles the run time, quadrupling the input size quadruples the run-time, and so forth. On the other hand, Computer B, running the binary search program, exhibits a logarithmic growth rate. Quadrupling the input size only increases the run time by a constant amount (in this example, 50,000 ns). Even though Computer A is ostensibly a faster machine, Computer B will inevitably surpass Computer A in run-time because it's running an algorithm with a much slower growth rate.
Orders of growth.
Informally, an algorithm can be said to exhibit a growth rate on the order of a mathematical function if beyond a certain input size "n", the function "f(n)" times a positive constant provides an upper bound or limit for the run-time of that algorithm. In other words, for a given input size "n" greater than some "n0" and a constant "c", the running time of that algorithm will never be larger than "c × f(n)". This concept is frequently expressed using Big O notation. For example, since the run-time of insertion sort grows quadratically as its input size increases, insertion sort can be said to be of order "O(n²)".
Big O notation is a convenient way to express the worst-case scenario for a given algorithm, although it can also be used to express the average-case — for example, the worst-case scenario for quicksort is "O(n²)", but the average-case run-time is "O(n log n)".
Empirical orders of growth.
Assuming the execution time follows power rule, "t ≈ k na", the coefficient "a" can be found by taking empirical measurements of run time formula_1 at some problem-size points formula_2, and calculating formula_3 so that formula_4. In other words, this measures the slope of the empirical line on the log–log plot of execution time vs. problem size, at some size point. If the order of growth indeed follows the power rule (and so the line on log–log plot is indeed a straight line), the empirical value of "a" will stay constant at different ranges, and if not, it will change (and the line is a curved line) - but still could serve for comparison of any two given algorithms as to their "empirical local orders of growth" behaviour. Applied to the above table:
It is clearly seen that the first algorithm exhibits a linear order of growth indeed following the power rule. The empirical values for the second one are diminishing rapidly, suggesting it follows another rule of growth and in any case has much lower local orders of growth (and improving further still), empirically, than the first one.
Evaluating run-time complexity.
The run-time complexity for the worst-case scenario of a given algorithm can sometimes be evaluated by examining the structure of the algorithm and making some simplifying assumptions. Consider the following pseudocode:
 1 "get a positive integer from input"
 2 if n > 10
 3 print "This might take a while..."
 4 for i = 1 to n
 5 for j = 1 to i
 6 print i * j
 7 print "Done!"
A given computer will take a discrete amount of time to execute each of the instructions involved with carrying out this algorithm. The specific amount of time to carry out a given instruction will vary depending on which instruction is being executed and which computer is executing it, but on a conventional computer, this amount will be deterministic. Say that the actions carried out in step 1 are considered to consume time T1, step 2 uses time T2, and so forth.
In the algorithm above, steps 1, 2 and 7 will only be run once. For a worst-case evaluation, it should be assumed that step 3 will be run as well. Thus the total amount of time to run steps 1-3 and step 7 is:
The loops in steps 4, 5 and 6 are trickier to evaluate. The outer loop test in step 4 will execute ( n + 1 )
times (note that an extra step is required to terminate the for loop, hence n + 1 and not n executions), which will consume T4( n + 1 ) time. The inner loop, on the other hand, is governed by the value of i, which iterates from 1 to i. On the first pass through the outer loop, j iterates from 1 to 1: The inner loop makes one pass, so running the inner loop body (step 6) consumes T6 time, and the inner loop test (step 5) consumes 2T5 time. During the next pass through the outer loop, j iterates from 1 to 2: the inner loop makes two passes, so running the inner loop body (step 6) consumes 2T6 time, and the inner loop test (step 5) consumes 3T5 time.
Altogether, the total time required to run the inner loop body can be expressed as an arithmetic progression:
which can be factored as
The total time required to run the outer loop test can be evaluated similarly:
which can be factored as
Therefore the total running time for this algorithm is:
which reduces to
As a rule-of-thumb, one can assume that the highest-order term in any given function dominates its rate of growth and thus defines its run-time order. In this example, n² is the highest-order term, so one can conclude that f(n) = O(n²). Formally this can be proven as follows:Prove that formula_13
formula_14
formula_15 ("for n ≥ 0")
Let k be a constant greater than or equal to [T1..T7]
formula_16
formula_17 ("for n ≥ 1") formula_18
Therefore formula_19 for formula_20
A more elegant approach to analyzing this algorithm would be to declare that [T1..T7] are all equal to one unit of time, in a system of units chosen so that one unit is greater than or equal to the actual times for these steps. This would mean that the algorithm's running time breaks down as follows:formula_21 ("for n ≥ 1") formula_22
Growth rate analysis of other resources.
The methodology of run-time analysis can also be utilized for predicting other growth rates, such as consumption of memory space. As an example, consider the following pseudocode which manages and reallocates memory usage by a program based on the size of a file which that program manages:
 while ("file still open")
 let n = "size of file"
 for "every 100,000 kilobytes of increase in file size"
 "double the amount of memory reserved"
In this instance, as the file size n increases, memory will be consumed at an exponential growth rate, which is order O(2n). This is an extremely rapid and most likely unmanageable growth rate for consumption of memory resources.
Relevance.
Algorithm analysis is important in practice because the accidental or unintentional use of an inefficient algorithm can significantly impact system performance. In time-sensitive applications, an algorithm taking too long to run can render its results outdated or useless. An inefficient algorithm can also end up requiring an uneconomical amount of computing power or storage in order to run, again rendering it practically useless.
Constant factors.
Analysis of algorithms typically focuses on the asymptotic performance, particularly at the elementary level, but in practical applications constant factors are important, and real-world data is in practice always limited in size. The limit is typically the size of addressable memory, so on 32-bit machines 232 = 4 GiB (greater if segmented memory is used) and on 64-bit machines 264 = 16 EiB. Thus given a limited size, an order of growth (time or space) can be replaced by a constant factor, and in this sense all practical algorithms are O(1) for a large enough constant, or for small enough data.
This interpretation is primarily useful for functions that grow extremely slowly: (binary) iterated logarithm (log*) is less than 5 for all practical data (265536 bits); (binary) log-log (log log "n") is less than 6 for virtually all practical data (264 bits); and binary log (log "n") is less than 64 for virtually all practical data (264 bits). An algorithm with non-constant complexity may nonetheless be more efficient than an algorithm with constant complexity on practical data if the overhead of the constant time algorithm results in a larger constant factor, e.g., one may have formula_23 so long as formula_24 and formula_25.
For large data linear or quadratic factors cannot be ignored, but for small data an asymptotically inefficient algorithm may be more efficient. This is particularly used in hybrid algorithms, like Timsort, which use an asymptotically efficient algorithm (here merge sort, with time complexity formula_26), but switch to an asymptotically inefficient algorithm (here insertion sort, with time complexity formula_27) for small data, as the simpler algorithm is faster on small data.

</doc>
<doc id="2233" url="http://en.wikipedia.org/wiki?curid=2233" title="Ælle of Sussex">
Ælle of Sussex

Ælle (; also Aelle or Ella) is recorded in early sources as the first king of the South Saxons, reigning in what is now called Sussex, England, from 477 to perhaps as late as 514. 
According to the "Anglo-Saxon Chronicle", Ælle and three of his sons are said to have landed at a place called Cymensora and fought against the local Britons. The chronicle goes on to report a victory in 491, at present day Pevensey, where the battle ended with the Saxons slaughtering their opponents to the last man. 
Ælle was the first king recorded by the 8th century chronicler Bede to have held "imperium", or overlordship, over other Anglo-Saxon kingdoms. In the late 9th-century "Anglo-Saxon Chronicle" (around four hundred years after his time) Ælle is recorded as being the first bretwalda, or "Britain-ruler", though there is no evidence that this was a contemporary title. Ælle's death is not recorded and although he may have been the founder of a South Saxon dynasty, there is no firm evidence linking him with later South Saxon rulers. The 12th-century chronicler Henry of Huntingdon produced an enhanced version of the "Anglo-Saxon Chronicle" that included 514 as the date of Ælle's death, but this is not secure.
Historical context.
Historians are divided on the detail of Ælle's life and existence as it was during the least-documented period in English history of the last two millennia.
By the early 5th century Britain had been Roman for over three hundred and fifty years. The most troublesome enemies of Roman Britain were the Picts of central and northern Scotland, and the Gaels known as Scoti, who were raiders from Ireland. Also vexatious were the Saxons, the name Roman writers gave to the peoples who lived in the northern part of what is now Germany and the southern part of the Jutland peninsula. Saxon raids on the southern and eastern shores of England had been sufficiently alarming by the late 3rd century for the Romans to build the Saxon Shore forts, and subsequently to establish the role of the Count of the Saxon Shore to command the defence against these incursions. Roman control of Britain finally ended in the early part of the 5th century; the date usually given as marking the end of Roman Britain is 410, when the Emperor Honorius sent letters to the British, urging them to look to their own defence. Britain had been repeatedly stripped of troops to support usurpers' claims to the Roman empire, and after 410 the Roman armies never returned.
Sources for events after this date are extremely scarce, but a tradition, reported as early as the mid-6th century by a British priest named Gildas, records that the British sent for help against the barbarians to Aetius, a Roman consul, probably in the late 440s. No help came. Subsequently, a British leader named Vortigern is supposed to have invited continental mercenaries to help fight the Picts who were attacking from the north. The leaders, whose names are recorded as Hengest and Horsa, rebelled, and a long period of warfare ensued. The invaders—Angles, Saxons, Jutes, and Frisians—gained control of parts of England, but lost a major battle at Mons Badonicus (the location of which is not known). Some authors have speculated that Ælle may have led the Saxon forces at this battle, while others reject the idea out of hand.
The British thus gained a respite, and peace lasted at least until the time Gildas was writing: that is, for perhaps forty or fifty years, from around the end of the 5th century until midway through the sixth. Shortly after Gildas's time the Anglo-Saxon advance was resumed, and by the late 6th century nearly all of southern England was under the control of the continental invaders.
Early sources.
There are two early sources that mention Ælle by name. The earliest is "The Ecclesiastical History of the English People", a history of the English church written in 731 by Bede, a Northumbrian monk. Bede mentions Ælle as one of the Anglo-Saxon kings who exercised what he calls "imperium" over "all the provinces south of the river Humber"; "imperium" is usually translated as "overlordship". Bede gives a list of seven kings who held "imperium", and Ælle is the first of them. The other information Bede gives is that Ælle was not a Christian—Bede mentions a later king as "the first to enter the kingdom of heaven".
The second source is the "Anglo-Saxon Chronicle", a collection of annals assembled in the Kingdom of Wessex in c. 890, during the reign of Alfred the Great. The "Chronicle" has three entries for Ælle, from 477 to 491, as follows:
The "Chronicle" was put together about four hundred years after these events. It is known that the annalists used material from earlier chronicles, as well as from oral sources such as sagas, but there is no way to tell where these lines came from. It should also be noted that the terms 'British' and 'Welsh' were used interchangeably, as 'Welsh' is the Saxon word meaning 'foreigner', and was applied to all the native Romano-British of the era.
Three of the places named can be identified :
The "Chronicle" mentions Ælle once more under the year 827, where he is listed as the first of the eight "bretwaldas", or "Britain-rulers". The list consists of Bede's original seven, plus Egbert of Wessex. There has been much scholarly debate over just what it meant to be a "bretwalda", and the extent of Ælle's actual power in southern England is an open question. It is also noteworthy that there is a long gap between Ælle and the second king on Bede's list, Ceawlin of Wessex, whose reign began in the late 6th century; this may indicate a period in which Anglo-Saxon dominance was interrupted in some way.
Earlier sources than Bede exist which mention the South Saxons, though they do not name Ælle. The earliest reference is still quite late, however, at about 692: a charter of King Nothelm's, which styles him "King of the South Saxons". Charters are documents which granted land to followers or to churchmen, and which would be witnessed by the kings who had power to grant the land. They are one of the key documentary sources for Anglo-Saxon history, but no original charters survive from earlier than the end of the 7th century.
There are other early writers whose works can shed light on Ælle's time, though they do not mention either him or his kingdom. Gildas's description of the state of Britain in his time is useful for understanding the ebb and flow of the Anglo-Saxon incursions. Procopius, a Byzantine historian, writing not long after Gildas, adds to the meagre sources on population movement by including a chapter on England in one of his works. He records that the peoples of Britain—he names the English, the British, and the Frisians—were so numerous that they were migrating to the kingdom of the Franks in great numbers every year. Although this is probably a reference to Britons emigrating to Armorica to escape the Anglo-Saxons. They subsequently gave their name to the area they settled as Brittany, or "la petite Bretagne" (literally little Britain).
Evidence from place names in Sussex.
The early dates given in the "Anglo-Saxon Chronicle" for the colonization of Sussex are supported by an analysis of the place names of the region. The strongest evidence comes from place names that end in "-ing", such as Worthing and Angmering. These are known to derive from an earlier form ending in "-ingas". "Hastings" for example, derives from "Hæstingas" which means "the followers or dependents of a person named Hæsta".
From west of Selsey Bill to east of Pevensey can be found the densest concentration of these names anywhere in Britain. There are a total of about forty-five place names in Sussex of this form, and the personal names from which these are derived appear in many cases to have gone out of current use before the 7th century, when written records appear again. Hence it is generally accepted that these place names are evidence of the establishment of Saxon communities with stable populations as early as the 5th and 6th centuries. In addition, Sussex has unusually few place names of British origin. This does not necessarily mean that the Saxons killed or drove out almost all of the native population, despite the slaughter of the Britons reported in the "Chronicle" entry for 491; however, it does imply that the invasion was on a scale that left little space for the British.
These lines of reasoning cannot prove the dates given in the "Chronicle", much less the existence of Ælle himself, but they do support the idea of an early conquest and the establishment of a settled kingdom.
Reign.
If the dates given by the "Anglo-Saxon Chronicle" are accurate to within half a century, then Ælle's reign lies in the middle of the Anglo-Saxon expansion, and prior to the final conquest of the Britons. It also seems consistent with the dates given to assume that Ælle's battles predate Mons Badonicus. This in turn would explain the long gap, of fifty or more years, in the succession of the "bretwaldas": if the peace gained by the Britons did indeed hold till the second half of the 6th century, it is not to be expected that an Anglo-Saxon leader should have anything resembling overlordship of England during that time. The idea of a pause in the Anglo-Saxon advance is also supported by the account in Procopius of 6th century migration from Britain to the kingdom of the Franks. Procopius's account is consistent with what is known to be a contemporary colonization of Armorica (now Brittany, in France); the settlers appear to have been at least partly from Dumnonia (modern Cornwall), and the area acquired regions known as Dumnonée and Cornouaille. It seems likely that something at that time was interrupting the general flow of the Anglo-Saxons from the continent to Britain.
The dates for Ælle's battles are also reasonably consistent with what is known of events in the kingdom of the Franks at that time. Clovis I united the Franks into a single kingdom during the 480s and afterwards, and the Franks' ability to exercise power along the southern coast of the English channel may have diverted Saxon adventurers to England rather than the continent.
It is possible, therefore, that a historical king named Ælle existed, who arrived from the continent in the late 5th century, and who conquered much of what is now Sussex. He may have been a prominent war chief with a leadership role in a federation of Anglo-Saxon groups fighting for territory in Britain at that time. This may be the origin of the reputation that led Bede to list him as holding overlordship over southern Britain. The battles listed in the "Chronicle" are compatible with a conquest of Sussex from west to east, against British resistance stiff enough to last fourteen years. His area of military control may have extended as far as Hampshire and north to the upper Thames valley, but it certainly did not extend across all of England south of the Humber, as Bede asserts. 
The historian Guy Halsall argues that as Ælle immediately preceded the late sixth-century King Ceawlin as Bretwalda, it is far more likely that Ælle dates to the mid sixth century, and that the "Chronicle" has moved his dates back a century in order to provide a foundation myth for Sussex which puts it chronologically and geographically between the origins of the kingdoms of Kent and Wessex.
Death and burial.
Ælle's death is not recorded by the "Chronicle", which gives no information about him, or his sons, or the South Saxons until 675, when the South Saxon king Æthelwalh was baptized.
It has been conjectured that, as Saxon war leader, Ælle may have met his death in the disastrous battle of Mount Badon when the Britons halted Saxon expansion If Ælle died within the borders of his own kingdom then it may well have been that he was buried on Highdown Hill with his weapons and ornaments in the usual mode of burial among the South Saxons. Highdown Hill is the traditional burial-place of the kings of Sussex.

</doc>
<doc id="2234" url="http://en.wikipedia.org/wiki?curid=2234" title="Atari">
Atari

Atari (from a Japanese verb meaning "to hit the target") is a corporate and brand name owned by several entities since its inception in 1972, currently by Atari Interactive, a subsidiary of the French publisher Atari, SA (ASA). The original Atari, Inc. founded in 1972 by Nolan Bushnell and Ted Dabney was a pioneer in arcade games, home video game consoles, and home computers. The company's products, such as "Pong" and the Atari 2600, helped define the electronic entertainment industry from the 1970s to the mid-1980s.
In 1984, the original Atari Inc. was split due to its role in the video game crash of 1983, and the arcade division was turned into Atari Games Inc. Atari Games received the rights to use the logo and brand name with appended text "Games" on arcade games, as well as rights to the original 1972–1984 arcade hardware properties. The Atari Consumer Electronics Division properties were in turn sold to Jack Tramiel's Tramel Technology Ltd., which then renamed itself to Atari Corporation. In 1996, Atari Corporation reverse-merged with disk-drive manufacturer JT Storage (JTS), becoming a division within the company.
In 1998, Hasbro Interactive acquired all Atari Corporation related properties from JTS, creating a new subsidiary, Atari Interactive. Infogrames Entertainment (IESA) bought Hasbro Interactive in 2001 and renamed it to Infogrames Interactive, later Atari Interactive in 2003, when Infogrames Inc. licensed the Atari name and logo from the latter and changed its name to Atari Inc., a name used for a company founded in 1993 as GT Interactive, which IESA also renamed to Infogrames, Inc. and acquired a 62% controlling interest in by 1999. After IESA's acquisition of Hasbro Interactive, Infogrames, Inc. intermittently published Atari branded titles for Infogrames Interactive. On October 11, 2008, Infogrames completed its acquisition of Atari, Inc., making it a wholly owned subsidiary.
History.
Atari Inc. (1972–1984).
In 1971, Nolan Bushnell and Ted Dabney founded an engineering firm, Syzygy Engineering, that designed and built "Computer Space", the world's first arcade video game, for Nutting Associates. On June 27, 1972 Atari, Inc. was incorporated and soon hired Al Alcorn as their first design engineer. Bushnell decided to have Alcorn produce as a test of his abilities, an arcade version of the Magnavox Odyssey's Tennis game, which would be named Pong. While Bushnell incorporated Atari in June 1972, Syzygy Company was never formally incorporated. Before Atari's official incorporation, Bushnell wrote down several words from the game go, eventually choosing "atari", a term which in the context of the game means a state where a stone or group of stones is imminently in danger of being taken by one's opponent. In Japanese, "atari"　(当たり, あたり, or アタリ) is the nominalized form of "ataru" （当たる, あたる, or アタル） (verb), meaning "to hit the target" or "to receive something fortuitously". The word 'atari' is used in Japanese when a prediction comes true or when someone wins a lottery. Atari was incorporated in the state of California on June 27, 1972.
In 1973, Atari secretly spawned a "competitor" called Kee Games, headed by Nolan's next door neighbor Joe Keenan, to circumvent pinball distributors' insistence on exclusive distribution deals; both Atari and Kee could market virtually the same game to different distributors, with each getting an "exclusive" deal. Though Kee's relationship to Atari was discovered in 1974, Joe Keenan's management of the subsidiary led to him being promoted president of Atari that same year.
In 1976, Bushnell, through a Grass Valley, CA. engineering firm—Cyan Engineering, started an effort to produce a flexible video game console that was capable of playing all four of Atari's then-current games. The result was the Atari Video Computer System, or "VCS" (Later renamed the Atari 2600 when the Atari 5200 was released). Bushnell knew he had another potential hit on his hands, but bringing the machine to market would be extremely expensive. Looking for outside investors, in 1976 Bushnell sold Atari to Warner Communications for an estimated $28–32 million, using part of the money to buy the Folgers Mansion. Nolan continued to have disagreements with Warner Management over the direction of the company, the discontinuing of the Pinball division and most importantly, he felt that the Atari 2600 should be discontinued. In 1978, the Kee Games brand was dropped. In December of that year during a heated argument between Nolan Bushnell and Manny Gerard, Bushnell was fired. "[W]e started fighting like cats and dogs. And then the wheels came off that fall. Warner claimed they fired me," recalled Bushnell. "I say I quit. It was a mutual separation."
A project to design a successor to the 2600 started as soon as the system shipped. The original development team estimated the 2600 had a lifespan of about three years, and decided to build the most powerful machine they could, given that time frame. Mid-way into the effort's time-frame, the home computer revolution was taking off, so the new machines were adapted, with the addition of a keyboard and various inputs, to produce the Atari 800, and its smaller cousin, the 400. Although a variety of issues made them less attractive than the Apple II for some users, the new machines had some success when they finally became available in quantity in 1980. In 1982, the Atari 5200 was released, based heavily on the 400 and 800 models, but without a keyboard. The 5200 was unsuccessful, due to a lack of backwards compatibility with the 2600 library, a small amount of games, and notoriously-unreliable controllers.
Under Warner and the Chairman and CEO they chose to run Atari, Raymond Kassar, Atari Inc. achieved its greatest success, selling millions of 2600s and computers. At its peak, Atari accounted for a third of Warner's annual income and was the fastest-growing company in the history of the United States at the time. However, Atari Inc. ran into problems in the early 1980s as interference from the New York-based Warner management increasingly affected daily operations. Its home computer, video game console, and arcade divisions operated independently of one another and rarely cooperated. Faced with fierce competition and price wars in the game console and home computer markets, Atari was never able to duplicate the success of the 2600.
These problems were followed by the video game crash of 1983, with losses that totaled more than $500 million. Warner's stock price slid from $60 to $20, and the company began searching for a buyer for its troubled division. In 1983, Ray Kassar was forced to resign, and executives involved in the Famicom lost track of the negotiations, and the deal eventually died. With Atari's further financial problems and the Famicom's runaway success in Japan after its July 16, 1983 release date, Nintendo decided to go it alone.
Financial problems continued to mount and Kassar's successor, James J. Morgan, had less than a year in which to tackle the company's problems, he began a massive restructuring of the company and worked with Warner Communications in May 1984 to create "NATCO" which stood for New Atari Company which would further lean the company facilities, personnel and spending and make the company profit. Unknown to James Morgan and the senior management of Atari, Warner had been in talks with Tramel Technology to buy Atari's Consumer electronics and Home Computer divisions. Negotiating up until close to midnight of July 1, 1984 Jack Tramiel purchased Atari. Warner sold the home computing and game console divisions of Atari to Tramiel for $50 cash and $240 million in promissory notes and stocks, giving Warner a 20% stake in Atari Corporation who then used it to create a new company under the name Atari Corporation. Warner retained the arcade division, continuing it under the name Atari Games, but sold it to Namco in 1985. Warner also sold the fledgling Ataritel to Mitsubishi.
Atari Corporation (1984–1996).
Under Tramiel's ownership, Atari Corp. used the remaining stock of game console inventory to keep the company afloat while they finished development on a 16/32-bit computer system, the Atari ST. ("ST" stands for "sixteen/thirty-two", referring to the machines' 16-bit bus and 32-bit processor core.) In April 1985, they released the first update to the 8-bit computer line — the Atari 65XE, the Atari XE series. June 1985 saw the release of the Atari 130XE, Atari User Groups received early sneak-preview samples of the new Atari 520ST's, and major retailer shipments hit store shelves in September 1985 of Atari's new 32-bit Atari ST computers. In 1986, Atari launched two consoles designed under Warner — the Atari 2600jr and the Atari 7800 console (which saw limited release in 1984). Atari rebounded, earning a $25 million profit that year.
In 1987, Atari acquired Federated Group for $67.3 million, securing shelf space in over 60 stores in California, Arizona, Texas and Kansas at a time when major American electronics outlets were reluctant to carry Atari-branded computers, and two-thirds of Atari's PC production was sold in Europe. The Federated Group (not related to Federated Department Stores) was sold to Silo in 1989.
In 1989, Atari released the Atari Lynx, a handheld console with color graphics, to much fanfare. A shortage of parts kept the system from being released nationwide for the 1989 Christmas season, and the Lynx lost market share to Nintendo's Game Boy which, despite only having a black and white display, was cheaper, had better battery life and had much higher availability. Tramiel emphasized computers over game consoles but Atari's proprietary computer architecture and operating system fell victim to the success of the Wintel platform while the game market revived. In 1989, Atari Corp. sued Nintendo for $250 million, alleging it had an illegal monopoly. Atari eventually lost the case when it was rejected by a US district court in 1992.
In 1993, Atari positioned its Jaguar as the only 64-bit interactive media entertainment system available, but it sold poorly.
By 1996, a series of successful lawsuits had left Atari with millions of dollars in the bank, but the failure of the Lynx and Jaguar left Atari without a product to sell. Tramiel and his family also wanted out of the business. The result was a rapid succession of changes in ownership. In July 1996, Atari merged with JTS Inc., a short-lived maker of hard disk drives, to form JTS Corp. Atari's role in the new company largely became that of holder for the Atari properties and minor support, and consequently the name largely disappeared from the market.
As a division of Hasbro (1998–2000).
In March 1998, JTS sold the Atari name and assets to Hasbro Interactive for $5 million—less than a fifth of what Warner Communications had paid 22 years earlier. This transaction primarily involved the brand and intellectual property, which now fell under the Atari Interactive division of Hasbro Interactive. The brand name changed hands again in December 2000 when French software publisher Infogrames took over Hasbro Interactive.
Infogrames/Atari SA (2001-present).
In October 2001, Infogrames (now Atari, SA) announced that it was "reinventing" the Atari brand with the launch of two new games featuring a prominent Atari branding on their boxarts : "Splashdown" and "MX Rider". On May 7, 2003, Infogrames had its majority-owned, but discrete US subsidiary Infogrames NA officially renamed Atari, Inc., renamed its European operations to Atari Europe but kept the original name of the main company Infogrames Entertainment. The original Atari holdings division purchased from Hasbro, Hasbro Interactive, was also made a separate corporate entity renamed as Atari Interactive.
On March 6, 2008, Infogrames made an offer to Atari Inc. to buy out all remaining public shares for a value of $1.68 per share, or $11 million total. The offer would make Infogrames sole owner of Atari Inc., thus making it a privately held company. On April 30, 2008, Atari Inc. announced its intentions to accept Infogrames' buyout offer and to merge with Infogrames. On October 8, 2008, Infogrames completed its acquisition of Atari Inc., making it a wholly owned subsidiary.
On December 9, 2008, Atari announced that it had acquired Cryptic Studios, an MMORPG developer.
Namco Bandai has purchased a 34% stake in Atari Europe on May 14, 2009, paving the way for its acquisition from Infogrames.
Atari has had significant financial issues for several years now, posting losses in the tens of millions since 2005.
In May 2009 Infogrames Entertainment, SA, the parent company of Atari Inc. and Atari Interactive Inc., announced it would change its name to Atari, SA.
In April 2010, Atari SA board member and former CEO David Gardner resigned. Original Atari Inc. co-founder Nolan Bushnell joined the board as a representative for Blubay holdings.
As of March 31, 2011, the Board of Directors consisted of Frank Dangeard, Jim Wilson, Tom Virden, Gene Davis, Alexandra Fichelson.
On January 21, 2013, Atari Inc., Atari Interactive Inc., Humongous, Inc., and California US Holdings, Inc. (collectively, the "Companies") filed petitions for relief under Chapter 11 of the United States Bankruptcy Code in the United States Bankruptcy Court for the Southern District of New York. All three Ataris emerged from bankruptcy one year later and the entering of the social casino gaming industry with Atari Casino. Frederic Chesnais, who now heads all three companies, stated that their entire operations consist of a staff of 10 people.
On June 22, 2014, Atari announced a new corporate strategy that would include a focus on "new audiences," specifically "LGBT, social casinos, real-money gambling, and YouTube."

</doc>
<doc id="2235" url="http://en.wikipedia.org/wiki?curid=2235" title="Afghan">
Afghan

Afghan (Pashto/Persian: افغان; see "etymology") refers to something from Afghanistan, particularly a citizen of that country. Prior to this definition, it was used by Persian speakers and those influenced by the Persian language to denote the Pashtun people. In modern times, "Afghan" is rarely used as an ethnic term for the Pashtuns but is rather used as the national demonym for all citizens of Afghanistan - Pashtuns, Tajiks, Hazaras, Uzbeks, Aimaqs, Turkmens, Balochs, Nuristanis, Pashayis, Pamiris, Arabs, Brahui, Qezelbash, Gujjar and others. 
According to Encyclopædia Iranica, the word Afghan (afḡān) in current political usage means any citizen of Afghanistan, regardless of their tribal or religious affiliation. According to the 1964 Constitution of Afghanistan, all Afghans are equal in rights and obligations before the law. The fourth article of the current Constitution of Afghanistan states that citizens of Afghanistan consist of Pashtuns, Tajiks, Hazara, Uzbek, Turkmen, Aymaq, Arab, Baluch, Pashayi, Nuristani, Qezelbash, Gujjars, Brahui, and members of other tribes.
As an adjective, the word Afghan also means "of or relating to Afghanistan or its people, language, or culture".
Afghani.
The term "Afghani" refers to the unit of Afghan currency. It is often improperly used for a person or thing related to Afghanistan. The incorrect use of the term may have originated during the Soviet war in Afghanistan when millions of Afghans took refuge in neighboring Pakistan and Iran.

</doc>
<doc id="2236" url="http://en.wikipedia.org/wiki?curid=2236" title="Acadia University">
Acadia University

Acadia University is a predominantly undergraduate university located in Wolfville, Nova Scotia, Canada with some graduate programs at the master's level and one at the doctoral level. The enabling legislation consists of Acadia University Act and the Amended Acadia University Act 2000.
The Wolfville Campus houses Acadia University Archives and the Acadia University Art Gallery. Acadia offers over 200 degree combinations in the Faculties of Arts, Pure and Applied Science, Professional Studies, and Theology. The student-faculty ratio is 15:1 and the average class size is 28. Open Acadia offers correspondence and distance education courses.
History.
 Acadia began as an extension of Horton Academy (1828), which was founded in Horton, Nova Scotia, by Baptists from Nova Scotia and Queen's College (1838). The College was later named Acadia College. Acadia University, established at Wolfville, Nova Scotia in 1838 has a strong Baptist religious affiliation.
It was designed to prepare men for the ministry and to supply education for lay members.
The two major Universities of the day in Nova Scotia were heavily controlled by Denominational structures. King's College (University of King's College) was an Anglican School and Dalhousie University, which was originally non-denominational, had placed itself under the control and direction of the Church of Scotland. It was the failure of Dalhousie to appoint a prominent Baptist pastor and scholar, Edmund Crawley, to the Chair of Classics, as had been expected, that really thrust into the forefront of Baptist thinking the need for a College established and run by the Baptists.
In 1838, the Nova Scotia Baptist Education Society founded Queen's College (named for Queen Victoria). The College began with 21 students in January 1839. The name "Queen's College" was denied to the Baptist school, so it was renamed "Acadia College" in 1841, in reference to the history of the area as an Acadian settlement. Acadia College awarded its first degrees in 1843 and became Acadia University in 1891, established by the Acadia University Act.
The Granville Street Baptist Church (now First Baptist Church (Halifax)) was an instrumental and determining factor in the founding of the University. It has played a supporting role throughout its history, and shares much of the credit for its survival and development. Many individuals who have made significant contributions to Acadia University, including the first president John Pryor, were members of the First Baptist Church Halifax congregation. Similarly, the adjacent Wolfville United Baptist Church plays a significant role in the life of the university.
The original charter of the college stated:
And be it further enacted, that no religious tests or subscriptions shall be required of the Professors Fellows, Scholars, Graduates or Officers of the said College; but that all the privileges and advantages thereof shall be open and free to all and every Person and Persons whomsoever, without regard to religious persuasion ... And it shall and may be lawful for the trustees and Governors of the said College to select as Professors, and other Teaches or Officers, competent persons of any religious persuasion whatever, provided such person or persons shall be of moral and religious character.
This was unique at the time, and a direct result of Baptists being denied entry into other schools that required religious tests of their students and staff.
In 1851, the power of appointing governors was transferred from the Nova Scotia Baptist Education Society to the Baptist Convention of the Maritime Provinces.
Charles Osborne Wickenden (architect), and J.C. Dumaresq designed the Central Building, Acadia College, 1878–79. 
Clara Belle Marshall, from Mount Hanley, Nova Scotia, became the first woman to graduate from Acadia University in 1879.
In 1891, there were changes in the Act of Incorporation.
The War Memorial House (more generally known as Barrax), which is a residence, and War Memorial Gymnasium 
are landmark buildings on the campus of Acadia University. The Memorial Hall and Gymnasium honours students who had enlisted and died in the First World War, and in the Second World War. Two granite shafts, which are part of the War Memorial Gymnasium complex at Acadia University, are dedicated to the university's war dead. The War Memorial House is dedicated to the war dead from Acadia University during the Second World War 
Andrew R. Cobb designed several campus buildings including: Raynor Hall Residence, 1916; , designed by Cobb in the Georgian style, and built by James Reid of Yarmouth, Nova Scotia was opened in 1915 as Horton Academy. Today, Horton Hall is the home of the Department of Psychology and Research and Graduate Studies. Emmerson Hall, built in 1913, is particularly interesting for the variety of building stones used. In 1967 Emmerson Hall was converted to classrooms and offices for the School of Education. It is a registered Heritage Property.
Unveiled on 16 August 1963, a wooden and metal organ in Manning Chapel, Acadia University, is dedicated to Acadia University's war dead of the First World War.
A memorial pipe organ in Convovation Hall, Acadia University is dedicated to the members of Acadia University killed during the First World War A book of remembrance in Manning Chapel, Acadia University was unveiled on 1 March 1998 through the efforts of the Wolfville Historical Society 
In 1966, the Baptist denomination relinquished direct control over the University. The denomination maintains nine seats on the University's Board of Governors.
On 4 January 2008, Dr. Gail Dinter-Gottlieb decided to step down as President and Vice Chancellor of the University before her term expired. Her resignation was effective 29 February 2008. Ray Ivany began his position as President and Vice-Chancellor on 1 April 2009.
Faculty strikes.
Acadia University's Board of Governors and members of the Acadia University Faculty Association (AUFA) have ratified a new covering the period 1 July 2010 to 30 June 2014. The faculty of Acadia University have been on strike twice in the history of the institution. The first was 24 February to 12 March 2004. The second was 15 October to 5 November 2007. The second strike was resolved after the province's labour minister, Mark Parent, appointed a mediator, on 1 November, to facilitate an agreement.
Academics.
Profile.
As a primarily undergraduate institution, the university places significant importance on teaching and instruction.
The mission of Acadia University is to provide a personalized and rigorous liberal education; promote a robust and respectful scholarly community; and inspire a diversity of students to become critical thinkers, lifelong learners, engaged citizens, and responsible global leaders.
Rankings.
Acadia University is consistently ranked among the top universities in Canada for undergraduate studies in the Maclean's comprehensive Canadian Universities rankings, coming second in Canada for the 2014 academic year and among the top five for the past decade. This has been attributed to Acadia's small class size and close relationships between the faculty and the students.
Faculties.
Acadia is organized into four faculties: Arts, Pure & Applied Science, Professional Studies and Theology. Each faculty is further divided into departments and schools specialized in areas of teaching and research.
Research.
The Division of Research & Graduate Studies is separate from the faculties and oversees graduate students as well as Acadia's research programs.
Acadia's research programs explore coastal environments, ethno-cultural diversity, social justice, environmental monitoring and climate change, organizational relationships, data mining, the impact of digital technologies, and lifestyle choices contributing to health and wellness. Acadia's research centres include the Tidal Energy Institute, and the Beaubassin Field Station. Applied research opportunities include research with local wineries and grape growers, alternative insect control techniques and technologies.
Innovation.
The Acadia Advantage.
In 1996, Acadia University pioneered the use of mobile computing technology in a post-secondary educational environment.
This academic initiative, named the Acadia Advantage, integrated the use of notebook computers into the undergraduate curriculum and featured innovations in teaching. By 2000, all full-time, undergraduate Acadia students were taking part in the initiative. The initiative went beyond leasing notebook computers to students during the academic year, and included training, user support and the use of course-specific applications at Acadia that arguably revolutionized learning at the Wolfville, N.S. campus and beyond.
Because of its pioneering efforts, Acadia is a laureate of Washington's Smithsonian Institution and a part of the permanent research collection of the National Museum of American History. It is the only Canadian university selected for inclusion in the Education and Academia category of the Computerworld Smithsonian Award.
In addition, Acadia University received the Pioneer Award for Ubiquitous Computing. In 2001, it achieved high rankings in the annual "Maclean's" University Rankings, including Best Overall for Primarily Undergraduate University in their opinion survey, and it received the Canadian Information Productivity Award in 1997 as it was praised as the first university in Canada to fully utilize information technology in the undergraduate curriculum.
In October 2006, Dr. Dinter-Gottlieb established a commission to review the Acadia Advantage learning environment 10 years after inception. The mandate of the commission was to determine how well the current Advantage program meets the needs of students, faculty, and staff and to examine how the role of technology in the postsecondary environment has changed at Acadia, and elsewhere. The commission was asked to recommend changes and enhancements to the Acadia Advantage that would benefit the entire university community and ensure its sustainability.
Some of the recommendations coming from the Acadia Advantage Renewal Report included developing a choice of model specifications and moving from Acadia-issued, student-leased notebook computers to a student-owned computer model. The compelling rationale for this was the integral role technology now plays in our lives, which was not present in 1996.
The University was also advised to unbundle its tuition structure so that the cost of an Acadia education is more detailed and students can understand how their investment in the future of the school is allotted. In September 2008, Acadia moved to a student-owned notebook computer version of the Acadia Advantage, now named Acadia Advantage 2.0.
Athletics.
Acadia's sports teams are called the Axemen and Axewomen. They participate in the Atlantic University Sports conference of Canadian Interuniversity Sport.
School spirit abounds with men's and women's varsity teams that have delivered more conference and national championships than any other institution in Atlantic University Sport. Routinely, more than one-third of Acadia's varsity athletes also achieve Academic All-Canadian designation through Canadian Interuniversity Sport by maintaining a minimum average of 80 per cent.
Expansion and modernization of Raymond Field was completed in the fall of 2007 and features the installation of an eight-lane all-weather running track and a move to the same premium artificial turf used by the New England Patriots of the National Football League for its main playing field. The Raymond Field modernization was a gift to the university by friends, alumni, and the province. War Memorial Gymnasium also saw the installation of a new playing floor to benefit its basketball and volleyball teams.
In September 2006, Acadia University announced its partnership with the Wolfville Tritons Swim Club and the Acadia Masters Swim Club to form the Acadia Swim Club and return competitive swimming to the university after a 14-year hiatus. On 26 September 2008, the university announced its intention to return swimming to a varsity status in September 2009.
Fight song.
Notable among a number of songs commonly played and sung at various events such as commencement, convocation, and athletic games are: "Stand Up and Cheer", the Acadia University fight song. According to 'Songs of Acadia College' (Wolfville, NS 1902-3, 1907), the songs include: 'Acadia Centennial Song' (1938); 'The Acadia Clan Song'; 'Alma Mater - Acadia;' 'Alma Mater Acadia' (1938) and 'Alma Mater Song.'
Symbols.
In 1974, Acadia was granted a coat of arms designed by the College of Arms in London, England. The coat of arms is two-tone, with the school's official colours, garnet and blue, on the shield. The axes represent the school's origins in a rural setting, and the determination of its founders who cleared the land and built the school on donated items and labour. The open books represent the intellectual pursuits of a university, and the wolves heads are a whimsical representation of the University's location in Wolfville. "In pulvere vinces" (In dust you conquer) is the motto.
The University seal depicts the Greek goddess of wisdom Athena in front of the first college hall.
The University also uses a stylized "A" as a logo for its sports teams.
Notable among a number of fight songs commonly played and sung at various events such as commencement, convocation, and athletic games are: the Acadia University alma mater set to the tune of "Annie Lisle". The lyrics are:
Historic buildings at Acadia University.
Seminary House, also known as the Ladies' Seminary, is a Second Empire style-building constructed in 1878 as a home for women attending the university. It was designated a National Historic Site of Canada in 1997 as Canada's oldest facility associated with the higher education of women.
Carnegie Hall, built in 1909, is a large, two-storey, Neo-classical brick building. It was designated under the provincial Heritage Property Act in 1989 as its construction in 1909 signified Acadia's evolution from classical college to liberal university.
Student life.
At Acadia University, students have access to the Student Union Building which serves as a hub for students and houses many Student Union organizations. The building also houses The Axe Lounge, a convenience store, an information desk and two food outlets. The university press, The Athenaeum, is a member of CUP.
Student government.
All students are represented by the Acadia Students' Union. 
The Union Executive for the 2013–2014 academic year: President - Callie Lathem, Vice President Programming - Chelsey Spinney, Vice President Academic - Liam Murphy, Vice President Finance - Jalen Sabean, Vice President Communications - Suzanne Gray. The student newspaper is "The Athenaeum."
Residences.
Approximately 1500 students live on-campus in 12 residences:

</doc>
<doc id="2237" url="http://en.wikipedia.org/wiki?curid=2237" title="Steel-string acoustic guitar">
Steel-string acoustic guitar

The steel-string acoustic guitar is a modern form of guitar that descends from the classical guitar, but is strung with steel strings for a brighter, louder sound. It is often referred to simply as an acoustic guitar, though the nylon-strung classical guitar is also sometimes called an acoustic guitar.
The most common type is often called a flat-top guitar, to distinguish it from the more specialized archtop guitar and other variations.
The standard tuning for an acoustic guitar is E-A-D-G-B-E (low to high), although many players, particularly fingerpickers, use alternate tunings (scordatura), such as "open G" (D-G-D-G-B-D), "open D" (D-A-D-F♯-A-D), or "drop D" (D-A-D-G-B-E).
Construction.
There are many variations in construction and materials used in steel-string guitars. Different combinations of woods and construction elements (for example, how the top is braced) affect the timbre or "tone" of the guitar. Many players and luthiers feel a well-made guitar's tone improves over time.
Types.
Acoustic guitars are commonly constructed in several different body types. In general, the guitar's soundbox can be thought of as composed of two connected chambers: the "upper bouts" and "lower bouts" (a "bout" being the rounded corner of an instrument body), which meet at the "waist", or the narrowest part of the body face near the soundhole. The proportion and overall size of these two parts helps determine the overall tonal balance and "native sound" of a particular body style – the larger the body, the louder the volume.
Any of these body type can optionally incorporate a "cutaway". A cutaway guitar has a redesigned upper bout that removes a section of the soundbox on the underside of the neck, hence the name "cutaway". This allows for easier access to the frets that are located on top of the soundbox past the heel of the neck. The tradeoff is reduced soundbox volume, and often a change in bracing, which can change the resonant qualities and hence the tone of the instrument.
All of the guitars above are relatively traditional in looks and construction, and are commonly referred to as "flattop" guitars. All are commonly seen and heard in popular music genres, including rock, blues, country, and folk. However, other styles of guitar have been introduced and enjoy moderate popularity, generally in more specific genres:
Tonewoods.
Traditionally, steel-string guitars have been made of a combination of various "tonewoods", or woods that have pleasing resonant qualities when used in instrument-making. Foremost are Sitka spruce, the most common, and Alpine and Adirondack spruce, the most sought-after, woods for the making of guitar tops. The back and sides of a particular guitar are typically made of the same wood; Brazilian or East Indian rosewood and Honduras mahogany are traditional choices, however, maple has been prized for the figuring that can be seen when it is cut in a certain way (such as "flame" and "quilt" patterns). A common non-traditional wood gaining popularity is sapele, which is tonally similar to mahogany but slightly lighter in color and possessing a deep grain structure that is visually appealing.
Due to decreasing availability and rising prices of premium-quality traditional tonewoods, many manufacturers have begun experimenting with alternative species of woods or more commonly available variations on the standard species. For example, some makers have begun producing models with redcedar or mahogany tops, or with spruce variants other than Sitka. Cedar is also common in the back and sides, as is basswood. Entry-level models, especially those made in East Asia, often use nato wood, which is again tonally similar to mahogany but is cheap to acquire. Some have also begun using non-wood materials, such as plastic or graphite. Carbon-fiber and phenolic composite materials have become desirable for building necks, and at least one high-end luthier (Composite Acoustics) produces a line of all-carbon-fiber guitars, prized for their high stability in changing climates that would cause wood instrument panels to swell and shrink.
Assembly.
The steel-string acoustic guitar evolved from the nylon- or gut-string classical guitar, and because steel strings have higher tension, heavier construction is required overall. One innovation is a metal bar called a truss rod, which is incorporated into the neck to strengthen it and provide adjustable counter-tension to the stress of the strings. Typically, a steel-string acoustic guitar is built with a larger soundbox than a standard classical guitar. A critical structural and tonal component of an acoustic guitar is the bracing, a systems of struts glued to the inside of the back and top. Steel-string guitars use different bracing systems from classical guitars, typically using X-bracing instead of fan bracing. (Another simpler system, called ladder bracing, where the braces are all placed across the width of the instrument, is used on all types of flat-top guitars on the back.) Innovations in bracing design have emerged, notably the A-brace developed by British luthier Roger Bucknall of Fylde Guitars.
Most luthiers and experienced players agree that a good solid top (as opposed to laminated or plywood) is the most important factor in the tone of the guitar. Solid backs and sides can also contribute to a pleasant sound, although laminated sides and backs are acceptable alternatives, commonly found in mid-level guitars (in the range of US$300–$1000).
From the 1960s through the 1980s, "by far the most significant developments in the design and construction of acoustic guitars" were made by the Ovation Guitar Company. It introduced a composite "roundback" bowl, which replaced the square back and sides of traditional guitars; because of its engineering design, Ovation guitars could be amplified without producing the obnoxious feedback that had plagued acoustic guitars before. Ovation also pioneered with electronics, such as pickup systems and electronic tuners.
"See Guitar for more details on the construction of acoustic guitars."
Amplification.
A steel-string guitar can be amplified with a:
The last type of guitar is commonly called an "acoustic-electric" or "electro-acoustic" guitar, as it can be played either "unplugged" as an acoustic or plugged in as an electric. The most common type is a piezoelectric pickup, which is composed of a thin sandwich of quartz crystal. When compressed, the crystal produces a small electrical current, so when placed under the bridge saddle, the vibrations of the strings through the saddle, and of the body of the instrument, are converted to a weak electrical signal. This signal is often sent to a pre-amplifier, which increases the signal strength and normally incorporates an equalizer. The output of the preamplifier then goes to a separate amplifier system similar to that for an electric guitar.
Several manufacturers produce specialised acoustic guitar amplifiers, which are designed to give undistorted and full-range reproduction.
Music and players.
Until the 1960s, the predominant forms of music played on the flat-top, steel-string guitar remained relatively stable and included acoustic blues, country, bluegrass, folk, and several genres of rock. The concept of playing solo steel-string guitar in a concert setting was introduced in the early 1960s by such performers as Davey Graham and John Fahey, who used country blues fingerpicking techniques to compose original compositions with structures somewhat like European classical music. Fahey contemporary Robbie Basho added elements of Indian classical music and Leo Kottke used a Faheyesque approach to make the first solo steel-string guitar "hit" record.
Steel-string guitars are also important in the world of flatpicking, as utilized by such artists as Clarence White, Tony Rice, Bryan Sutton, Doc Watson and David Grier. Luthiers have been experimenting with redesigning the acoustic guitar for these players. These flat-top, steel-string guitars are constructed and voiced more for classical-like fingerpicking and less for chordal accompaniment (strumming). Some luthiers have increasingly focused their attention on the needs of fingerstylists and have developed unique guitars for this style of playing.
Many other luthiers attempt to recreate the guitars of the "Golden Era" of C.F. Martin & Co. This was started by Roy Noble, who built the guitar played by Clarence White from 1968 to 1972, and was followed by Bill Collings, Marty Lanham, Dana Bourgeois, Randy Lucas, Lynn Dudenbostel and Wayne Henderson, a few of the luthiers building guitars today inspired by vintage Martins, the pre–World War II models in particular. As prices for vintage Martins continue to rise exponentially, upscale guitar enthusiasts have demanded faithful recreations and luthiers are working to fill that demand.

</doc>
<doc id="2238" url="http://en.wikipedia.org/wiki?curid=2238" title="Antipope John XXIII">
Antipope John XXIII

Baldassarre Cossa (c. 1370 – 22 December 1419) was antipope John XXIII (1410–1415) during the Western Schism. The Catholic Church regards him as an antipope, as he opposed the Pope whom the Catholic Church now recognizes as the rightful successor of Saint Peter. He was eventually deposed and tried for various crimes, though later accounts question the veracity of those accusations.
Early life.
Baldassarre Cossa was born on the island of Procida or Ischia in the Kingdom of Naples into a noble but impoverished family. Initially he followed a military career, taking part in the Angevin-Neapolitan war. His two brothers were sentenced to death for piracy by Ladislaus of Naples.
He studied law at the University of Bologna and obtained a doctorate. In 1392 he entered the service of Pope Boniface IX, first working in Bologna and then in Rome. (The Western Schism had begun in 1378 and there were two competing popes at the time, one in Avignon supported by France and Spain, and one in Rome supported by most of Italy, Germany and England.) Still a member of the laity, he became Cardinal deacon in 1402 and Papal legate in Forlì in 1403. At this time Cossa also had some links with local robber bands, which were often used to intimidate his rivals and attack carriages. These connections added to his influence and power in the region.
Role in the Western Schism.
The Council of Pisa.
He was one of the seven cardinals who, in May 1408, deserted Pope Gregory XII, and, with those following Antipope Benedict XIII from Avignon, convened the Council of Pisa, of which Cossa became the leader. The aim of the council was to end the schism; to this end they deposed Gregory XII and Benedict XIII and elected the new pope Alexander V in 1409. Gregory and Benedict ignored this decision however, so that there were now three simultaneous claimants to the Papacy.
Election to the Papacy.
Alexander V died soon after, and on 25 May 1410 Cossa was consecrated pope, taking the name John XXIII. He had been ordained priest only one day earlier. John XXIII was acknowledged as pope by France, England, Bohemia, Prussia, Portugal, parts of the Holy Roman Empire, and numerous Northern Italian city states, including Florence and Venice; however, the Avignon Pope Benedict XIII was regarded as pope by the Kingdoms of Aragon, Castile, Sicily and Scotland and Gregory XII was still favored by Ladislaus of Naples, Carlo I Malatesta, the princes of Bavaria, Louis III, Elector Palatine, and parts of Germany and Poland.
The Medici had supported Cossa in his campaign to become cardinal and pope. Once in office, John XXIII made the Medici Bank the bank of the papacy, contributing considerably to the family's wealth and prestige.
John had his officials sell indulgences, a controversial practice that was protested in various parts of Europe, for instance by the followers of Jan Hus in Prague.
The main enemy of John was Ladislaus of Naples, who protected Gregory XII in Rome. Following his election as pope, John spent a year in Bologna and then joined forces with Louis II of Anjou to march against Ladislaus. An initial victory proved short-lived and Ladislaus retook Rome in May 1413, forcing John to flee to Florence.
In Florence he met Sigismund, King of the Romans. Sigismund wanted to end the schism and urged John to call a general council. John did so with hesitation, at first trying to have the council held in Italy (rather than in a German Imperial City, as Sigismund wanted). The Council of Constance was convened on 30 October 1413. During the third session, rival Pope Gregory XII authorized the council as well. The council resolved that all three popes should abdicate and a new pope be elected.
Flight from the Council of Constance.
In March, John escaped from Constance disguised as a postman. According to the Klingenberger Chronicle, written by a noble client of Frederick IV, Duke of Austria, John XXIII travelled down the Rhine to Schaffhausen in a boat, while Frederick accompanied him with a small band of men on horseback. There was a huge outcry in Constance when it was discovered that John had fled, and Sigismund was furious about this setback to his plans for ending the Schism. The King of the Romans issued orders to all the powers on the Upper Rhine and in Swabia stating that he had declared Frederick to be an outlaw and that his lands and possessions were forfeit. In due course this led to a great deal of political upheaval and many Austrian losses in the region, notably in Aargau to the Swiss Confederation.
In the meantime, Pope John XXIII and Frederick fled further downriver along the Rhine to the town of Freiburg im Breisgau, which recognised the duke of Austria as its lord. There Sigismund's lieutenant Ludwig III, Elector Palatine caught up with them. He convinced Frederick that he stood to lose too much by harbouring the fugitive pope, and the Austrian duke agreed to give himself and John up and return to Constance.
Deposition.
During his absence John was deposed by the council, and upon his return he was tried for heresy, simony, schism and immorality, and found guilty on all counts. Gibbon wrote, "The more scandalous charges were suppressed; the vicar of Christ was accused only of piracy, rape, sodomy, murder and incest." John was given over to Ludwig III, Elector Palatine, who imprisoned him for several months in Heidelberg and Mannheim.
The last remaining claimant in Avignon, Benedict XIII, refused to resign and was excommunicated. Martin V was elected as new pope in 1417.
Death and burial.
Cossa, as he was again, was imprisoned in Germany. He was freed in 1418 after a heavy ransom was paid by the Medici. He went to Florence where he submitted to Martin V who made him Cardinal Bishop of Frascati. Cossa died only a few months later.
The Medici oversaw the construction of his magnificent tomb by Donatello and Michelozzo in the Battistero di San Giovanni in Florence. Pope Martin V protested in vain against the inscription on the sarcophagus: "John the former pope".
The 1910 "Catholic Encyclopedia" remarks that "Undeniably secular and ambitious, his moral life was not above reproach, and his unscrupulous methods in no wise accorded with the requirements of his high office ... the heinous crimes of which his opponents in the council accused him were certainly gravely exaggerated." One of his secretaries concluded that John was "a great man in temporal things, but a complete failure and worthless in spiritual things".
Numbering issues.
He should not be confused with Pope John XXIII of the twentieth century. When Angelo Roncalli was elected pope in 1958, there was some confusion as to whether he would be "John XXIII" or "John XXIV"; he then declared that he was John XXIII to put this question to rest. There was no John XX; this is why Gibbon refers to the antipope John as John XXII.
Notes and references.
In 1983 political satirist/novelist Richard Condon ("The Manchurian Candidate") wrote "A Trembling Upon Rome," a novel of historical fiction about the life of Baldassare Cossa.

</doc>
<doc id="2241" url="http://en.wikipedia.org/wiki?curid=2241" title="Antonio Salieri">
Antonio Salieri

Antonio Salieri (18 August 1750 – 7 May 1825) was an Italian classical composer, conductor and teacher born in Legnago, south of Verona, in the Republic of Venice, but who spent his adult life and career as a subject of the Habsburg Monarchy.
Salieri was a pivotal figure in the development of late 18th-century opera. As a student of Florian Leopold Gassmann, and a protégé of Gluck, Salieri was a cosmopolitan composer who wrote operas in three languages. Salieri helped to develop and shape many of the features of operatic compositional vocabulary and his music was a powerful influence on contemporary composers.
Appointed the director of the Italian opera by the Habsburg court, a post he held from 1774–92, Salieri dominated Italian language opera in Vienna. During his career he also spent time writing works for opera houses in Venice, Rome, and Paris. His dramatic works were widely performed throughout Europe during his lifetime. As the Austrian imperial Kapellmeister from 1788 to 1824, he was responsible for music at the court chapel and attached school. Even as his works dropped from performance, and he wrote no new operas after 1804, he still remained one of the most important and sought-after teachers of his generation, and his influence was felt in every aspect of Vienna's musical life. Franz Schubert, Ludwig van Beethoven and Franz Liszt were among the most famous of his pupils.
Salieri's music slowly disappeared from the repertoire between 1800 and 1868, and was rarely heard after that period until the revival of his fame in the late 20th century. This revival was due to the dramatic and highly fictionalized depiction of Salieri in Peter Shaffer's 1979 play "Amadeus", which was given its greatest exposure in its 1984 film version, directed by Miloš Forman. His music today has regained some modest popularity via recordings. It is also the subject of increasing academic study and a small number of his operas have returned to the stage. In addition there is now a Salieri Opera Festival sponsored by the Fondazione Culturale Antonio Salieri and dedicated to rediscovering his work and those of his contemporaries. It is developing as an annual autumn event in his native town of Legnago, where a theater has been renamed in his honour.
Biography.
Salieri started his musical studies in his native town of Legnago; he was first taught at home by his older brother Francesco Salieri (a former student of the violinist and composer Giuseppe Tartini), and he received further lessons from the organist of the Legnago Cathedral, Giuseppe Simoni, a pupil of Padre Giovanni Battista Martini. Salieri would recall little from his childhood in later years except a passion for sugar, reading and music. He twice ran away from home without permission to hear his elder brother play violin concertos in neighboring churches on festival days (resulting in the loss of his beloved sugar), and he also recounted being chastised by his father after failing to greet a local priest with proper respect. Salieri responded to the reprimand by saying that the priest's organ playing displeased him because it was in an inappropriately theatrical style. Sometime between 1763 and 1764 Salieri suffered the death of both parents and was briefly taken in by an anonymous brother, a monk in Padua, and then for unknown reasons in 1765 or 1766 he became the ward of a Venetian nobleman named Giovanni Mocenigo (which Giovanni is at this time unknown), a member of the powerful and well connected Mocenigo family. It is possible that Antonio's father and Giovanni were friends or business associates, but this is obscure. While living in Venice Salieri continued his musical studies with the organist and opera composer Giovanni Battista Pescetti, then following Pescetti's sudden death he studied with the opera singer Ferdinando Pacini or Pasini. It was through Pacini that Salieri gained the attention of the composer Florian Leopold Gassmann, who, impressed with his talents and concerned for his future, took the young orphan to Vienna where he personally directed and paid for the remainder of his musical education.
Salieri and Gassmann arrived in Vienna on 15 June 1766. Gassmann's first act was to take Salieri to the Italian Church to consecrate his teaching and service to God, an event that left a deep impression on Salieri for the rest of his life. Salieri's education included instruction in Latin and Italian poetry by Fr. Don Pietro Tommasi, instruction in the German language, and European literature. His music studies revolved around vocal composition, and thoroughbass. His musical theory training in harmony and counterpoint was rooted in Johann Fux's Gradus ad Parnassum, which Salieri translated during each Latin lesson. As a result Salieri continued to live with Gassmann even after Gassmann's marriage, an arrangement that lasted until the year of Gassmann's death and Salieri's own marriage in 1774. Few of Salieri's compositions have survived from this early period. In his old age Salieri hinted that these works were either purposely destroyed, or had been lost with the exception of a few works for the church. Among these sacred works there survives a Mass in C major written without a "Gloria" and in the antique a cappella style (presumably for one of the church's penitential seasons) and dated 2 August 1767. A complete opera composed in 1769 (presumably as a culminating study) "La vestale" ("The Vestal Virgin") has also been lost.
Beginning in 1766 Gassmann introduced Salieri to the daily chamber music performances held during Emperor Joseph II's evening meal. Salieri quickly impressed the Emperor, and Gassmann was instructed to bring his pupil as often as he wished. This was the beginning of a relationship between monarch and musician that would last until Joseph's death in 1790. Salieri met Pietro Antonio Domenico Trapassi, better known as Metastasio and Christoph Willibald Gluck during this period at the famous Sunday morning salons held at the home of the Martinez family. Here Metastasio had an apartment and participated in the weekly gatherings. Over the next several years Metastasio gave Salieri informal instruction in prosody and the declamation of Italian poetry, and Gluck became an informal advisor, friend and confidante. It was toward the end of this extended period of study that Gassmann was called away on a new opera commission and a gap in the theater's program allowed for Salieri to make his debut as a composer of a completely original opera buffa. Salieri's first full opera was composed during the winter and carnival season of 1770; "Le donne letterate" and was based on Molière's "Les Femmes Savantes" ("The Learned Ladies") with a libretto by Giovanni Gastone Boccherini, a dancer in the court ballet and a brother of the famous composer Luigi Boccherini. The modest success of this opera would launch Salieri's 34 year operatic career as a composer of over 35 original dramas.
Early Viennese period and operas (1770–1778).
Following the modest success of "Le donne letterate" Salieri received new commissions writing two additional operas in 1770 both with libretti by Boccherini. The first a pastoral opera, "L'amore innocente" ("Innocent Love") was a light hearted comedy set in the Austrian mountains, and the second was based on an episode from Cervantes "Don Quixote" – "Don Chisciotte alle nozze di Gamace" ("Don Quixote at the Marriage of Camacho"). In these first works, drawn mostly from the traditions of mid-century opera buffa, Salieri showed a penchant for experimentation and for mixing the established characteristics of specific operatic genres. Don Chisciotte was a mix of ballet and opera buffa, and the lead female roles in "L'amore innocente" were designed to contrast and highlight the different traditions of operatic writing for soprano, even borrowing stylistic flourishes from opera-seria in the use of coloratura in what was a short pastoral comedy more in keeping with a Roman Intermezzo. The mixing and pushing against the boundaries of established operatic genres would be a continuing hallmark of Salieri's own personal style, and in his choice of material for the plot (as in his first opera), he manifested a lifelong interest in subjects drawn from classic drama and literature.
Salieri's first great success was in the realm of serious opera. Commissioned for an unknown occasion Salieri's "Armida" was based on Torquato Tasso's epic poem "La Gerusalemme liberata" ("Jerusalem Delivered") and premiered on 2 June 1771. "Armida" is a tale of love and duty in conflict and is saturated in magic. The opera is set during the First Crusade and it features a dramatic mix of ballet, aria, ensemble and choral writing combining theatricality, scenic splendor and high emotionalism. The work clearly followed in Gluck's footsteps and embraced his reform of serious opera begun with "Orfeo ed Euridice" and "Alceste". The libretto to "Armida" was by Marco Coltellini the house poet for the imperial theaters. While Salieri followed the precepts set forth by Gluck and his librettist Ranieri de' Calzabigi in the preface to "Alceste"; Salieri also drew on some musical ideas from the more traditional opera-seria and even opera buffa, creating a new synthesis in the process. "Armida" was translated into German and widely performed, especially in the northern German states, where it helped to establish Salieri's reputation as an important and innovative modern composer It would also be the first opera to receive a serious preparation in a piano and vocal reduction by Carl Friedrich Cramer in 1783.
"Armida" was soon followed by Salieri's first truly popular success; a commedia per musica in the style of Carlo Goldoni "La fiera di Venezia" ("The Fair of Venice"). "La fiera" was written for Carnival in 1772 and premiered on 29 January. Here Salieri returned to his collaboration with the young Boccherini who crafted an original plot. "La fiera" would feature characters singing in three languages, a bustling portrayal of the Ascension-tide Fair and Carnival in Venice, and large and lengthy ensembles and choruses. It also included an innovative scene that would combine a series of on stage dances with singing from both solo protagonists and the chorus. A pattern to be imitated by later composers, most famously and successfully by Wolfgang Amadeus Mozart in "Don Giovanni". Salieri would also write several bravura arias for a soprano playing the part of a middle class character that would combine coloratura and concertante woodwind solos, another innovation for a comic opera that was to be widely imitated.
Salieri's next two operas were not particular or lasting successes, of the two only "La secchia rapita" ("The Stolen Bucket"), deserves mention. A parody of Metastasian opera-seria it featured dazzling parodies of the high flown and emotive arias found in that genre, as well as bold and innovative orchestrations, including the first known use of three tympani. Again a classic of Renaissance literature was the basis of the libretto by Boccherini, in this case a comic mock-epic by Tassoni, in which a war between Modena and Bologna ensues over a stolen bucket. This uneven work was followed by another popular comedic success "La locandiera" ("Mine Hostess"), an adaptation of the classic and popular spoken stage comedy "La locandiera" by Carlo Goldoni, the libretto was prepared by Domenico Poggi.
The majority of Salieri's modest number of instrumental works also date from this time. Salieri's instrumental works have been judged by various critics and scholars to lack the inspiration and innovation found in his writing for the stage. These orchestral works are mainly in the galant style, and although they show some development toward the late classical, they reflect a general weakness in comparison to his operatic works of the same and later periods. These works were written for mostly unknown occasions and artists. They include two concertos for pianoforte, one in C major and one in B flat major (both 1773); a concerto for organ in C Major in two movements, (the middle movement is missing from the autograph score, or perhaps, it was an improvised organ solo) (also 1773); two concertante works: a concerto for oboe, violin and cello in D major (1770), and a flute and oboe concerto in C major (1774). These works are among the most frequently recorded of Salieri's compositions.
Upon Gassmann's death on 21 January, most likely due to complications from an accident with a carriage some years earlier, Salieri succeeded him as assistant director of the Italian opera in early 1774. In 1775 Salieri married Therese Helferstorfer on 10 October, she was the daughter of a recently deceased financier and official of the court treasury. Sacred music was not a high priority for the composer during this stage of his career, but he did compose an Alleluia for chorus and orchestra in 1774.
During the next three years Salieri was primarily concerned with rehearsing and conducting the Italian opera company in Vienna and teaching. His three complete operas written during this time show the development of his compositional skills, but included no great success, either commercially, or artistically. His most important compositions during this period were a symphony in D major, performed in the summer of 1776, and the oratorio "La passione di Gesù Cristo" with a text by Metastasio performed during Advent of 1776.
After the financial collapse of the Italian opera company in 1777 due to financial mis-management, Joseph II decided to end the performance of Italian opera, French spoken drama, and ballet. Instead, the two court-owned theaters would be reopened under new management, and partly subsidized by the Imperial Court, as a new National Theater. The re-launched theaters would promote German language plays and musical productions that reflected Austrian (or as Joseph II would have said) German values, traditions and outlook. The Italian opera buffa company was therefore replaced by a German language Singspiel troupe. For Joseph and his supports of Imperial reform, besides encouraging any first buddings of pan-national pride that would unite his multi-lingual and ethnic subjects under one common language; they also hoped to save a considerable amount of money in the process. Beginning in 1778 Emperor wished to have new works, in German, composed by his own subjects and brought on the stage with clear Imperial support. This in effect left Salieri's role as assistant court composer in a much reduced position. Salieri also had never truly mastered the German language, and he now felt no longer competent to continue as assistant opera director. A further blow to his career was landed when the spoken drama and musical Singspiel were placed on an equal footing. For the young composer there would be few, if any, new compositional commissions to receive from the court. Salieri was left with few financial options and he began casting about for new opportunities.
Italian tour (1778–1780).
However, in 1778 Gluck turned down an offer to compose the inaugural opera for La Scala in Milan; upon the suggestion of Joseph II and with the approval of Gluck, Salieri was offered the commission, which he gratefully accepted. Joseph II granted Salieri permission to take a year-long leave of absence (later extended) thus enabling him to write for La Scala and to undertake a tour of Italy. Salieri's Italian tour of 1778–80 began with the production of "Europa riconosciuta" ("Europa Recognized") for La Scala (which was revived in 2004 for the same opera house's re-opening following extensive renovations). From Milan Salieri included stops in Venice and Rome and finally a return to Milan. During this tour he wrote three new comic operas and he also collaborated with Giacomo Rust on one opera, "Il Talismano" ("The Talisman"). Of his Italian works one, "La scuola de' gelosi" ("The School for Jealousy"), a witty study of amorous intrigue and emotion, would prove a popular and lasting international success.
Middle Viennese period and Parisian operas (1780–1788).
Upon his return at imperial behest to Vienna in 1780, he wrote one German singspiel "Der Rauchfangkehrer" or ("The Chimney Sweep") which premiered in 1781. Salieri's "Chimney Sweep" and Mozart's work for the same company in 1782, "Die Entführung aus dem Serail" ("The Abduction from the Seraglio") would be the only two major successes to emerge from the German singspiel experiment, and only Mozart's opera would survive on the stage beyond the close of the 18th century. In 1783 the Italian opera company was revived with singers partly chosen and vetted by Salieri during his Italian tour, the new season would open with a slightly re-worked version of Salieri's recent success "La scuola de' gelosi". Salieri then returned to his rounds of rehearsing, composition and teaching. However, his time at home in Vienna would be quickly brought to a close when an opportunity to write an opera for Paris arose, again through the patronage of Gluck Salieri traveled abroad to fulfill an important commission.
The opera "Les Danaïdes" ("The Danaids") is a five-act tragédie lyrique; the plot was based on an ancient Greek legend that had been the basis for the first play in a trilogy by Aeschylus, entitled "The Suppliants". The original commission that reached Salieri in 1783–84 was to assist Gluck in finishing a work for Paris that had been all but completed; in reality, Gluck had failed to notate any of the score for the new opera and gave the entire project over to his young friend. Gluck feared that the Parisian critics would denounce the opera by a young composer known mostly for comic pieces and so the opera was originally billed in the press as being a new work by Gluck with some assistance from Salieri, then shortly before the premiere of the opera the Parisian press reported that the work was to be partly by Gluck and partly by Salieri, and finally after popular and critical success were won on stage the opera was acknowledged in a letter to the public by Gluck as being wholly by the young Salieri. "Les Danaïdes" was received with great acclaim and its popularity with audiences and critics alike produced several further requests for new works for Paris audiences by Salieri. "Les Danaïdes" followed in the tradition of reform that Gluck had begun in the 1760s and that Salieri had emulated in his earlier opera "Armida". Salieri's first French opera contained scenes of great solemnity and festivity; yet overshadowing it all was darkness and revenge. The opera depicted politically motivated murder, filial duty and love in conflict, tyrannicide and finally eternal damnation. The opera with its dark overture, lavish choral writing, many ballet scenes, and electrifying finale depicting a glimpse of hellish torture kept the opera on the stage in Paris for over forty years. A young Hector Berlioz recorded the deep impression this work made on him in his "Mémoires".
Upon returning to Vienna following his success in Paris, Salieri met and befriended Lorenzo Da Ponte and had his first professional encounters with Mozart. Da Ponte would write his first opera libretto for Salieri, "Il ricco d'un giorno" ("A Rich Man for a Day") in 1784, it was not a success. Salieri next turned to Giambattista Casti as a librettist, a more successful set of collaboration flowed from this pairing. In the mean time Da Ponte would begin work with Mozart on "Le nozze di Figaro" ("The Marriage of Figaro"). (For the famous relationship between Mozart and Salieri please see below.) Salieri soon produced one of his greatest works with the text by Casti "La grotta di Trofonio" ("The Cave of Trophonius") in 1785, the first opera buffa published in full score by Artaria. Shortly after this success Joseph II had Mozart and Salieri each contribute a one-act opera and/or singspiel for production at a banquet in 1786. Salieri collaborated with Casti to produce a parody of the relationship between poet and composer in "Prima la musica e poi le parole" ("First the Music and then the Words"). This short work also highlighted the typical backstage antics of two high flown sopranos. Salieri then returned to Paris for the premiere of his tragédie lyrique "Les Horaces" ("The Horatii") which proved a failure. However the failure of this work was more than made up for with his next Parisian opera "Tarare" with a libretto by Beaumarchais. This was intended to be the "nec plus ultra" of reform opera, a completely new synthesis of poetry and music that was an 18th-century anticipation of the ideals of Richard Wagner. He also created a sacred cantata "Le Jugement dernier" ("The Last Judgement"). The success of his opera "Tarare" was such that it was soon translated into Italian at Joseph II's behest by Lorenzo Da Ponte as "Axur, Re d'Ormus" ("Axur, King of Hormuz") and staged at the royal wedding of Franz II in 1788.
Late Viennese operas (1788–1804).
In 1788 Salieri returned to Vienna where he remained for the rest of his life. In that year he became Kapellmeister of the Imperial Chapel upon the death of Giuseppe Bonno; as Kapellmeister he conducted the music and musical school connected with the chapel until shortly before his death, being official retired from the post in 1824.
His Italian adaptation of "Tarare", "Axur" would prove to be his greatest international success. "Axur" was widely produced throughout Europe and it even reached South America with the exiled royal house of Portugal in 1824. "Axur" and his other new compositions completed by 1792 would mark the height of Salieri's popularity and his influence. Just as his apogee of fame was being reached abroad, his influence in Vienna would begin to diminish with the death of Joseph II in 1790. Joseph's death deprived Salieri of his greatest patron and protector. During this period of imperial change in Vienna and revolutionary ferment in France, Salieri composed two additional extremely innovative musical dramas to libretti by Giovanni Casti. Due, however, to their satiric and overtly liberal political inclinations, both operas were seen as unsuitable for public performance in the politically reactive cultures of Leopold II and later Francis II. This resulted in two of his most original operas being consigned to his desk drawer, namely "Cublai, gran kan de' Tartari" ("Kublai Grand Kahn of Tartary") a satire on the autocracy and court intrigues at the court of the Russian Czarina, Catherine the Great, and "Catilina" a semi-comic-semi-tragic account of the Catiline conspiracy that attempted to overthrow the Roman republic during the consulship of Cicero. These operas were composed in 1787 and 1792 respectively. Two other operas of little success and longterm importance were composed in 1789, and one great popular success "La cifra" ("The Cipher").
As Salieri's political position became very insecure he was retired as director of the Italian opera in 1792. He continued to write new operas per imperial contract until 1804, when he voluntarily withdrew from the stage. Of his late works for the stage only two works gained wide popular esteem during his life, "Palmira, regina di Persia" ("Palmira, Queen of Persia") 1795 and "Cesare in Farmacusa" ("Caesar on Pharmacusa"), both drawing on the heroic and exotic success established with "Axur". His late opera based on William Shakespeare's "The Merry Wives of Windsor", "Falstaff ossia Le tre burle" ("Falstaff, or the Three Tricks"), (1799) has found a wider audience in modern times than its original reception promised. His last opera was a German language singspiel "Die Neger", ("The Negroes"), a melodrama set in colonial Virginia with a text by Georg Friedrich Treitschke (the author of the libretto for Beethoven's "Fidelio") performed in 1804 and was a complete failure.
Life after opera (1804–1825).
When Salieri retired from the stage, he recognized that artistic styles had changed and he felt that he no longer had the creative capacity to adapt or the emotional desire to continue. Also as Salieri aged he moved slowly away from his more liberal political stances as he saw the enlightened reform of Joseph II's reign, and the hoped for reforms of the French revolution, replaced with more radical revolutionary ideas. As the political situation threatened and eventually overwhelmed Austria, which was repeatedly crushed by French political forces, Salieri's first and most important biographer Mosel described the emotional effect that this political, social, and cultural upheaval had on the composer. Mosel noted that these radical changes, especially the invasion and defeat of Austria, and the occupation of Vienna intertwined with the personal losses that struck Salieri in the same period led to his withdrawal from operatic work. Related to this Mosel quotes the aged composer concerning the radical changes in musical taste that were underway in the age of Beethoven, "From that period [circa 1800] I realized that musical taste was gradually changing in a manner completely contrary to that of my own times. Eccentricity and confusion of genres replaced reasoned and masterful simplicity."
As his teaching and work with the imperial chapel continued, his duties required the composition of a large number of sacred works, and in his last years it was almost exclusively in religious works and teaching that Salieri occupied himself. Among his compositions written for the chapels needs were two complete sets of vespers, many graduals, offertories, and four orchestral masses. During this period he lost his only son in 1805 and his wife in 1807.
Salieri continued to conduct publicly (including the performance of Haydn's "The Creation", during which Haydn collapsed, and several premiers by Beethoven including the 1st and 2nd Piano Concertos and "Wellington's Victory"). He also continued to help administer several charities and organize their musical events.
His remaining secular works in this late period fall into three categories: first, large scale cantatas and one oratorio "Habsburg" written on patriotic themes or in response to the international political situation, pedagogical works written to aid his students in voice, and finally simple songs, rounds or canons written for home entertainment; many with original poetry by the composer. He also composed one large scale instrumental work in 1815 intended as a study in late classical orchestration: "Twenty-Six Variations for the Orchestra on a Theme called La Folia di Spagna". The theme is likely folk derived and is known as "La Folia". This simple melodic and harmonic progression had served as an inspiration for many baroque composers, and would be used by later romantic and post-romantic composers. Salieri's setting is a brooding work in the minor key, which rarely moves far from the original melodic material, its main interest lies in the deft and varied handling of orchestral colors. "La Folia" was the most monumental set of orchestral variations before Brahms' "Variations on a Theme by Haydn".
His teaching of budding young musicians continued, and among his pupils in composition (usually vocal) were Ludwig van Beethoven, Antonio Casimir Cartellieri, Franz Liszt, Franz Schubert and many other luminaries of the early Romantic period. He also instructed many prominent singers throughout his long career. All but the wealthiest of his pupils received their lessons for free, a tribute to the kindness Gassmann had shown Salieri as a penniless orphan.
Salieri was committed to medical care and suffered dementia for the last year and a half of his life. He died in Vienna on 7 May 1825, and was buried in the Matzleinsdorfer Friedhof on 10 May. At his memorial service on 22 June 1825 his own Requiem in C minor – composed in 1804 – was performed for the first time. His remains were later transferred to the Zentralfriedhof. His monument is adorned by a poem written by Joseph Weigl, one of his pupils:
Works.
Opera.
During his time in Vienna, Salieri acquired great prestige as a composer and conductor, particularly of opera, but also of chamber and sacred music. Among the most successful of his 37 operas staged during his lifetime were "Armida" (1771), "La fiera di Venezia" (1772), "La scuola de' gelosi" (1778), "Der Rauchfangkehrer" (1781), "Les Danaïdes" (1784), which was first presented as a work of Gluck's, "La grotta di Trofonio" (1785), "Tarare" (1787) ("Tarare" was reworked and revised several times as was "Les Danaïdes" ), "Axur, re d'Ormus" (1788), "La cifra" (1789), "Palmira, regina di Persia" (1795), "Il mondo alla rovescia" (1795), "Falstaff" (1799), and "Cesare in Farmacusa" (1800).
Sacred works.
Salieri's earliest surviving work is a Mass in C major. He would write four major orchestral masses, a requiem, and many offertories, graduals, vesper settings, and sacred cantatas and oratorios. Much of his sacred music dates from after his appointment as Hofkapellmeister in 1788.
Instrumental works.
His small instrumental output includes two piano concerti, a concerto for organ written in 1773, a concerto for flute, oboe and orchestra (1774), a triple concerto for oboe, violin and cello, and a set of twenty-six variations on "La follia di Spagna" (1815).
Interaction with Mozart.
In the 1780s while Mozart lived and worked in Vienna, he and his father Leopold wrote in their letters that several "cabals" of Italians led by Salieri were actively putting obstacles in the way of Mozart's obtaining certain posts or staging his operas. For example, Mozart wrote in December 1781 to his father that "the only one who counts in [the Emperor's] eyes is Salieri". Their letters suggest that both Mozart and his father, being Germans who resented the special place that Italian composers had in the courts of the Austrian princes, blamed the Italians in general and Salieri in particular for all of Mozart's difficulties in establishing himself in Vienna. Mozart wrote to his father in May 1783 about Salieri and Lorenzo Da Ponte, the court poet: "You know those Italian gentlemen; they are very nice to your face! Enough, we all know about them. And if [Da Ponte] is in league with Salieri, I'll never get a text from him, and I would love to show here what I can really do with an Italian opera." In July 1783 Mozart wrote to his father of "a trick of Salieri's", one of several letters in which he accused Salieri of trickery. Decades after Mozart's death, a rumour began to circulate that Mozart had been poisoned by Salieri. This rumour has been attributed by some to a rivalry between the German and the Italian schools of music. Carl Maria von Weber, a relative of Mozart by marriage whom Wagner has characterized as the most German of German composers, is said to have refused to join Ludlams-Höhle, a social club of which Salieri was a member and avoided having anything to do with him. These rumors then made their way into popular culture. Albert Lortzing's "Singspiel" "Szenen aus Mozarts Leben" LoWV28 (1832) uses the cliché of the jealous Salieri trying to hinder Mozart's career.
Ironically, Salieri's music was much more in the tradition of Gluck and Gassmann than of the Italians like Paisiello or Cimarosa. In 1772, Empress Maria Theresa commented on her preference of Italian composers over Germans like Gassmann, Salieri or Gluck. While Italian by birth, Salieri had lived in imperial Vienna for almost 60 years and was regarded by such people as the music critic Friedrich Rochlitz as a German composer.
The biographer Alexander Wheelock Thayer believes that Mozart's rivalry with Salieri could have originated with an incident in 1781 when Mozart applied to be the music teacher of Princess Elisabeth of Württemberg, and Salieri was selected instead because of his reputation as a singing teacher. In the following year Mozart once again failed to be selected as the Princess's piano teacher. "Salieri and his tribe will move heaven and earth to put it down", Leopold Mozart wrote to his daughter Nannerl. But at the time of the premiere of "Figaro", Salieri was busy with his new French opera "Les Horaces". In addition, when Lorenzo Da Ponte was in Prague preparing the production of Mozart's setting of his "Don Giovanni", the poet was ordered back to Vienna for a royal wedding for which Salieri's "Axur, re d'Ormus" would be performed. Obviously, Mozart was not pleased by this.
However, even with Mozart and Salieri being rivals for certain jobs, there is very little evidence that the relationship between the two composers was at all acrimonious beyond this, especially after 1785 or so when Mozart had become established in Vienna. Rather, they appeared to usually see each other as friends and colleagues and supported each other's work. For example, when Salieri was appointed Kapellmeister in 1788 he revived "Figaro" instead of bringing out a new opera of his own; and when he went to the coronation festivities for Leopold II in 1790 he had no fewer than three Mozart masses in his luggage. Salieri and Mozart even composed a cantata for voice and piano together, called "Per la ricuperata salute di Ophelia," which celebrated the return to stage of the singer Nancy Storace. This work has been lost, although it had been printed by Artaria in 1785. Mozart's "Davide penitente" (1785), his Piano Concerto KV 482 (1785), the Clarinet Quintet (1789) and the 40th Symphony (1788) had been premiered on the suggestion of Salieri, who supposedly conducted a performance of it in 1791. In his last surviving letter from 14 October 1791, Mozart tells his wife that he collected Salieri and Caterina Cavalieri in his carriage and drove them both to the opera; about Salieri's attendance at his opera "The Magic Flute", speaking enthusiastically: "He heard and saw with all his attention, and from the overture to the last choir there was not a piece that didn't elicit a 'Bravo!' or 'Bello!' out of him [...]."
Salieri, along with Mozart's protégé J. N. Hummel, educated Mozart's younger son Franz Xaver Mozart, who was born in the year his father died.
Modern performances of Salieri's work.
In 2003, mezzo-soprano Cecilia Bartoli released "The Salieri Album", a CD with 13 arias from Salieri's operas, most of which had never been recorded before. Patrice Michaels sang a number of his arias on the CD "Divas of Mozart's Day". In 2008, another female opera star, Diana Damrau, released a CD with seven Salieri coloratura arias. Since 2000, there have also been complete recordings issued or re-issued of the operas "Axur Re d'Ormus", "Falstaff", "Les Danaïdes", "La Locandiera", "La grotta di Trofonio", "Prima la musica e poi le parole" and "Il mondo alla rovescia". Salieri has yet to fully re-enter the general repertory, but performances of his works are progressively becoming more regular.
His operas "Falstaff" (1995 production) and "Tarare" (1987 production) have been released on DVD. In 2004, the opera "Europa riconosciuta" was staged in Milan for the reopening of La Scala in Milan, with soprano Diana Damrau in the title role. This production was also broadcast on television.
In November 2009 at the Teatro Salieri in Legnago occurred the first staging in modern times of his opera "Il mondo alla rovescia", a co-production between the Fondazione Culturale Antonio Salieri and the Fondazione Arena di Verona for the Salieri Opera Festival.
Use of music by Salieri in films.
Salieri has even begun to attract some attention from Hollywood. In 2001, his triple concerto was used in the soundtrack of "The Last Castle", featuring Robert Redford and James Gandolfini. It is a story that builds on the rivalry between a meticulous but untested officer (Gandolfini) serving as the warden of a military prison and an imprisoned but much admired and highly decorated general (Redford). The Salieri piece is used as the warden's theme music, seemingly to invoke the image of jealousy of the inferior for his superior. In 2006, the movie "Copying Beethoven" referred to Salieri in a more positive light. In this movie a young female music student hired by Beethoven to copy out his Ninth Symphony is staying at a monastery. The abbess tries to discourage her from working with the irreverent Beethoven. She notes that she too once had dreams, having come to Vienna to study opera singing with Salieri. Most recently the 2008 film "Iron Man" used the Larghetto movement from Salieri's Piano Concerto in C major. The scene where Obadiah Stane, the archrival of 'Tony' Stark, the wealthy industrialist turned Ironman, tells Tony that he is being ousted from his company by the board, Obadiah plays the opening few bars of the Salieri concerto on a piano in Stark's suite.
Fictional treatments.
Salieri's life and especially his relationship with Mozart has been a subject of many stories. Within a few years of Salieri's death in 1825, Alexander Pushkin wrote his "little tragedy" "Mozart and Salieri" (1831) as a dramatic study of the sin of envy. Russian composer Nikolai Rimsky-Korsakov adapted Pushkin's play as an opera of the same name in 1898.
A hugely popular yet heavily fictionalized perpetuation of the story came in Peter Shaffer's play "Amadeus" (1979) and the Oscar-winning 1984 film directed by Miloš Forman based upon it. Salieri was portrayed in the award-winning play at London's National Theatre by Paul Scofield. Salieri is played in the film by F. Murray Abraham, who won the Academy Award for Best Actor for the part. Abraham depicts Salieri as a Machiavellian, Iago-esque character, who uses his connections to keep Mozart as the underdog and slowly destroy Mozart's career. The play does not portray Salieri as a murderer but rather has him hastening Mozart's demise through a series of plots, leaving him destitute. Salieri is characterized as both in awe of and insanely jealous of Mozart, going so far as to renounce God for blessing his adversary; "Amadeus" means love of God, or God's love, and the play can be said to be about God-given talent, or the lack thereof: Salieri is hospitalized in a mental institution, where he announces himself as "the patron saint of mediocrity".
Salieri's supposed hatred for Mozart is also alluded to in a spoof opera entitled "A Little Nightmare Music", by P.D.Q. Bach. In the opera, Salieri attempts to poison an anachronistic Shaffer but is bumped by a "clumsy oaf", which causes him to inadvertently poison Mozart instead and spill wine on his favorite coat.
Patrick Stewart played Salieri in the 1985 production "The Mozart Inquest". Florent Mothe portrays Salieri in the 2009 French musical "Mozart, l'opéra rock".
Upcoming period drama, "Virtuoso", directed by Alan Ball is largely centred around the early life of Salieri.
References.
Notes
Cited sources
Further reading
External links.
Scores

</doc>
<doc id="2244" url="http://en.wikipedia.org/wiki?curid=2244" title="Cobble Hill Tunnel">
Cobble Hill Tunnel

The Cobble Hill Tunnel (popularly the Atlantic Avenue Tunnel) of the Long Island Rail Road (LIRR) is an abandoned railroad tunnel beneath Atlantic Avenue in downtown Brooklyn, New York City. When open, it ran for about 2517 ft between Columbia Street and Boerum Place. It is the oldest railway tunnel beneath a city street in North America that was fully devoted to rail.
Construction and operation.
Construction began in May 1844. The tunnel opened for use on December 3, 1844, but was not completely finished until late Spring 1845. It was built mainly to satisfy public demand for creation of a grade-separated right of way for the Brooklyn and Jamaica Railroad (later Long Island Rail Road) on its way to the South Ferry at the foot of Atlantic Street (later Atlantic Avenue), where passengers could catch ferries to Manhattan. The construction of the tunnel also lowered the LIRR's grade through Cobble Hill.
In exchange for building the tunnel, the City of Brooklyn granted the B&J permission to operate its steam locomotives on Atlantic Street west of Fifth Avenue (then Parmentier's Garden/Gowanus Lane), all the way to Brooklyn's South Ferry (the present location of Brooklyn's Pier 7). Prior to the tunnel being built, the LIRR's western terminus was Atlantic Street at Clinton Street. Train cars were hauled by teams of horses along Atlantic Street from Clinton Street to Parmentier's Garden, where steam locomotives were attached. While the tunnel was being built, the railroad operated to a temporary terminal at Pacific Street and Henry Street.
The Cobble Hill Tunnel was part of the first rail link between New York City and Boston, Massachusetts. The railroad connected Lower Manhattan via the South Ferry to Greenport on the North Fork of Long Island, where a ferry connected to Stonington, Connecticut to a rail link that continued to Boston. This avoided some difficult construction of bridges over the rivers of southern Connecticut. In 1848, the New York and New Haven Railroad Line was completed through Connecticut, providing a direct, faster rail connection from New York City to Boston. The Cobble Hill Tunnel and the Long Island Railroad remained the primary means of access to most of central Long Island from Manhattan and New York City. As built, the tunnel was 21 ft wide, 17 ft high and 2517 ft long.
Insofar as it carried railroad trains under a city street, some have claimed it be the world's first subway tunnel, although unlike in current rapid transit subway systems, it had no stations. The ends of the tunnel were sealed in the fall of 1861. The similar Murray Hill Tunnel on the New York and Harlem Railroad was built as an open cut around 1836, and roofed over around the 1850s, and is in use for automobile traffic.
Closure controversy.
In 1861, the New York State Legislature voted to ban railroad locomotives from within the limits of the City of Brooklyn. A tax assessment was ordered on all property owners along Atlantic Street (today Atlantic Avenue), to defray the costs of the closure. It was undisclosed at the time that New York State Governor John A. King was a major shareholder in the Brooklyn and Jamaica Railroad (later the Long Island Rail Road) and therefore had a conflict of interest and stood to benefit by the compensation payments to the railroad from the tax assessment.
Dormancy.
Walt Whitman wrote of the tunnel:
In March 1916, the Bureau of Investigation suspected German terrorists were making bombs in the tunnel, and broke through the roof of the tunnel with jackhammers. They found nothing, installed an electric light, and resealed it. In the 1920s it was rumored used for both mushroom growing and bootleg whiskey stills even though there was no access into the main portion of the tunnel. It became an object of local folklore and legend. In 1936, the New York City Police Department unsuccessfully attempted to enter the tunnel, in order to look for the body of a hoodlum supposedly buried there. In 1941 it was rumored to have been inspected by the federal Works Progress Administration to determine its structural strength, but there is no evidence of this. A few years later, it was once again rumored to have been opened, this time by the FBI, in an unsuccessful search for spies; however, there is no evidence of this. During the late 1950s it was sought by two rail historians, George Horn and Martin Schachne, but they did not gain access to the tunnel itself.
Rediscovery.
Having fallen from public notice, the tunnel was rediscovered in 1981 by then 18-year-old Robert Diamond, who entered from a manhole he located at Atlantic Avenue and Court Street, crawled a distance of 70 ft underground through a filled-in section of tunnel less than two feet high, and located the bulkhead wall that sealed off the main portion of the tunnel. With the assistance of a Brooklyn Union Gas Co. (now National Grid) engineering crew, he then broke through the massive concrete bulkhead wall, which is several feet thick. Diamond thereby opened access to the main portion of the tunnel, and began to popularize the tunnel as an antiquity. He led tours of its interior from 1982 until December 17, 2010, when the Department of Transportation terminated his contract, citing safety concerns. The tunnel has been listed on the National Register of Historic Places since 1989.
The History Channel series "Cities of the Underworld" ran a segment ("New York's Secret Societies") on the tunnel in Fall 2008. The TV show "Treasure Hunters" used it in an episode.
References.
Notes
Further reading
</dl>

</doc>
<doc id="2245" url="http://en.wikipedia.org/wiki?curid=2245" title="Annapolis Valley">
Annapolis Valley

The Annapolis Valley is a valley and region in the Canadian province of Nova Scotia. It is located in the western part of the Nova Scotia peninsula, formed by a trough between two parallel mountain ranges along the shore of the Bay of Fundy. Statistics Canada, defines the Annapolis Valley as an economic region, composed of Annapolis County, Kings County, and Hants County.
Geography.
The valley measures approximately 126 km in length from Digby and the Annapolis Basin in the west to Wolfville and the Minas Basin in the east, spanning the counties of Digby, Annapolis and Kings.
Some also include the western part of Hants County, including the towns of Hantsport and Windsor even further to the east, but geographically speaking they are part of the Avon River valley.
The steep face of basaltic North Mountain shelters the valley from the adjacent Bay of Fundy and rises over 260 m in elevation near Lawrencetown. The granitic South Mountain rises to a somewhat higher elevation and shelters the valley from the climate of the Atlantic Ocean approximately 100 kilometres further south on the province's South Shore.
The shelter provided by these two mountainous ridges has produced a "micro climate" which provides relatively mild temperatures for the region and, coupled with the fertile glacial sedimentary soils on the valley floor, the region is conducive to growing vegetable and fruit crops. Particularly famous for its apple crop, the valley hosts in excess of 1,000 farms of various types, the majority being relatively small family-owned operations.
Within the valley itself are two "major" rivers, the Annapolis River which flows west from the Caribou Bog in the central part of the valley into the Annapolis Basin, and the Cornwallis River which flows east from Caribou Bog into the Minas Basin. The North Mountain ridge forms the north side of the Annapolis Valley. Also flowing east, in two smaller valleys north of the Cornwallis River, are the Canard River and the Habitant River, both of which also flow into the Minas Basin.
History.
Long settled by the Mi'kmaq Nation, the valley experienced French settlement at the Habitation at Port-Royal, near modern day Annapolis Royal in the western part of the valley, beginning in 1605. From there, the Acadians spread throughout the Valley, in various communities, building dykes to claim the tidal lands along the Annapolis and Cornwallis Rivers. They continued throughout the Annapolis Valley until the British-ordered expulsion of Acadians in 1755 which is memorialized at Grand Pré in the eastern part of the valley. New England Planters moved in to occupy the abandoned Acadian farming areas and the region also saw subsequent settlement by Loyalist refugees of the American Revolutionary War, as well as foreign Protestants. These were followed by significant numbers of freed Africans in the War of 1812, Irish immigrants in the mid-19th century and Dutch immigrants after World War II. Agriculture in the Annapolis valley boomed in the late 19th century with the arrival of the Windsor and Annapolis Railway, later the Dominion Atlantic Railway, which developed large export markets for Annapolis Valley apples.
Economy.
The Valley has been traditionally been built on a diversified agricultural industry, with a wide range of output ranging from livestock to fruit trees and berries. The last quarter century has also seen the development of a wine industry, with such notable wineries as Gaspereau Vineyards winning national and international awards for their produce.
Today, the Valley is still largely dominated by agriculture but also has a growing diversity in its economies, partly aided by the importance of post-secondary education centres provided by Acadia University in Wolfville, and the Nova Scotia Community College campuses located in Kentville, Middleton, Lawrencetown, and Digby.
Michelin has an important truck tire manufacturing plant in Waterville and the Department of National Defence has its largest air force base in Atlantic Canada located at CFB Greenwood along with an important training facility at Camp Aldershot, near Kentville.
Tourism is also an important industry and the Annapolis Valley is known for its scenic farmland, although today some is threatened with suburban development in the eastern end, and a great deal has been abandoned. The valley also struggles with pollution from farm runoffs and residential sewers in its two major rivers, the Annapolis River and the Cornwallis River.
The Valley is home to the annual Apple Blossom Festival, held in late spring. In July is the annual Steer Bar-B-Que in Kingston, and Heart of the Valley Festival in Middleton. August sees Mud Creek Days in Wolfville and the Annapolis Valley Exhibition in Lawrencetown. Bridgetown's Cider Festival comes in mid-September. The Canadian Deep Roots Music Festival is held each year at the end of September in Wolfville, a community-based festival, supported by both The Town of Wolfville and Acadia University and built on countless hours of volunteerism by a stable base of over 100 volunteers, and on in-kind and financial support from virtually all sectors of the Valley community. Farmers markets in Annapolis Royal, Bridgetown, Middleton, Kentville, Kingsport, Berwick and Wolfville bring a wealth of fresh produce and other fine goods to the public every week. In the fall the Pumpkin People in Kentville entice the imagination.
Communities.
Population centres in the valley from west to east include:

</doc>
<doc id="2246" url="http://en.wikipedia.org/wiki?curid=2246" title="Analgesic">
Analgesic

An analgesic, or painkiller, is any member of the group of drugs used to achieve analgesia — relief from pain. The word "analgesic" derives from Greek ἀν-, "without", and ἄλγος, "pain".
Analgesic drugs act in various ways on the peripheral and central nervous systems. They are distinct from anesthetics, which reversibly eliminate sensation. Analgesics include paracetamol (known in the US as acetaminophen or simply APAP), the non-steroidal anti-inflammatory drugs (NSAIDs) such as the salicylates, and opioid drugs such as morphine and oxycodone.
In choosing analgesics, the severity and response to other medication determines the choice of agent; the World Health Organization (WHO) pain ladder specifies mild analgesics as its first step.
Analgesic choice is also determined by the type of pain: For neuropathic pain, traditional analgesics are less effective, and there is often benefit from classes of drugs that are not normally considered analgesics, such as tricyclic antidepressants and anticonvulsants.
Major classes.
Paracetamol and NSAIDs.
The exact mechanism of action of paracetamol/acetaminophen is uncertain but appears to act centrally in the brain rather than peripherally in nerve endings. Aspirin and the other non-steroidal anti-inflammatory drugs (NSAIDs) inhibit cyclooxygenases, leading to a decrease in prostaglandin production. In contrast to paracetamol and the opioids, this reduces not only pain but inflammation as well.
Paracetamol has few side-effects and is regarded as generally safe in low and infrequent doses as prescribed or per manufacturer's instructions, otherwise use can lead to potentially life-threatening liver damage and occasionally kidney damage. Side effects include Bloody or black, tarry stools, bloody or cloudy urine, fever with or without chills (not present before treatment and not caused by the condition being treated), pain in the lower back and/or side (severe and/or sharp), pinpoint red spots on the skin, skin rash, hives, or itching, sore throat (not present before treatment and not caused by the condition being treated), sores, ulcers, or white spots on the lips or in the mouth, sudden decrease in the amount of urine, unusual bleeding or bruising, unusual tiredness or weakness, yellow eyes or skin.
While paracetamol is usually taken orally or rectally, an intravenous preparation introduced in 2002 has been shown to improve pain relief and reduce opioid consumption in the perioperative setting.
NSAIDs can predispose to in some patients peptic ulcers, renal failure, allergic reactions, and occasionally tinnitus with excess dosage, and they can increase the risk of hemorrhage by affecting platelet function. The use of aspirin in children under 16 suffering from viral illness has been linked to Reye's syndrome, a rare but severe liver disorder.
COX-2 inhibitors.
These drugs have been derived from NSAIDs. The cyclooxygenase enzyme inhibited by NSAIDs was discovered to have at least 2 different versions: COX1 and COX2. Research suggested most of the adverse effects of NSAIDs to be mediated by blocking the COX1 (constitutive) enzyme, with the analgesic effects being mediated by the COX2 (inducible) enzyme. Thus, the COX2 inhibitors were developed to inhibit only the COX2 enzyme (traditional NSAIDs block both versions in general). These drugs (such as rofecoxib, celecoxib, and etoricoxib) are equally effective analgesics when compared with NSAIDs, but cause less gastrointestinal hemorrhage in particular.
After widespread adoption of the COX-2 inhibitors, it was discovered that most of the drugs in this class increase the risk of cardiovascular events by 40% on average. This led to the withdrawal of rofecoxib and valdecoxib, and warnings on others. Etoricoxib seems relatively safe, with the risk of thrombotic events similar to that of non-coxib NSAID diclofenac.
Opioids.
Morphine, the archetypal opioid, and various other substances (e.g., codeine, oxycodone, hydrocodone, dihydromorphine, pethidine) all exert a similar influence on the cerebral opioid receptor system. Buprenorphine is thought to be a partial agonist of the opioid receptor, and tramadol is an opiate agonist with SNRI properties. Tramadol is structurally closer to venlafaxine than to codeine and delivers analgesia by not only delivering "opiate-like" effects (through mild agonism of the mu receptor) but also by acting as a weak but fast-acting serotonin releasing agent and norepinephrine reuptake inhibitor. Tapentadol, with some structural similarities to tramadol, presents what is believed to be a novel drug working through two (and possibly three) different modes of action in the fashion of both a traditional opioid and as a SNRI. The effects of serotonin and norepinephrine on pain, while not completely understood, have had causal links established and drugs in the SNRI class are commonly used in conjunction with opioids (especially tapentadol and tramadol) with greater success in pain relief. Dosing of all opioids may be limited by opioid toxicity (confusion, respiratory depression, myoclonic jerks and pinpoint pupils), seizures (tramadol), but opioid-tolerant individuals usually have higher dose ceilings than patients without tolerance. 
Opioids, while very effective analgesics, may have some unpleasant side-effects. Patients starting morphine may experience nausea and vomiting (generally relieved by a short course of antiemetics such as phenergan). Pruritus (itching) may require switching to a different opioid. Constipation occurs in almost all patients on opioids, and laxatives (lactulose, macrogol-containing or co-danthramer) are typically co-prescribed.
When used appropriately, opioids and similar narcotic analgesics are otherwise safe and effective, however risks such as addiction and the body's becoming used to the drug (tolerance) can occur. The effect of tolerance means that frequent use of the drug may result in its diminished effect so, when safe to do so, the dosage may need to be increased to maintain effectiveness. This may be of particular concern regarding patients suffering with chronic pain.
Flupirtine.
Flupirtine is a centrally acting K+ channel opener with weak NMDA antagonist properties. It is used in Europe for moderate to strong pain and migraine and its muscle-relaxant properties. It has no anticholinergic properties and is believed to be devoid of any activity on dopamine, serotonin, or histamine receptors. It is not addictive, and tolerance usually does not develop. However, tolerance may develop in single cases.
Specific agents.
In patients with chronic or neuropathic pain, various other substances may have analgesic properties. Tricyclic antidepressants, especially amitriptyline, have been shown to improve pain in what appears to be a central manner. Nefopam is used in Europe for pain relief with concurrent opioids. The exact mechanism of carbamazepine, gabapentin, and pregabalin is similarly unclear, but these anticonvulsants are used to treat neuropathic pain with differing degrees of success. Anticonvulsants are most commonly used for neuropathic pain as their mechanism of action tends to inhibit pain sensation.
Specific forms and uses.
Combinations.
Analgesics are frequently used in combination, such as the paracetamol and codeine preparations found in many non-prescription pain relievers. They can also be found in combination with vasoconstrictor drugs such as pseudoephedrine for sinus-related preparations, or with antihistamine drugs for allergy sufferers.
While the use of paracetamol, aspirin, ibuprofen, naproxen, and other NSAIDS concurrently with weak to mid-range opiates (up to about the hydrocodone level) has been said to show beneficial synergistic effects by combatting pain at multiple sites of action, several combination analgesic products have been shown to have few efficacy benefits when compared to similar doses of their individual components. Moreover, these combination analgesics can often result in significant adverse events, including accidental overdoses, most often due to confusion that arises from the multiple (and often non-acting) components of these combinations.
Topical or systemic.
Topical analgesia is generally recommended to avoid systemic side-effects. Painful joints, for example, may be treated with an ibuprofen- or diclofenac-containing gel (The labeling for topical diclofenac has been updated to warn about drug-induced hepatotoxicity.); capsaicin also is used topically. Lidocaine, an anesthetic, and steroids may be injected into painful joints for longer-term pain relief. Lidocaine is also used for painful mouth sores and to numb areas for dental work and minor medical procedures. In February 2007 the FDA notified consumers and healthcare professionals of the potential hazards of the use of topical anesthetics. These topical anesthetics contain anesthetic drugs such as lidocaine, tetracaine, benzocaine, and prilocaine in a cream, ointment, or gel.
Psychotropic agents.
Tetrahydrocannabinol (THC) and some other cannabinoids, either from the "Cannabis sativa" plant or synthetic, have analgesic properties, although the use of cannabis derivatives is currently illegal in many countries. A recent study finds that inhaled cannabis is effective in alleviating neuropathy and pain resulting from, e.g., spinal injury and multiple sclerosis.
Other psychotropic analgesic agents include ketamine (an NMDA receptor antagonist), clonidine and other α2-adrenoreceptor agonists, and mexiletine and other local anaesthetic analogues.
Atypical, adjuvant analgesics & potentiators.
Drugs that have been introduced for uses other than analgesics are also used in pain management. Both first-generation (such as amitriptyline) and newer anti-depressants (such as duloxetine) are used alongside NSAIDs and opioids for pain involving nerve damage and similar problems. Other agents directly potentiate the effects of analgesics, such as using hydroxyzine, promethazine, carisoprodol, or tripelennamine to increase the pain-killing ability of a given dose of opioid analgesic.
Adjuvant analgesics, also called atypical analgesics, include nefopam, orphenadrine, pregabalin, gabapentin, cyclobenzaprine, scopolamine, and other drugs possessing anticonvulsant, anticholinergic, and/or antispasmodic properties, as well as many other drugs with CNS actions. These drugs are used along with analgesics to modulate and/or modify the action of opioids when used against pain, especially of neuropathic origin.
Dextromethorphan has been noted to slow the development of tolerance to opioids and exert additional analgesia by acting upon the NMDA receptors; some analgesics such as methadone and ketobemidone and perhaps piritramide have intrinsic NMDA action.
High-alcohol liquor, two forms of which found in the US Pharmacopoeia up until 1916 and in common use by physicians well into the 1930s, has been used in the past as an agent for dulling pain, due to the CNS depressant effects of ethyl alcohol, a notable example being the American Civil War. However, the ability of alcohol to relieve severe pain is likely inferior to many analgesics used today (e.g., morphine, codeine). As such, in general, the idea of alcohol for analgesia is considered a primitive practice in virtually all industrialized countries today.
The use of adjuvant analgesics is an important and growing part of the pain-control field and new discoveries are made practically every year. Many of these drugs combat the side-effects of opioid analgesics, an added bonus. For example, antihistamines including orphenadrine combat the release of histamine caused by many opioids. Stimulants such as methylphenidate, caffeine, ephedrine, dextroamphetamine, methamphetamine, and cocaine work against heavy sedation and may elevate mood in distressed patients as do the antidepressants. The use of medicinal cannabis remains a debated issue.

</doc>
<doc id="2250" url="http://en.wikipedia.org/wiki?curid=2250" title="Abiotic stress">
Abiotic stress

Abiotic stress is defined as the negative impact of non-living factors on the living organisms in a specific environment. The non-living variable must influence the environment beyond its normal range of variation to adversely affect the population performance or individual physiology of the organism in a significant way.
Whereas a biotic stress would include such living disturbances as fungi or harmful insects, abiotic stress factors, or stressors, are naturally occurring, often intangible, factors such as intense sunlight or wind that may cause harm to the plants and animals in the area affected. Abiotic stress is essentially unavoidable.
Abiotic stress affects animals, but plants are especially dependent on environmental factors, so it is particularly constraining. Abiotic stress is the most harmful factor concerning the growth and productivity of crops worldwide. Research has also shown that abiotic stressors are at their most harmful when they occur together, in combinations of abiotic stress factors.
Examples.
Abiotic stress comes in many forms. The most common of the stressors are the easiest for people to identify, but there are many other, less recognizable abiotic stress factors which affect environments constantly.
The most basic stressors include: 
Lesser-known stressors generally occur on a smaller scale. They include: poor edaphic conditions like rock content and pH levels, high radiation, compaction, contamination, and other, highly specific conditions like rapid rehydration during seed germination.
Effects.
Abiotic stress, as a natural part of every ecosystem, will affect organisms in a variety of ways. Although these effects may be either beneficial or detrimental, the location of the area is crucial in determining the extent of the impact that abiotic stress will have. The higher the latitude of the area affected, the greater the impact of abiotic stress will be on that area. So, a taiga or boreal forest is at the mercy of whatever abiotic stress factors may come along, while tropical zones are much less susceptible to such stressors.
Benefits.
One example of a situation where abiotic stress plays a constructive role in an ecosystem is in natural wildfires. While they can be a human safety hazard, it is productive for these ecosystems to burn out every once in a while so that new organisms can begin to grow and thrive.
Even though it is healthy for an ecosystem, a wildfire can still be considered an abiotic stressor, because it puts an obvious stress on individual organisms within the area. Every tree that is scorched and each bird nest that is devoured is a sign of the abiotic stress. On the larger scale, though, natural wildfires are positive manifestations of abiotic stress.
What also needs to be taken into account when looking for benefits of abiotic stress, is that one phenomenon may not affect an entire ecosystem in the same way. While a flood will kill most plants living low on the ground in a certain area, if there is rice there, it will thrive in the wet conditions.
Another example of this is in phytoplankton and zooplankton. The same types of conditions are usually considered stressful for these two types of organisms. They act very similarly when exposed to ultraviolet light and most toxins, but at elevated temperatures the phytoplankton reacts negatively, while the thermophilic zooplankton reacts positively to the increase in temperature.ok The two may be living in the same environment, but an increase in temperature of the area would prove stressful only for one of the organisms.
Lastly, abiotic stress has enabled species to grow, develop, and evolve, furthering natural selection as it picks out the weakest of a group of organisms. Both plants and animals have evolved mechanisms allowing them to survive extremes.
Detriments.
The most obvious detriment concerning abiotic stress involves farming. It has been claimed by one study that abiotic stress causes the most crop loss of any other factor and that most major crops are reduced in their yield by more than 50% from their potential yield.
Because abiotic stress is widely considered a detrimental effect, the research on this branch of the issue is extensive. For more information on the harmful effects of abiotic stress, see the sections below on plants and animals.
In plants.
A plant’s first line of defense against abiotic stress is in its roots. If the soil holding the plant is healthy and biologically diverse, the plant will have a higher chance of surviving stressful conditions.
Facilitation, or the positive interactions between different species of plants, is an intricate web of association in a natural environment. It is how plants work together. In areas of high stress, the level of facilitation is especially high as well. This could possibly be because the plants need a stronger network to survive in a harsher environment, so their interactions between species, such as cross-pollination or mutualistic actions, become more common to cope with the severity of their habitat.
Plants also adapt very differently from one another, even from a plant living in the same area. When a group of different plant species was prompted by a variety of different stress signals, such as drought or cold, each plant responded uniquely. Hardly any of the responses were similar, even though the plants had become accustomed to exactly the same home environment.
Rice ("Oryza sativa") is a classic example. Rice is a staple food throughout the world, especially in China and India. Rice plants experience different types of abiotic stresses, like drought and high salinity. These stress conditions have a negative impact on rice production. Genetic diversity has been studied among several rice varieties with different genotypes using molecular markers.
In animals.
For animals, the most stressful of all the abiotic stressors is heat. This is because many species are unable to regulate their internal body temperature. Even in the species that are able to regulate their own temperature, it is not always a completely accurate system. Temperature determines metabolic rates, heart rates, and other very important factors within the bodies of animals, so an extreme temperature change can easily distress the animal’s body. Animals can respond to extreme heat, for example, through natural heat acclimation or by burrowing into the ground to find a cooler space.
It is also possible to see in animals that a high genetic diversity is beneficial in providing resiliency against harsh abiotic stressors. This acts as a sort of stock room when a species is plagued by the perils of natural selection. A variety of galling insects are among the most specialized and diverse herbivores on the planet, and their extensive protections against abiotic stress factors have helped the insect in gaining that position of honor.
In endangered species.
Biodiversity is determined by many things, and one of them is abiotic stress. If an environment is highly stressful, biodiversity tends to be low. If abiotic stress does not have a strong presence in an area, the biodiversity will be much higher.
This idea leads into the understanding of how abiotic stress and endangered species are related. It has been observed through a variety of environments that as the level of abiotic stress increases, the number of species decreases. This means that species are more likely to become population threatened, endangered, and even extinct, when and where abiotic stress is especially harsh.

</doc>
<doc id="2251" url="http://en.wikipedia.org/wiki?curid=2251" title="Accusative case">
Accusative case

The accusative case (abbreviated acc) of a noun is the grammatical case used to mark the direct object of a transitive verb. The same case is used in many languages for the objects of (some or all) prepositions. It is a noun that is having something done to it, usually joined (such as in Latin) with the nominative case. The syntactic functions of the accusative consist of designating the immediate object of an action, the intended result, the goal of a motion, and the extent of an action.
The accusative case existed in Proto-Indo-European and is present in some Indo-European languages (including Latin, Sanskrit, Greek, German, Polish, Romanian, Russian, Ukrainian), in the Uralic languages, in Altaic languages, and in Semitic languages (such as Hebrew and Classical Arabic). Finnic languages, such as Finnish and Estonian, have two cases to mark objects, the accusative and the partitive case. In morphosyntactic alignment terms, both perform the accusative function, but the accusative object is telic, while the partitive is not.
Modern English, which almost entirely lacks declension in its nouns, does not have an explicitly marked accusative case even in the pronouns. Such forms as "whom", "them", and "her" derive rather from the old Germanic dative forms, of which the -m and -r endings are characteristic. This conflation of the old accusative, dative, instrumental, and (after prepositions) genitive cases is the "oblique case". Most modern English grammarians no longer use the Latin accusative/dative model, though they tend to use the terms "objective" for oblique, "subjective" for nominative, and "possessive" for genitive "(see Declension in English)." "Hine", a true accusative masculine third person singular pronoun, is attested in some northern English dialects as late as the 19th century.
Etymology.
The English name "accusative (case)" is an Anglicisation of the Latin "accūsātīvus" ("cāsus"), which was translated from Ancient Greek αἰτιατικὴ (πτῶσις), "aitiatikē (ptôsis)". The Greek term can mean either "(inflection) for something caused" or "for an accusation". The intended meaning was likely the first, which would be translated as Latin "causātīvus" or "effectīvus", but the Latin term was a translation of the second. Compare Russian вини́тельный "vinítel’nyj", from винить "vinít’" "to blame".
Description.
In the sentence He sees the woman", "he" is the subject of the sentence, while in "The woman sees him, "him" is the object. In English we distinguish the two uses by different forms of the pronoun: he/him. If, however, instead of a pronoun, we use a noun, we make no such distinction in the form of the word. Thus, we use the same word "man" in both The man sees the woman" and "The woman sees the man. In many languages, however, different forms of the word are used not only for pronouns, but for nouns too. For example, in Latin "The man sees the woman" = "Vir feminam videt", while "The woman sees the man" = "Femina virum videt". For "man", Latin uses "vir" for the subject, and "virum" for the object. Likewise, in the same pair of sentences, we have "femina" for a subject and "feminam" for object. The form used for the direct object ("him", "virum", "feminam") is known as the "accusative case", while the form used for the subject ("he", "vir", "femina") is known as the nominative case.
Just as with pronouns and nouns, many inflected languages also make distinctions between cases in their adjectives and (for languages that have them) articles. Thus in German, "the giant" as the subject of a sentence may be expressed as "der Riese": nominative case. As the object of a verb, this becomes "den Riesen", the accusative.
Examples.
Indo-European languages.
Latin.
In Latin, nouns, adjectives, or pronouns in the accusative case ("accusativus") can be used
For the accusative endings, see Latin declension.
Latin prepositions.
Some Latin prepositions take a noun in the accusative. A few prepositions may take either an accusative or an ablative, in which case the accusative indicates motion, and the ablative indicates no motion. E.g. "in casā", "in the cottage"; "in casam", "into the cottage".
This "aide-memoire" was taught in schools when Latin was on the curriculum:
"Ante, apud, ad, adversus,"
"Circum, circa, citra, cis,"
"Contra, inter, erga, extra,"
"Infra, intra, iuxta, ob,"
"Penes, pone, post," and "praeter,"
"Prope, propter, per, secundum,"
"Supra, versus, ultra, trans:"
When 'motion' 'tis, not 'state' they mean.**
Or try: ** "And unto these if motion be intended,"
"Let In, Sub, Super, Subter be appended ' '
German.
German uses the accusative to mark direct objects and objects of certain prepositions, or adverbs relating to time. The accusative is only marked for masculine articles, pronouns, adjectives, and weak nouns.
German articles.
The masculine forms for German articles, e.g., "der" ('the'), "ein" ('a/an'), "mein" ('my'), etc., change in the accusative case: they always end in "-en". The article of feminine, neutral and plural forms do not change.
For example, "Hund" (dog) is a masculine ("ein/der") word, so the article changes when used in the accusative case:
German pronouns.
Some German pronouns also change in the accusative case.
German prepositions.
The accusative case is also used after particular German prepositions. These include "bis, durch, entlang, für, gegen, ohne, um", after which the accusative case is always used, and "an, auf, hinter, in, neben, über, unter, vor, zwischen" which can govern either the accusative or the dative. The latter prepositions take the accusative when motion or action is specified (being done into/onto the space), but take the dative when location is specified (being done in/on that space). These prepositions are also used in conjunction with certain verbs, in which case it is the verb in question which governs whether the accusative or dative should be used.
German adjectives.
Adjective endings also change in the accusative case. Another factor that determines the endings of adjectives is whether the adjective is being used after a definite article (the), after an indefinite article (a/an) or without any article before the adjective ("many" green apples).
German adverbial use.
In German, the accusative case is also used for some adverbial expressions, mostly temporal ones, as in ""Diesen Abend bleibe ich daheim" (This evening I'm staying at home), where "diesen Abend" is marked as accusative, although not a direct object.
Russian.
In Russian, accusative is used not only to display the direct object of an action, but also to indicate the destination or goal of motion. It is also used with some prepositions. The prepositions "в" and "на" can both take accusative in situations where they are indicating the goal of a motion.
In the masculine, Russian also distinguishes between animate and inanimate nouns with regard to the accusative; only the animates carry a marker in this case.
In fact Russian almost lost the real PIE accusative case, since only singular feminine nouns ending in 'a' have a distinct form. Other words use the genitive case or the nominative case in place of the accusative, depending on their animacy.
Armenian.
While the Armenian dialects both have a de facto accusative case, Eastern Armenian uses an accusative marker for transitive verbs
Example:
գիրք - girkh - book (Nominative)
ուսուցիչ - usuchičh - teacher (Nominative)
Արամը վերցրեց գիրքը: 
Aramë verchrech girkhë
Aram took the book.
Արամը սիրում է իր ուսուցչին: 
Aramë sirum ē ir usuchčhin
Aram loves his teacher.
Greek.
In both Ancient and Modern Greek, nouns, adjectives, verb participles, articles and pronouns are used in the accusative case, when they indicate a direct object or if they are preceded by a preposition. There is a wide variety of accusative markers depending on gender, number and declension. Like in Latin, all neuter names yield the same form in both the nominative and the accusative case in Ancient Greek. In its modern successor, this rule also extends to most feminine nouns, except these ending to -ος.
Example: "He was also calumniating Socrates.""
Constructed languages.
Esperanto.
Esperanto grammar involves only two cases, a nominative and an accusative. The accusative is formed by the addition of "-n" to the nominative form, and is the case used for direct objects. Other case functions, including dative functions, are achieved with prepositions, all of which normally take the nominative case. Direction of motion can be expressed either by the accusative case, or by the preposition "al" (to) with the nominative.
Ido.
In Ido the "-n" suffix is optional, as subject–verb–object order is assumed when it is not present. Note that this is sometimes done in Esperanto, especially by beginners, but it is considered incorrect while in Ido it is the norm.
Uralic languages.
Finnish.
According to traditional Finnish grammars, the accusative is the case of a total object, while the case of a partial object is the partitive. The negative forms of verbs always take the partial object, whereas in positive sentences it depends on the nature of the action, the main rule being that incomplete or indefinite action requires a partial object.
The accusative singular is identical either to the nominative (often called nominative-accusative) or the genitive (genitive-accusative). In plural, only nominative-accusative exists. The active verb forms usually require the total object in the genitive-accusative and passive forms take the nominative-accusative. The only exceptions to this rule are imperative first and second persons, and the rarely used third infinitive in instructive, which take the total object in nominative-accusative.
The personal pronouns and the personal interrogative pronoun "kuka/ken" have a special accusative form ending in "-t" which is used in place of both nominative-accusative and genitive-accusative. For example, the accusative form of "hän" (he/she) is "hänet", and the accusative form of "kuka" (or "ken") is "kenet".
The major new Finnish grammar, "Iso suomen kielioppi", breaks with the traditional classification by limiting the accusative case to the special case of the personal pronouns and "kuka/ken". The new grammar considers other total objects as being in the nominative or genitive case.
Hungarian.
The accusative case in Hungarian applies to nouns, pronouns; even to adjectives and numerals when either of them stands alone in the sense of direct object.
Accusative is formed by the suffix -t. In many cases, "-t" is preceded by a suffix-initial vowel, primarily based on specific vowel harmony, resulting in "-et", "-ot", or "-öt". The rules are complex, also involve consonants, and have exceptions. Thus: k"e"rt"et" "garden", k"é"k"et" "blue"; h"a"t"o"t "six"; p"o"lc"ot" "shelf"; k"ö"d"öt" "fog".
In some words, a low vowel "a" or "e" appears instead of the expected harmonic vowel: e.g. fal"at" (ˣfal"ot") "wall"; nyolc"at" (ˣnyolc"ot") "eight"; könyv"et" (ˣkönyv"öt") "book".
In fewer cases, the root of the word is also affected. Word endings "-a" or "-e" will (even if they are the endings of a preceding suffix) change to "-á" and "-é", respectively, before "-t". E.g.: f"a" (tree) -> fát. The long vowel of a one-syllable word may get shortened. E.g.: úr (lord) -> "u"rat. But: b"ú"r (Boer) -> b"ú"rt. If a word has more than one syllable and the last syllable ends in a consonant, the vowel of the last syllable may drop. E.g.: köröm (fingernail) -> "körmöt. But: kör"öm" ("my" circle) -> körömet". Notably, the first-person and second-person personal pronouns have quite unique accusative forms (indeed, as indicated in the table, in the singular case the ending "-et" is rather optional, even considered archaic).
Semitic languages.
An ending for accusative case existed in Proto-Semitic, Akkadian, and Ugaritic, but today it is preserved only in literary Arabic and Ge'ez.
Classical Arabic.
In Arabic, the accusative case (also the subjunctive mood) is called النصب "an-naṣb", and a word in the accusative case (also a verb in the subjunctive) is called المنصوب "al-manṣūb", both from the verb نصب "naṣaba" "set up". The accusative is used to mark the object of a verb and to form adverbs.

</doc>
<doc id="2257" url="http://en.wikipedia.org/wiki?curid=2257" title="Apostolic succession">
Apostolic succession

Apostolic succession is the method whereby the ministry of the Christian Church is held to be derived from the apostles by a continuous succession, which has usually been associated with a claim that the succession is through a series of bishops. This series was seen originally as that of the bishops of a particular see founded by one or more of the apostles, but it is generally understood today as meaning a series of bishops, regardless of see, each consecrated by other bishops themselves consecrated similarly in a succession going back to the apostles. Christians of the Roman Catholic, Orthodox, Old Catholic, Anglican, Moravian, and Scandinavian Lutheran traditions maintain that "a bishop cannot have regular or valid orders unless he has been consecrated in this apostolic succession."
Apostolic succession "may also be understood as a continuity in doctrinal teaching from the time of the apostles to the present." For example, the British Methodist Conference locates the "true continuity" with the Church of past ages in "the continuity of Christian experience, the fellowship in the gift of the one Spirit; in the continuity in the allegiance to one Lord, the continued proclamation of the message; the continued acceptance of the mission;..."
Those who hold for the importance of apostolic succession via episcopal laying on of hands appeal to the New Testament, which, they say, implies a personal apostolic succession (from Paul to Timothy and Titus, for example). They appeal as well to other documents of the early Church, especially the Epistle of Clement. In this context, Clement explicitly states that the apostles appointed bishops as successors and directed that these bishops should in turn appoint their own successors; given this, such leaders of the Church were not to be removed without cause and not in this way. Further, proponents of the necessity of the personal apostolic succession of bishops within the Church point to the universal practice of the undivided early Church (up to AD 431), before being divided into the Church of the East, Oriental Orthodoxy, the Eastern Orthodox Church and the Catholic Church.
Some Protestants deny the need for this type of continuity and the historical claims involved have been severely questioned; Eric Jay comments that the account given of the emergence of the episcopate in chapter III of the encyclical "Lumen Gentium" (1964) "is very sketchy, and many ambiguities in the early history of the Christian ministry are passed over"
Meanings.
Michael Ramsey (Archbishop of Canterbury, 1961–1974), described three meanings of "apostolic succession":
He adds that this last has been controversial in that it has been claimed that this aspect of the doctrine is not found before the time of Augustine of Hippo, while others allege that it is implicit in the Church of the second and third centuries.
In its 1982 statement on Baptism, Eucharist and Ministry, the Faith and Order Commission of the World Council of Churches stated that "the primary manifestation of apostolic succession is to be found in the apostolic tradition of the Church as a whole... Under the particular historical circumstances of the growing Church in the early centuries, the succession of bishops became one of the ways, together with the transmission of the Gospel and the life of the community, in which the apostolic tradition of the Church was expressed." It spoke of episcopal succession as something that churches that do not have bishops can see "as a sign, though not a guarantee, of the continuity and unity of the Church" and that all churches can see "as a sign of the apostolicity of the life of the whole church".
The Porvoo Common Statement (1996), agreed to by the Anglican churches of the British Isles and most of the Lutheran churches of Scandinavia and the Baltic, also stated that "the continuity signified in the consecration of a bishop to episcopal ministry cannot be divorced from the continuity of life and witness of the diocese to which he is called."
The teaching of the Second Vatican Council on apostolic succession has been summed up as follows:
In the early Fathers.
The doctrine was formulated in the second century in the first of the three senses given by Ramsey, originally as a response to Gnostic claims of having received secret teaching from Christ or the apostles; it emphasised the public manner in which the apostles had passed on authentic teaching to those whom they entrusted with the care of the churches they founded and that these in turn had passed it on to their successors. Only later was it given a different meaning, a process in which Augustine (Bp of Hippo Regis, 395–430) played a part by emphasising the idea of "the link from consecrator to consecrated whereby the grace of order was handed on."
Writing about AD 94, Clement of Rome states that the apostles appointed successors to continue their work where they had planted churches and for these in their turn to do the same because they foresaw the risk of discord. He uses both 'bishop' and 'presbyter' to refer to these men. The interpretation of his writing is disputed, but it is clear that he supports some sort of approved continuation of the ministry exercised by the apostles which in its turn was derived from Christ.
Hegesippus (180?) and Irenaeus (180) introduce explicitly the idea of the bishop's succession in office as a guarantee of the truth of what he preached in that it could be traced back to the apostles. and they produced succession lists to back this up. That this succession depended on the fact of ordination to a vacant see and the status of those who administered the ordination is seldom commented on. Woollcombe also states that no one questioned the apostolicity of the See of Alexandria despite the fact that its Popes were consecrated by the college of presbyters up till the time of the Council of Nicaea in 325. Irenaeus also refers to a succession of presbyters who preserve the tradition "which originates from the apostles". and later goes on to speak of their having "an infallible gift of truth"["charisma veritatis certum"]. Jay comments that this is sometimes seen as an early reference to the idea of the transmission of grace through the apostolic succession which in later centuries was understood as being specifically transmitted through the laying on of hands by a bishop within the apostolic succession (the "pipeline theory"). He warns that this is open to the grave objection that it makes grace a (quasi)material commodity and represents an almost mechanical method of imparting what is by definition a free gift. He adds that the idea cannot be squeezed out of Irenaeus' words.
Writing a little later, Tertullian makes the same main point but adds expressly that recently founded churches (such as his own in Carthage) could be considered apostolic if they had "derived the tradition of faith and the seeds of doctrine" from an apostolic church. His disciple, Cyprian (Bishop of Carthage 248–58) appeals to the same fundamental principle of election to a vacant see in the aftermath of the Decian Persecution when denying the legitimacy of his rigorist rival in Carthage and that of the anti-pope Novatian in Rome; however, the emphasis is now on legitimating his episcopal ministry as a whole and specifically his exclusive right to administer discipline to the lapsed rather than on the content of what is taught. Cyprian also laid great emphasis on the fact that any minister who broke with the Church lost "ipso facto" the gift of the Spirit which had validated his orders. This meant that he had no power or authority to celebrate an efficacious sacrament.
As transmission of grace.
For the adherents of this understanding of apostolic succession, grace is transmitted during episcopal consecrations (the ordination of bishops) by the laying on of hands of bishops previously consecrated within the apostolic succession). They hold that this lineage of ordination derives from the Twelve Apostles, thus making the Church the continuation of the early Apostolic Christian community. They see it as one of four elements that define the true Church of Jesus Christ and legitimize the ministry of its clergy, since only a bishop within the succession can perform valid ordinations, and only bishops and presbyters (priests) ordained by bishops in the apostolic succession can validly celebrate (or "confect") several of the other sacraments, including the Eucharist, reconciliation of penitents, confirmation and anointing of the sick.
This position was stated by John Henry Newman in the following words:
We [priests of the Church of England] have been born, not of blood, nor of the will of the flesh, nor of the will of man, but of God. The Lord Jesus Christ gave His Spirit to His Apostles; they in turn laid their hands on those who should succeed them; and these again on others; and so the sacred gift has been handed down to our present bishops, who have appointed us as their assistants, and in some sense representatives. ... we must necessarily consider none to be "really" ordained who have not "thus" been ordained.
Apostolicity as doctrinal and related continuity.
Most Protestant denominations deny the need of maintaining episcopal continuity with the early Church, holding that the role of the apostles was that, having been chosen directly by Jesus as witnesses of his resurrection, they were to be the "special instruments of the Holy Spirit in founding and building up the Church". The Church is "built upon 'the foundation of the Prophets and Apostles' (Ephes. ii. 20); but a foundation does not repeat itself". When the apostles died, they were replaced by their writings. To share with the apostles the same faith, to believe their word as found in the Scriptures, to receive the same Holy Spirit, is to them the only meaningful "continuity". The most meaningful "apostolic succession" for most Protestants, then, is a "faithful succession" of apostolic teaching.
Max Thurian describes the classic Reformed/Presbyterian concept of apostolic succession in the following terms. "The Christian ministry is not derived from the people but from the pastors; a scriptural ordinance provides for this ministry being renewed by the ordination of a presbyter by presbyters; this ordinance originates with the apostles, who were themselves presbyters, and through them it goes back to Christ as its source.". However, in itself:
These realities form a "composite faithfulness" and are (i) "perseverance in the apostolic doctrine"; (ii) "the will to proclaim God's word"; (iii) "communion in the fundamental continuity of the Church, the Body of Christ, the faithful celebration of Baptism and the Eucharist"; (iv) "succession in the laying on of hands, the sign of ministerial continuity".
Objections to the transmission of grace theory.
Protestants have objected that this theory is not explicitly found in Scripture and the New Testament uses 'bishop' and 'presbyter' as alternative names for the same office. Furthermore, it is not clearly found in the writings of the Fathers before Augustine in the fourth century and attempts to read it back as implicit in earlier writers are flawed because it is possible to show that significant changes occurred.
For example, Barrett points out that the Pastoral Epistles are concerned that ministers of the generation of Timothy and Titus should pass on the doctrine they had received to the third generation. Teaching and preaching are "the main, almost the only, activities of ministry." However, in Clement of Rome ministerial activity is liturgical: the undifferentiated 'presbyter-bishops' are to "make offerings to the Lord at the right time and in the right places" something which is simply not defined by the evangelists. More significant still is the change in the use of sacrificial language: for Paul the Eucharist is a receiving of gifts from God, the Christian sacrifice is the offering of our bodies (Romans 12). Moving on to Ignatius of Antioch, Barrett states that here we find a sharp distinction between 'presbyter' and 'bishop': the latter now stands out as "an isolated figure" who is to be obeyed and without whom it is not lawful to baptise or hold a love-feast. He also points out that when Ignatius writes to the Romans, there is no mention of a bishop of the Roman Church, "which we may suppose had not yet adopted the monarchical episcopate." Jalland comes to a similar conclusion and locates the change from the "polyepiscopacy" of the house church model in Rome, to monepiscopacy as occurring before the middle of the second century.
Similar objections are voiced by Harvey who comments that there is a "strong and ancient tradition" that the presence of an ordained man is necessary for the celebration of the Eucharist. But, there is "certainly no evidence for this view in the New Testament" and in the case of Clement of Rome and Ignatius of Antioch the implication is not that it "cannot" be celebrated by anyone else, but that it "ought" not. In the third century, this "concern for propriety" begins to be displaced by the concept of 'power' to do so which means that in the absence of such a man it is "literally impossible" for a Eucharist to be celebrated.
Churches claiming apostolic succession.
Churches that claim some form of episcopal apostolic succession, dating back to the apostles or to leaders from the apostolic era, include the Catholic Church, the Eastern Orthodox and Oriental Orthodox Churches, the Church of the East, the Anglican Communion, some Lutheran Churches (see below), and other smaller bodies incorporating the term "Catholic". The Anglican Communion (see below) and those Lutheran Churches which claim apostolic succession do not specifically teach this but exclusively practice episcopal ordination. While some Anglicans claim it for their communion, their views are often nuanced and there is widespread reluctance to 'unchurch' Christian bodies which lack it.
Roman Catholics recognise the validity of the apostolic successions of the bishops, and therefore the rest of the clergy, of the Eastern Orthodox, Oriental Orthodox, Church of the East, Old Catholic Church (Union of Utrecht only), and Polish National Catholic Church. The Eastern Orthodox generally recognise Roman Catholic orders, but have a different concept of the apostolic succession as it exists outside of Eastern Orthodoxy. The lack of apostolic succession through bishops is the primary basis on which Protestant communities are not considered "churches" by the Orthodox churches and the Roman Catholic Church.
Apostolic founders.
An early understanding of apostolic succession is represented by the traditional claims of various churches, as organised around important episcopal sees, to have been founded by specific apostles. On the basis of these traditions, the churches in question often claim to have inherited specific authority, doctrines and/or practices on the authority of their founding apostle(s), which is understood to be continued by the bishops of the apostolic throne of the church that each founded and whose original leader he was. Thus:
Teachings.
Catholic Church.
In Roman Catholic theology, the doctrine of apostolic succession states that Christ gave the full sacramental authority of the Church to the Twelve Apostles in the sacrament of Holy Orders, making them the first bishops. By conferring the fullness of the sacrament of Holy Orders on the apostles, they were given the authority to confer the sacrament of Holy Orders on others, thus consecrating more bishops in a direct lineage that can trace its origin back to the Twelve Apostles and Christ. This direct succession of bishops from the apostles to the present day bishops is referred to as apostolic succession.
Papal primacy is different though related to apostolic succession as described here. The Catholic Church has traditionally claimed a unique leadership role for the Apostle Peter, believed to have been named by Jesus as head of the Apostles and as a focus of their unity, who became the first Bishop of Rome, and whose successors inherited the role and accordingly became the leaders of the worldwide Church as well. Even so, Catholicism acknowledges the papacy is built on apostolic succession, not the other way around. As such, apostolic succession is a foundational doctrine of authority in the Catholic Church.
Catholicism holds that Christ entrusted the Apostles with the leadership of the community of believers, and the obligation to transmit and preserve the "deposit of faith" (the experience of Christ and his teachings contained in the doctrinal "tradition" handed down from the time of the apostles and the written portion, which is Scripture). The apostles then passed on this office and authority by ordaining bishops to follow after them.
Roman Catholic theology holds that the apostolic succession effects the power and authority to administer the sacraments except for baptism and matrimony. (Baptism may be administered by anyone and matrimony by the couple to each other.) Authority to so administer such sacraments is passed on only through the sacrament of Holy Orders, a rite by which a priest is ordained (ordination can be conferred only by a bishop). The bishop, of course, must be from an unbroken line of bishops stemming from the original apostles selected by Jesus Christ. Thus, apostolic succession is necessary for the valid celebration of the sacraments today.
In the early 18th century, Pope Benedict XIII, whose orders were descended from Scipione Rebiba, personally consecrated at least 139 bishops for various important European sees, including German, French, English and New World bishops. These bishops in turn consecrated bishops almost exclusively for their respective countries causing other episcopal lineages to die off.
Roman Catholics recognise the validity of the apostolic successions of the bishops, and therefore the rest of the clergy, of the Eastern Orthodox, Oriental Orthodox, Assyrian, Old Catholic, and some Independent Catholic Churches. Rome does not recognise any Anglican orders as valid; Pope Leo XIII in the bull "Apostolicae curae" of 1896 declared Anglican orders "absolutely null and utterly void", a view held as "definitive teaching" by the Holy See. This conflict stems from the Anglican Church's revision of its rite of ordination for its bishops during the 16th century. Most of today's Anglican bishops trace their succession back to a bishop who was ordained with the revised form and who thus would be viewed as invalid and incapable of validly ordaining, no matter what form he used.
Writing in "The Tablet" of 29 May 1982, Timothy Dufort argued that all Anglican bishops in Europe today can claim valid episcopal descent from validly ordained bishops through involvement of Old Catholic bishops in Anglican episcopal ordinations. This view has not been accepted by the Holy See, and the question has been further complicated by the Anglican ordination of women, which is seen as implying that, in ordination, the Anglican Communion does not intend to do what the Roman Catholic Church does. In a document it published in July 1998, the Congregation for the Doctrine of the Faith stated that the Catholic Church's declaration on the invalidity of Anglican ordinations is a teaching that the Church has definitively propounded and that therefore requires "firm and definitive assent".
On 29 June 2007, the Congregation for the Doctrine of the Faith explained why apostolic succession is integral to, and indeed, "a constitutive element" of the Church. In response to the question why the Second Vatican Council and other official statements of the Catholic Church do not call Protestant Christian Communities "Churches", it stated that "according to Catholic doctrine, these Communities do not enjoy "apostolic succession" in the sacrament of Orders, and are, therefore, deprived of a constitutive element of the Church. These ecclesial Communities which, specifically because of the absence of the sacramental priesthood, have not preserved the genuine and integral substance of the Eucharistic Mystery cannot, according to Catholic doctrine, be called 'Churches' in the proper sense".
Orthodox churches.
While Eastern Orthodox sources often refer to the bishops as "successors of the apostles" under the influence of Scholastic theology, strict Orthodox ecclesiology and theology hold that all legitimate bishops are properly successors of Peter. This also means that presbyters (or "priests") are successors of the apostles. As a result, Orthodox theology makes a distinction between a geographical or historical succession and proper ontological or ecclesiological succession. Hence, the bishops of Rome and Antioch can be considered successors of Peter in a historical sense on account of Peter's presence in the early community. This does not imply that these bishops are more successors of Peter than all others in an ontological sense.
According to ancient canons still observed with the Orthodox communion, a bishop must be consecrated by at least three other bishops; so-called "single handed ordinations" do not exist. Moreover, bishops are never ordained "at large" but only for a specific Eucharist community, in due historical and sacramental succession.
Views concerning other churches.
The Eastern Orthodox have often permitted non-Orthodox clergy to be rapidly ordained within Orthodoxy as a matter of pastoral necessity and economia. Priests entering Eastern Orthodoxy from Oriental Orthodoxy and Roman Catholicism have usually been received by "vesting" and have been allowed to function immediately within Eastern Orthodoxy as priests. Recognition of Roman Catholic orders by the Russian Orthodox Church was stipulated in 1667 by the Synod of Moscow, but this position is not universal within the Eastern Orthodox communion. The validity of a priest's ordination is decided by each autocephalic Orthodox church.
The Armenian Apostolic Church, which is one of the Oriental Orthodox churches, recognises Roman Catholic episcopal consecrations without qualification.
Anglican Communion.
The Anglican Communion "has never officially endorsed any one particular theory of the origin of the historic episcopate, its exact relation to the apostolate, and the sense in which it should be thought of as God given, and in fact tolerates a wide variety of views on these points". Its claim to apostolic succession is rooted in the Church of England's evolution as part of the Western Church. Apostolic succession is viewed not so much as conveyed mechanically through an unbroken chain of the laying-on of hands, but as expressing continuity with the unbroken chain of commitment, beliefs and mission starting with the first apostles; and as hence emphasising the enduring yet evolving nature of the Church. The Anglican—Roman Catholic International Commission report expressed broad agreement in the nature of apostolic succession as the ‘effective sign’ of the apostolicity of the whole people of God, living in fidelity to the teaching and mission of the apostles.
When Henry VIII broke away from the jurisdiction of Rome in 1533/4, the English Church retained the episcopal polity and apostolic succession inherent in its Catholic past; however, Protestant theology gained a certain foothold and under his successor, Edward VI what had been an administrative schism became a Protestant reformation under the guiding hand of Thomas Cranmer. Although care was taken to maintain the unbroken sequence of episcopal consecrations, particularly in the case of Matthew Parker, who was consecrated Archbishop of Canterbury in 1559 by two bishops who had been ordained in the 1530s with the Roman Pontifical and two ordained with the Edwardine Ordinal of 1550, apostolic succession was not seen as a major concern that a true ministry could not exist without episcopal consecrations: English Reformers such as Richard Hooker rejected the Catholic position that Apostolic Succession is divinely commanded or necessary for true Christian ministry. The ""foreign" Reformed [Presbyterian] Churches" were genuine ones despite the lack of apostolic succession because they had been abandoned by their bishops at the Reformation.
In very different ways both James II and William III of England made it plain that the Church of England could no longer count on the 'godly prince' to maintain its identity and traditions and the 'High Church' clergy of the time began to look to the idea of apostolic succession as a basis for the church's life. For William Beveridge (Bp of St Asaph 1704–8) the importance of this lay in the fact that Christ himself is "continually present at such imposition of hands; thereby transferring the same Spirit, which He had first breathed into His Apostles, upon others successively after them"., but the doctrine did not really come to the fore until the time of the Tractarians.
Newman writing of the apostolic succession stated: "We must necessarily consider none to be "really" ordained who has not been "thus" ordained". After quoting this, Michael Ramsey continues: "With romantic enthusiasm, the Tractarians propagated this doctrine. In doing so they involved themselves in some misunderstandings of history and in some confusion of theology". He goes on to explain that they ascribed to early Anglican authors a far more exclusive version of the doctrine than was the case, they blurred the distinction between succession in office (Irenaeus) and succession in consecration (Augustine); they spoke of apostolic succession as the channel of grace in a way that failed to do justice to His gracious activity within all the dispensations of the New Covenant.(p. 111) Newman, and after him, Charles Gore held that the episcopate was passed down from the apostles through men like Timothy and Titus to single bishops in particular localities (monarchial episcopacy). However Bp. Lightfoot argued that monarchial episcopacy evolved upwards from a college of presbyters by the elevation of one of their number to be the episcopal president(p. 116) and A.C. Headlam laid great stress on Irenaeus' understanding of succession (see above) which had been lost from sight behind the Augustinian 'pipe-line theory'.(pp. 117,18)
Eastern Orthodox views on Anglican orders.
In the 20th century there have been a variety of positions taken by the various Eastern Orthodox Churches on the validity of Anglican orders. In 1922 the Patriarch of Constantinople recognised them as valid. He wrote: "That the orthodox theologians who have scientifically examined the question have almost unanimously come to the same conclusions and have declared themselves as accepting the validity of Anglican Orders."
Succeeding judgements, however, have been more conflicting. The Eastern Orthodox churches require a totality of common teaching to recognise orders and in this broader view find ambiguities in Anglican teaching and practice problematic. Accordingly, in practice Anglican clergy who convert to Orthodoxy are treated as if they had not been ordained and must be ordained in the Eastern Orthodox communion as would a lay person.
Roman Catholic judgement on Anglican orders.
In the Catholic Church, Pope Leo XIII stated in his 1896 bull "Apostolicae curae" that the Catholic Church believes specifically that the Anglican Church's consecrations are "absolutely null and utterly void" because of changes made to the rite of consecration under Edward VI, thus denying that Anglicans participate in the apostolic succession. Anglican clergy, then, are ordained as Catholic priests upon entry into the Catholic Church.
A reply from the Archbishops of Canterbury and York (1896) was issued to counter Pope Leo's arguments: "Saepius officio: Answer of the Archbishops of Canterbury and York to the Bull Apostolicae Curae of H. H. Leo XIII". They argued that if the Anglican orders were invalid, then the Roman orders were as well since the Pope based his case on the fact that the Anglican ordinals used did not contain certain essential elements but these were not found in the early Roman rites either. However, Catholics argue, this argument does not consider the sacramental intention involved in validating Holy Orders. In other words, Catholics believe that the ordinands were reworded so as to invalidate the ordinations because the intention behind the alterations in the rite was a fundamental change in Anglican understanding of the priesthood.
It is Roman Catholic doctrine that the teaching of "Apostolicae curae" is a truth to be "held definitively", as stated in a commentary by the Congregation for the Doctrine of the Faith. Cardinal Basil Hume explained the conditional character of his ordination of Graham Leonard, former Anglican bishop of the Diocese of London, to the priesthood in the following way: "While firmly restating the judgement of "Apostolicae Curae" that Anglican ordination is invalid, the Catholic Church takes account of the involvement, in some Anglican episcopal ordinations, of bishops of the Old Catholic Church of the Union of Utrecht who are validly ordained. In particular and probably rare cases the authorities in Rome may judge that there is a 'prudent doubt' concerning the invalidity of priestly ordination received by an individual Anglican minister ordained in this line of succession." At the same time, he stated: "Since the church must be in no doubt of the validity of the sacraments celebrated for the Catholic community, it must ask all who are chosen to exercise the priesthood in the Catholic Church to accept sacramental ordination in order to fulfill their ministry and be integrated into the apostolic succession." Since "Apostolicae curae" was issued many Anglican jurisdictions have revised their ordinals, bringing them more in line with ordinals of the early Church.
Timothy Dufort, writing in The Tablet in 1982, argued that by 1969 all Anglican bishops had acquired apostolic succession fully recognized by Rome, since from the 1930s Old Catholic bishops (whose orders Rome recognises as valid) have acted as co-consecrators in the ordination of Anglican bishops. This view is not accepted by the Roman Catholic Church itself, which continues to require that Anglican clergy be ordained absolutely (not conditionally) if they are to exercise a ministry in that church.
Porvoo Communion of Churches.
Negotiated at Järvenpää, Finland, and inaugurated with a celebration of the eucharist at Porvoo Cathedral in 1992, this agreement of unity includes the mutual recognition of the traditional apostolic succession among the following Churches:
Of note is the fact that at least one of the Scandinavian Lutheran Churches in the Porvoo Communion of Churches, the Church of Denmark has bishops, but strictly speaking they were not in the historic apostolic succession prior to their entry into the Porvoo Communion, since their Episcopate and Holy Orders derived from Dr. Johannes Bugenhagen, who was a pastor, not a bishop. In 2010, the Church of Denmark joined the Porvoo Communion of Churches, after a process of mutual consecrations of bishops had led to the introduction of historic apostolic succession. The Lutheran Church in Great Britain also joined the Porvoo Agreement, in 2014.
Lutheran churches.
Wide variations exist within Lutheranism on this issue. Most Lutheran churches in Scandinavian countries are favorable to the traditional doctrine of apostolic succession. Others de-emphasize it, e.g., many German Lutheran churches in former Prussian lands, resulting from their state-ordered union with Reformed (Calvinist) churches in 1817.
Lutheran claims to apostolic succession.
In Scandinavia and the Baltic region, Lutheran churches participating in the Porvoo Communion (those of Iceland, Norway, Sweden, Finland, Estonia, and Lithuania), as well as non Porvoo membership Lutheran churches in the region (including those of Latvia, and Russia), believe that they ordain their bishops in the apostolic succession in lines stemming from the original apostles. "The New Westminster Dictionary of Church History" states that "In Sweden the apostolic succession was preserved because the Catholic bishops were allowed to stay in office, but they had to approve changes in the ceremonies."
What made the Church of Sweden an evangelical-catholic church was to Archbishop Söderblom the fact that the Reformation in Sweden was a 'church improvement' and a 'process of purification' which did "not" create a new church. As a national church, the Church of Sweden succeeded in bringing together medieval Swedish tradition with the rediscovery of the gospel which the Reformation brought with it. Archbishop Söderblom included the historic episcopate in the tradition-transmitting elements. The Church of Sweden was, according to Söderblom, in an even higher degree than the Anglican Church a "via media". —Together in Mission and Ministry: The Porvoo Common Statement
The Lutheran Church of Finland was then one with the Church of Sweden and so holds the same view regarding the see of Åbo/Turku.
Similarly, in the High Church Lutheranism of Germany, some religious brotherhoods like Hochkirchliche St. Johannes-Bruderschaft and Hochkirchlicher Apostolat St. Ansgar have managed to arrange for their own bishop to be re-ordained in apostolic succession. The members of these brotherhoods do not form into separate ecclesia.
The Evangelical Lutheran Church in America, North America's largest Lutheran body, became united in the historic episcopate of the Episcopal Church in 2000, upon the signing of "Called to Common Mission". By this document the full communion between the Evangelical Lutheran Church in America and the Episcopal Church was established. As such, "all episcopal installations in the Evangelical Lutheran Church in America take place with the participation of bishops in the apostolic succession." The Evangelical Lutheran Church in America is headed by a presiding bishop who is elected by the churchwide assembly for a six-year term.
In recent years a number of Lutheran churches at the most Catholic edge of the Evangelical Catholic High Church Lutheran spectrum in the United States of America have accepted the doctrine of apostolic succession and have successfully recovered it, generally from Independent Catholic Churches. At present, most of these church bodies have memberships numbering in the hundreds.
The Catholic Church "has never officially expressed its judgement on the validity of orders as they have been handed down by episcopal succession in these two national Lutheran churches."
Indifference to the issue.
Many German Lutherans appear to demur on this issue, which may be sourced in the church governance views of Martin Luther. Luther's reform movement, however, usually did not as a rule abrogate the ecclesiastic office of Bishop.
An important historical context to explicate the wide differences among German Lutheran Churches is the Prussian Union of 1817, whereby the secular government directed the Lutheran Churches in Prussia to merge with non-Lutheran Reformed Churches in Prussia. The Reformed Churches generally oppose on principle the traditional doctrine of ecclesiastic Apostolic Succession, e.g., not usually even recognising the church office of Bishop. Later in the 19th century, other Lutheran and Reformed congregations merged to form united church bodies in some of the other 39 states of the German Confederation, e.g., in Anhalt, Baden, Bremen, Hesse and Nassau, Hesse-Kassel and Waldeck, and the Palatinate. Yet the partial nature of this list also serves to show that in Germany there remained many Lutherans who never did unite with the Reformed.
Other Lutheran Churches seem indifferent as a matter of understood doctrine regarding this particular issue of ecclesiastical governance. In America, the conservative Missouri Synod places its church authority in the congregation rather than in the bishop, though its founder, C.F.W. Walther, while establishing congregational polity for the Missouri Synod, did consider Polity (a Church's form of government) to be a matter of adiaphora (something indifferent.) Still, other conservative Lutherans, however, may favour High Church Lutheranism which remains generally favourable to the traditional doctrine of Apostolic Succession (see above). The Wisconsin Evangelical Lutheran Synod, a Confessional Lutheran body holds that "Since the first ordained Lutheran pastors were ordained by pastors who had been ordained in the Roman Catholic church and so on through the generations, we could claim historic succession as plausibly as can Roman Catholic priests if it simply were dependent on being ordained in a line of pastors." However, these Lutherans reject Roman Catholic claims to apostolic succession, since they hold that Roman Catholic bishops "have not preserved apostolic doctrine".
Methodist Church.
In the beginnings of the Methodist movement, adherents were instructed to receive the sacraments within the Anglican Church; however, the American Methodists soon petitioned to receive the sacraments from the local preachers who conducted worship services and revivals. The Bishop of London refused to ordain ministers in the British American colonies. John Wesley, the founder of the movement, was reluctant to allow unordained preachers to administer the sacraments:
We believe it would not be right for us to administer either Baptism or the Lord's Supper unless we had a commission so to do from those Bishops whom we apprehend to be in a succession from the Apostles.—Rev. John Wesley, A.D. 1745
Some scholars argue that in 1763, Greek Orthodox bishop Erasmus of the Diocese of Arcadia, who was visiting London at the time, consecrated John Wesley a bishop, and ordained several Methodist lay preachers as priests, including John Jones. However, Wesley could not openly announce his episcopal consecration without incurring the penalty of the Præmunire Act. In light of Wesley's episcopal consecration, the Methodist Church can lay a claim on apostolic succession, as understood in the traditional sense. Since the John Wesley ordained and sent forth every Methodist preacher in his day, who preached and baptized and ordained, and since every Methodist preacher who has ever been ordained as a Methodist was ordained in this direct "succession" from Wesley, then the Methodist Church teaches that it has all the direct merits coming from apostolic succession, if any such there be. This apostolic succession is recognized by Unity Catholic Church, an independent Catholic church.
However, most Methodists view apostolic succession outside its high church sense. This is because Wesley believed that the offices of bishop and presbyter constituted one order, citing an ancient opinion from the Church of Alexandria. He knew that for two centuries the succession of bishops in the Church of Alexandria was preserved through ordination by presbyters alone and was considered valid by the ancient church.
Since the Bishop of London refused to ordain ministers in the British American colonies, this constituted an emergency and as a result, on 2 September 1784, Wesley, along with a priest from the Anglican Church and two other elders, operating under the ancient Alexandrian habitude, ordained Thomas Coke a superintendent, although Coke embraced the title bishop.
Today, the United Methodist Church follows this ancient Alexandrian practice as bishops are elected from the presbyterate: the "Discipline of the Methodist Church", in ¶303, affirms that "ordination to this ministry is a gift from God to the Church. In ordination, the Church affirms and continues the apostolic ministry through persons empowered by the Holy Spirit." It also uses sacred scripture in support of this practice, namely, 1 Timothy 4:14, which states: Neglect not the gift that is in thee, which was given thee by the laying on of the hands of the "presbytery".—St. Paul of Tarsus, KJV
The Methodist Church also buttresses this argument with the leg of sacred tradition of the Wesleyan Quadrilateral by citing the Church Fathers, many of whom concur with this view.
In addition to the aforementioned arguments, or perhaps instead of them, in 1937 the annual Conference of the British Methodist Church located the "true continuity" with the Church of past ages in "the continuity of Christian experience, the fellowship in the gift of the one Spirit; in the continuity in the allegiance to one Lord, the continued proclamation of the message; the continued acceptance of the mission;..." [through a long chain which goes back to the] "the first disciples in the company of the Lord Himself ... This is our doctrine of apostolic succession" [which neither depends on, nor is secured by,] "an official succession of ministers, whether bishops or presbyters, from apostolic times, but rather by fidelity to apostolic truth". 
In June 2014, the Church of Ireland, a province of the Anglican Communion, extended its lines of apostolic succession into the Methodist Church in Ireland, as "the Archbishop of Dublin and Bishop of Down and Dromore took part in the installation of the new President of the Methodist Church of Ireland, the Rev. Peter Murray, the superintendent of the North West Methodist circuit in Londonderry." In May 2014, the "Church of Ireland’s General Synod approved an agreement signed with the Methodist Church that provided for the interchangeability of clergy, allowing an ordained minister of either church to come under the discipline and oversight of the other."
Moravian Church.
The Moravian Church teaches that it has preserved apostolic succession. In order to preserve apostolic succession, three Moravian Brethren were consecrated bishops by Bishop Stephen of Austria, a Waldensian bishop who had been ordained by a Roman Catholic bishop in 1434. These three consecrated bishops returned to Lititz and then ordained other Moravians, thereby preserving the historic episcopate.
Denominations that reject apostolic succession.
Some Nonconformist Protestants, particularly those in the Calvinist tradition, deny the doctrine of apostolic succession, believing that it is neither taught in Scripture nor necessary for Christian teaching, life, and practice. Accordingly, these Protestants strip the notion of apostolic succession from the definition of "apostolic" or "apostolicity." For them, to be apostolic is simply to be in submission to the teachings of the original twelve apostles as recorded in Scripture. This doctrinal stance reflects the Protestant view of authority, embodied in the doctrine known as Sola Scriptura.
Among the original champions of Protestantism who rejected the doctrine of apostolic succession were John Calvin, and Martin Luther. They both said that the episcopacy was inadequate to address corruption, doctrinal or otherwise, and that this inadequacy justified the intervention of the church of common people. In part this position was also necessary, as otherwise there would have been no means to elicit or initiate reform of the church.
In the 20th century, there has been more contact between Protestants and Christians from Eastern traditions which claim apostolic succession for their ministry. Like the Roman Catholic Church, these ancient Eastern churches may use the doctrine of apostolic succession in ministry in their apologetics against some forms of Protestantism. Some Protestants feel that such claims of apostolic succession are proven false by the differences in traditions and doctrines between these churches: Roman Catholics and Eastern Orthodox consider both the Church of the East and the Oriental Orthodox churches to be heretical, having been anathematized in the early ecumenical councils of Ephesus (431) and Chalcedon (451) respectively. However, churches that claim apostolic succession in ministry distinguish this from doctrinal orthodoxy, holding that "it is possible to have valid orders coming down from the apostles, and yet not to have a continuous spiritual history coming down from the apostles".
All Christians who have a genuine relationship with God through and in Christ are part of the "true Church", according to exemplary statements of evangelical Protestant theology, notwithstanding condemnation of the Catholic Church by some Protestants. According to these statements, claims that one or more denominations might be the "true Church" are nothing more than propaganda which has evolved over centuries to support authoritarian claims—based on tradition or based on scripture—of merely human institutions. Such claims can be found among the worldwide community of Christians. Yet all appear to treasure the truth that liberates, and Jesus taught his followers to love one another.
Other teachings on apostolic succession.
Latter Day Saint Movement.
Denominations within the Latter Day Saint movement claim apostolic succession through the process of restoration. According to their teaching, a period of universal apostasy followed the death of the Twelve Apostles. Without apostles or prophets left on the earth with the legitimate Priesthood Authority, many of the true teachings and practices of Christianity were lost. Eventually these were restored to the prophet Joseph Smith and various others in a series of divine conferrals and ordinations by angelic men who had held this authority during their lifetimes (see this partial list of restoration events). As it relates to apostolic succession, Joseph Smith and Oliver Cowdery said that the apostles Peter, James, and John appeared to them in 1829 and conferred upon them the Melchizedek Priesthood and with it "the keys of the kingdom, and of the dispensation of the fulness of times".
For The Church of Jesus Christ of Latter-day Saints (LDS Church), the largest denomination in the Latter Day Saint movement, Apostolic Succession is the leadership of the Church being established through the Quorum of the Twelve Apostles. Each time the President of the Church dies, the most senior Apostle, who is designated as the President of the Quorum of the Twelve Apostles, is set apart as the new church president.
Ecclesia Gnostica Catholica.
Although no longer Christian, Ecclesia Gnostica Catholica, also known as E.G.C., recognizes apostolic succession as a major spiritual tenet. Because E.G.C. has since accepted the Law of Thelema, a religion which claims to supersede Christianity, it is no longer concerned with apostolic succession deriving from Jesus. Instead, apostolic succession in E.G.C. is derived from The Master Therion, known by his civil name as Aleister Crowley and considered by Thelemites to be the Prophet of the Aeon.
Unlike apostolic succession in Christianity, E.G.C. does not claim that Thelemic Succession grants the power to remit and retain sins. Instead, the point of a valid line of succession in E.G.C. is to grant the authority to claim communion and benediction of the Gnostic Saints.

</doc>
<doc id="2264" url="http://en.wikipedia.org/wiki?curid=2264" title="List of Anglo-Saxon monarchs and kingdoms">
List of Anglo-Saxon monarchs and kingdoms

A succession of monarchs ruled the various independent kingdoms which arose in England following the end of Roman rule in Britain in the 5th century. The most prominent of these kingdoms were Kent, East Anglia, Sussex, Wessex, Mercia and Northumbria, with each kingdom often recognising their own monarch.
The early genealogies are based on the (semi-historical) Anglo-Saxon royal genealogies as compiled in the 9th century.

</doc>
<doc id="2268" url="http://en.wikipedia.org/wiki?curid=2268" title="Ascorbic acid">
Ascorbic acid

Ascorbic acid is a naturally occurring organic compound with antioxidant properties. It is a white solid, but impure samples can appear yellowish. It dissolves well in water to give mildly acidic solutions. Ascorbic acid is one form ("vitamer") of vitamin C. It was originally called -hexuronic acid, but, when it was found to have vitamin C activity in animals ("vitamin C" being defined as a vitamin activity, not then a specific substance), the suggestion was made to rename it. The new name, ascorbic acid, is derived from "a-" (meaning "no") and "scorbutus" (scurvy), the disease caused by a deficiency of vitamin C. Because it is derived from glucose, many non-human animals are able to produce it, but humans require it as part of their nutrition. Other vertebrates which lack the ability to produce ascorbic acid include some primates, guinea pigs, teleost fishes, bats, and some birds, all of which require it as a dietary micronutrient (that is, in vitamin form).
History.
From the middle of the 18th century, it was noted that lemon and lime juice could help prevent sailors from getting scurvy. At first, it was supposed that the acid properties were responsible for this benefit; however, it soon became clear that other dietary acids, such as vinegar, had no such benefits. In 1907, two Norwegian physicians reported an essential disease-preventing compound in foods that was distinct from the one that prevented beriberi. These physicians were investigating dietary-deficiency diseases using the new animal model of guinea pigs, which are susceptible to scurvy. The newly discovered food-factor was eventually called vitamin C.
From 1928 to 1932, the Hungarian research team led by Albert Szent-Györgyi, as well as that of the American researcher Charles Glen King, identified the antiscorbutic factor as a particular single chemical substance. At the Mayo clinic, Szent-Györgyi had isolated the chemical hexuronic acid from animal adrenal glands. He suspected it to be the antiscorbutic factor but could not prove it without a biological assay. This assay was finally conducted at the University of Pittsburgh in the laboratory of King, which had been working on the problem for years, using guinea pigs. In late 1931, King's lab obtained adrenal hexuronic acid indirectly from Szent-Györgyi and, using their animal model, proved that it is vitamin C, by early 1932.
This was the last of the compound from animal sources, but, later that year, Szent-Györgyi's group discovered that paprika pepper, a common spice in the Hungarian diet, is a rich source of hexuronic acid. He sent some of the now-more-available chemical to Walter Norman Haworth, a British sugar chemist. In 1933, working with the then-Assistant Director of Research (later Sir) Edmund Hirst and their research teams, Haworth deduced the correct structure and optical-isomeric nature of vitamin C, and in 1934 reported the first synthesis of the vitamin. In honor of the compound's antiscorbutic properties, Haworth and Szent-Györgyi now proposed the new name of "a-scorbic acid" for the compound. It was named -ascorbic acid by Haworth and Szent-Györgyi when its structure was finally proven by synthesis.
In 1937, the Nobel Prize for chemistry was awarded to Haworth for his work in determining the structure of ascorbic acid — shared with Paul Karrer, who received his award for work on vitamins — and the prize for Physiology or Medicine that year went to Albert Szent-Györgyi for his studies of the biological functions of -ascorbic acid.
The American physician Fred R. Klenner, M.D. promoted vitamin C as a cure for many diseases in the 1950s by elevating the dosages greatly to as much as tens of grams vitamin C daily orally and by injection. From 1967 on, Nobel prize winner Linus Pauling recommended high doses of ascorbic acid as a prevention against cold and cancer; he took 18 grams daily.
Acidity.
Ascorbic acid is classed as a reductone. The ascorbate anion is stabilized by electron delocalization, as shown above in terms of resonance between two canonical forms. For this reason, ascorbic acid is much more acidic than would be expected if the compound contained only isolated hydroxyl groups.
Antioxidant mechanism.
The ascorbate ion is the predominant species at typical biological pH values. It is a mild reducing agent and antioxidant. It is oxidized with loss of one electron to form a radical cation and then with loss of a second electron to form dehydroascorbic acid. It typically reacts with oxidants of the reactive oxygen species, such as the hydroxyl radical. Such radicals are damaging to animals and plants at the molecular level due to their possible interaction with nucleic acids, proteins, and lipids. Sometimes these radicals initiate chain reactions. Ascorbate can terminate these chain radical reactions by electron transfer. Ascorbic acid is special because it can transfer a single electron, owing to the resonance-stabilized nature of its own radical ion called, semidehydroascorbate. The net reaction is:
The oxidized forms of ascorbate are relatively unreactive and do not cause cellular damage.
However, being a good electron donor, excess ascorbate in the presence of free metal ions can not only promote but also initiate free radical reactions, thus making it a potentially dangerous pro-oxidative compound in certain metabolic contexts.
In exposure to oxygen ascorbic acid undergo further oxidative decomposition to various products including diketogulonic acid, xylonic acid, threonic acid and oxalic acid.
Food chemistry.
Ascorbic acid and its sodium, potassium, and calcium salts are commonly used as antioxidant food additives. These compounds are water-soluble and, thus, cannot protect fats from oxidation: For this purpose, the fat-soluble esters of ascorbic acid with long-chain fatty acids (ascorbyl palmitate or ascorbyl stearate) can be used as food antioxidants. Eighty percent of the world's supply of ascorbic acid is produced in China.
The relevant European food additive E numbers are:
It creates volatile compounds when mixed with glucose and amino acids in 90 °C.
It is a cofactor in tyrosine oxidation.
Biosynthesis.
Ascorbic acid is found in plants and animals where it is produced from glucose. Animals must either produce it or digest it, otherwise a lack of vitamin C may cause scurvy, which may eventually lead to death. Reptiles and older orders of birds make ascorbic acid in their kidneys. Recent orders of birds and most mammals make ascorbic acid in their liver where the enzyme -gulonolactone oxidase is required to convert glucose to ascorbic acid. Humans, other higher primates, guinea pigs and most bats require dietary -gulonolactone oxidase because the enzyme catalysing the last step in the biosynthesis is highly mutated and non-functional, therefore, unable to make ascorbic acid. Synthesis and signalling properties are still under investigation.
Animal ascorbic acid biosynthesis pathway.
The biosynthesis of ascorbic acid starts with the formation of UDP-glucuronic acid. UDP-glucuronic acid is formed when UDP-glucose undergoes two oxidations catalyzed by the enzyme UDP-glucose 6-dehydrogenase. UDP-glucose 6-dehydrogenase uses the co-factor NAD+ as the electron acceptor. The transferase UDP-glucuronate pyrophosphorylase removes a UMP and glucuronokinase, with the cofactor ADP, removes the final phosphate leading to -glucuronic acid. The aldehyde group of this is reduced to a primary alcohol using the enzyme glucuronate reductase and the cofactor NADPH, yielding -gulonic acid. This is followed by lactone formation with the hydrolase gluconolactonase between the carbonyl on C1 and hydroxyl group on the C4. -Gulonolactone then reacts with oxygen, catalyzed by the enzyme -gulonolactone oxidase (which is nonfunctional in humans and other primates) and the cofactor FAD+. This reaction produces 2-oxogulonolactone, which spontaneously undergoes enolization to form ascorbic acid.
Plant ascorbic acid biosynthesis pathway.
There are many different biosynthesis pathways for ascorbic acid in plants. Most of these pathways are derived from products found in glycolysis and other pathways. For example, one pathway goes through the plant cell wall polymers. The plant ascorbic acid biosynthesis pathway most principal seems to be -galactose. -Galactose reacts with the enzyme -galactose dehydrogenase, whereby the lactone ring opens and forms again but with between the carbonyl on C1 and hydroxyl group on the C4, resulting in -galactonolactone. -Galactonolactone then reacts with the mitochondrial ﬂavoenzyme -galactonolactone dehydrogenase. to produce ascorbic acid. -Ascorbic acid has a negative feedback on -galactose dehydrogenase in spinach.
Ascorbic acid efflux by embryo of dicots plants is a well-established mechanism of iron reduction, and a step obligatory for iron uptake.
Yeasts do not make -ascorbic acid but rather a similar antioxidant known as -erythroascorbic acid.
Industrial preparation.
Ascorbic acid is prepared in industry from glucose in a method based on the historical Reichstein process. In the first of a five-step process, glucose is catalytically hydrogenated to sorbitol, which is then oxidized by the microorganism "Acetobacter suboxydans" to sorbose. Only one of the six hydroxy groups is oxidized by this enzymatic reaction. From this point, two routes are available. Treatment of the product with acetone in the presence of an acid catalyst converts four of the remaining hydroxyl groups to acetals. The unprotected hydroxyl group is oxidized to the carboxylic acid by reaction with the catalytic oxidant TEMPO (regenerated by sodium hypochlorite — bleaching solution). Historically, industrial preparation via the Reichstein process used potassium permanganate as the bleaching solution. Acid-catalyzed hydrolysis of this product performs the dual function of removing the two acetal groups and ring-closing lactonization. This step yields ascorbic acid. Each of the five steps has a yield larger than 90%.
A more biotechnological process, first developed in China in the 1960s, but further developed in the 1990s, bypasses the use of acetone-protecting groups. A second genetically-modified microbe species, such as mutant "Erwinia", among others, oxidises sorbose into 2-ketogluconic acid (2-KGA), which can then undergo ring-closing lactonization via dehydration. This method is used in the predominant process used by the ascorbic acid industry in China, which supplies 80% of world's ascorbic acid. American and Chinese researchers are competing to engineer a mutant that can carry out a one-pot fermentation directly from glucose to 2-KGA, bypassing both the need for a second fermentation and the need to reduce glucose to sorbitol.
There exists a -ascorbic acid, which does not occur in nature but can be synthesized artificially. It has identical antioxidant properties to -ascorbic acid yet has far less vitamin C activity (although not quite zero). This fact is taken as evidence that the antioxidant properties of ascorbic acid are only a small part of its effective vitamin activity. To be specific, -ascorbate is known to participate in many specific enzyme reactions that require the correct enantiomer (-ascorbate and not -ascorbate). -Ascorbic acid has a specific rotation of formula_1°.
Determination.
The traditional way to analyze the ascorbic acid content is the process of titration with an oxidizing agent, and several procedures have been developed, mainly relying on iodometry. Iodine is used in the presence of a starch indicator. Iodine is reduced by ascorbic acid, and, when all the ascorbic acid has reacted, the iodine is then in excess, forming a blue-black complex with the starch indicator. This indicates the end-point of the titration. As an alternative, ascorbic acid can be treated with iodine in excess, followed by back titration with sodium thiosulfate using starch as an indicator. The preceding iodometric method has been revised to exploit reaction of ascorbic acid with iodate and iodide in acid solution. Electrolyzing the solution of potassium iodide produces iodine, which reacts with ascorbic acid. The end of process is determined by potentiometric titration in a manner similar to Karl Fischer titration. The amount of ascorbic acid can be calculated by Faraday's law.
An uncommon oxidising agent is "N"-bromosuccinimide, (NBS). In this titration, the NBS oxidizes the ascorbic acid in the presence of potassium iodide and starch. When the NBS is in excess (i.e., the reaction is complete), the NBS liberates the iodine from the potassium iodide, which then forms the blue-black complex with starch, indicating the end-point of the titration.

</doc>
<doc id="2273" url="http://en.wikipedia.org/wiki?curid=2273" title="AFC Ajax">
AFC Ajax

Amsterdamsche Football Club Ajax (]), also AFC Ajax or Ajax Amsterdam, is a Dutch professional football club based in Amsterdam. Historically, Ajax (named after the legendary Greek hero) is the most successful club in the Netherlands, with 33 Eredivisie titles and 18 KNVB Cups. Along with PSV Eindhoven and Feyenoord, it is one of the country's "big three" clubs that have dominated Dutch football (and that are the only three clubs in the Netherlands that have never been relegated from the top division).
Ajax is historically one of the most successful clubs in the world; according to the IFFHS, Ajax were the seventh-most successful European club of the 20th century. The club is one of the five teams that has earned the right to keep the European Cup and to wear a multiple-winner badge; they won consecutively in 1971–1973. In 1972, they completed the continental treble by winning the Eredivisie, KNVB Cup, and the European Cup. Ajax's last international trophies were the 1995 Intercontinental Cup and the 1995 Champions League, where they defeated Milan in the final; they lost the 1996 Champions League final on penalties to Juventus.
Ajax is also one of three teams to win the continental treble and the Intercontinental Cup in the same season/calendar year; This was achieved in the 1971–72 season. Ajax, Juventus, Bayern Munich, and Chelsea are the four clubs to have won all three major UEFA club competitions. They have also won the Intercontinental Cup twice, the 1991–92 UEFA Cup, as well as the Karl Rappan Cup, a predecessor of the UEFA Intertoto Cup in 1962. Ajax plays at the Amsterdam Arena, which opened in 1996. They previously played at De Meer Stadion and the Amsterdam Olympic Stadium (for international matches).
History.
Ajax was founded in Amsterdam on 18 March 1900. The club achieved promotion to the highest level of Dutch football in 1911 and had its first major success in 1917, winning the KNVB Beker, the Netherlands' national cup. The following season, Ajax became national champion for the first time. The club defended its title in 1918–19, becoming the only team to achieve an unbeaten season in the Netherlands Football League Championship.
Throughout the 1920s, Ajax was a strong regional power, winning the Eerste Klasse West division in 1921, 1927 and 1928, but could not maintain its success at national level. This changed in the 1930s, with the club winning five national championships (1931, 1932, 1934, 1937, 1939), making it the most successful Dutch team of the decade. Ajax won its second KNVB Cup in 1942–43, and an eighth Dutch title in 1946–47, the last season the club was managed by Englishman Jack Reynolds, who, up to this point, had overseen all of its national championship successes as well as its 1917 KNVB Cup win.
In 1956, the first season of the Netherlands' new professional league, the Eredivisie, was played with Ajax participating as a founding member. The Amsterdam club became the first national champions under the new format and made its debut in the European Champion Clubs' Cup the following year, losing to Hungarian champions Vasas SC 6–2 on aggregate at the quarter-final stage. The team were again Eredivisie champions in 1960 and won a third KNVB Cup in 1961.
In 1965, Rinus Michels, who had played for the club between 1946 and 1958, was appointed manager of Ajax, implementing his philosophy of Total Football which was to become synonymous with both Ajax and the Netherlands national football team. A year earlier, Johan Cruijff, who would go on to become the greatest Dutch footballer of all time, made his debut. Between them, Michels and Cruijff led Ajax through the most successful period in its history, winning seven Eredivisie titles, four KNVB Cups and three European Cups.
Ajax won the Dutch championship in 1966, 1967, and 1968, and reached the 1969 European Cup Final, losing to A.C. Milan. During the 1966–67 season, Ajax scored a record 122 goals in an Eredivisie season and also won the KNVB Cup to achieve its first league and cup double. In 1969–70, Ajax won a fourth Dutch league championship and second league and cup double in five seasons, winning 27 out of 34 league games and scoring 100 goals.
The 1970–71 season saw Ajax retain the KNVB Cup and reach the 1971 European Cup Final, where they beat Panathinaikos 2–0 with goals from Dick van Dijk and Arie Haan to become continental champions for the first time, with Cruijff being named European Footballer of the Year. After this success, Michels departed to become manager of FC Barcelona and was replaced by the Romanian Ștefan Kovács. In Kovács' first season, Ajax completed a treble of the European Cup, the Eredivisie and a third consecutive KNVB Cup. The following season, the team beat Argentine club Independiente to win the 1972 Intercontinental Cup and retained their Eredivisie and European Cup titles, becoming the first club to win three consecutive European Cups since Real Madrid in the 1950s.
In 1973, Michels' Barcelona broke the world transfer record to bring Cruijff to Catalonia. Kovács also departed to become manager of the France national football team signalling the end of this period of international success.
In 1976–77, Ajax won its first domestic championship in four seasons and recorded a double of the Eredivisie and KNVB Cup two years later.
The early 1980s saw the return of Johan Cruijff to the club, as well as the emergence of young players Marco van Basten and Frank Rijkaard. The team won back-to-back Eredivisie titles in 1982 and 1983, with all three playing a significant role in the latter. After Cruijff's sale to rivals Feyenoord in 1983, Van Basten became Ajax's key player, top scoring in the Eredivisie for four seasons between 1983–84 and 1986–87.
In 1985, Cruijff returned to Ajax as manager and the team ended his first season in charge with 120 goals from 34 matches. However, Ajax still finished as runner up to PSV by eight points. The following season, Ajax again lost out on the Eredivisie title to PSV, but won the European Cup Winners' Cup, its first continental trophy in fourteen years. After this, Cruijff left the club to become manager of Barcelona and Rijkaard and Van Basten were sold to Sporting CP and A.C. Milan respectively. Despite these losses, Ajax reached a second consecutive Cup Winners' Cup final in 1988, where they lost to Belgian club KV Mechelen.
The 1988–89 season saw Dennis Bergkamp, a young forward who had first appeared under Cruijff in 1986, establish himself as a regular goalscorer for Ajax. Bergkamp helped Ajax to the 1989–90 Eredivisie title and was the top scorer in the division in 1990–91, 1991–92 and 1992–93. Under the management of Louis van Gaal, Ajax won the UEFA Cup in 1992 to become the second club, after Juventus, to have won all three major European club competitions.
After the sale of Bergkamp to Internazionale in 1993, Van Gaal re-signed the experienced Frank Rijkaard to complement his young Ajax team featuring academy graduates Frank and Ronald de Boer, Edwin van der Sar, Clarence Seedorf, Edgar Davids, Michael Reiziger, and Winston Bogarde, as well as mercurial foreign talents Finidi George, Nwankwo Kanu and Jari Litmanen, and veteran captain Danny Blind. The team regained the Dutch championship in 1993–94, and won it again in 1994–95 and 1995–96 to become the first Ajax side to win three back-to-back championships since 1968. The height of Van Gaal's success came in 1994–95, where Ajax became the first, and to date only, team to complete an entire Eredivisie season unbeaten. The team also won its first European Cup since its glorious 1970s era, beating Milan in the 1995 UEFA Champions League Final 1–0, with the winning goal scored by 18-year-old Patrick Kluivert. Ajax again reached the final a year later but were defeated on penalties by Juventus.
Ajax's return as a European force was short lived as Van Gaal and several members of the squad soon departed to some of the continent's biggest clubs. The 2000s was a lean decade for the club with only two Eredivisie championships won. However, Ajax's academy continued to produce star players such as Wesley Sneijder and Rafael van der Vaart.
In 2010, Frank de Boer was appointed manager of Ajax and led the club to its first league title in seven years, and record 30th title overall, in the 2010–11 season. This was followed by back-to-back wins in 2011–12 and 2012–13 to match his three consecutive titles as a player in the 1990s. In 2013–14, Ajax were again Eredivisie champions, winning four consecutive league titles for the first time in the club's history.
Youth program.
The club is also particularly famous for its renowned youth program that has produced many Dutch talents over the years – Johan Cruijff, Edwin van der Sar, Dennis Bergkamp, former national team top scorer Patrick Kluivert, and former national team coach Marco van Basten. Dutch national first-team players Rafael van der Vaart, Ryan Babel, Wesley Sneijder, Maarten Stekelenburg, Eljero Elia, André Ooijer, John Heitinga and Nigel de Jong had also came through the ranks at Ajax and all are now playing for top-flight clubs. Ajax also regularly supplies the Dutch national youth teams with local talent. First team regulars Siem de Jong, Urby Emanuelson and Gregory van der Wiel are former youth internationals who made the successful step up to the senior side.
Due to mutual agreements with foreign clubs, the youth academy has also signed foreign players as teenagers before making first team debuts, such as Belgian defensive trio Jan Vertonghen, Toby Alderweireld and Thomas Vermaelen along with winger Tom de Mul, all of whom are full internationals as well as Dutch international Vurnon Anita as well as Javier Martina from Curaçao.
Ajax has also expanded its talent searching program to South Africa with Ajax Cape Town. Ajax Cape Town was set up with the help of Rob Moore. Ajax has also had a satellite club in the United States under the name Ajax America, until it filed for bankruptcy. There are some youth players from Ajax Cape Town that have been drafted into the Eredivisie squad, such as South African internationals Steven Pienaar, Thulani Serero and Cameroonian international Eyong Enoh.
In 1995, the year Ajax won the Champions League, the Dutch national team was almost entirely composed of Ajax players, with Edwin van der Sar in goal; players such as Michael Reiziger, Frank de Boer, and Danny Blind in defense; Ronald de Boer, Edgar Davids, and Clarence Seedorf in midfield; and Patrick Kluivert and Marc Overmars in attack.
In 2011 AFC Ajax opened its first youth academies outside the Netherlands, when the club partnered up with George Kazianis and All Star Consultancy in Greece to open the Ajax Hellas Youth Academy. The offices are based in Nea Smyrni, Attica, with the main training facility located on the island of Corfu, hosting a total of 15 football youth academies throughout Greece and Cyprus. Eddie van Schaik heads the organization as coach and consultant, introducing the Ajax football philosophy at the various Greek football training camps.
Stadiums.
Ajax' first stadium was built in 1911 out of wood and was called "Het Houten Stadion" (The Wooden Stadium). Ajax later played in the stadium built for the 1928 Summer Olympics hosted in Amsterdam. This stadium, designed by Jan Wils, is known as the Olympic Stadium. In 1934, Ajax moved to De Meer Stadion in east Amsterdam, designed by architect and Ajax-member Daan Roodenburgh, who had also designed the club's first stadium. It could accommodate 29,500 spectators and Ajax continued to play there until 1996. For big European and national fixtures the club would often play at the Olympic Stadium, which could accommodate about twice the number of spectators.
In 1996, Ajax moved to a new home ground in the southeast of the city known as the Amsterdam ArenA This was built by the Amsterdam city authority at a cost of $134 million. The stadium is capable of holding approximately 52,000 people. The average attendance in 2006/07 was 48,610, rising in the next season to 49,128. The ArenA has a retractable roof and set a trend for other modern stadiums built in Europe in the following years. In the Netherlands, the ArenA has earned a reputation for a terrible grass pitch caused by the removable roof that, even when open, takes away too much sunlight and fresh air. During the 2008–2009 season ground staff introduced an artificial lighting system that has finally reduced this problem considerably.
The much-loved De Meer stadium was torn down and the land was sold to the city council. A residential neighbourhood now occupies the area. The only thing left of the old stadium are the letters AJAX, nowadays in place on the façade of the youth training grounds De Toekomst, near the Amsterdam Arena.
Crest and colours.
Crest.
In 1900, when the club was founded, the emblem of Ajax was just a picture of an Ajax player. The crest was slightly altered following the club's promotion to the top division in 1911 to match the club's new outfits. In 1928, the club logo was introduced with the head of the Greek hero Ajax. The logo was once again changed in 1990 into an abstract version of the previous one. The new logo still sports the portrait of Ajax, but drawn with just 11 lines, symbolizing the 11 players of a football team.
Colors.
Ajax originally played in an all-black uniform with a red sash tied around the players' waists, but that uniform was soon replaced by a red/white striped shirt and black shorts. Red, black and white are the three colours of the flag of Amsterdam. However, when, under manager Jack Kirwan, the club got promoted to the top flight of Dutch football for the first time in 1911 (then the "Eerste Klasse" or 'First Class', later named the Eredivisie), Ajax were forced to change their colours because Sparta Rotterdam already had exactly the same outfit. Special kits for away fixtures did not exist at the time and according to football association regulations the newcomers had to change their colours if two teams in the same league had identical uniforms. Ajax opted for white shorts and white shirt with a broad, vertical red stripe over chest and back, which still is Ajax's outfit.
Financial.
AFC Ajax N.V..
AFC Ajax are the only Dutch club with an Initial public offering (IPO). The club is registered as a Naamloze vennootschap (N.V.) listed on the stock exchange Euronext Amsterdam, since 17 May 1998. With a launch price of ƒ25,- (Guilders) the club managed to a bring their total revenue up to €54 million euros (converted) in their first year on the market. After short lived success however the rate dropped, at one point as low as €3,50. Criticism was brought forth that the legal grid for a naamloze vennootschap would not be suitable for a Football club, and that the sports related ambitions would suffer from the new commercial interests of the now listed Ajax. Shares of the company in the year 2008 were valued at approximately €5,90 per share.
In 2008 a Commission under guidance of honorary member Uri Coronel concluded, that the IPO was of no value to the club, and that measures should be taken to exit the stock exchange by purchasing back all public shares. Ajax remain on the stock exchange.
Sponsorship.
Ajax's shirts have been sponsored by TDK from 1982 to 1991, and by ABN AMRO from 1991 to 2008. AEGON then replaced ABN AMRO as the new head sponsor for a period of seven years. On 1 April 2007, Ajax wore a different sponsor for the match against Heracles Almelo: "Florius". Florius is a banking program launched by ABN AMRO who wanted it to be the shirt sponsor for one match.
The shirts have been manufactured by Le Coq Sportif (1973–1977), Puma (1977–1980), Le Coq Sportif (1980–1984), Kappa (1985-1989) and Umbro (1989–2000) in the past, and by Adidas since 2000 (until at least 2019).
In conclusion of the 2013–14 season, Ajax won the Football shirt of the Year award for their black and rose colored away shirt by adidas. An annual award presented by Subside Sports which had previously been won by Internazionale, Juventus and the Belgium national team. It was Ajax first time winning the award.
On 7 November 2014 it was announced that Ajax had agreed to 4,5 year contract worth €8 million annually with Dutch cable operating company Ziggo as the new shirt sponsor for the club. Having extended their contract with AEGON for half a season until December, the club featured "Fonds Gehandicaptensport", a charitable fund for handicapped sports on its away shirts for a six-month period before transitioning to Ziggo in 2015.
Other teams.
Reserves team.
Jong Ajax ("formerly more commonly known as Ajax 2") is the reserve team of AFC Ajax. The team is composed mostly of professional footballers, who are often recent graduates from the highest youth level (Ajax A1) serving their first professional contract as a reserve, or players who are otherwise unable to play in the first team.
Since 1992 Jong Ajax have competed in the Beloften Eredivisie, competing against other reserve teams such as Jong PSV, Jong FC Groningen or Jong AZ. They have won the Beloften Eredivisie title a record eight times, as well as the KNVB Reserve Cup three times, making them the most successful reserve squad in the Netherlands. By winning the Beloften Eredivisie title, Jong Ajax were able to qualify for the actual KNVB Cup, even advancing to the semi-finals on three occasions. Their best result in the Dutch Cup was under manager Jan Olde Riekerink in 2001-02, when a semi-final loss to FC Utrecht in a Penalty shoot-out after extra time, which saw Utrecht advance, and thus preventing an Ajax vs. Jong Ajax Dutch Cup final.
The 2013–14 season marked the Jupiler League debut of the AFC Ajax reserves' squad Jong Ajax. Previously playing in the Beloften Eredivisie (a separate league for reserve teams, not included in the Dutch professional or amateur league structure) players were allowed to move around freely between the reserve team and the first team during the season. This is no longer the case as Jong Ajax now registers and fields a separate squad from that of Ajax first team for the Eerste Divisie, the second tier of professional football in the Netherlands. Their home matches are played at Sportpark De Toekomst, except for the occasional match in the Amsterdam Arena. Now regarded a semi-professional team in their own respect, the only period in which players are able to move between squads are during the transfer windows, unless the player has made less than 15 appearances for the first team, then he is still eligible to appear in both first team and second team matches during the season. Furthermore the team is not eligible for promotion to the Eredivisie or to participate in the KNVB Cup. Jong Ajax were joined in the Eerste Divisie by Jong Twente and Jong PSV, reserve teams who have also moved from the Beloften Eredivisie to the Eerste Divisie, in place of VV Katwijk, SC Veendam and AGOVV Apeldoorn, increasing the total amount of teams in the Jupiler League from 18 to 20.
Ajax reserve squad Jong Ajax left the Beloften Eredivisie in 2013, having held a 21-year tenure in the reserves league, having also won the league title a record eight times. (1994, 1996, 1998, 2001, 2002, 2004, 2005, 2009)
Amateur team.
AFC Ajax Amateurs, better known as Ajax Zaterdag is a Dutch amateur football club founded 18 March 1900. It is the amateur team of the professional club AFC Ajax, who play their home matches at the Sportpark De Toekomst training grounds to a capacity of 5,000. The team was promoted from the Eerste Klasse to the Hoofdklasse ahead of the 2011–12 season, the league in which they are currently competing. The team has won the Eerste Klasse title twice, as well as the *KNVB District Cup West I on two occasions as well.
Furthermore, Ajax Zaterdag have also managed to qualify for the KNVB Cup on their own accord on three occasions, namely in 2004, 2005 and in 2008, even advancing to the second round before bowing out to Vitesse on 24 September 2008 during their last appearance in the cup tournament.
Women's team.
AFC Ajax Vrouwen ("English: AFC Ajax Women") are the women's team of AFC Ajax, competing in the BeNe League, the highest level of professional football in Belgium and the Netherlands. Founded on 18 May 2012, the women's team saw Ajax attracting many of the Netherlands top talents, with International players such as Anouk Hoogendijk, Daphne Koster and Petra Hogewoning joining the Amstedam club on its maiden season in women's professional football. The team won their first piece of silverware when the defeated PSV/FC Eindhoven 2–1 in the final of the KNVB Women's Cup.
Other sports.
Baseball team.
Ajax HVA (1922–1972) was the baseball team of AFC Ajax founded in 1922, and competing as founding members of the Honkbal Hoofdklasse, the top flight of professional baseball in the Netherlands. Ajax won the national baseball title a total of four times (1924, 1928, 1942, 1948) before the club opted to no longer field a baseball team, and to focus solely on football in 1972. Ajax spent a total of 50 years at the top flight of Baseball in the Netherlands from 1922 to 1972. The dissolution of Ajax baseball club resulted in the players finding a new sponsor in a mustard manufacturing company called Luycks, while merging with the Diemen Giants to become the Luycks Giants, thus replacing both former clubs.
Affiliated clubs.
The following clubs are currently affiliated with AFC Ajax:
The following clubs were affiliated with AFC Ajax in the past:
Rivalries.
"As one of the traditional big three clubs in the Netherlands, Ajax have amassed a number of intense rivalries over the years. Listed below are the most significant of the rivalries involving Ajax Amsterdam."
Rivalry with Feyenoord.
Feyenoord from Rotterdam are Ajax's arch rivals. Every year both clubs play the "De Klassieker" ("The Classic"), a match between the teams from the two largest cities of the Netherlands. During the seventies, Ajax and Feyenoord were the only two clubs in the Netherlands who were able to clinch national titles, as well as achieve continental and even global success. A meeting between the two clubs became the measure for who was truly the best club in the Netherlands. The Klassieker is the most famous of all the rivalries in the Netherlands and the matches are always sold out. The fixture is seen in the public eye as "The graceful and elegant football of Ajax, against the indomitable fighting spirit of Feyenoord". The confidence of the Capital versus the Blue collar mentality of Rotterdam. Matches are known for their tension and violence, both on and off the pitch. Over the years several violent incidents have taken place involving rival supporters, leading to the current prohibition of away-supporters in both stadiums. The lowest point was reached on 23 March 1997, when supporters of both clubs meet on a field near Beverwijk, where Ajax-supporter Carlo Picornie was fatally injured, the incident is commonly referred to as the "Battle of Beverwijk".
Rivalry with PSV.
PSV are also a rival of Ajax, but in terms of tension and rivalry, these matches are not as loaded as the duels with Feyenoord. The rivalry has existed for some time with PSV and stems from various causes, such as the different interpretations of whether current national and international successes of both clubs correlates and the supposed opposition between the Randstad and the province. The matches between these two teams is commonly referred to as "De Topper" ("The Topper"), and involves the two most trophy-laden sides in Dutch football and is essentially a clash of two competing schools of thought in Dutch football. Historically PSV compete with a workmanlike ethic, preferring a more robust 4-3-1-2 or 4-2-3-1, typically shunning the seductive 4-3-3 approach favoured in Amsterdam. While Rinus Michels and Johan Cruijff helped to innovate Total Football in the sixties and seventies, a different philosophy was honed in Eindhoven by Kees Rijvers and Guus Hiddink in the late seventies and eighties. This in turn has created one of the more philosophical rivalries in football, an ideological battleground, which is gradually becoming as heated and intense as the matches Ajax and Feyenoord partake in.
Rivalries with other clubs.
Aside from Feyenoord and PSV, Ajax have several other rivalries, although in most cases the sentiment is mostly felt by the opposition and is more directed towards Ajax, with one of them being FC Utrecht. Although the rivalry is more felt on the Utrecht side then with Ajax, matchups between the two sides are often quite intense. Both teams have fanatic supporters, and clashes off the pitch are more often the rule than the exception. The same goes for ADO Den Haag, with both supporter-groups often getting in conflicts, when ADO-Hooligans set fire to the Supporters home of Ajax, and Ajax-Hooligans subsequently broke into the Supporters home of ADO tensions between the two clubs rose. In 2006 Supporters from both clubs were banned from attending away matches for five years, due to frequent violent outbreaks and clashes.
Further teams who share a rivalry with Ajax include FC Twente, FC Groningen and AZ. Although the latter are often regarded by Ajax-supporters as the club's little brother. Being from nearby Alkmaar, and with both clubs sharing the same Province, match-ups between the two sides are commonly known as the "De Noord-Hollandse Derby" ("North Holland Derby") and are often very competitive, intense and loaded fixtures.
Past rivalries include local Amsterdam derbies between Ajax and clubs such as Blauw-Wit, DWS and De Volewijckers (who later merged to become FC Amsterdam in 1972). The tension between the local sides lessened however, as the division of the clubs through playing in different leagues over time became greater. Years of not competing in the same league resulted in less frequent match-ups, until tensions finally settled between the Amsterdam clubs. The last Amsterdam derby to take place in an official league match was when Ajax defeated FC Amsterdam 5-1, on 19 March 1978.
Supporters.
Ajax are known for having fanatic core supporter-groups, of which F-Side and VAK410 are the most famous. F-Side were founded on 3 October 1976, and are situated right behind the goal In the Amsterdam ArenA, on the southern end of the stadium in rows 125–129. Their name is derived from the group's former location on the F-side of the old De Meer Stadion. The F-side supporters are responsible for a big part of the atmosphere in the stadium, but are also known for rioting during and after matches. If in any match Ajax should win the coin toss, the second half of the match Ajax always play towards the south-end of the stadium. VAK410 (English: Row 410) were founded in 2001 and are situated in the Zuidhoek ("South corner") of the stadium on the upper ring in rows 424–425. The group was originally situated on the North-West side of the stadium in row 410, from where it derives its name, until relocating to their current place in the stands in 2008. Members of VAK410 are known to perform various stunts, which include massive banners, to enhance the atmosphere in the stadium. Neither F-Side or VAK410 have seats in their sections of the stadium, and both groups stand for the duration of the match.
Through the official "Football Top 20" of Dutch sports research group "SPORT+MARKT" it was revealed in 2010 that Ajax had approximately 7,1 million supporters throughout Europe. Slightly more than rivals Feyenoord and PSV (each 1,6 and 1,3 million, respectively), which put Ajax in 15th place for most supporters in all of Europe. The study also revealed that approximately 39% of the Netherlands were Ajax supporters. Not only does Ajax have a lot of supporters, but several fans attend their matches in European competition, with an average attendance of 48.677 spectators for every International match Ajax played, putting the team at 12th place in Europe for highest attendance, ahead of big name clubs such as Milan, Manchester City or Chelsea. It is noteworthy that not all stadiums share the capacity of the Amsterdam Arena.
Supporters clubs.
The Supporters Club Ajax (Dutch: "Supportersvereniging Ajax") is officially the largest Supporters club in the Netherlands with 94,000 members. Founded on 7 May 1992, the supporters club organize big monthly events throughout the Netherlands, and particularly around the official Ajax Open Training Day, which attracts thousands of supporters each year. Furthermore the Supporters group is responsible for the Ajax Life website, as well as the fanzine which is issued 20 times a year. In 2006, the AFCA Supportersclub was introduced as the club's second official supporters' association, through the merger of the Onafhankelijke Fanclub Ajax (OFA) and the Ajax Supporters Delegatie (ASD). The AFCA Supportersclub has a reported 42,000 members, as well as a former member on the Board of Administration of Ajax, in Ronald Pieloor.
Average attendance.
This graph displays the average attendance for home matches of Ajax from 1988–2012, whereby the difference in capacity of the De Meer Stadion and the Amsterdam ArenA (est. 1996) is clearly visible.
Jewish connection.
Historically, Ajax was popularly seen as having "Jewish roots". Although not an official Jewish club like the city's WV-HEDW, Ajax has had a Jewish image since the 1930s when the home stadium was located next to a Jewish neighbourhood of Amsterdam-Oost and opponents saw many supporters walking through the Nieuwmarkt/Waterloopleinbuurt (de Jodenhoek) to get to the stadium. The city of Amsterdam was historically referred to as a Mokum city, Mokum (מקום) being the Yiddish word for "place" or "safe haven", and as anti-Semitic chants and name calling developed and intensified at the old De Meer Stadion from frustrated supporters of opposing clubs, Ajax fans (few of whom are actually Jewish) responded by embracing Ajax's "Jewish" identity: calling themselves "super Jews", chanting "Jews, Jews" ("Joden, Joden") at games, and adopting Jewish symbols such as the Star of David and the Israeli flag.
This Jewish imagery eventually became a central part of Ajax fans' culture. At one point ringtones of "Hava Nagila", a Hebrew folk song, could be downloaded from the club's official website. Beginning in the 1980s, fans of Ajax's rivals escalated their antisemitic rhetoric, chanting slogans like "Hamas, Hamas/Jews to the gas" ("Hamas, hamas, joden aan het gas"), hissing to imitate the flow of gas, giving Nazi salutes, etc. The eventual result was that many (genuinely) Jewish Ajax fans stopped going to games.
In the 2000s the club began trying to persuade fans to drop their Jewish image. In 2013 a documentary titled "Superjews" was released by NTR and Viewpoint Productions which premiered at the International Documentary Film Festival Amsterdam (IDFA). The film was directed by Nirit Peled, an Israeli living in Amsterdam, and an independent film maker who offers a very personal view into the game, the lore of Ajax and its relation to Judaism from both the supporters as well as from a Jewish perspective.
Players.
Current squad.
"As of 23 May 2015.
Notable former players.
The players below are part of the AFC Ajax Hall of Fame.
Honours.
Official trophies (recognized by UEFA and FIFA).
Other trophies.
Ajax have won numerous friendly tournaments, unsanctioned by UEFA or FIFA, including the Amsterdam Tournament, Bruges Matins Trophy, Trofeo Santiago Bernabéu, Eusébio Cup, Ted Bates Trophy, Jalkapalloturnaus and Chippie Polar Cup. ("For a complete list, see main article")
Honorary club members.
Ajax have a total of 45 honorary club members, from people who have been invested within the club's administrative engagements, to committed players who have excelled in the athletic department. Of those 45 members 38 have since deceased. Seven members still remain, having been reduced from eight members after Piet Keizer denounced his membership.
The remaining 38 honorary members who have since passed away:
Results.
Domestic results.
Below is a table with Ajax's domestic results since the introduction of the Eredivisie in 1956.
Club van 100.
The Club van 100 is the official list of Football players who have appeared in one hundred or more official matches for AFC Ajax. The club currently has a total of 150 members with Daley Blind being the latest addition. The record for league appearances is held by Mr. Ajax himself Sjaak Swart, who appeared in 463 league matches for Ajax 1. There is a beneficiary team called Lucky Ajax, which was initiated by Sjaak Swart. Lucky Ajax participate in at least one match a year, usually in the name of charity, and commonly at football ceremonies to bid farewell to retiring players. One of the prerequisites for playing on Lucky Ajax, which is invitational only, is that you are a member of the Club van 100, having made at least 100 official match appearances for Ajax Amsterdam in the first team of the club.
Lucky Ajax.
Lucky Ajax are a beneficiary team that was initiated by Sjaak Swart in the seventies, competing in at least one match a year, usually in the name of charity and/or to bid farewell to retiring former Ajax players. The team is made up of various members of the Club van 100 of Ajax who will come out of retirement for this match to face the Ajax squad that is current of that year. Past participants have included Barry Hulshoff, Sonny Silooy, Simon Tahamata, Ronald Koeman, Tscheu La Ling, Gerrie Mühren, John van 't Schip, Brian Roy, Stanley Menzo, Peter van Vossen and Fred Grim. The name Lucky Ajax is derived from the famous "Lucky Ajax" nickname from how people used to refer to the club when Ajax would either win a match by chance, by a decision of a referee, or by coincidence such as was said to be the case during the infamous Mistwedstrijd (Fog Match).
Number 14 shirt.
As of the 2007–08 season, no player could wear the number 14 shirt at Ajax, after the club decided to retire the shirt out of respect for Johan Cruyff, "the legendary number fourteen". Cruyff himself laughed off the tribute saying the club had to let its best player play with number 14. Spanish midfielder Roger was the last player to wear the number. Marvin Zeegelaar wore the shirt number In preparation for the 2011–12 season in one preseason match, while Aras Özbiliz wore the number 14 shirt in one preseason match ahead of the 2011–12 season as well. The club stated that this was in fact not done in error.
List of players to wear the number 14 shirt since Johan Cruyff's departure.
Team tournaments.
Amsterdam Tournament.
Established in 1975 as the Amsterdam 700 Tournament to celebrate 700 years of history in the city. The tournament was hosted annually each summer by Ajax until 1992, when the last edition of the original tournament was played. It returned in 1999 with the backing of the International Event Partnership (IEP). Four teams participate in the competition, played in a league format since 1986. Since its return, the tournament has used an unusual point scoring system. As with most league competitions, three points are awarded for a win, one for a draw, and none for a loss. However, an additional point is awarded for each goal scored. The system is designed to reward teams that adopt a more attacking style of play. Each entrant plays two matches, with the winner being the club that finishes at the top of the table. The original competition was held at De Meer, Ajax's home between 1934 and 1996. The Amsterdam Arena has played host to the event since its return until the last edition was played in 2009. Ajax is the most successful team of the tournament, having won it a record 10 times, while S.L. Benfica from Portugal were the last team to win the tournament in 2009.
Copa Amsterdam.
Established in 2005, the Copa Amsterdam is an international friendly football tournament for Under-19 youth teams, that is organized by Ajax and the Amsterdam city council, which takes place at the Olympic Stadium as part of the annual Amsterdam Sports Weekend, a citywide sponsored initiative to promote 'sports and recreation' within the city of Amsterdam. Each Summer the city of Amsterdam and Ajax invite U-19 teams from various top clubs from around the World to participate in the tournament. Seven teams are invited and play in the competition every year with the ninth edition of the tournament having occurred in 2013. Over the years, clubs such as Barcelona, Juventus, Chelsea and Real Madrid have had their senior youth teams participate in the tournament. Cruzeiro from Brazil are the most successful club in the history of the tournament, having won it three times in total, while Ajax Cape Town from South Africa are the current cup holders.
Future Cup.
Established in 2010, the AEGON Future Cup is an international friendly tournament for Under-17 youth teams, which is organized by AFC Ajax and their main sponsor, the insurance company AEGON. The tournament is held each year at the Amsterdam Arena and at the Sportpark De Toekomst, the teams training ground, which also inspired the name of the competition, since "De Toekomst" in Dutch means The Future. Every year during the Easter weekend, six U-17 teams are invited to participate in the competition, while the seventh place for the contesters is reserved for the winners of the "Craques Mongeral AEGON Future Cup" in Brazil, the sister competition of the tournament in South America. Youth teams from top clubs such as Manchester United, Bayern München, Milan and many more have participated in the competition over the years. Ajax are the most successful club of the tournament, having won the trophy a total of three times, and current cup holders having defeated Liverpool in the final of the latest edition.
See also.
Other teams
Former teams
Stadia
Media
Musea
Other

</doc>
<doc id="2274" url="http://en.wikipedia.org/wiki?curid=2274" title="Arthur Eddington">
Arthur Eddington

Sir Arthur Stanley Eddington, OM, FRS (28 December 1882 – 22 November 1944) was a British astronomer, physicist, and mathematician of the early 20th century who did his greatest work in astrophysics. He was also a philosopher of science and a popularizer of science. The Eddington limit, the natural limit to the luminosity of stars, or the radiation generated by accretion onto a compact object, is named in his honour.
He is famous for his work regarding the theory of relativity. Eddington wrote a number of articles that announced and explained Einstein's theory of general relativity to the English-speaking world. World War I severed many lines of scientific communication and new developments in German science were not well known in England. He also conducted an expedition to observe the Solar eclipse of 29 May 1919 that provided one of the earliest confirmations of relativity, and he became known for his popular expositions and interpretations of the theory.
Early years.
Eddington was born 28 December 1882 in Kendal, Westmorland (now Cumbria), England, the son of Quaker parents, Arthur Henry Eddington and Sarah Ann Shout.
His father taught at a Quaker training college in Lancashire before moving to Kendal to become headmaster of Stramongate School. He died in the typhoid epidemic which swept England in 1884. His mother was left to bring up her two children with relatively little income. The family moved to Weston-super-Mare where at first Stanley (as his mother and sister always called Eddington) was educated at home before spending three years at a preparatory school.
In 1893 Eddington entered Brynmelyn School. He proved to be a most capable scholar, particularly in mathematics and English literature. His performance earned him a scholarship to Owens College, Manchester (what was later to become the University of Manchester) in 1898, which he was able to attend, having turned 16 that year. He spent the first year in a general course, but turned to physics for the next three years. Eddington was greatly influenced by his physics and mathematics teachers, Arthur Schuster and Horace Lamb. At Manchester, Eddington lived at Dalton Hall, where he came under the lasting influence of the Quaker mathematician J. W. Graham. His progress was rapid, winning him several scholarships and he graduated with a B.Sc. in physics with First Class Honours in 1902.
Based on his performance at Owens College, he was awarded a scholarship to Trinity College at the University of Cambridge in 1902. His tutor at Cambridge was Robert Alfred Herman and in 1904 Eddington became the first ever second-year student to be placed as Senior Wrangler. After receiving his M.A. in 1905, he began research on thermionic emission in the Cavendish Laboratory. This did not go well, and meanwhile he spent time teaching mathematics to first year engineering students. This hiatus was brief.
Death.
Eddington died of cancer in the Evelyn Nursing Home, Cambridge, on 22 November 1944. His body was cremated at Cambridge Crematorium (Cambridgeshire) on 27 November 1944; the cremated remains were buried in the grave of his mother in the Ascension Parish Burial Ground in Cambridge.
Astronomy.
In January 1906, Eddington was nominated to the post of chief assistant to the Astronomer Royal at the Royal Greenwich Observatory. He left Cambridge for Greenwich the following month. He was put to work on a detailed analysis of the parallax of 433 Eros on photographic plates that had started in 1900. He developed a new statistical method based on the apparent drift of two background stars, winning him the Smith's Prize in 1907. The prize won him a Fellowship of Trinity College, Cambridge. In December 1912 George Darwin, son of Charles Darwin, died suddenly and Eddington was promoted to his chair as the Plumian Professor of Astronomy and Experimental Philosophy in early 1913. Later that year, Robert Ball, holder of the theoretical Lowndean chair also died, and Eddington was named the director of the entire Cambridge Observatory the next year. In May 1914 he was elected a Fellow of the Royal Society and won their Royal Medal in 1918 and delivered their Bakerian Lecture in 1926.
Eddington also investigated the interior of stars through theory, and developed the first true understanding of stellar processes. He began this in 1916 with investigations of possible physical explanations for Cepheid variables. He began by extending Karl Schwarzschild's earlier work on radiation pressure in Emden polytropic models. These models treated a star as a sphere of gas held up against gravity by internal thermal pressure, and one of Eddington's chief additions was to show that radiation pressure was necessary to prevent collapse of the sphere. He developed his model despite knowingly lacking firm foundations for understanding opacity and energy generation in the stellar interior. However, his results allowed for calculation of temperature, density and pressure at all points inside a star, and Eddington argued that his theory was so useful for further astrophysical investigation that it should be retained despite not being based on completely accepted physics. James Jeans contributed the important suggestion that stellar matter would certainly be ionized, but that was the end of any collaboration between the pair, who became famous for their lively debates.
Eddington defended his method by pointing to the utility of his results, particularly his important mass-luminosity relation. This had the unexpected result of showing that virtually all stars, including giants and dwarfs, behaved as ideal gases. In the process of developing his stellar models, he sought to overturn current thinking about the sources of stellar energy. Jeans and others defended the Kelvin–Helmholtz mechanism, which was based on classical mechanics, while Eddington speculated broadly about the qualitative and quantitative consequences of possible proton-electron annihilation and nuclear fusion processes.
With these assumptions, he demonstrated that the interior temperature of stars must be millions of degrees. In 1924, he discovered the mass-luminosity relation for stars (see Lecchini in #External links and references ). Despite some disagreement, Eddington's models were eventually accepted as a powerful tool for further investigation, particularly in issues of stellar evolution. The confirmation of his estimated stellar diameters by Michelson in 1920 proved crucial in convincing astronomers unused to Eddington's intuitive, exploratory style. Eddington's theory appeared in mature form in 1926 as "The Internal Constitution of the Stars", which became an important text for training an entire generation of astrophysicists.
Eddington's work in astrophysics in the late 1920s and the 1930s continued his work in stellar structure, and precipitated further clashes with Jeans and Edward Arthur Milne. An important topic was the extension of his models to take advantage of developments in quantum physics, including the use of degeneracy physics in describing dwarf stars.
Dispute with Chandrasekhar on existence of black holes.
The topic of extension of his models precipitated his famous dispute with Subrahmanyan Chandrasekhar, who was then a student at Cambridge. Chandrasekhar's work presaged the discovery of black holes, which at the time seemed so absurdly non-physical that Eddington refused to believe that Chandrasekhar's purely mathematical derivation had consequences for the real world. History clearly proved Eddington wrong, but his motivation remains a matter of some controversy. Chandrasekhar's narrative of this incident, in which his work is harshly rejected, portrays Eddington as rather cruel, dogmatic, and racist. This is at variance with Eddington's character as described by other contemporaries. Eddington's criticism seems to have been based on a suspicion that a purely mathematical derivation from relativity theory was not enough to explain away the seemingly daunting physical paradoxes that were inherent to degenerate stars.
Relativity.
During World War I, Eddington was Secretary of the Royal Astronomical Society, which meant he was the first to receive a series of letters and papers from Willem de Sitter regarding Einstein’s theory of general relativity. Eddington was fortunate in being not only one of the few astronomers with the mathematical skills to understand general relativity, but owing to his internationalist and pacifist views inspired by his Quaker religious beliefs, one of the few at the time who was still interested in pursuing a theory developed by a German physicist. He quickly became the chief supporter and expositor of relativity in Britain. He and Astronomer Royal Frank Watson Dyson organized two expeditions to observe a solar eclipse in 1919 to make the first empirical test of Einstein’s theory: the measurement of the deflection of light by the sun's gravitational field. In fact, Dyson’s argument for the indispensability of Eddington’s expertise in this test was what prevented Eddington from eventually having to enter military service.
When conscription was introduced in Britain on 2 March 1916, Eddington intended to apply for an exemption as a conscientious objector. Cambridge University authorities instead requested and were granted an exemption on the ground of Eddington's work being of national interest. In 1918, this was appealed against by the Ministry of National Service. Before the appeal tribunal in June, Eddington claimed conscientious objector status, which was not recognised and would have ended his exemption in August 1918. A further two hearings took place in June and July, respectively. Eddington's personal statement at the June hearing about his objection to war based on religious grounds is on record. Astronomer Royal, Sir Frank Dyson, supported Eddington at the July hearing with a written statement, emphasising Eddington's essential role in the solar eclipse expedition to Principe in May 1919. Eddington made clear his willingness to serve in the Friends' Ambulance Unit, the Red Cross, or as a harvest labourer. However, the tribunal's decision to grant a further twelve months exemption from military service was on condition of Eddington continuing his astronomy work, in particular in preparation for the Principe expedition. The war ended before the end of his exemption.
After the war, Eddington travelled to the island of Príncipe near Africa to watch the solar eclipse of 29 May 1919. During the eclipse, he took pictures of the stars in the region around the Sun. According to the theory of general relativity, stars with light rays that passed near the Sun would appear to have been slightly shifted because their light had been curved by its gravitational field. This effect is noticeable only during eclipses, since otherwise the Sun's brightness obscures the affected stars. Eddington showed that Newtonian gravitation could be interpreted to predict half the shift predicted by Einstein.
Eddington's observations published the next year confirmed Einstein's theory, and were hailed at the time as a conclusive proof of general relativity over the Newtonian model. The news was reported in newspapers all over the world as a major story. Afterward, Eddington embarked on a campaign to popularize relativity and the expedition as landmarks both in scientific development and international scientific relations.
It has been claimed that Eddington's observations were of poor quality, and he had unjustly discounted simultaneous observations at Sobral, Brazil, which appeared closer to the Newtonian model, but a 1979 re-analysis with modern measuring equipment and contemporary software validated Eddington's results and conclusions. The quality of the 1919 results was indeed poor compared to later observations, but was sufficient to persuade contemporary astronomers. The rejection of the results from the Brazil expedition was due to a defect in the telescopes used which, again, was completely accepted and well-understood by contemporary astronomers.
Throughout this period, Eddington lectured on relativity, and was particularly well known for his ability to explain the concepts in lay terms as well as scientific. He collected many of these into the "Mathematical Theory of Relativity" in 1923, which Albert Einstein suggested was "the finest presentation of the subject in any language." He was an early advocate of Einstein's General Relativity, and an interesting anecdote well illustrates his humour and personal intellectual investment: Ludwik Silberstein, a physicist who thought of himself as an expert on relativity, approached Eddington at the Royal Society's (6 November) 1919 meeting where he had defended Einstein's Relativity with his Brazil-Principe Solar Eclipse calculations with some degree of skepticism, and ruefully charged Arthur as one who claimed to be one of three men who actually understood the theory (Silberstein, of course, was including himself and Einstein as the other two). When Eddington refrained from replying, he insisted Arthur not be "so shy", whereupon Eddington replied, "Oh, no! I was wondering who the third one might be!"
Cosmology.
Eddington was also heavily involved with the development of the first generation of general relativistic cosmological models. He had been investigating the instability of the Einstein universe when he learned of both Lemaître's 1927 paper postulating an expanding or contracting universe and Hubble's work on the recession on the spiral nebulae. He felt the cosmological constant must have played the crucial role in the universe's evolution from an Einsteinian steady state to its current expanding state, and most of his cosmological investigations focused on the constant's significance and characteristics. In "The Mathematical Theory of Relativity," Eddington interpreted the cosmological constant to mean that the universe is "self-gauging".
Fundamental theory and the Eddington number.
During the 1920s until his death, he increasingly concentrated on what he called "fundamental theory" which was intended to be a unification of quantum theory, relativity, cosmology, and gravitation. At first he progressed along "traditional" lines, but turned increasingly to an almost numerological analysis of the dimensionless ratios of fundamental constants.
His basic approach was to combine several fundamental constants in order to produce a dimensionless number. In many cases these would result in numbers close to 1040, its square, or its square root. He was convinced that the mass of the proton and the charge of the electron were a "natural and complete specification for constructing a Universe" and that their values were not accidental. One of the discoverers of quantum mechanics, Paul Dirac, also pursued this line of investigation, which has become known as the Dirac large numbers hypothesis, and some scientists even today believe it has something to it.
A somewhat damaging statement in his defence of these concepts involved the fine structure constant, α. At the time it was measured to be very close to 1/136, and he argued that the value should in fact be exactly 1/136 for epistemological reasons. Later measurements placed the value much closer to 1/137, at which point he switched his line of reasoning to argue that one more should be added to the degrees of freedom, so that the value should in fact be exactly 1/137, the Eddington number. Wags at the time started calling him "Arthur Adding-one". This change of stance detracted from Eddington's credibility in the physics community. The is estimated at 1/137.035 999 074(44).
Eddington believed he had identified an algebraic basis for fundamental physics, which he termed "E-numbers" (representing a certain group – a Clifford algebra). These in effect incorporated spacetime into a higher-dimensional structure. While his theory has long been neglected by the general physics community, similar algebraic notions underlie many modern attempts at a grand unified theory. Moreover, Eddington's emphasis on the values of the fundamental constants, and specifically upon dimensionless numbers derived from them, is nowadays a central concern of physics. In particular, he predicted a number of hydrogen atoms in the Universe 136 x 2256, or equivalently the half of the total number of particles protons + electrons. When equalized with the non-dark energy equivalent number of hydrogen atoms (3/10) x Rc2/GmH, this corresponds to a Universe radius R = 13.8 Giga light year, a value predicted for years from universal constants using an atomic-cosmic symmetry, and compatible with c-times the so-called Universe age 13.80(4) Gyr, as determined by the recent mission Planck (March 2003).
He did not complete this line of research before his death in 1944; his book "Fundamental Theory" was published posthumously in 1948.
Eddington number for cycling.
Eddington is credited with devising a measure of a cyclist's long-distance riding achievements. The Eddington number in the context of cycling is defined as the maximum number E such that the cyclist has cycled E miles on E days. For example an Eddington number of 70 would imply that the cyclist has cycled at least 70 miles in a day on 70 occasions. Achieving a high Eddington number is difficult since moving from, say, 70 to 75 will probably require more than five new long distance rides since any rides shorter than 75 miles will no longer be included in the reckoning. Eddington's own E-number was 84.
The Eddington number for cycling is analogous to the "h"-index that quantifies both the actual scientific productivity and the apparent scientific impact of a scientist.
Philosophy.
Idealism.
Sir Arthur Eddington wrote in his book "The Nature of the Physical World" that "The stuff of the world is mind-stuff."
The mind-stuff of the world is, of course, something more general than our individual conscious minds... The mind-stuff is not spread in space and time; these are part of the cyclic scheme ultimately derived out of it... It is necessary to keep reminding ourselves that all knowledge of our environment from which the world of physics is constructed, has entered in the form of messages transmitted along the nerves to the seat of consciousness... Consciousness is not sharply defined, but fades into subconsciousness; and beyond that we must postulate something indefinite but yet continuous with our mental nature... It is difficult for the matter-of-fact physicist to accept the view that the substratum of everything is of mental character. But no one can deny that mind is the first and most direct thing in our experience, and all else is remote inference."—Eddington, "The Nature of the Physical World", 276-81.
The idealist conclusion was not integral to his epistemology but was based on two main arguments.
The first derives directly from current physical theory. Briefly, mechanical theories of the ether and of the behavior of fundamental particles have been discarded in both relativity and quantum physics. From this, Eddington inferred that a materialistic metaphysics was outmoded and that, in consequence, since the disjunction of materialism or idealism are assumed to be exhaustive, an idealistic metaphysics is required. The second, and more interesting argument, was based on Eddington's epistemology, and may be regarded as consisting of two parts. First, all we know of the objective world is its structure, and the structure of the objective world is precisely mirrored in our own consciousness. We therefore have no reason to doubt that the objective world too is "mind-stuff." Dualistic metaphysics, then, cannot be evidentially supported.
But, second, not only can we not know that the objective world is nonmentalistic, we also cannot intelligibly suppose that it could be material. To conceive of a dualism entails attributing material properties to the objective world. However, this presupposes that we could observe that the objective world has material properties. But this is absurd, for whatever is observed must ultimately be the content of our own consciousness, and consequently, nonmaterial.
Ian Barbour, in his book Issues in Science and Religion (1966), p. 133, cites Arthur Eddington's The Nature of the Physical World (1928) for a text that argues The Heisenberg Uncertainty Principles provides a scientific basis for "the defense of the idea of human freedom" and his Science and the Unseen World (1929) for support of philosophical idealism "the thesis that reality is basically mental".
Charles De Koninck points out that Eddington believed in objective reality existing apart from our minds, but was using the phrase "mind-stuff" to highlight the inherent intelligibility of the world: that our minds and the physical world are made of the same "stuff" and that our minds are the inescapable connection to the world. As De Koninck quotes Eddington,
There is a doctrine well known to philosophers that the moon ceases to exist when no one is looking at it. I will not discuss the doctrine since I have not the least idea what is the meaning of the word existence when used in this connection. At any rate the science of astronomy has not been based on this spasmodic kind of moon. In the scientific world (which has to fulfill functions less vague than merely existing) there is a moon which appeared on the scene before the astronomer; it reflects sunlight when no one sees it; it has mass when no one is measuring the mass; it is distant 240,000 miles from the earth when no one is surveying the distance; and it will eclipse the sun in 1999 even if the human race has succeeded in killing itself off before that date.—Eddington, "The Nature of the Physical World", 226
Indeterminism.
Against Albert Einstein and others who advocated determinism, indeterminism—championed by Eddington—says that a physical object has an ontologically undetermined component that is not due to the epistemological limitations of physicists' understanding. The uncertainty principle in quantum mechanics, then, would not necessarily be due to hidden variables but to an indeterminism in nature itself.
Popular and philosophical writings.
Eddington wrote a clever parody of "The Rubaiyat of Omar Khayyam", recounting his 1919 solar eclipse experiment. It contained the following quatrain:
 <poem>
Oh leave the Wise our measures to collate
 One thing at least is certain, LIGHT has WEIGHT,
One thing is certain, and the rest debate —
Light-rays, when near the Sun, DO NOT GO STRAIGHT.</poem>
During the 1920s and 30s, Eddington gave innumerable lectures, interviews, and radio broadcasts on relativity, in addition to his textbook "The Mathematical Theory of Relativity", and later, quantum mechanics. Many of these were gathered into books, including "The Nature of the Physical World" and "New Pathways in Science". His skillful use of literary allusions and humor helped make these famously difficult subjects quite accessible.
Eddington's books and lectures were immensely popular with the public, not only because of Eddington’s clear and entertaining exposition, but also for his willingness to discuss the philosophical and religious implications of the new physics. He argued for a deeply rooted philosophical harmony between scientific investigation and religious mysticism, and also that the positivist nature of modern physics (i.e., relativity and quantum physics) provided new room for personal religious experience and free will. Unlike many other spiritual scientists, he rejected the idea that science could provide proof of religious propositions. 
He is sometimes misunderstood as having promoted the infinite monkey theorem in his 1928 book "The Nature of the Physical World", with the phrase "If an army of monkeys were strumming on typewriters, they might write all the books in the British Museum". It is clear from the context that Eddington is not suggesting that the probability of this happening is worthy of serious consideration. On the contrary, it was a rhetorical illustration of the fact that below certain levels of probability, the term "improbable" is functionally equivalent to "impossible".
His popular writings made him, quite literally, a household name in Great Britain between the world wars.

</doc>
<doc id="2275" url="http://en.wikipedia.org/wiki?curid=2275" title="Apple II">
Apple II

The Apple II (styled as apple ][) is an 8-bit home computer, one of the first highly successful mass-produced microcomputer products, designed primarily by Steve Wozniak (Steve Jobs oversaw the development of the Apple II's unusual case and Rod Holt developed the unique power supply). It was introduced in 1977 at the West Coast Computer Faire by Jobs and was the first consumer product sold by Apple Computer. It is the first model in a series of computers which were produced until Apple IIe production ceased in November 1993.
History.
The earliest Apple IIs were assembled in Silicon Valley, and later in Texas; printed circuit boards were manufactured in Ireland and Singapore. The first computers went on sale on June 10, 1977 with a MOS Technology 6502 microprocessor running at 1.023 MHz, two game paddles, 4 kB of RAM, an audio cassette interface for loading programs and storing data, and the Integer BASIC programming language built into the ROMs. The video controller displays 24 lines by 40 columns of monochrome, upper-case-only (the original character set matches ASCII characters 20h to 5Fh) text on the screen, with NTSC composite video output suitable for display on a TV monitor, or on a regular TV set by way of a separate RF modulator. The original retail price of the computer was $1,298 USD (with 4 kB of RAM) and $2,638 USD (with the maximum 48 kB of RAM). To reflect the computer's color graphics capability, the Apple logo on the casing has rainbow stripes, which remained a part of Apple's corporate logo until early 1998.
Overview.
In the May 1977 "BYTE", Steve Wozniak published a detailed description of his design; the article began, "To me, a personal computer should be small, reliable, convenient to use and inexpensive".
The Apple II at first used data cassette storage like most other microcomputers of the time. In 1978 the company introduced an external 5¼-inch floppy disk drive, the Disk II, attached via a controller card that plugs into one of the computer's expansion slots (usually slot 6). The Disk II interface, created by Wozniak, is regarded as an engineering masterpiece for its economy of electronic components.
The approach taken in the Disk II controller is typical of Wozniak's designs. The Apple II uses several engineering shortcuts to save hardware and reduce costs. For example, taking advantage of the way that 6502 instructions only access memory every other clock cycle, the video generation circuitry's memory access on the otherwise unused cycles avoids memory contention issues and also eliminates the need for a separate refresh circuit for the DRAM chips. Rather than use a complex analog-to-digital circuit to read the outputs of the game controller, Wozniak used a simple timer circuit whose period is proportional to the resistance of the game controller, and used a software loop to measure the timer.
The text and graphics screens have a complex arrangement (the scanlines were not stored in sequential areas of memory) which is reputedly due to Wozniak's realization that doing it that way would save a chip; it was less expensive to have software calculate or look up the address of the required scanline than to include the extra hardware. Similarly, in the high-resolution graphics mode, color is determined by pixel position and can thus be implemented in software, saving Wozniak the chips needed to convert bit patterns to colors. This also allows for subpixel font rendering since orange and blue pixels appear half a pixel-width farther to the right on the screen than green and purple pixels.
Display and graphics.
Color on the Apple II series uses a quirk of the NTSC television signal standard, which made color display relatively easy and inexpensive to implement. The original NTSC television signal specification was black-and-white. Color was added on later by adding a 3.58-MHz subcarrier signal that was partially ignored by B&W TV sets. Color is encoded based on the "phase" of this signal in relation to a reference "color burst" signal. The result is that the position, size, and intensity of a series of pulses define color information. These pulses can translate into "pixels" on the computer screen, with the possibility of exploiting composite artifact colors.
The Apple II display provides two pixels per subcarrier cycle. When the color burst reference signal is turned on and the computer attached to a color display, it can display green by showing one alternating pattern of pixels, magenta with an opposite pattern of alternating pixels, and white by placing two pixels next to each other. Blue and orange are available by tweaking the offset of the pixels by half a pixel-width in relation to the color-burst signal. The high-resolution display offers more colors by compressing more, narrower pixels into each subcarrier cycle.
The coarse, low-resolution graphics display mode works differently, as it can output a pattern of dots per pixel to offer more color options. These patterns are stored in the character generator ROM and replace the text character bit patterns when the computer is switched to low-res graphics mode. The text mode and low-res graphics mode use the same memory region and the same circuitry is used for both.
Sound.
Rather than having a dedicated sound-synthesis chip, the Apple II has a toggle circuit that can only emit a click through a built-in speaker or a line out jack; all other sounds (including two, three and, eventually, four-voice music and playback of audio samples and speech synthesis) are generated entirely by software that clicked the speaker at just the right times. Similar techniques are used for cassette storage: the cassette output works the same as the speaker, and the input is a simple zero-crossing detector that serves as a relatively crude (1-bit) audio digitizer. Routines in the ROM encode and decode data in frequency-shift keying for the cassette.
Third-party devices and applications.
Wozniak's open design and the Apple II's multiple expansion slots permit a wide variety of third-party devices, including peripheral cards such as serial controllers, display controllers, memory boards, hard disks, networking components, and realtime clocks. There are plug-in expansion cards – such as the Z-80 SoftCard – that permit the Apple to use the Z80 processor and run programs for the CP/M operating system, including the dBase II database and the WordStar word processor. There is also a third-party 6809 card that allows OS-9 Level One to be run. Third-party sound cards greatly improve audio capabilities, allowing simple music synthesis and text-to-speech functions. Apple II accelerator cards double or quadruple the computer's speed.
Reception.
After seeing a crude, wire-wrapped prototype demonstrated by Steve Wozniak and Steve Jobs in November 1976, "BYTE" predicted in April 1977 that the Apple II "may be the first product to fully qualify as the 'appliance computer' ... a completed system which is purchased off the retail shelf, taken home, plugged in and used". The computer's color graphics capability especially impressed the magazine. The magazine published a favorable review of the computer in March 1978, concluding that "For the user that wants color graphics, the Apple II is the only practical choice available in the 'appliance' computer class".
"Personal Computer World" in August 1978 also cited the color capability as a strength, stating that "the prime reason that anyone buys an Apple II must surely be for the colour graphics". While mentioning the "oddity" of the artifact colors that produced output "that is not always what one wishes to do", it noted that "no-one has colour graphics like this at this sort of price". The magazine praised the sophisticated monitor software, user expandability, and comprehensive documentation, and concluded that "the Apple II is a very promising machine" which "would be even more of a temptation were its price slightly lower ... for the moment, colour is an Apple II".

</doc>
<doc id="2279" url="http://en.wikipedia.org/wiki?curid=2279" title="April 3">
April 3

April 3 is the day of the year in the Gregorian calendar.

</doc>
<doc id="2282" url="http://en.wikipedia.org/wiki?curid=2282" title="Alexis Korner">
Alexis Korner

Alexis Korner (19 April 1928 – 1 January 1984) was a British blues musician and radio broadcaster, who has sometimes been referred to as "a founding father of British blues". A major influence on the sound of the British music scene in the 1960s, Korner was instrumental in bringing together various English blues musicians.
Early career.
Alexis Andrew Nicholas Koerner was born in Paris to an Austrian Jewish father and a Turkish-Greek mother. He spent his childhood in France, Switzerland and North Africa and arrived in London in 1940 at the start of World War II. One memory of his youth was listening to a record by black pianist Jimmy Yancey during a German air raid. Korner said, "From then on all I wanted to do was play the blues."
After the war, Korner played piano and guitar (his first guitar was built by friend and author Sydney Hopkins, who wrote "Mister God, This Is Anna") and in 1949 joined Chris Barber's Jazz Band where he met blues harmonica player Cyril Davies. They started playing together as a duo, started the influential London Blues and Barrelhouse Club in 1955 and made their first record together in 1957. Korner made his first official record on Decca Records DFE 6286 in the company of Ken Colyer's Skiffle Group. His talent extended to playing mandolin on one of the tracks of this rare British EP, recorded in London on 28 July 1955. Korner brought many American blues artists, previously virtually unknown in Britain, to perform.
The 1960s.
In 1961, Korner and Davies formed Blues Incorporated, initially a loose-knit group of musicians with a shared love of electric blues and R&B music. The group included, at various times, such influential musicians as Charlie Watts, Jack Bruce, Ginger Baker, Long John Baldry, Graham Bond, Danny Thompson and Dick Heckstall-Smith. It also attracted a wider crowd of mostly younger fans, some of whom occasionally performed with the group, including Mick Jagger, Keith Richards, Brian Jones, Geoff Bradford, Rod Stewart, John Mayall and Jimmy Page.
One story is that the Rolling Stones went to stay at Korner's house late one night, in the early 1960s, after a performance. They entered in the accepted way, by climbing in through the kitchen window, to find Muddy Waters' band sleeping on the kitchen floor.
Although Cyril Davies left the group in late-1962, Blues Incorporated continued to record, with Korner at the helm, until 1966. However, by that time its originally stellar line-up (and crowd of followers) had mostly left to start their own bands. "While his one-time acolytes the Rolling Stones and Cream made the front pages of music magazines all over the world, Korner was relegated to the role of 'elder statesman'."
Although he himself was a blues purist, Korner criticised better-known British blues musicians during the blues boom of the late 1960s for their blind adherence to Chicago blues, as if the music came in no other form. He liked to surround himself with jazz musicians and often performed with a horn section drawn from a pool that included, among others, saxophone players Art Themen, Mel Collins, Dick Heckstall-Smith, Lol Coxhill, Dick Morrissey, John Surman and trombonist Mike Zwerin.
Broadcasting.
In the 1960s Korner began a media career, working initially as a show business interviewer and then on ITV's "Five O'Clock Club", a children's TV show. Korner also wrote about blues for the music papers, and continued to maintain his own career as a blues artist, especially in Europe.
On 17 October 1967, Korner interviewed the Jimi Hendrix Experience for the BBC radio show"Top Gear". Some of these tracks, including audio of Korner himself, appear on the Hendrix double-CD "BBC Sessions", including Korner playing slide guitar on "(I'm Your) Hoochie Coochie Man".
While touring Scandinavia he first joined forces with guitarist and singer Peter Thorup, together forming the band New Church, who were one of the support bands at the Rolling Stones Free Concert in Hyde Park, London, on 5 July 1969. Jimmy Page reportedly found out about a new singer, Robert Plant, who had been jamming with Korner, who wondered why Plant had not yet been discovered. Plant and Korner were in the process of recording a full album with Plant on vocals until Page had asked him to join "the New Yardbirds", a.k.a. Led Zeppelin. Only two songs are in circulation from these recordings: "Steal Away" and "Operator". Alexis Korner gave one of his last radio interviews to BBC Midlands on the "Record Collectors Show" with Mike Adams and the Late Chris Savory.
1970s.
In 1970 Korner and Thorup formed a big-band ensemble, C.C.S. – short for "The Collective Consciousness Society" – which had several hit singles produced by Mickie Most, including a version of Led Zeppelin's "Whole Lotta Love", which was used as the theme for BBC's "Top of the Pops" between 1971 and 1981. Another instrumental called "Brother" was used as the theme to the BBC Radio 1 Top 20/40 when Tom Browne/Simon Bates presented the programme in the 1970s. It was also used in the 1990s on Radio Luxembourg for the Top 20 Singles chart and was hosted by Shaun Tilley. This was the period of Korner's greatest commercial success in the UK.
1970s to 1984.
In 1973, he formed another group, Snape, with Boz Burrell, Mel Collins, and Ian Wallace, who were previously together in King Crimson. Korner also played on B.B. King's "In London" album, and cut his own, similar "supersession" album; "Get Off My Cloud", with Keith Richards, Steve Marriott,Peter Frampton, Nicky Hopkins and members of Joe Cocker's Grease Band. In the mid-1970s, while touring Germany, Korner established an intensive working relationship with bassist Colin Hodgkinson who played for the support act Back Door. They would continue to collaborate right up until Korner's death.
In the 1970s Korner's main career was in broadcasting. In 1973 he presented a unique 6-part documentary on BBC Radio 1, "The Rolling Stones Story", and in 1977 he established a Sunday-night blues and soul show on Radio 1, "Alexis Korner's Blues and Soul Show", which ran until 1981. He also used his gravelly voice to great effect as an advertising voice-over artist. In 1978, for Korner's 50th birthday, an all-star concert was held featuring many of his above-mentioned friends, as well as Eric Clapton, Paul Jones, Chris Farlowe, Zoot Money and others, which was later released as "The Party Album", and as a video.
In 1981, Korner joined another "supergroup", Rocket 88, a project led by Ian Stewart based on boogie-woogie keyboard players, which featured a rhythm section comprising Jack Bruce and Charlie Watts, among others, as well as a horn section. They toured Europe and released an album on Atlantic Records. He played in Italy with Paul Jones and the Blues Society of Italian bluesman Guido Toffoletti.
Family life and death.
In 1950, Korner married Roberta Melville, daughter of art critic Robert Melville. A chain smoker, on 1 January 1984 aged 55, Korner died of lung cancer in Westminster Hospital, London. He was survived by a daughter, singer Sappho Gillett Korner (died 2006) and two sons, guitarist Nicholas 'Nico' Korner (died 1988) and sound engineer Damian Korner (died 2010).

</doc>
<doc id="2284" url="http://en.wikipedia.org/wiki?curid=2284" title="Assault gun">
Assault gun

An assault gun is a gun or howitzer mounted on a motor vehicle or armored chassis, designed for use in the direct fire role in support of infantry when attacking other infantry or fortified positions. The term is a literal translation of the German word "Sturmgeschütz". Germany introduced the first purpose-built assault gun, the StuG III, in the late 1930s thus establishing this category of armoured vehicles.
Historically, the custom-built fully armored assault guns usually mounted the gun or howitzer in a fully enclosed casemate on a tank chassis. The use of a casemate instead of a turret limited these weapons' field of fire, but allowed a larger gun to be fitted relative to the chassis, more armor to be fitted for the same weight, and provided a cheaper construction. In most cases, these turretless vehicles also presented a lower profile as a target for the enemy.
The assault gun looks and works in the same way as the similar tank destroyer, the only difference in most cases being the gun. Assault guns generally used larger calibre, lower velocity guns, with their primary ammunition being that of high-explosive shells; these were meant for taking out soft targets as outlined in its infantry support role. This was contrasted with the tank destroyer, which utilized higher velocity, and therefore oftentimes smaller calibre guns, firing armour-piercing shells as their primary ammunition. These vehicles thus oftentimes sacrificed being able to fire a good high explosive shell in exchange for maximal armour penetration characteristics. Towards the beginning of the war, a single vehicle could generally be used in both roles, but that changed as the classes became increasingly specialized as the war progressed.
History.
World War II.
Assault guns were primarily used during World War II by the forces of Nazi Germany and the Soviet Union. Early in the war, the Germans began to create makeshift assault guns by mounting their infantry support weapons on the bed of a truck or on obsolete tanks with the turret removed. Later in the war, both the Germans and the Soviets introduced fully armored purpose-built assault guns into their arsenals.
Early on, the Soviets built the KV-2, a variant of the KV-1 heavy tank with a short-barreled 152 mm howitzer mounted in an oversized turret. This was not a success in battle, and was replaced with a very successful series of increasingly powerful turretless assault guns: the SU-76, SU-122, and the heavy SU-152, which were followed by the ISU-122 and ISU-152 on the new IS heavy tank chassis.
The primary German assault gun was the Sturmgeschütz III (StuG III). Late production StuG III variants, armed with a high-velocity dual-purpose 75mm gun blurred the line between assault guns and tank destroyers and was the Wehrmacht's most-produced armored fighting vehicle, at some 9,400 examples. The Germans also built a number of other fully armored turretless assault guns, including the StuG IV, Brummbär and Sturmtiger. The latter two were very heavy vehicles and were built only in small quantities.
Battalions of assault guns, usually StuG IIIs, commonly replaced the intended panzer battalion in the German panzergrenadier divisions due to the chronic shortage of tanks, and were sometimes used as makeshifts even in the panzer divisions. Independent battalions were also deployed as 'stiffeners' for infantry divisions, and the StuG III's anti-tank capabilities bolstered dwindling tank numbers on the Eastern and Western fronts.
American and British forces also deployed vehicles designed for a close support role, but these were conventional tanks whose only significant modification was the replacement of the main gun with a howitzer. Two versions of the American Sherman tank were armed with the M4 105 mm howitzer, the M4(105) and the M4A3(105). The Churchill, Centaur and Cromwell tanks were all produced in versions armed with 95 mm howitzers: the Churchill Mark V and Mark VIII, the Centaur Mark IV and the Cromwell Mark VI. Earlier British tanks, such as the Crusader cruiser tank and the Matilda II Infantry tank were produced in versions armed with the 3-inch howitzer, the first versions of the Churchill tank also had this gun in a hull mounting. As the amount of German armour encountered by the Allies decreased, especially in Italy, a number of American tank destroyer units were used in the assault gun role for infantry support.
The AVRE version of the Churchill Tank was armed with a Spigot mortar that fired a 40 lb HE-filled projectile (nicknamed the "Flying Dustbin") 150 yd. Its task was to attack fortified positions such as bunkers at close range (see Hobart's Funnies).
Postwar use.
In the post-WWII era, vehicles fitting into an "assault gun" category were developed as a light-weight, air-deployable, direct fire weapon for use with airborne troops. Current weapons were either based on jeeps or small tracked vehicles and the airborne troops thus always fought at a distinct disadvantage in terms of heavy weapons. The Soviet Union and the United States were the most attracted to the idea of providing this capability to traditionally light airborne forces. Their answers to the problem were similar, with the United States developing the M56 Scorpion and the Soviet Union developing the ASU-57, both essentially air-droppable light anti-tank guns.
The Soviets went on to develop an improved air-droppable assault gun, the ASU-85, which served through the 1980s, while their SU-100 remained in service with Communist countries, including Vietnam and Cuba, years after WW2. The US M56 and another armored vehicle, the M50 Ontos, were to be the last of the more traditional assault guns in US service. Improvised arrangements such as M113 personnel carriers with recoilless rifles were quickly replaced by missile carrier vehicles in the anti-tank role.
The only vehicle with the qualities of an assault gun to be fielded after the removal of the M50 and M56 from service within the US military was the M551 Sheridan. The Sheridan's gun was a low-velocity weapon suitable in the assault role, but with the addition of the Shillelagh missile could double in the anti-tank role as well. The Sheridan, however, was not developed as an assault gun but as a light reconnaissance vehicle.
Currently there appears to be a move toward wheeled vehicles fitting a "tank destroyer" or "assault gun" role, such as the M1128 Mobile Gun System of the US Army, the Centauro Wheeled Tank Destroyer of the Italian and Spanish Armies, the Chinese anti-tank gun PTL-02 and the French AMX 10 RC heavy armored car. While these vehicles might be useful in a direct fire role, none were developed with this specifically in mind, reminiscent of the use of tank destroyers by the US military in the assault gun role during WWII.

</doc>
<doc id="2286" url="http://en.wikipedia.org/wiki?curid=2286" title="Tank destroyer">
Tank destroyer

A tank destroyer or tank hunter is a type of armoured fighting vehicle armed with a gun or missile launcher, and is designed specifically to engage enemy armoured vehicles. Tanks are generally armoured fighting vehicles designed for front-line combat which combines operational mobility and tactical offensive and defensive capabilities and perform all primary tasks of the armoured troops on the battlefield; the tank destroyer on the other hand is specifically designed mainly for taking on enemy armour. Many have been based on a tracked tank chassis, while others are wheeled.
Since World War II, gun-armed tank destroyers have fallen out of favor as armies have favored multirole main battle tanks. However, lightly armored anti tank guided missile (ATGM) carriers are commonly used for supplementary long-range anti-tank work. The resurgence of expeditionary warfare in the past twenty years has seen the emergence of gun-armed wheeled vehicles, sometimes called "protected gun systems", which may bear a superficial resemblance to tank destroyers, but are employed as direct fire support units typically providing support in low-intensity operations such as the wars in Iraq and Afghanistan.
World War II.
Dedicated anti-tank vehicles made their first major appearance in the Second World War as combatants developed effective armored vehicles and tactics. Some were little more than stopgap solutions, mounting an anti-tank gun on a tracked vehicle to give mobility, while others were more sophisticated designs. An example of the development of tank destroyer technology throughout the war are the Marder III and Hetzer vehicle, that were very different in spite of being based on the same chassis: Marder was straightforwardly an anti-tank gun on tracks whereas Hetzer traded some firepower (its Pak 39, designed to operate within the confines of a fully armored fighting compartment, fires the same projectiles from a reduced propellant charge compared to Marder's Pak 40) for better armor protection and ease of concealment on the battlefield. 
Except for most American designs, tank destroyers were all turretless and had fixed or casemate superstructures. When a tank destroyer was used against enemy tanks from a defensive position such as by ambush, the common lack of a rotating turret was not particularly critical, while the lower silhouette was highly desirable. The turretless design allowed accommodation of a more powerful gun, typically a dedicated anti-tank gun (in lieu of a regular tank's general-purpose main gun that fired both anti-tank and high explosive ammunition) that had a longer barrel than could be mounted in a turreted tank on the same chassis. The lack of a turret increased the vehicle's internal volume, allowing for increased ammunition stowage and crew comfort. Eliminating the turret allowed the vehicle to carry thicker armor than would otherwise be the case, and also allowed this armour to be concentrated in the hull. Sometimes there was no armored roof (only a weather cover) to keep the overall weight down to the limit that the chassis could bear. The absence of a turret meant that tank destroyers could be manufactured significantly cheaper, faster and more easily than the tanks on which they were based and found particular favor when production resources were lacking. After hard lessons early in the war, machine guns were mounted for use against infantry, but the limited traverse of the mounting meant that they were still less effective than those used on turreted tanks.
Polish.
Variants of the Polish TKS and TK-3 tankettes up-armed with 20 mm gun (23–26 vehicles) were operationally deployed in the invasion of Poland. They were used as an anti-tank component of the reconnaissance units.
German.
The first German tank destroyers were the "Panzerjäger" ("tank hunters") which took an existing anti-tank gun and mounted it on a convenient chassis to give mobility, usually with just a three-sided gun shield for crew protection. For instance, 202 obsolete Panzer I light tanks were modified by removing the turret and were rebuilt as the Panzerjäger I self-propelled Skoda 47 mm anti-tank gun. Similarly, Panzer II tanks were used on the eastern front. Captured Soviet 76.2 mm anti-tank guns were mounted on modified Panzer II chassis, producing the Marder II self-propelled anti-tank gun. The most common mounting was a German 75 mm anti-tank gun on the Czech Panzer 38(t) chassis to produce the Marder III. The Panzer 38(t) chassis was also used to make the Jagdpanzer 38 'Hetzer' casemate style tank destroyer. The Panzerjäger series continued up to the 88 mm equipped Nashorn. 
German tank destroyers based on the Panzer III and later German tanks were unique in that they had more armor than their tank counterparts. One of the more successful German tank destroyers was actually designed as a self-propelled artillery gun, the Sturmgeschütz III. Based on the Panzer III tank chassis, the Sturmgeschütz III was originally fitted with a low-velocity gun, and was assigned to the artillery arm for infantry fire support. Later, after encountering Soviet tanks, it was refitted with a comparatively short-barreled high-velocity anti-tank gun, usually with a muzzle brake, enabling it to function as a tank destroyer. The "Sturmgeschütz III" from its 1938 origin used a new casemate-style superstructure with an integrated design similar to the later "Jagdpanzer" to completely enclose the crew. It was employed in infantry support and offensive armored operations as well as in the defensive anti-tank role. The StuG III was the most-produced German armored fighting vehicle of any type built during the war years, with some 10,000 examples built from January 1940 through March 1945. 
Although the early German "Panzerjäger" carried more effective weapons than the tanks on which they were based, they were generally lacking in protection for the crew, having thinly armored open-topped superstructures. The "open-topped" design format of the "Panzerjäger" vehicles was succeeded by the "Jagdpanzer" '("hunting tanks") which mounted the gun in true casemate-style superstructures, completely enclosing the crew compartment in armor that would usually be integral to the hull. The first of these "Jagdpanzer"s was the "Ferdinand" (later renamed the "Elefant"), a 70-ton monster built from the already-built quantity of ninety-one Porsche VK4501(P)-based Tiger I losing contract contender's hulls and drive systems, mounting a long-barreled 88 mm cannon in an added casemate, more like the earlier "Panzerjägers" had with their added-on armor shielding for the guncrew, but in the "Elefant" completely enclosing the gun and firing crew in the added casemate, as the later purpose-built "Jagdpanzers" would. However, the "Elefant" proved to be mechanically unreliable and difficult to maneuver, and once all ninety-one unturreted "Porsche Tiger" hulls/drive systems were converted, no more were built. The German Army had more success with the Jagdpanther. Introduced in mid-1944, the Jagdpanther was considered the best of the casemate-design Jagdpanzer designs. It featured the same powerful PaK 43 88mm cannon used on the unwieldy "Elefant", now fitted to the chassis of the medium Panther tank, providing greatly improved armor-penetrating capability in a medium-weight vehicle. 
Facing an increasingly defensive war, the German Army turned to larger and more powerfully armed Jagdpanzer designs, and in July 1944 the first "Jagdtiger" rolled off the production line; the heaviest German armored fighting vehicle to go into active service. The "Jagdtiger" featured a huge 128 mm PaK 44 cannon and heavy armor protection. Only 88 "Jagdtiger" vehicles were produced, barely matching the total number of the earlier Ferdinand/Elefant vehicles. They were first deployed to combat units in September 1944. 
The decision of German armored vehicle designers to use a casemate-style superstructure for all tank destroyers had the advantage of a reduced silhouette, allowing the crew to more frequently fire from defilade ambush positions. Such designs were also easier and faster to manufacture and offered good crew protection from artillery fire and shell splinters. However, the lack of a rotating turret limited the gun's traverse to a few degrees. This meant that the entire tank normally had to be turned onto its target by the driver, a much slower process than simply rotating a powered turret. If the vehicle became immobilized due to engine failure or track damage, it could not rotate its gun to counter opposing tanks, making it highly vulnerable to counterfire. This vulnerability was later exploited by opposing tank forces. Even the largest and most powerful of German tank destroyers were found abandoned on the field after a battle, having been immobilized by one or more hits by high explosive (HE) or armor-piercing (AP) shells to the track or front drive sprocket.
Soviet.
As with the Germans, most of the Soviet designs mounted anti-tank guns, with limited traverse in casemate-style turretless hulls, in a general design format looking much like the Germans' own "Jagdpanzer" vehicles. The results were smaller, lighter, and simpler to build than tanks, but could carry larger guns. The Soviets produced the 85 mm SU-85 and 100 mm SU-100 self-propelled guns based on the same chassis as the T-34 medium tank, as well as the 122 mm ISU-122 and 152 mm ISU-152 which shared components with the IS-2 heavy tank and was nicknamed "Zveroboy" ("beast killer") for its ability to destroy German Tigers, Panthers and Elefants. The predecessor of the ISU 152 was the SU 152, built on the KV1S chassis and shared many similarities (incl. its gun) with the ISU 152. The ISU-152 built as a heavy assault gun, relied on the weight of the shell fired from its M-1937/43 howitzer to defeat tanks. In 1943, the Soviets also shifted all production of light tanks like the T-70 to much simpler and better-armed SU-76 self-propelled guns, which used the same drive train. The SU-76 was originally designed as an anti-tank vehicle, but was soon relegated to the infantry-support role.
American.
U.S. Army and counterpart British designs were very different in conception. U.S. doctrine was based, in light of the fall of France, on the perceived need to defeat German blitzkrieg tactics, and U.S. units expected to be faced with large numbers of German tanks attacking on relatively narrow fronts. These were "expected" to break through a thin screen of anti-tank guns, hence the decision that the main anti-tank units – the Tank Destroyer (TD) battalions – should be concentrated and very mobile. In actual practice, such German attacks rarely happened; throughout the war only one battalion ever fought in an engagement quite like that which had originally been envisaged (the 601st, at the Battle of El Guettar). The Tank Destroyer Command eventually numbered over 100,000 men and 80 battalions each equipped with 36 self-propelled tank destroyers or towed guns.
Only a few shots were expected to be fired from any firing position. Strong reconnaissance elements were provided so that TDs would be able to use pre-arranged firing positions to best advantage. Flanking fire by TDs was emphasized, both to penetrate thinner enemy side armor, and to reduce the likelihood of accurate enemy return fire.
All American tank destroyers were officially known by exactly the same collective term used for American self-propelled artillery ordnance, "Gun Motor Carriage". The designs were intended to be very mobile and heavily armed. Most of the tank-hull based designs used special open-topped turrets, of a differing design to the original tank it was to be based on, which was meant to both save weight and to accommodate a larger gun. The earliest expedient design was an M3 Half-track mounting an M1897 75 mm gun in a limited-traverse mount, and called the 75 mm Gun Motor Carriage M3. Another, considerably less successful, early design mounted a 37-mm anti-tank gun in the bed of a Dodge 3/4-ton truck - the 37-mm GMC M6. By far the most common US design was the 3in Gun Motor Carriage M10 (Wolverine), later supplemented by the 90 mm Gun Motor Carriage M36 - both based on the M4 Sherman hull and powertrain - and the 76 mm Gun Motor Carriage M18 (Hellcat), based on a unique hull and powertrain design, with a slight visual resemblance to what was used for the later M24 Chaffee light tank. The M18 came closest to the US ideal; the vehicle was very fast, small, and mounted a 76 mm gun in a roofless open turret. The M36 Jackson GMC possessed the only American-origin operational gun that could rival the vaunted 88 mm German anti-tank ordnance, the 90 mm M3 gun, and the M36 remained in service well after World War II. The only dedicated American-origin, casemate hull design fighting vehicle of any type to be built during the war, that resembled the German and Soviet tank destroyers in hull and general gun mounting design, was the experimental T28 Super Heavy Tank, which mounted a 105 mm T5E1 long-barrel cannon, which had a maximum firing range of 12 miles (20 km), and was originally designed as a self-propelled assault gun to breach Germany's Siegfried Line defenses. 
Of these tank destroyers, only the 90 mm gun of the M36 proved to be effective against the frontal armor of Germans' larger armored vehicles at long range. The open top and light armor made these tank destroyers vulnerable to anything greater than small-arms fire. As the number of German tanks encountered by American forces steadily decreased throughout the war, most battalions were split up and assigned to infantry units as supporting arms, fighting as assault guns or being used essentially as tanks.
Doctrinists' expectation that German tanks would be engaged in mass formation was a failed assumption. In reality, German attacks effectively utilized combined arms on the ground fighting cohesively. American tank destroyer battalions comprised three tank destroyer companies supported by nine security sections. The single-purpose tactics of the tank destroyer battalion failed to account for non-tank threats.
British.
British tanks in the early years of the war, both infantry and cruiser, were (with the exception of the pre-war Matilda I design), equipped with a gun intended to and capable of use against enemy tanks - the 40 mm Ordnance QF 2 pounder. This was replaced with the 57 mm Ordnance QF 6 pounder when that became available. There was extra impetus given to the development of anti-tank weaponry, which culminated in the 76mm Ordnance QF 17 pounder, widely considered one of the best anti-tank guns of the war.
Towed anti-tank guns were the domain of the Royal Artillery rather than the Royal Armoured Corps and vehicles adapted to mount artillery, including anti-tank self-propelled guns such as the Deacon (6pdr on an armoured wheeled truck chassis) and Archer (17pdr on tracked chassis), were their preserve, as were US-supplied vehicles.
The self-propelled guns that were built in the "tank destroyer" mold came about through the desire to field the QF 17 pounder anti-tank gun and simultaneous lack of suitable tanks to carry it. As a result they were of a somewhat extemporized nature. Mounting the gun on the Valentine tank chassis in a fixed superstructure gave the Archer, looking somewhat like the light-chassis German Marder III in appearance. The 17 pounder was also used to re-equip the US-supplied M10 Tank Destroyer, replacing the American 3-inch gun to produce the 17pdr SP Achilles. 
While there was a general move to a general purpose gun that was usable against both tanks and in supporting infantry, there was a need to put the 17 pdr into a tank for use against the enemy's heavy tanks. The Cruiser Mk VIII Challenger was a project to bring a 17 pdr tank into use to support the Cromwell cruiser tank. Delays led to it being outnumbered in use by the Sherman Firefly, but a derivative of Challenger was the more-or-less open-topped variant "Avenger" which was delayed until post war before entering service. A cut-down 17 pdr - the 77mmHV was used to equip the Comet tank in the last year of the war.
The closest the British came to developing an armored tank destroyer in the vein of the German Jagdpanzers or Soviet ISU series was the Churchill 3-inch Gun Carrier - a Churchill tank chassis with a boxy superstructure in place of the turret and mounting a 3-inch anti-aircraft gun. Although a number were ordered, they were not put into service as the immediate threat passed. The design was rejected in favor of developing a 17 pounder armed Cromwell tank variant, ultimately leading to the Comet tank. The Tortoise "heavy assault tank" , intended for use in breaking through fixed defensive lines, was well armoured and had a very powerful 32-pounder (94 mm) gun, but did not reach service use.
By 1944, a number of the Shermans in British use were being converted to Sherman Fireflies by adding the QF 17 pounder gun. Initially this gave each troop (platoon) of Shermans one powerfully armed tank. By war's end - through the production of more Fireflies and the replacement of Shermans by British tanks - about 50% of Shermans in British service were Fireflies.
Post-World War II.
In the face of the Warsaw Pact, a general need for extra firepower was identified. In the 1950s, the UK produced the FV 4101 Charioteer to beef up the tank regiments, mounting a 20 pounder gun in an oversize turret on the Cromwell tank hull—it lacked the all round capability of the Centurion tank. In the late 1960s, Germany developed the Kanonenjagdpanzer, essentially a modernized World War II Jagdpanzer mounting a 90 mm gun. As Soviet designs became more heavily armored, the 90 mm gun became ineffective and the Kanonenjagdpanzers were retrofitted for different roles or retired. Some provisions were made for the fitting of a 105 mm cannon, and many of the vehicles were modified to fire HOT or TOW missiles in place of a main gun. These upgraded variants remained in service into the 1990s.
With the development of flexible anti-tank missiles, which were capable of installation on almost any vehicle in the 1960s, the concept of the tank destroyer has morphed into light vehicles with missiles. With the weight of main battle tanks growing to the forty to seventy-tonne range, airborne forces were unable to deploy reasonable anti-tank forces. The result was a number of attempts to make a light vehicle, including the conventional ASU-85, the recoilless rifle-armed Ontos, and missile-armed Hornet Malkara armored car and Sheridan light assault vehicle. The latest entry into that category is the 2S25 Sprut-SD, armed with a current-issue 125 mm tank gun that is also capable of launching missiles like the 9M119 Svir.
Modern.
Many forces' infantry fighting vehicles (IFV) carry anti-tank missiles in every infantry platoon, and attack helicopters have also added anti-tank capability to the modern battlefield. But there are still dedicated anti-tank vehicles with very heavy long-range missiles, and ones intended for airborne use. 
There have also been dedicated anti-tank vehicles built on ordinary armored personnel carrier or armored car chassis. Examples include the U.S. M901 ITV (Improved TOW Vehicle) and the Norwegian NM142, both on an M113 chassis, several Soviet ATGM launchers based on the BRDM reconnaissance car, the British FV438 Swingfire and FV102 Striker and the German Raketenjagdpanzer series built on the chassis of the HS 30 and Marder IFV.
A US Army combined arms battalion has two infantry companies with TOW missile-armed Bradley IFVs and can bring a large concentration of accurate and lethal fire to bear on an attacking enemy unit that uses AFVs. They can be complemented by mobile units of AH-64 Apache Helicopters armed with Hellfire antitank missiles.
Missile carrying vehicles however are referred to as anti-tank missile carriers instead of tank destroyers.
Some gun-armed tank destroyers continue to be used. China has developed the tracked PTZ89 and the wheeled PTL02 tank destroyers. PTZ89 is armed with a 120 mm smoothbore cannon while PTL02, developed by NORINCO for the PLA's new light (rapid reaction) mechanized infantry divisions, carries a 100 mm one (a version armed with a 105 mm rifled gun is available for export). PTL02 is built on the 6×6 wheeled chassis of the WZ551 APC.
Italy and Spain use the Italian-built Centauro, a wheeled tank destroyer with a 105 mm cannon. The gun-armed tank destroyer may possibly see revival in the US Army through the introduction of the Stryker, more specifically, the M1128 Mobile Gun System, a Stryker variant armed with a 105 mm cannon which has remote control and autoloading capabilities. Originally, the Canadian Forces had considered replacing their aging Leopard 1 tanks with the Stryker Mobile Gun System. But with the increased use of IEDs capable of destroying Strykers by insurgent forces, they opted instead to purchase the Leopard 2 tank.
References.
</dl>

</doc>
<doc id="2287" url="http://en.wikipedia.org/wiki?curid=2287" title="Armored car (military)">
Armored car (military)

A military armored (or armoured) car is a wheeled light armored vehicle, lighter than other armored fighting vehicles, primarily being armored and/or armed for self-defense of the occupants. Other multi-axled wheeled military vehicles can be quite large, and actually be superior to some smaller tracked vehicles in terms of armor and armament.
History.
Armed car.
The Motor Scout was designed and built by British inventor F.R. Simms in 1898. It was the first armed petrol engine powered vehicle ever built. The vehicle was a De Dion-Bouton quadricycle with a mounted Maxim machine gun on the front bar. An iron shield in front of the car protected the driver.
Another early armed car was invented by Royal Page Davidson at Northwestern Military and Naval Academy in 1898 with the Davidson-Duryea gun carriage and the later Davidson Automobile Battery armored car.
However, these were not 'armored cars' as the term is understood today, as they provided no real protection for their crews against any kind of opposing fire. They were also, by virtue of their small capacity engines, far less efficient than the cavalry and horse-drawn guns that they were intended to complement.
First armored cars.
At the beginning of the twentieth century, the first military armored vehicles were manufactured, by adding armor and weapons to existing vehicles.
The first armoured car was the Simms' Motor War Car, designed by F.R. Simms and built by Vickers, Sons & Maxim of Barrow on a special Coventry-built Daimler chassis with a German-built Daimler motor in 1899. and a single prototype was ordered in April 1899 The prototype was finished in 1902, too late to be used during the Boer War.
The vehicle had Vickers armour 6 mm thick and was powered by a four-cylinder 3.3-litre 16 hp Cannstatt Daimler engine giving it a maximum speed of around 9 miles per hour (14.5 km/h). The armament, consisting of two Maxim guns, was carried in two turrets with 360° traverse. It had a crew of four. Simms' Motor War Car was presented at the Crystal Palace, London, in April 1902.
Another early armoured car of the period was the French Charron, Girardot et Voigt 1902, presented at the "Salon de l'Automobile et du cycle" in Brussels, on 8 March 1902. The vehicle was equipped with a Hotchkiss machine gun, and with 7 mm armour for the gunner.
The Italians used armored cars during the Italo-Turkish War. A great variety of armored cars appeared on both sides during World War I and these were used in various ways.
World War I.
Generally, the armored cars were used by more or less independent car commanders. However, sometimes they were used in larger units up to squadron size. The cars were primarily armed with light machine guns. But larger units usually employed a few cars with heavier guns. As air power became a factor, armored cars offered a mobile platform for anti-aircraft guns.
The first effective use of an armored vehicle in combat was achieved by the Belgian Army in August–September 1914. They had placed Cockerill armour plating and a Hotchkiss machine gun on Minerva Armored Cars. Their successes in the early days of the war convinced the Belgian GHQ to create a Corps of Armoured Cars, who would be sent to fight on the Eastern front once the western front immobilized after the Battle of the Yser.
The British Royal Naval Air Service dispatched aircraft to Dunkirk to defend the UK from Zeppelins. The officers' cars followed them and these began to be used to rescue downed reconnaissance pilots in the battle areas. They mounted machine guns on them and as these excursions became increasingly dangerous, they improvised boiler plate armoring on the vehicles provided by a local shipbuilder. In London Murray Sueter ordered "fighting cars" based on Rolls-Royce, Talbot and Wolseley chassis. By the time Rolls-Royce Armoured Cars arrived in December 1914, the mobile period on the Western Front was already over. As described below, they had a fascinating birth and long and interesting service.
More tactically important was the development of formed units of armoured cars, such as the Canadian Automobile Machine Gun Brigade, which was the first fully mechanized unit in the history of the British Army. The brigade was established on September 2, 1914 in Ottawa, as Automobile Machine Gun Brigade No. 1 by Brigadier-General Raymond Brutinel. The Brigade was originally equipped with 8 Armoured Autocars mounting 2 machine guns. By 1918 Brutinel's force consisted of two Motor Machine Gun Brigades (each of five gun batteries containing eight weapons apiece). The brigade, and its armoured cars, provided yeoman service in many battles, notably at Amiens.
The Rolls-Royce Armoured Car was famously proposed, developed, and utilised by the 2nd Duke of Westminster. He took a squadron of these cars to France in time to make a noted contribution to the Second Battle of Ypres, and thereafter the cars with their master were sent to the Middle East to play a part in the British campaign in Palestine and elsewhere. These cars appear in the memoirs of numerous officers of the BEF during the earlier stages of the Great War - their ducal master often being described in an almost piratical style.
World War II.
The British Royal Air Force (RAF) in the Middle East was equipped with Rolls-Royce Armoured Cars and Morris tenders. Some of these vehicles were among the last of a consignment of ex-Royal Navy armored cars that had been serving in the Middle East since 1915. In September 1940 a section of the No. 2 Squadron RAF Regiment Company was detached to General Wavell’s ground forces during the first offensive against the Italians in Egypt. It is said that these armored cars became ‘the eyes and ears of Wavell’. During the actions in the October of that year the Company was employed on convoy escort tasks, airfield defense, fighting reconnaissance patrols and screening operations.
During the Anglo-Iraqi War, some of the units located in the British Mandate of Palestine were sent to Iraq and drove Fordson armored cars. "Fordson" armored cars were Rolls-Royce armored cars which received new chassis from a Fordson truck in Egypt.
Since the Treaty of Versailles did not mention armored cars, Germany began developing them early. By the start of the new war, the German army possessed some highly effective reconnaissance vehicles, such as the "Schwerer Panzerspähwagen".
The Soviet BA-64 was influenced by a captured "Leichter Panzerspähwagen" before it was first tested in January 1942.
In the second half of the war, the American M8 Greyhound and the British Daimler Armoured Cars featured turrets with light guns (40 mm or less) mounted in turrets. As with other wartime armored cars, their reconnaissance roles emphasized greater speed and stealth than a tracked vehicle could provide, so their limited armor, armament and off-road capabilities were seen as acceptable compromises.
Military use.
A military armored car is a type of armored fighting vehicle having wheels (from four to ten large, off-road wheels) instead of tracks, and usually light armor. Armored cars are typically less expensive and on roads have better speed and range than tracked military vehicles. They do however have less mobility as they have less off-road capabilities because of the higher ground pressure. They also have less obstacle climbing capabilities than tracked vehicles. Wheels are more vulnerable to enemy fire than tracks, they have a higher signature and in most cases less armor than comparable tracked vehicles. As a result they are not intended for heavy fighting; their normal use is for reconnaissance, command, control, and communications, or for use against lightly armed insurgents or rioters. Only some are intended to enter close combat, often accompanying convoys to protect soft-skinned vehicles.
Light armored cars, such as the British Ferret are armed with just a machine gun. Heavier vehicles are armed with autocannon or a small tank gun. The heaviest armored cars, such as the German, World War II era SdKfz 234 or the modern, US M1128 Mobile Gun System, mount the same guns that arm medium tanks.
Armored cars are popular for peacekeeping or internal security duties. Their appearance is less confrontational and threatening than tanks, and their size and maneuverability is said to be more compatible with tight urban spaces designed for wheeled vehicles. However they do have a larger turning radius compared to tracked vehicles which can turn on the spot and their tires are vulnerable and are less capable in climbing and crushing obstacles. However when there is true combat they are easily outgunned and lightly armored. The threatening appearance of a tank is often enough to keep an opponent from attacking, whereas a less threatening vehicle such as an armored car is more likely to be attacked.
Many modern forces now have their dedicated armored car designs, to exploit the advantages noted above. Examples would be the M1117 Armored Security Vehicle of the USA or Alvis Saladin of the post-World War II era in the United Kingdom.
Alternatively, civilian vehicles may be modified into improvised armored cars in "ad hoc" fashion. Many militias and irregular forces adapt civilian vehicles into AFVs (armored fighting vehicles) and troop carriers, and in some regional conflicts these "technicals" are the only combat vehicles present. On occasion, even the soldiers of national militaries are forced to adapt their civilian-type vehicles for combat use, often using improvised armor and scrounged weapons.

</doc>
<doc id="2288" url="http://en.wikipedia.org/wiki?curid=2288" title="Self-propelled anti-aircraft weapon">
Self-propelled anti-aircraft weapon

An anti-aircraft vehicle, also known as a self-propelled anti-aircraft gun (SPAAG) or self-propelled air defense system (SPAD), is a mobile vehicle with a dedicated anti-aircraft capability. The Russian equivalent of "SPAAG" is "ZSU", for "zenitnaya samokhodnaya ustanovka", ("anti-aircraft self-propelled mount").
Specific weapon systems used include machine guns, autocannons, larger guns, or missiles, and some mount both guns and longer-ranged missiles (Pantsir-S1). Platforms used include both trucks and heavier combat vehicles such as APCs and tanks, which add protection from aircraft, artillery, and small arms fire for front line deployment.
Anti-aircraft guns are usually mounted in a quickly-traversing turret with a high rate of elevation, for tracking fast-moving aircraft. They are often in dual or quadruple mounts, allowing a high rate of fire. Today, missiles (generally mounted on similar turrets) have largely supplanted anti-aircraft guns.
History.
World War I.
Anti-aircraft machine guns have long been mounted on trucks, and these were quite common during World War I. A predecessor of the WW2 German "88" anti-aircraft gun, the WWI German 77 mm anti-aircraft gun, was truck-mounted and used to great effect against British tanks.
The British QF 3 inch 20 cwt was mounted on trucks for use on the Western Front.
Inter-war period.
Between the two World Wars the United Kingdom developed the Birch gun, a general purpose artillery piece on an armoured tracked chassis capable of maintaining formation with their current tanks. The gun could be elevated for anti-aircraft use.
Vickers Armstrong also developed a SPAAG based on the chassis of the Mk.E 6-ton light tank/Dragon Medium Mark IV tractor, mounting a Vickers QF-1 "Pom-Pom" gun of 40 mm. About 26 were sold to Siam and saw action as Infantry support guns and AA guns during the Franco-Thai war (1940-1941) along with 30 Vickers Mk.E Type B 6-ton tanks. This was probably the first tracked SPAAG manufactured in series. Later the British also developed a version of the Mk.VI light tank armed with 4 machine guns that was known as Light Tank AA Mk.I. And also a twin 15 mm version based on the Light Tank Mk.V was built.
Among early pre-war pioneers of self-propelled AA guns were the Germans. By the time of the war, they fielded the SdKfz 10/4 and 6/2, cargo halftracks mounting single 20 mm or 37 mm AA guns (respectively). Later in the war similar German halftracks mounted quadruple 20 mm weapons.
World War II.
Larger guns followed on larger trucks, but these mountings generally required off-truck setup in order to unlimber the stabilizing legs these guns needed. One exception to this rule was the Italian Cannone da 90/53 which was highly effective when mounted on trucks, a fit known as the "autocannoni da 90/53". The 90/53 was a feared weapon, notably in the anti-tank role, but only a few hundred had been produced by the time of the armistice in 1943.
Other nations tended to work on truck chassis. Starting in 1941, the British developed the "en portee" method of mounting an anti-tank gun (initially a 2 pounder) on a truck. This was to prevent the weapon from being damaged by long-distance towing across rough, stony deserts, and it was intended only to be a carrying method, with the gun unloaded for firing. However, crews tended to fire their weapons from their vehicles for the mobility this method provided, with consequent casualties. 
This undoubtedly inspired their Morris C9/B (officially the "Carrier, SP, 4x4, 40 mm AA"), a Bofors 40 mm AA gun mounted on a chassis derived from the Morris "Quad" Field Artillery Tractor truck. Similar types, based on 3-ton lorries, were produced in Britain, Canada and Australia, and together formed the most numerous self-propelled AA guns in British service.
The U.S. Army brought truck-towed Bofors 40 mm AA guns along with truck-mounted units fitted with mechanized turrets when they sailed, first for Great Britain and then onto France. The turrets carried four .50 inch (12.7 mm) machine guns, which were designed to be adjusted to converge at the single point where enemy aircraft were expected to appear at low altitude in conduction of strafing runs directed at large infantry and field artillery units.
Interest in mobile AA turned to heavier vehicles with the mass and stability needed to easily train weapons of all sizes. Probably the desire, particularly in German service, for anti-aircraft vehicles to be armoured for their own protection also assisted this trend.
The concept of an armored SPAAG was pioneered by Hungary during World War II Hungary by producing the 40M Nimrod based on the Luftvärnskanonvagn L-62 Anti II license acquired from Sweden. Germany followed later with their "Flakpanzer" series. German World War II SPAAGs include the Möbelwagen, Wirbelwind, Ostwind and Kugelblitz. Other forces followed with designs of their own, notably the American M16 created by mounting quadruple M2 machine guns on a M3 Half-track.
The British developed their own SPAAGs throughout the war mounting multiple machine guns and light cannon on various tank and armoured car chassis and by 1943, the Crusader AA tanks, which mounted the Bofors 40 mm gun or two-three Oerlikon 20 mm cannon. Although used during the Normandy landings, by that point German aircraft were contained by the Allies own air forces and they were largely unneeded.
Cold War and later.
The introduction of jet engines and the subsequent rough doubling of aircraft speeds greatly reduced the effectiveness of the SPAAG against attack aircraft. A typical SPAAG round might have a muzzle velocity on the order of 1000 m/s and might take as long as two to three seconds to reach a target at its maximum range. An aircraft flying at 1000 km/h is moving at a rate of about 280 m/s. This means the aircraft will have moved hundreds of meters during the flight time of the shells, greatly complicating the aiming problem to the point where close passes were essentially impossible to aim using manual gunsights. This speed also allowed the aircraft to rapidly fly out of range of the guns; even if the aircraft passes directly over the SPAAG, it would be within its firing radius for under 30 seconds.
SPAAG development continued through the early 1950s with ever-larger guns, improving the range and allowing the engagement to take place at longer distances where the crossing angle was smaller and aiming was easier. Examples including the 40 mm U.S. M42 Duster and the 57 mm Soviet ZSU-57-2. However, both were essentially obsolete before they entered service, and found employment solely in the ground-support role. The M42 was introduced to the Vietnam War to counter an expected North Vietnamese air offensive, but when this failed to materialize it was used as an effective direct-fire weapon. The ZSU-57 found similar use in the Yugoslav Wars, where its high-angle fire was useful in the mountainous terrain.
By the late 1950s the US Army had given up on the SPAAG concept, considering all gun-based weapons to be useless against modern aircraft. This belief was generally held by many forces, and the anti-aircraft role turned almost exclusively to missile systems. The Soviet Union remained an outlier, beginning development of a new SPAAG in 1957, which emerged as the ZSU-23-4 in 1965. This system included search-and-track radars, fire control, and automatic gun-laying, greatly increasing its effectiveness against modern targets. The ZSU-23 proved very effective when used in concert with SAMs; the presence of SAMs forced aircraft to fly low to avoid their radars, placing them within range of the ZSUs.
The success of the ZSU-23 led to a resurgence of SPAAG development. This was also prompted by the introduction of attack helicopters in the 1970s, which could hide behind terrain and then "pop up" for an attack lasting only a few tens of seconds; missiles were ineffective at low altitudes, while the helicopters would often be within range of the guns for a rapid counterattack. Notable among these later systems is the German Gepard, the first western SPAAG to offer performance equal to or better than the ZSU. This system was widely copied in various NATO forces. US attempts to introduce a new SPAAG were doomed to become a series of half-measures and dismal failures; the failure of the missile-based MIM-46 Mauler led to the introduction of the optically-aimed M163 VADS of very short range, and the long-delayed and finally cancelled M247 Sergeant York which offered almost laughable performance in testing, unable to hit even stationary targets. 
SPAAG development continues, with many modern examples often combining both guns and short-range missiles. Examples include the Soviet/Russian Tunguska-M1, which supplanted the ZSU-23 in service, newer versions of the Gepard, and the British Marksman turret, which can be used on a wide variety of platforms. Other single-type examples include the South Korean K30 Biho and K263A1 radar-guided Vulcan, Chinese Type 95 SPAAA, Swedish CV9040 AAV, Polish PZA Loara, American M6 Bradley Linebacker and M1097 Humvee Avenger, Yugoslavian BOV-3, Canadian ADATS, Japanese Type 87 SPAAG, Italian SIDAM 25 and Otomatic, and versions of the French AMX-13, Turkish ACV-15 with Zıpkın PMADS.

</doc>
<doc id="2289" url="http://en.wikipedia.org/wiki?curid=2289" title="AZ Alkmaar">
AZ Alkmaar

Alkmaar Zaanstreek (]), better known as AZ Alkmaar or simply AZ (]), is a Dutch professional football club from Alkmaar and the Zaanstreek. The club plays in the Eredivisie, the highest professional football league in the Netherlands, and hosts home games at the AFAS Stadion.
AZ has won the Eredivisie twice, in 1980–81 and 2008–09. In the same season as their first league title, they also reached the UEFA Cup Final, which they lost to Ipswich Town. In addition, the team has won the KNVB Cup on four occasions.
History.
1954-1972: Foundation and first years.
AZ was founded on 10 May 1967 as AZ '67, the result of a merger of Alkmaar '54 and FC Zaanstreek. FC Zaanstreek was formed in 1964, continuing the professional adventure of the Kooger Football Club (). KFC had been founded in 1910, had nearly become National Champion in 1934 through a narrow loss to Ajax in the finals, and had been professional since 1955.
In 1964, the brothers Cees and Klaas Molenaar, former players for KFC and owners of a growing appliance store chain, sought to create a powerful football team in Zaanstreek by merging the two local professional teams: KFC and .
After this merger failed, they successfully merged KFC (now "FC Zaanstreek") with Alkmaar '54; the team would be based in Alkmaar. 
Partially through the hiring of expensive foreign players, the new club soon acquired large debts.
1972-1985: The Molenaar years.
Fortunately in 1972 the Molenaar brothers bailed it out and invested heavily in the club, to the point that AZ '67 were successful in the late seventies and early eighties, regularly playing European football from 1977 to 1982 whilst also winning the Dutch Cup three times over that period.
After four close league campaigns AZ finally became Dutch champions in 1981, they were the only team other than the "big three" (Ajax, Feyenoord, and PSV) to do so in a 44-year period spanning from 1965 to 2009, when AZ once again won the league title. They won the 1980–81 season with overwhelming power, winning 27 of 34 matches and only losing once whilst scoring a club record 101 goals and conceding just 30 goals.
The same season AZ reached the final of the UEFA Cup, losing 5–4 on aggregate to Ipswich Town. The next year in the UEFA Champions League they lost in the second round 3–2 on aggregate to Liverpool.
Georg Keßler was AZ's manager over most of these years (1978–82), while star players included: Kees Kist the club's highest ever goalscorer with 212 goals and the first ever Dutchman to win the European Golden Boot in 1979 when he scored 34 goals in a season; Jan Peters who played 120 games for AZ during this period scoring 30 goals from midfield; Hugo Hovenkamp played 239 games in defence for AZ from 1975–83 as well as receiving 31 caps for the Netherlands from 1977–83 and playing each game in Euro '80 while an AZ player. 
John Metgod spent six years at AZ playing 195 games as a defender, scoring 26 goals including a goal against Ipswich Town in the final of the UEFA Cup. Like Hovenkamp, Metgod was included in the Netherlands squad for Euro '80; The Danish forward Kristen Nygaard who spent 10 years at AZ scoring 104 goals in 363 games between 1972 and 1982.
1985-1993: The interim years.
The club deteriorated after Klaas Molenaar left the club in 1985 (Cees died in 1979). AZ were relegated in 1988 from the Eredivisie.
1993-2009: The Scheringa years.
The involvement of businessman Dirk Scheringa in the mid 1990s marked the revival of the club as AZ returned to the Eredivisie in 1998.
After a 22-year hiatus from European football AZ appeared in the 2004–05 UEFA Cup advancing to the semi-finals. The second leg of the semi-final against Sporting CP had a heart-breaking conclusion, when Sporting scored in the 122nd minute (2 minutes into stoppage time) to reach an aggregate score of 4–4, Sporting advanced to the Final thanks to the away goals rule. In the same season AZ finished third in the Eredivisie, qualifying for the UEFA Cup again. These were great achievements for the club which does not have a similar sized fanbase relative to Eredivisie and European rivals; AZ's home ground until the 2006–07 season, the Alkmaarderhout, had a capacity of only 8,390.
In the summer of 2006, the club moved to a new 17,000 capacity stadium AZ Stadion.
AZ had a very good 2006–07 season, despite ending in disaster. Going into the last game of the 2006–07 season, AZ led PSV and Ajax by goal difference in the Eredivisie, but ended up third after losing their last match against the now relegated and bottom of the table Excelsior, playing with 10 men for 80 minutes. 
Furthermore AZ lost the KNVB Cup final to Ajax 8–7 after a penalty shoot-out and also lost to Ajax over two play-off games for the Champions League. After the season, key players like Tim de Cler, Danny Koevermans, and Shota Arveladze left the team.
A remarkable run ended in the 2007–08 season; AZ lost a group game against Everton 3–2 in the UEFA Cup which ended an unbeaten run of 32 home matches in European competitions, a record which ran from 1977 to 2007. 
Also on this season AZ performed so badly (first round loss in the KNVB Cup, elimination from the UEFA Cup group stage and 11th place league finish), that team manager Louis van Gaal felt obliged to hand in his resignation in March 2008. However, after protests from the players and directors, van Gaal withdrew his resignation.
The 2008–09 season had an unpromising start with two defeats against NAC Breda and ADO Den Haag. However, starting with a 1–0 victory over defending league champions PSV, AZ didn't lose a game in the next 28 matches, including a run of 11 matches where AZ did not concede an opposition goal. Three weeks before the end of the season AZ became Eredivisie champions beating nearest rivals Twente and Ajax comfortably. Being league champions, AZ qualified for the UEFA Champions League for the second time, but only took four points from six matches and finished bottom of their group.
2009-Present: Recent years.
Ronald Koeman succeeded Louis van Gaal after the 2008–09 season. Van Gaal had already left for Bayern Munich after becoming league champions with AZ. Koeman became the manager for AZ on 17 May 2009. On 5 December 2009 AZ announced that Koeman no longer was in charge of AZ, after losing 7 of the first 16 games in his reign. Former Rangers and Zenit St. Petersburg manager Dick Advocaat took over for the rest of the season. Under Advocaat, AZ achieved some good results and secured European football for the next season.
For the 2010–11 season AZ appointed Gertjan Verbeek as their new manager. AZ finished the 2010–11 season in 4th place, securing Europa League football for the next season. In the KNVB Cup AZ reached the last eight, where they were beaten by rivals Ajax with 1–0. AZ finished third in their Europa League group, thus not qualifying for the knock out round.
The 2011–12 season AZ finished the Eredivisie in 4th place and performed significantly better in cup competitions, reaching the semi-finals in the KNVB cup (losing to Heracles Almelo after extra time) and the quarter-finals in the Europa League, ultimately losing to Valencia after beating Udinese, Anderlecht, Malmö FF, Austria Wien, Metalist Kharkiv, Aalesund and FK Baumit Jablonec.
On 21 December 2011, during the quarter-finals of the KNVB Cup, a 19 year old Ajax fan entered the Amsterdam ArenA pitch in the 36th minute, with Ajax winning 1–0, attacking AZ goalkeeper Esteban Alvarado. The fan slipped and Alvarado kicked the fan twice, which led to the goalkeeper being sent off. Following this, Gertjan Verbeek ordered his players to leave the pitch for the dressing room in protest. Later, the match was played again on 19 January 2012, with Alvarado's red card rescinded. AZ won the match 3–2.
The 2012–13 season started in the Europa League with a qualifying play-off round against Guus Hiddinks Anzhi Makhachkala, AZ were hammered 6–0 on aggregate. Disappointingly AZ finished the Eredivisie in 10th place, however AZ won silverware by winning the domestic cup after beating PSV 2-1. Winning the KNVB Beker AZ automatically qualified for Europa League football despite finishing the league in tenth position and out of the league's Europa League play-off system.
In September 2013, just a day after emphatically beating PSV, then league leaders, Verbeek was dismissed as first team manager by the club due to 'a lack of chemistry' between the management and players. He was replaced by Dick Advocaat for the rest of the season until a permanent replacement was found. Advocaat took AZ to the semi-finals of the KNVB Beker, the quarter-finals of the Europa League and 8th in the league, ultimately losing to FC Groningen in Europa League play-off final round (their 58th game of the season, a club record).
The 2014–15 season started with a new manager at the helm, former SC Heerenveen manager and Ajax player Marco van Basten.
Current squad.
"As of 1 June 2015"
"For recent transfers, see List of Dutch football transfers summer 2015"
Stadium and sponsor.
AZ play their home games at the AFAS Stadion, located in the southern part of the city of Alkmaar. The stadium, which is owned directly by the club, was opened in 2006 and replaced the old Alkmaarderhout venue as the DSB Stadion. The stadium currently has a capacity of "17,023". During its design stages the name Victorie Stadion was frequently used, referring to the Dutch War of Independence, the phrase ""n Alkmaar begint de victorie" (Victory begins in Alkmaar)" in particular. Until now, this name hasn't been officially in use, the board instead opting for sponsorship deals because of financial motives. However, to this day the name maintains a good share of support among the fans.
In order to further increase revenue, the "AZ board" of directors decided to extend the capacity of the new stadium to a minimum of "30,000" seated spectators somewhere in the future. The extension will be realised by constructing a second tier to three of the four stands. The main stand with all technical areas, "VIP" and sponsor and media facilities will remain in place. However, these plans were put on hold after the DSB bankruptcy and there are no current plans to increase the capacity.
In October 2009 sponsor DSB Bank was declared bankrupt.
The stadium name temporarily changed from DSB Stadion to AZ Stadion, as it was considered undesirable that the stadium was linked with a non-existent bank. In February 2010 a new main sponsor was found: construction works service provider BUKO from Beverwijk.
A year later, in the season 2010–11, "AFAS Erp Software" took over as official shirt sponsor, also taking over duties as stadium sponsor. The current external name of the ground is AFAS Stadion.
AZ in Europe.
Below is a table with AZ's international results in the past seasons.
Domestic results.
Below is a table with AZ's domestic results since the introduction of professional football in 1956.

</doc>
<doc id="2296" url="http://en.wikipedia.org/wiki?curid=2296" title="Adrenal gland">
Adrenal gland

The adrenal glands (also known as suprarenal glands) are endocrine glands that produce a wide variety of hormones. They are found on the top of the kidneys and consist of a number of different layers that directly influence the structure and function of the glands. Each gland has an outer cortex made of steroid-producing cells surrounding a core of medulla, formed by chromaffin cells in direct relationship with the sympathetic nervous system. The adrenal cortex is divided into three zones according to their functions and microscopic appearance.
The adrenal cortex produces a class of steroid hormones, the corticosteroids, which are classified according to their effects. Mineralocorticoids, produced in the zona glomerulosa, help in the regulation of blood pressure and electrolyte balance. Glucocorticoids such as cortisol, are synthesized in the zona fasciculata and their functions include regulation of glycogen and lipid metabolism and immune system suppression. The innermost layer of the cortex, the zona reticularis produces androgens (steroid hormones) that are converted to fully functional sex hormones in the gonads and other target organs. The production of steroid hormones is named steroidogenesis, and involves a number of reactions and processes that take place in cortical cells. The medulla produces the catecholamines, epinephrine, and norepinephrine which function to provoke a quick response on diverse organs in stress situations.
Regulation of synthesis and secretion of adrenal hormones is equally varied. Mineralocorticoid production is mainly under influence of the renin–angiotensin–aldosterone system, in which specialized juxtaglomerular cells of the kidneys monitor blood volume and start a cascade of reactions that leads to the stimulation of aldosterone synthesis in the zona glomerulosa. Cortisol and androgen synthesis are under control of the hypothalamic-pituitary-adrenal (HPA) axis in a classic example of a negative feedback loop, in which the hypothalamus and pituitary gland release stimulating hormones whenever cortisol levels are low. In contrast, release of medullary catecholamines is regulated by direct innervation from the sympathetic nervous system.
There are a number of endocrine diseases and disorders that can affect the normal functioning of the adrenal gland. Overproduction of corticosteroid hormones leads to Cushing's syndrome, whereas insufficiency is commonly associated with Addison's disease. Congenital adrenal hyperplasia is a genetic disease produced by a disregulation of endocrine control mechanisms. A variety of tumors can arise from adrenal tissue, and are commonly found in medical imaging when searching for other diseases.
Structure.
The adrenal glands are located bilaterally in the retroperitoneum superior and slightly medial to the kidneys. In humans, the right adrenal gland is pyramidal in shape, whereas the left adrenal gland is semilunar in shape; in non-humans, they are quadrilateral in shape. The combined weight of the adrenal glands in an adult human ranges from 7 to 10 grams.
The adrenal glands are surrounded by an adipose capsule and are enclosed within the renal fascia, a fibrous structure that also surrounds the kidney. A weak septum of connective tissue separates the glands from the kidneys and facilitates surgical removal of the kidneys without damage to the glands. The adrenal glands are in close relationship with the diaphragm, and are attached to the crura of the diaphragm by means of the renal fascia.
Each adrenal gland has two anatomically and functionally distinct parts, the outer adrenal cortex and the inner medulla, both of which produce hormones. The cortex mainly produces aldosterone, cortisol and androgens, while the medulla produces adrenaline and noradrenaline.
Cortex.
The adrenal cortex is devoted to production of corticosteroid and androgen hormones. Specific cortical cells produce particular hormones including aldosterone, cortisol, and androgens such as androstenedione. Under normal unstressed conditions, the human adrenal glands produce the equivalent of 35–40 mg of cortisone acetate per day.
The adrenal cortex comprises three zones, or layers. This "anatomic zonation" can be appreciated at the microscopic level, where each zone can be recognized and distinguished from one another based on structural and anatomic characteristics. The adrenal cortex exhibits "functional zonation" as well: by virtue of the characteristic enzymes present in each zone, the zones produce and secrete distinct hormones.
Zona glomerulosa.
The outermost layer of the adrenal cortex, the zona glomerulosa, lies immediately under the fibrous capsule of the gland. Cells in this layer form ovoid groups, separated by trabeculae of connective tissue that are continuous with the fibrous capsule of the gland and carry wide capillaries.
This layer is the main site for production of aldosterone, a mineralocorticoid, by the action of the enzyme aldosterone synthase. Aldosterone is a hormone largely responsible for the long-term regulation of blood pressure.
The expression of neuron-specific proteins in the zona glomerulosa cells of human adrenocortical tissues has been predicted and reported by several authors and it was suggested that the expression of proteins like the neuronal cell adhesion molecule (NCAM) in the cells of the zona glomerulosa reflects the regenerative feature of these cells, which would lose NCAM immunoreactivity after moving to the zona fasciculata. However, together with other data on neuroendocrine properties of zona glomerulosa cells, NCAM expression may reflect a neuroendocrine differentiation of these cells. Voltage-dependent calcium channels have been detected in the zona glomerulosa of the human adrenal, which suggests that calcium-channel blockers may directly influence the adrenocortical biosynthesis of aldosterone in vivo.
Zona fasciculata.
Situated between the glomerulosa and reticularis, the zona fasciculata is responsible for producing mainly glucocorticoids such as cortisol. It is the widest of the three layers as it composes nearly 80% of the cortical volume. The cells, arranged in columns radially oriented towards the medulla, have numerous lipid droplets responsible of the pale staining nature of the cytoplasm. Abundant mitochondria and a complex smooth endoplasmic reticulum are also present in the cells of this layer.
Zona reticularis.
The innermost cortical layer, the zona reticularis, lies directly next to the medulla. It produces androgens, mainly dehydroepiandrosterone (DHEA), DHEA sulfate (DHEA-S), and androstenedione (the precursor to testosterone) in humans. Its small cells form irregular cords and clusters, separated by capillaries and connective tissue. The cells contain relatively small quantities of cytoplasm and lipid droplets, and sometimes display brown lipofuscin pigment.
Medulla.
The adrenal medulla is the core of the adrenal gland, and is surrounded by the adrenal cortex. The chromaffin cells of the medulla (named for their characteristic brown staining with chromic acid salts) are the body's main source of the circulating catecholamines adrenaline and noradrenaline, released by the medulla. Approximately 20% noradrenaline (norepinephrine) and 80% adrenaline (epinephrine) are secreted.
To carry out its part of this response, the adrenal medulla receives input from the sympathetic nervous system through preganglionic fibers originating in the thoracic spinal cord from T5–T11. Because it is innervated by preganglionic nerve fibers, the adrenal medulla can be considered as a specialized sympathetic ganglion. Unlike other sympathetic ganglia, however, the adrenal medulla lacks distinct synapses and releases its secretions directly into the blood.
Blood supply.
Although variations of the blood supply to the adrenal glands (and kidneys) are common, there are usually three arteries that supply each adrenal gland:
Venous drainage of the adrenal glands is achieved via the suprarenal veins:
The central adrenomedullary vein is a particular type of blood vessel in the adrenal medulla. Its structure is different from the other veins in that the smooth muscle in its tunica media (the middle layer of the vessel) is arranged in conspicuous, longitudinally oriented bundles.
The suprarenal vein exits the adrenal gland through a depression on its anterior surface known as the hilum. Note that the arteries supplying the suprarenal gland do not pass through the hilum.
The suprarenal veins may form anastomoses with the inferior phrenic veins. Since the right supra-renal vein is short and drains directly into the inferior vena cava it is likely to injure the latter during removal of right adrenal for various reasons.
The adrenal glands (alongside the thyroid gland) have one of the greatest blood supply per gram of tissue of any organ. Up to 60 arterioles may enter each adrenal gland. This may be one of the reasons that lung cancer commonly metastasizes to the adrenals.
Function.
The adrenal gland secretes a number of different hormones which are metabolised by enzymes either within the gland or in other parts of the body. These hormones are involved in a number of different pathways.
Corticosteroid production.
All corticosteroid hormones share cholesterol as a common precursor. In consequence, the first step in steroidogenesis is cholesterol uptake or synthesis. Cells that produce steroid hormones provide themselves with cholesterol in various ways. Their main source is dietary cholesterol transported in the blood as LDL, which enters the cells through receptor-mediated endocytosis, although endogenous synthesis in the endoplasmic reticulum is sufficient when LDL levels are abnormally low as represented in people with abetalipoproteinemia (a genetic disorder of intestinal lipid absorption). In lysosomes, cholesterol is separated from the proteic component of LDL and then stored within cell membranes or bound with proteins.
The initial part of conversion of cholesterol into steroid hormones involves a number of enzymes of the cytochrome P450 family that are located in the inner membrane of mitochondria. Transport of cholesterol from the outer to the inner membrane is facilitated by steroidogenic acute regulatory protein (StAR) and is the rate-limiting step of steroid synthesis. The functional zonation of the adrenal cortex is determined by the presence of distinct enzymes in each particular layer, explaining how the different layers produce unique hormones from a common precursor.
The first enzymatic step in the production of all steroid hormones is cleavage of the cholesterol side chain, a reaction that forms pregnenolone as a product and is catalyzed by the enzyme P450scc, also known as cholesterol desmolase. After the production of pregnenolone, specific enzymes of each cortical layer further modify it. Enzymes involved in this process include both mitochondrial and cytoplasmic P450s and hydroxysteroid dehydrogenases (HSDs). Usually a number of intermediate steps in which pregnenolone is modified several times are required to form the functional hormones. Enzymes that catalyze reactions in these metabolic pathways are involved in a number of endocrine diseases. For example, the most common form of congenital adrenal hyperplasia develops as a result of deficiency of 21-hydroxylase, an enzyme involved in an intermediate step of cortisol production.
Regulation of corticosteroid production.
Glucocorticoids are under the regulatory influence of the hypothalamus-pituitary-adrenal (HPA) axis. Glucocorticoid synthesis is stimulated by adrenocorticotropic hormone (ACTH), a hormone of the anterior pituitary. In turn, production of ACTH is stimulated by the presence of corticotropin-releasing hormone (CRH), which is released by neurons of the hypothalamus. ACTH acts on the adrenal cells first by increasing the levels of StAR within the cells, and then of all steroidogenic P450 enzymes. The HPA axis is an example of a negative feedback system, in which cortisol itself acts as a direct inhibitor of both CRH and ACTH synthesis. The HPA-axis also interacts with the immune system through increased secretion of ACTH at the presence of certain molecules of the inflammatory response.
Mineralocorticoid secretion is regulated mainly by the renin–angiotensin–aldosterone system (RAAS), the concentration of potassium, and ACTH to a lesser extent. Sensors of blood pressure in the juxtaglomerular apparatus of the kidneys release the enzyme renin into the blood, which starts a cascade of reactions that lead to formation of angiotensin II. Angiotensin receptors in cells of the zona glomerulosa recognize the substance, and upon binding they stimulate the release of aldosterone.
Catecholamine production.
Epinephrine and norepinephrine are catecholamines, water-soluble compounds that have a structure made of a catechol group and an amino group. The adrenal glands are responsible for the majority of circulating epinephrine (adrenaline) in the body, but only for a small amount of circulating norepinephrine (noradrenaline). These hormones are released in the adrenal medulla, which is richly vascular. Epinephrine and norepinephrine act at adrenoreceptors throughout the body, with effects that include an increase in blood pressure and heart rate.
Catecholamines are produced in chromaffin cells (the main type of cells in the adrenal medulla) from tyrosine, a non-essential amino acid derived from food or produced from phenylalanine in the liver. The enzyme tyrosine hydroxylase converts tyrosine to L-DOPA in the first step of catecholamine synthesis. L-DOPA is then converted to dopamine before it can be turned into norepinephrine. In the cytosol, norepinephrine is converted to epinephrine by the enzyme phenylethanolamine N-methyltransferase (PNMT) and stored in granules. Glucocorticoids produced in the adrenal cortex stimulate the synthesis of catecholamines by increasing the levels of tyrosine hydroxylase and PNMT.
The adrenal medulla is innervated by splanchnic nerves of the sympathetic nervous system, which signal the release of catecholamines from the storage granules by stimulating the opening of calcium channels in the cell membrane.
Effects of adrenal hormones.
Mineralocorticoids.
Aldosterone is the main mineralocorticoid produced in the body. Its effects are on the distal convoluted tubule and collecting duct of the kidney where it causes increased reabsorption of sodium and increased excretion of both potassium (by principal cells) and hydrogen ions (by intercalated cells of the collecting duct). Aldosterone is responsible for the reabsorption of about 2% of filtered sodium in the kidneys, which is nearly equal to the entire sodium content in human blood under normal glomerular filtration rates. Sodium retention is also a response of the distal colon and sweat glands to aldosterone receptor stimulation. Although sustained production of aldosterone requires persistent calcium (Ca2+) entry through low-voltage activated Ca2+ channels, isolated zona glomerulosa cells are considered nonexcitable, with recorded membrane voltages that are too hyperpolarized to permit Ca2+ channels entry. However, mouse zona glomerulosa cells within adrenal slices spontaneously generate membrane potential oscillations of low periodicity; this innate electrical excitability of zona glomerulosa cells provides a platform for the production of a recurrent Ca2+ channels signal that can be controlled by angiotensin II and extracellular potassium, the two major regulators of aldosterone production.[30] Angiotensin II originates from plasmatic angiotensin I after the conversion of angiotensinogen by renin produced by the juxtaglomerular cells of the kidney.[
Glucocorticoids.
Cortisol is the main glucocorticoid produced under normal conditions and its actions include mobilization of fats, proteins, and carbohydrates, but it does not increase under starvation conditions. Additionally, cortisol enhances the activity of other hormones including glucagon and catecholamines. The zona fasciculata secretes a basal level of cortisol but can also produce bursts of the hormone in response to adrenocorticotropic hormone (ACTH) from the anterior pituitary.
Adrenal androgens.
Cells in zona reticularis of the adrenal glands produce male sex hormones, or androgens, the most important of which is DHEA. In general, these hormones do not have an overall effect in the male body, and are converted to more potent androgens such as testosterone and DHT or to estrogens (female sex hormones) in the gonads, acting in this way as a metabolic intermediate.
Epinephrine and norepinephrine.
Epinephrine and norepinephrine are catecholamines that act at adrenergic receptors throughout the body, with effects including constriction of small arteries, dilation of veins, and an increase in the heartrate. Adrenergic receptors are G protein-coupled receptors. This means that they interact with G proteins, a family of enzymes that start a chain of reactions leading to the formation of intracellular second messengers. There are many classes of adrenergic receptors, and the specific response in the cell upon binding of either epinephrine or norepinephrine depends on the mechanism of action of those receptors. For example, when epinephrine or norepinephrine bind to β-adrenergic receptors, the level of cAMP (a second messenger) rises inside the cell, but if they bind to α2-adrenergic receptors in other tissues, the level of cAMP lowers.
Development.
The adrenal glands are composed of two heterogenous types of tissue: in the center there is the adrenal medulla, which produces and releases mostly adrenaline to the blood in stress situations as part of the sympathetic nervous system. Surrounding the medulla is the cortex, which produces a wide variety of steroid hormones. These tissues come from different embryological precursors and have distinct prenatal developments.
Cortex.
Adrenal cortex tissue is derived from the intermediate mesoderm. It first appears 33 days after fertilisation, shows steroidogenic (steroid hormone production) capabilities by the eighth week and undergoes rapid growth during the first trimester of pregnancy. The fetal adrenal cortex is different from its adult counterpart, as it is composed of two distinct zones: the inner fetal zone, which carries most of the hormone-producing activity, and the outer definitive zone, which is in a proliferative phase. The fetal zone produces large amounts of adrenal androgens (male sex hormones) that are used by the placenta for estrogen biosynthesis. Cortical development of the adrenal gland is regulated mostly by ACTH, a hormone produced by the pituitary gland that stimulates cortisol synthesis. During midgestation, the fetal zone occupies most of the cortical volume and produces 100–200 mg/day of DHEA-S, an androgen and precursor of both androgens and estrogens (female sex hormones). Adrenal hormones, especially glucocorticoids such as cortisol are considered essential for prenatal development of organs, particularly for the maturation of the fetal lungs. The adrenal gland decreases in size after birth because of the rapid disappearance of the fetal zone, with a decrease in androgen secretion.
Adrenarche.
During childhood, androgen synthesis and secretion remain low, but several years before puberty (from 6–8 years of age) changes occur in both anatomical and functional aspects of cortical androgen production that lead to increased secretion of DHEA and DHEA-S. These changes are part of a process called adrenarche, which has only been described in humans and some other primates. Adrenarche is independent of ACTH or gonadotropins and correlates with a progressive thickening of the zona reticularis layer of the cortex. Functionally, adrenarche provides a source of androgens for the development of axillary and pubic hair before the beginning of puberty.
Medulla.
The adrenal medulla is derived from neural crest cells, which come from the ectoderm layer of the embryo. These cells migrate from their initial position and aggregate in the vicinity of the dorsal aorta, a primitive blood vessel, which activates the differentiation of these cells through the release of proteins known as BMPs. These cells then undergo a second migration from the dorsal aorta to form the adrenal medulla and other organs of the sympathetic nervous system. Cells of the adrenal medulla are also called chromaffin cells because they contain granules that stain with chromium salts, a characteristic not present in all sympathetic organs. Glucocorticoid production by the adrenal cortex was thought to be responsible for this differentiation, but now the available data suggest that BMP-4 secreted in the adrenal tissue is the primary responsible for the differentiation, and that glucocorticoids have a role in the posterior development of the cells.
Clinical significance.
Corticosteroid overproduction.
Cushing's syndrome.
Cushing's syndrome is the manifestation of glucocorticoid excess. It can be the result of a prolonged treatment with glucocorticoids or be caused by an underlying disease which produces alterations in the HPA axis or the production of cortisol. Causes can be further classified into ACTH-dependent or ACTH-independent. The most common cause of endogenous Cushing's syndrome is a pituitary adenoma which causes an excessive production of ACTH. The disease produces a wide variety of signs and symptoms which include obesity, diabetes, increased blood pressure, excessive body hair (hirsutism), osteoporosis, depression and, most distinctively, stretch marks in the skin, caused by its progressive thinning.
Primary aldosteronism.
When the zona glomerulosa produces excess aldosterone, the result is primary aldosteronism. Causes for this condition are bilateral hyperplasia of the glands and aldosterone-producing adenomas, which is called Conn's syndrome. Primary aldosteronism produces hypertension and electrolyte imbalance, increasing potassium depletion and sodium retention.
Adrenal insufficiency.
Addison's disease.
Addison's disease refers to primary hypoadrenalism, which is a deficiency in glucocorticoid production. In the Western world, Addison's disease is more commonly autoimmune, where the body produces antibodies against cells of the adrenal cortex. Worldwide, the disease is more frequently caused by infection, especially from tuberculosis. A distinctive feature of Addison's disease is hyperpigmentation of the skin, which presents with other nonspecific symptoms such as fatigue. An adrenal crisis is
a medical emergency in which low glucocorticoid and mineralocorticoid levels result in hypovolemic shock and an array of nonspecific symptoms such as vomiting and fever. An adrenal crisis can progressively lead to stupor and coma.
Secondary and tertiary adrenal insufficiency.
Secondary adrenal insufficiency occurs when a part of the body is affected by a condition that impairs the production of hormones in the adrenal cortex. The most common cause of secondary adrenal insufficiency is a pituitary adenoma, which may affect the ability of the pituitary gland to produce adrenocorticotropic hormone (ACTH). This hormone is vital in the event of physiological stress, as it stimulates the adrenal glands into action: if absent, this action will not occur and an Addisonian crisis may follow unless an emergency hydrocortisone injection is given.
Tertiary adrenal insufficiency results from a deficiency in the production of CRH (produced by the hypothalamus).
Congenital adrenal hyperplasia.
Congenital adrenal hyperplasia is a congenital disease in which mutations of enzymes that produce steroid hormones result in a glucocorticoid deficiency and malfunction of the negative feedback loop of the HPA axis. In the HPA axis, cortisol (a glucocorticoid) inhibits the release of CRH and ACTH, hormones that in turn stimulate corticosteroid synthesis. As cortisol cannot be synthesized, these hormones are released in high quantities and stimulate production of other corticosteroids instead. The most common form of congenital adrenal hyperplasia is due to 21-hydroxylase deficiency. 21-hydroxylase is necessary for production of both mineralocorticoids and glucocorticoids, but not androgens. Therefore, ACTH stimulation of the adrenal cortex induces the release of excessive amounts of adrenal androgens, which can lead to the development of ambiguous genitalia and secondary sex characteristics.
Adrenal tumors.
Adrenal tumors are commonly found as incidentalomas, unexpected asymptomatic tumors found during medical imaging. They are seen in around 3.4% of CT scans, and in most cases they are benign adenomas. Adrenal carcinomas are very rare, with an incidence of 1 case per million per year.
Pheochromocytomas are tumors of the adrenal medulla that arise from chromaffin cells. They can produce a variety of nonspecific symptoms, which include headaches, sweating, anxiety and palpitations. Common signs include hypertension and tachycardia. Surgery, especially adrenal laparoscopy, is the most common treatment for small pheochromocytomas.
History.
Bartolomeo Eustachi, an Italian anatomist, is credited with the first description of the adrenal glands in 1564. One of the most recognized works on the adrenal glands came in 1855 with the publication of "On the Constitutional and Local Effects of Disease of the Suprarenal Capsule", by the English physician Thomas Addison. In his monography, Addison described what the French physician George Trousseau would later name Addison's disease, an eponym still used today for a condition of adrenal insufficiency and its related clinical manifestations. In 1894, English physiologists George Oliver and Edward Schafer studied the action of adrenal extracts and observed their pressor effects. In the following decades several physicians experimented with extracts form the adrenal cortex to treat Addison's disease. Edward Calvin Kendall, Philip Hench and Tadeusz Reichstein were then awarded the 1950 Nobel Prize in Physiology or Medicine for the isolation of cortisone from the adrenal cortex.
Etymology.
The adrenal glands are named for their location relative to the kidneys. The term "adrenal" comes from "ad-" (Latin, "near") and "renes" (Latin, "kidney"). Similarly, "suprarenal" is derived from "supra-" (Latin, "above") and "renes".

</doc>
<doc id="2299" url="http://en.wikipedia.org/wiki?curid=2299" title="American Media (publisher)">
American Media (publisher)

American Media, Inc. is an American publisher of magazines, supermarket tabloids, and books.
History.
The modern American Media came into being after Generoso Pope, Jr., longtime owner of the "National Enquirer", died in 1988, and his tabloids came under new ownership. American tabloids began consolidating in 1990, when American Media bought "Star" from Rupert Murdoch. The purchase of Globe Communications (owner of the "Globe" and the "National Examiner") followed nine years later.
American Media is not to be confused with American Media Distribution the international news coverage firm. American Media's corporate headquarters in Boca Raton, Florida, figured prominently in news headlines in late 2001, after an anthrax attack was perpetrated on the company. Since then the corporate headquarters have moved to New York City at 1 Park Avenue in Manhattan, before moving to the Financial District to the former JP Morgan Chase headquarters at 4 New York Plaza. That building was severely damaged by Hurricane Sandy but reopened in February 2013. The CEO, David J. Pecker, travels between the Boca Raton and New York offices while managing the company.
AMI continued to expand after it bought Joe Weider's Weider Publications in 2002. Joe Weider continues to manage control of his magazines under AMI's Weider Publications subsidiary.
American Media also owns Distribution Services, an in-store magazine merchandising company. In fall 2002, it launched the book-publishing imprint, AMI Books.
Roger Altman, through Evercore Partners, bought a controlling stake in American Media in 1999. In 2009, American Media was taken over by its bondholders to keep it out of bankruptcy.
In November 2010, American Media filed for Chapter 11 bankruptcy protection due to nearly $1 billion in debt, and assets of less than $50,000. Its subsidiary, American Media Operations Inc., listed assets of $100 to $500 million and debt of over $1 billion. It exited in December.
In May 2014, American Media announced a decision to shift the headquarters of the "National Enquirer" from Florida, where it had been located since 1971, back to New York City, where it originally began as "The New York Enquirer" in 1926.
In 2015, American Media sold "Shape", "Natural Health", and "Fit Pregnancy" to Meredith.

</doc>
<doc id="2303" url="http://en.wikipedia.org/wiki?curid=2303" title="Aramaic language">
Aramaic language

Aramaic (Classical Syriac: ܐܪܡܝܐ "Arāmāyā") is a family of languages or dialects, belonging to the Semitic family. More specifically, it is a part of the Northwest Semitic subfamily, which also includes Canaanite languages such as Hebrew and Phoenician. The Aramaic script was widely adopted for other languages and is ancestral to both the Arabic and modern Hebrew alphabets.
During its approximately 3,100 years of written history, Aramaic has served variously as a language of administration of empires and as a language of divine worship. It was the lingua franca of the Neo-Assyrian Empire (911-605 BC), Neo-Babylonian Empire (605-539 BC) and Achaemenid Empire (539-323 BC), of the Neo-Assyrian states of Assur, Adiabene, Osroene and Hatra, the Aramean state of Palmyra, and the day-to-day language of Yehud Medinata and of Judaea (539 BC – 70 AD), the language that Jesus probably used the most, the language of large sections of the biblical books of Daniel and Ezra, and is the main language of the Talmud and Syriac Christianity, in particular the Assyrian Church of the East, the Nestorian Church, the Chaldean Catholic Church, the Ancient Church of the East, the Saint Thomas Christian Churches in India, the Syriac Orthodox Church, the Assyrian Pentecostal Church, and the Maronite Church. It is also the language of the Mandeans and their Gnostic religion, Mandeanism, as well as the language of the once widespread but now extinct Manichaean religion.
However, Jewish Aramaic was different from the other forms both in lettering and grammar. Parts of the Dead Sea Scrolls are in Jewish Aramaic showing the Jewish lettering, related to the Hebrew script. Aramaic was also the original language of the Bahrani people of Eastern Arabia.
Aramaic's long history and diverse and widespread use has led to the development of many divergent varieties, which are sometimes considered dialects, though they are distinct enough that they are sometimes considered languages. Therefore, there is not one singular, static Aramaic language; each time and place rather has had its own variation. Aramaic is retained as a liturgical language by certain Eastern Christian churches, in the form of Syriac, the Aramaic variety by which Eastern Christianity was diffused, whether or not those communities once spoke it or another form of Aramaic as their vernacular, but have since shifted to another language as their primary community language.
Modern Aramaic is spoken today as a first language by many scattered, predominantly small, and largely isolated communities of differing Christian, Jewish, and Mandean ethnic groups of West Asia—most numerously by the Assyrians in the form of Assyrian Neo-Aramaic and Chaldean Neo-Aramaic—that have all retained use of the once dominant lingua franca despite subsequent language shifts experienced throughout the Middle East. The Aramaic languages are now considered endangered.
Etymology.
The term "Aramaic", meaning the language of Arameans settling in the region of ancient , ארם or ܐܪܡ (ʾArām), derives from the Hebrew/Aramaic root verb רום (rum) meaning "to rise, be high, piled up, or tall".
"Aram" is used as a proper name of several people in the Torah (Hebrew Bible) including descendants of Shem (Genesis 10:22), Abraham (Genesis 22:21) and Jacob (1 Chronicles 7:34). "Ram" is another Biblical name of one of King David's ancestors (Ruth 4:19) also in use meaning "high, exalted or mighty." "Ram" also occurs as parts of names such as the second syllable of "Avram" (Founder of Judiasm and later called "Avraham" or "Abraham"), "Av" meaning "father" and "ram" meaning exalted.
Ancient , bordering Northern Israel and now called Syria, is considered the linguistic epicenter of Aramaic, the language of the Arameans who settled the area during the Bronze Age circa 3500 BC. There is some confusion about the origin of the language, often mistaken to have originated within Assyria (Iraq). In fact, Arameans carried their language and writing into Mesopotamia by voluntary migration, by forced exile of conquering armies, and by nomadic Chaldean invasions of Babylonia in 1200 BC to 1000 BC. Interestingly, the Christian primary text written in Koine Greek, New Testament, translates the word "Hebrew" as "Aramaic". Part of this confusion is attributed to the Greek naming "Aram" "Syria" (Συρια; Acts 15:41, Galatians 1:21), and at the same time calling "Assyria" (Iraq) "Syria".
Geographic distribution.
During the Neo-Assyrian and the Neo-Babylonian period, Aramaeans, the native speakers of Aramaic, began to settle in greater numbers, at first in Babylonia, and later in Assyria (Upper Mesopotamia, modern-day northern Iraq, northeast Syria, northwest Iran, and south eastern Turkey). The influx eventually resulted in the Neo-Assyrian Empire (911-605 BC) adopting an Akkadian-influenced Imperial Aramaic as the "lingua franca" of its empire. This policy was continued by the short-lived Neo-Babylonian Empire and Median Empire, and all three empires became operationally bilingual in written sources, with Aramaic used alongside Akkadian. The Persian Empire (539-323 BC) continued this tradition, and the extensive influence of these empires led to Aramaic gradually becoming the "lingua franca" of most of western Asia, the Arabian Peninsula, Asia Minor, the Caucasus, and Egypt. Aramaic writing has been found as far north as Hadrian's Wall in Ancient Britain, in the form of inscriptions in Aramaic, made by Assyrian and Aramean soldiers serving in the Roman Legions in northern England during the 2nd century AD.
From the late 7th century AD to the 14th century AD, Aramaic was gradually replaced as the "lingua franca" of the Middle East by Arabic. However, Aramaic remains a spoken, literary, and liturgical language among indigenous Assyrians, and also some Jews. It is spoken by the Assyrians of Iraq, northeastern Syria, southeastern Turkey, and northwest Iran, with diaspora communities in Armenia, Georgia, Azerbaijan and southern Russia. Mandaeans also continue to use Aramaic as a liturgical language, as most are now Arabic-speakers. There are still also a small number of native speakers of Western Aramaic in isolated villages in western Syria. The turbulence of the last two centuries (particularly the Assyrian Genocide) has seen speakers of first-language and literary Aramaic dispersed throughout the world. However, there are a number of sizable Assyrian towns in northern Iraq such as Alqosh, Bakhdida, Bartella, Tel Esqof, and Tel Keppe, and numerous small villages, where Aramaic is still the main spoken language, and many large cities in this region also have Assyrian Aramaic-speaking communities, particularly Mosul, Irbil, Kirkuk, Dohuk, and Hasakah.
Aramaic languages and dialects.
Aramaic is often spoken of as a single language. However, it is in reality a group of related languages, rather than a single monolithic language—something which it has never been. Some Aramaic languages differ more from each other than the Romance languages do among themselves. Its long history, extensive literature, and use by different religious communities are all factors in the diversification of the language. Some Aramaic dialects are mutually intelligible, whereas others are not, not unlike the situation with modern Varieties of Arabic. Some Aramaic languages are known under different names; for example, Syriac is particularly used to describe the Eastern Aramaic of indigenous Christian ethnic communities of Assyrians (a.k.a. Chaldo-Assyrians) in Iraq, southeastern Turkey, northeastern Syria, and northwestern Iran, and Saint Thomas Christians in India. Most dialects can be described as either "Eastern" or "Western", the dividing line being roughly the Euphrates, or slightly west of it. It is also helpful to draw a distinction between those Aramaic languages that are modern living languages (often called "Neo-Aramaic"), those that are still in use as literary languages, and those that are extinct and are only of interest to scholars. Although there are some exceptions to this rule, this classification gives "Modern", "Middle", and "Old" periods, alongside "Eastern" and "Western" areas, to distinguish between the various languages and dialects that are Aramaic.
Writing system.
The earliest Aramaic alphabet was based on the Phoenician alphabet. In time, Aramaic developed its distinctive "square" style. The ancient Israelites and other peoples of Canaan adopted this alphabet for writing their own languages. Thus, it is better known as the Hebrew alphabet today. This is the writing system used in Biblical Aramaic and other Jewish writing in Aramaic. The other main writing system used for Aramaic was developed by Christian communities: a cursive form known as the Syriac alphabet. A highly modified form of the Aramaic alphabet, the Mandaic alphabet, is used by the Mandaeans.
In addition to these writing systems, certain derivatives of the Aramaic alphabet were used in ancient times by particular groups: Nabataean in Petra, for instance and Palmyrenean in Palmyra. In modern times, Turoyo (see below) has sometimes been written in a Latin alphabet.
History.
The history of Aramaic is broken down into three broad periods:
This classification is based on that used by Klaus Beyer*.
Old Aramaic.
The term "Old Aramaic" is used to describe the varieties of the language from its first known use until the point roughly marked by the rise of the Sasanian Empire (224 CE), dominating the influential, eastern dialect region. As such, the term covers over thirteen centuries of the development of Aramaic. This vast time span includes all Aramaic that is now effectively extinct.
The central phase in the development of Old Aramaic was its official use by the Achaemenid Empire (500–330 BCE). The period before this, dubbed "Ancient Aramaic", saw the development of the language from being spoken in Aramaean city-states to become a major means of communication in diplomacy and trade throughout Mesopotamia, the Levant and Egypt. After the fall of the Achaemenid Empire, local vernaculars became increasingly prominent, fanning the divergence of an Aramaic dialect continuum and the development of differing written standards.
Ancient Aramaic.
"Ancient Aramaic" refers to the earliest known period of the language, from its origin until it becomes the "lingua franca" of the Fertile Crescent. It was the language of the Aramaean city-states of Damascus, Hamath and Arpad.
There are inscriptions that evidence the earliest use of the language, dating from the 10th century BC. These inscriptions are mostly diplomatic documents between Aramaean city-states. The alphabet of Aramaic at this early period seems to be based on Phoenician, and there is a unity in the written language. It seems that, in time, a more refined alphabet, suited to the needs of the language, began to develop from this in the eastern regions of Aram. Oddly, the dominance of the Neo-Assyrian Empire under Tiglath-Pileser III over Aram in the middle of the 8th century led to the establishment of Aramaic as a lingua franca of the empire, rather than it being eclipsed by Akkadian.
From 700 BC, the language began to spread in all directions, but lost much of its homogeneity. Different dialects emerged in Assyria, Babylonia, the Levant and Egypt. However, the Akkadian-influenced Aramaic of Assyria, and then Babylon, started to come to the fore. As described in 2 Kings 18:26, Hezekiah, king of Judah, negotiates with Assyrian ambassadors in Aramaic, the author claiming this was so that the common people would not understand. Around 600 BC, Adon, a Canaanite king, used Aramaic to write to an Egyptian Pharaoh.
"Chaldee" or "Chaldean Aramaic" used to be common terms for the Aramaic of the Chaldean dynasty of Babylonia. It was used to describe Biblical Aramaic, which was, however, written in a later style. It is not to be confused with the modern language Chaldean Neo-Aramaic.
Imperial Aramaic.
Around 500 BC, following the Achaemenid conquest of Mesopotamia under Darius I, Aramaic (as had been used in that region) was adopted by the conquerors as the "vehicle for written communication between the different regions of the vast empire with its different peoples and languages. The use of a single official language, which modern scholarship has dubbed Official Aramaic or Imperial Aramaic, can be assumed to have greatly contributed to the astonishing success of the Achaemenids in holding their far-flung empire together for as long as they did". In 1955, Richard Frye questioned the classification of Imperial Aramaic as an "official language", noting that no surviving edict expressly and unambiguously accorded that status to any particular language. Frye reclassifies Imperial Aramaic as the "lingua franca" of the Achaemenid territories, suggesting then that the Achaemenid-era use of Aramaic was more pervasive than generally thought.
Imperial Aramaic was highly standardised; its orthography was based more on historical roots than any spoken dialect, and the inevitable influence of Persian gave the language a new clarity and robust flexibility. For centuries after the fall of the Achaemenid Empire (in 331 BC), Imperial Aramaic – or near enough for it to be recognisable – would remain an influence on the various native Iranian languages. Aramaic script and – as ideograms – Aramaic vocabulary would survive as the essential characteristics of the Pahlavi writing system.
One of the largest collections of Imperial Aramaic texts is that of the Persepolis fortification tablets, which number about five hundred. Many of the extant documents witnessing to this form of Aramaic come from Egypt, and Elephantine in particular (see Elephantine papyri). Of them, the best known is the "Wisdom of Ahiqar", a book of instructive aphorisms quite similar in style to the biblical book of Proverbs. Achaemenid Aramaic is sufficiently uniform that it is often difficult to know where any particular example of the language was written. Only careful examination reveals the occasional loan word from a local language.
A group of thirty Aramaic documents from Bactria have been discovered, and an analysis was published in November 2006. The texts, which were rendered on leather, reflect the use of Aramaic in the 4th century BC Achaemenid administration of Bactria and Sogdiana.
Post-Achaemenid Aramaic.
The conquest by Alexander the Great did not destroy the unity of Aramaic language and literature immediately. Aramaic that bears a relatively close resemblance to that of the 5th century BC can be found right up to the early 2nd century BCE. The Seleucids imposed Greek in the administration of Syria and Mesopotamia from the start of their rule. In the 3rd century BCE, Greek overtook Aramaic as the common language in Egypt and Syria. However, a post-Achaemenid Aramaic continued to flourish from Judaea, Assyria, Mesopotamia, through the Syrian Desert and into northern Arabia and Parthia.
Biblical Aramaic is the Aramaic found in four discrete sections of the Hebrew Bible:
Biblical Aramaic is a somewhat hybrid dialect. It is theorized that some Biblical Aramaic material originated in both Babylonia and Judaea before the fall of the Achaemenid dynasty. According to historical criticism, defiant Jewish propaganda shaped Aramaic Daniel during Seleucid rule. These stories might have existed as oral traditions at their earliest stage. This might be one factor that led to differing collections of Daniel in the Greek Septuagint and the Masoretic Text, which presents a lightly Hebrew-influenced Aramaic.
Under the category of post-Achaemenid is Hasmonaean Aramaic, the official language of Hasmonaean Judaea (142–37 BC). It influenced the Biblical Aramaic of the Qumran texts, and was the main language of non-biblical theological texts of that community. The major Targums, translations of the Hebrew Bible into Aramaic, were originally composed in Hasmonaean. Hasmonaean also appears in quotations in the Mishnah and Tosefta, although smoothed into its later context. It is written quite differently from Achaemenid Aramaic; there is an emphasis on writing as words are pronounced rather than using etymological forms.
Babylonian Targumic is the later post-Achaemenid dialect found in the Targum Onqelos and Targum Jonathan, the "official" targums. The original, Hasmonaean targums had reached Babylon sometime in the 2nd or 3rd century AD. They were then reworked according to the contemporary dialect of Babylon to create the language of the standard targums. This combination formed the basis of Babylonian Jewish literature for centuries to follow.
Galilean Targumic is similar to Babylonian Targumic. It is the mixing of literary Hasmonaean with the dialect of Galilee. The Hasmonaean targums reached Galilee in the 2nd century AD, and were reworked into this Galilean dialect for local use. The Galilean Targum was not considered an authoritative work by other communities, and documentary evidence shows that its text was amended. From the 11th century CE onwards, once the Babylonian Targum had become normative, the Galilean version became heavily influenced by it.
Babylonian Documentary Aramaic is a dialect in use from the 3rd century CE onwards. It is the dialect of Babylonian private documents, and, from the 12th century, all Jewish private documents are in Aramaic. It is based on Hasmonaean with very few changes. This was perhaps because many of the documents in BDA are legal documents, the language in them had to be sensible throughout the Jewish community from the start, and Hasmonaean was the old standard.
Nabataean Aramaic is the language of the Arameo-Arab kingdom of Petra. The kingdom ("c." 200 BC–106 AD) covered the east bank of the Jordan River, the Sinai Peninsula and northern Arabia. Perhaps because of the importance of the caravan trade, the Nabataeans began to use Aramaic in preference to Old North Arabic. The dialect is based on Achaemenid with a little influence from Arabic: "l" is often turned into "n", and there are a few Arabic loanwords. Some Nabataean Aramaic inscriptions exist from the early days of the kingdom, but most are from the first four centuries AD The language is written in a cursive script that is the precursor to the modern Arabic alphabet. The number of Arabic loanwords increases through the centuries, until, in the 4th century, Nabataean merges seamlessly with Arabic.
Palmyrene Aramaic is the dialect that was in use in the Syriac city state of Palmyra in the Syrian Desert from 44 BC to 274 AD. It was written in a rounded script, which later gave way to cursive Estrangela. Like Nabataean, Palmyrene was influenced by Arabic, but to a much lesser degree.
Arsacid Aramaic, that in use during the Arsacid empire (247 BC – 224 AD), represents a continuation of Achaemenid Aramaic, widely spoken throughout the west of the empire. Aramaic continued as the scribal basis for Pahlavi as it developed for the needs of Parthian: using an Aramaic-derived script and incorporating many heterograms, or Aramaic words meant to be read as Parthian ones. The Arsacids saw themselves as a continuation of Achaemenid rule, and so Arsacid Aramaic, more than any other post-Achaemenid dialect, continued the tradition of the chancery of Darius I. Over time, however, it came under the influence of contemporary, spoken Aramaic, Georgian and Persian. After the conquest of the Parthians by the Persian-speaking Sassanids, Arsacid Pahlavi and Aramaic were influential on Sasanian language use.
Late Old Eastern Aramaic.
The dialects mentioned in the last section were all descended from Achaemenid Imperial Aramaic. However, the diverse regional dialects of Late Ancient Aramaic continued alongside these, often as simple, spoken languages. Early evidence for these spoken dialects is known only through their influence on words and names in a more standard dialect. However, these regional dialects became written languages in the 2nd century BC. These dialects reflect a stream of Aramaic that is not dependent on Imperial Aramaic, and shows a clear division between the regions of Mesopotamia, Babylon and the east, and Judah, Syria, and the west.
In the East, the dialects of Palmyrene and Arsacid Aramaic merged with the regional languages to create languages with a foot in Imperial and a foot in regional Aramaic. The written form of Mandaic, the language of the Mandaean religion, was descended from the Arsacid chancery script.
In the kingdom of Osroene, centred on Edessa and founded in 132 BCE, the regional dialect became the official language: Old Syriac. On the upper reaches of the Tigris, East Mesopotamian Aramaic flourished, with evidence from Hatra, Assur and the Tur Abdin. Tatian, the author of the gospel harmony the Diatessaron came from Assyria, and perhaps wrote his work (172 CE) in East Mesopotamian rather than Syriac or Greek. In Babylonia, the regional dialect was used by the Jewish community, Jewish Old Babylonian (from "c." 70 CE). This everyday language increasingly came under the influence of Biblical Aramaic and Babylonian Targumic.
Late Old Western Aramaic.
The western regional dialects of Aramaic followed a similar course to those of the east. They are quite distinct from the eastern dialects and Imperial Aramaic. Aramaic came to coexist with Canaanite dialects, eventually completely displacing Phoenician in the 1st century BCE and Hebrew around the turn of the 4th century CE.
The form of Late Old Western Aramaic used by the Jewish community is best attested, and is usually referred to as Jewish Old Palestinian. Its oldest form is Old East Jordanian, which probably comes from the region of Caesarea Philippi. This is the dialect of the oldest manuscript of Enoch ("c." 170 BCE). The next distinct phase of the language is called Old Judaean into the 2nd century CE. Old Judaean literature can be found in various inscriptions and personal letters, preserved quotations in the Talmud and receipts from Qumran. Josephus' first, non-extant edition of his "Jewish War" was written in Old Judaean.
The Old East Jordanian dialect continued to be used into the 1st century AD by pagan communities living to the east of the Jordan. Their dialect is often then called Pagan Old Palestinian, and it was written in a cursive script somewhat similar to that used for Old Syriac. A Christian Old Palestinian dialect may have arisen from the pagan one, and this dialect may be behind some of the Western Aramaic tendencies found in the otherwise eastern Old Syriac gospels (see Peshitta).
Languages during Jesus' lifetime.
It is generally believed by Christian scholars that in the 1st century CE, Jews in Judaea primarily spoke Aramaic with a decreasing number using Hebrew as a native language. Many learned Hebrew as a liturgical language. Additionally, Koine Greek was the lingua franca or international language of the Middle East in trade, among the Hellenized classes (much like French in the 18th,19th and 20th centuries in Europe), and in the Roman administration. Latin, the language of the Roman army and higher levels of administration, had almost no impact on the linguistic landscape.
In addition to the formal, literary dialects of Aramaic based on Hasmonaean and Babylonian there were a number of colloquial Aramaic dialects. Seven dialects of Western Aramaic were spoken in the vicinity of Judaea in Jesus' time. They were probably distinctive yet mutually intelligible. Old Judaean was the prominent dialect of Jerusalem and Judaea. The region of Engedi had the South-east Judaean dialect. Samaria had its distinctive Samaritan Aramaic, where the consonants "he", "heth" and "‘ayin" all became pronounced as "aleph". Galilean Aramaic, the dialect of Jesus' home region, is only known from a few place names, the influences on Galilean Targumic, some rabbinic literature and a few private letters. It seems to have a number of distinctive features: diphthongs are never simplified into monophthongs. East of the Jordan, the various dialects of East Jordanian were spoken. In the region of Damascus and the Anti-Lebanon mountains, Damascene Aramaic was spoken (deduced mostly from Modern Western Aramaic). Finally, as far north as Aleppo, the western dialect of Orontes Aramaic was spoken.
The three languages influenced one another, especially Hebrew and Aramaic. Hebrew words entered Jewish Aramaic (mostly technical religious words but also everyday words like "‘ēṣ" "wood"). Vice versa, Aramaic words entered Hebrew (not only Aramaic words like "māmmôn" "wealth" but Aramaic ways of using words like making Hebrew "rā’ûi", "seen" mean "worthy" in the sense of "seemly", which is a loan translation of Aramaic "ḥāzê" meaning "seen" and "worthy").
The Greek of the New Testament often preserves non-Greek "semiticisms", including transliterations of Semitic words:
The 2004 film "The Passion of the Christ" used Aramaic for much of its dialogue, specially reconstructed by a scholar, William Fulco, S.J. Where the appropriate words (in 1st century Aramaic) were no longer known, he used the Aramaic of Daniel, 4th-century Syriac and Hebrew as the basis for his work.
Middle Aramaic.
The 3rd century CE is taken as the threshold between Old and Middle Aramaic. During that century, the nature of the various Aramaic languages and dialects begins to change. The descendants of Imperial Aramaic ceased to be living languages, and the eastern and western regional languages began to form vital, new literatures. Unlike many of the dialects of Old Aramaic, much is known about the vocabulary and grammar of Middle Aramaic.
Eastern Middle Aramaic.
Only two of the Old Eastern Aramaic languages continued into this period. In the north of the region, Old Syriac moved into Middle Syriac. In the south, Jewish Old Babylonian became Jewish Middle Babylonian. The post-Achaemenid, Arsacid dialect became the background of the new Mandaic language.
Syriac.
Syriac (also "Middle Syriac") is the classical, literary, liturgical and often spoken language of Syriac Christians to this day, particularly the Assyrian church of the East, Chaldean Catholic Church, Ancient Church of the East, Syriac Orthodox and Saint Thomas Christian churches. It originated in Northern Mesopotamia. Its golden age was the 4th to 6th centuries. This period began with the translation of the Bible into the language: the Peshitta and the masterful prose and poetry of Ephrem the Syrian. Middle Syriac, unlike its forebear, is a thoroughly Christian language, although in time it became the language of those opposed to the Byzantine leadership of the Church of the East. Missionary activity by Assyrian and Nestorian Christians led to the spread of Syriac from Mesopotamia through Persia and into Central Asia, India and China.
Jewish Middle Babylonian Aramaic.
Jewish Middle Babylonian is the language employed by Jewish writers in Babylonia between the 4th century and the 11th century AD. It is most commonly identified with the language of the Babylonian Talmud (which was completed in the 7th century) and of post-Talmudic (Geonic) literature, which are the most important cultural products of Babylonian Jewry. The most important epigraphic sources for the dialect are the hundreds of Aramaic magic bowls written in the Jewish script.
Mandaic.
Mandaic, spoken by the Mandeans of Iraq, is a sister dialect to Jewish Babylonian Aramaic, though it is both linguistically and culturally distinct. Classical Mandaic is the language in which the Mandaean's Gnostic religious literature was composed. It is characterized by a highly phonetic orthography.
Western Middle Aramaic.
The dialects of Old Western Aramaic continued with Jewish Middle Palestinian (in Hebrew "square script"), Samaritan Aramaic (in the old Hebrew script) and Christian Palestinian (in cursive Syriac script). Of these three, only Jewish Middle Palestinian continued as a written language.
Jewish Middle Palestinian Aramaic.
In 135, after the Bar Kokhba revolt, many Jewish leaders, expelled from Jerusalem, moved to Galilee. The Galilean dialect thus rose from obscurity to become the standard among Jews in the west. This dialect was spoken not only in Galilee, but also in the surrounding parts. It is the linguistic setting for the Jerusalem Talmud (completed in the 5th century), Palestinian targumim (Jewish Aramaic versions of scripture), and midrashim (biblical commentaries and teaching). The standard vowel pointing for the Hebrew Bible, the Tiberian system (7th century), was developed by speakers of the Galilean dialect of Jewish Middle Palestinian. Classical Hebrew vocalisation, therefore, in representing the Hebrew of this period, probably reflects the contemporary pronunciation of this Aramaic dialect.
Middle Judaean, the descendant of Old Judaean, is no longer the dominant dialect, and was used only in southern Judaea (the variant Engedi dialect continued throughout this period). Likewise, Middle East Jordanian continues as a minor dialect from Old East Jordanian. The inscriptions in the synagogue at Dura-Europos are either in Middle East Jordanian or Middle Judaean.
Samaritan Aramaic.
The Aramaic dialect of the Samaritan community is earliest attested by a documentary tradition that can be dated back to the 4th century. Its modern pronunciation is based on the form used in the 10th century.
Israelite Christian Aramaic.
The language of Western-Aramaic-speaking Christians is evidenced from the 6th century, but probably existed two centuries earlier. The language itself comes from Christian Old Palestinian, but its writing conventions were based on early Middle Syriac, and it was heavily influenced by Greek. For example, the name Jesus, although "Išo" in Aramaic, is written "Yesûs" in Christian Israelite.
Modern Aramaic.
Over 400,000 people of various communities from across the Middle East, and recent emigrants who have moved out of these communities, speak one of several varieties of Modern Aramaic (also called "Neo-Aramaic") natively, including Christians, Jews, Mandaeans and Muslims. Having lived in remote areas as insulated communities, the remaining modern speakers of Aramaic dialects escaped the linguistic pressures experienced by others during the large-scale language shifts that saw the proliferation of other tongues among those who previously did not speak them, most recently the Arabization of the Middle East and North Africa by Muslim Arabians, during their spread of Islam. Most of the people of that region who converted to Islam, and many from the remaining unconverted population, also adopted Arabic as their first language. The Aramaic-speaking peoples such as Assyrians have preserved their traditions with schools, printing presses and now with electronic media.
The Neo-Aramaic languages are now farther apart in their mutual intelligibility than perhaps they have ever been. Instability throughout the Middle East over the past century has led to a worldwide diaspora of Aramaic-speakers. For Aramaic-speaking Jews, 1950 is a watershed year: the founding of the state of Israel (1948) and consequent Jewish exodus from Arab lands, including Iraq, led most Iraqi Jews, both Aramaic-speaking and Arabic-speaking Iraqi Jews, to emigrate to Israel. However, immigration to Israel has led to the Jewish Neo-Aramaic (and Jewish Iraqi Arabic) being replaced by Modern Hebrew (Ivrit) among children of the migrants. The practical extinction of many Jewish dialects seems imminent.
Modern Eastern Aramaic.
Modern Eastern Aramaic exists in a wide variety of dialects and languages. There is significant difference between the Aramaic spoken by Jews, Chaldo-Assyrian Christians, and Mandaeans.
The Christian languages are often called Modern Syriac (or Neo-Syriac, particularly when referring to their literature), being deeply influenced by the literary and liturgical language of Middle Syriac. However, they also have roots in numerous, previously unwritten, local Aramaic varieties, and are not purely the direct descendants of the language of Ephrem the Syrian. The varieties are not all mutually intelligible. The principal Christian varieties are Assyrian Neo-Aramaic and Chaldean Neo-Aramaic used by the ethnic Assyrians of Iraq, south east Turkey, Iran and north east Syria.
The Judeo-Aramaic languages are now mostly spoken in Israel, and most are facing extinction. The Jewish varieties that have come from communities that once lived between Lake Urmia and Mosul are not all mutually intelligible. In some places, for example Urmia, Christians and Jews speak mutually unintelligible varieties of Modern Eastern Aramaic in the same place. In others, the Nineveh Plains around Mosul for example, the varieties of the two faith communities are similar enough to allow conversation.
Modern Western Syriac (also called Central Neo-Aramaic, being in between Western Neo-Aramaic and Eastern Neo-Syriac) is generally represented by Turoyo, the language of the Tur Abdin. A related language, Mlahsô, has recently become extinct.
Mandaeans, living in the Khūzestān Province of Iran and scattered throughout Iraq, speak Modern Mandaic. It is quite distinct from any other Aramaic variety.
Modern Central Aramaic.
Central Neo-Aramaic consists of Turoyo and the recently extinct Mlahsô.
Modern Western Aramaic.
Very little remains of Western Aramaic. It is still spoken in the villages of Ma'loula, Bakh`a and Jubb`adin on Syria's side of the Anti-Lebanon mountains, as well as by some people who migrated from these villages, to Damascus and other larger towns of Syria. All these speakers of Modern Western Aramaic are fluent in Arabic, which has now become the main language in these villages.
Sounds.
Each dialect of Aramaic has its own distinctive pronunciation, and it would not be feasible here to go into all these properties. Aramaic has a phonological palette of 25 to 40 distinct phonemes. Some modern Aramaic pronunciations lack the series of "emphatic" consonants, and some have borrowed from the inventories of surrounding languages, particularly Arabic, Azerbaijani, Kurdish, Persian and Turkish.
Vowels.
As with most Semitic languages, Aramaic can be thought of as having three basic sets of vowels:
These vowel groups are relatively stable, but the exact articulation of any individual is most dependent on its consonantal setting.
The open vowel is an open near-front unrounded vowel ("short" "a", somewhat like the first vowel in the English "batter", [a]). It usually has a back counterpart ("long" "a", like the "a" in "father", [ɑ], or even tending to the vowel in "caught", [ɔ]), and a front counterpart ("short" "e", like the vowel in "head", [ɛ]). There is much correspondence between these vowels between dialects. There is some evidence that Middle Babylonian dialects did not distinguish between the short "a" and short "e". In West Syriac dialects, and possibly Middle Galilean, the long "a" became the "o" sound. The open "e" and back "a" are often indicated in writing by the use of the letters "alaph" (a glottal stop) or "he" (like the English "h").
The close front vowel is the "long" "i" (like the vowel in "need", [i]). It has a slightly more open counterpart, the "long" "e", as in the final vowel of "café" ([e]). Both of these have shorter counterparts, which tend to be pronounced slightly more open. Thus, the short close "e" corresponds with the open "e" in some dialects. The close front vowels usually use the consonant "y" as a mater lectionis.
The close back vowel is the "long" "u" (like the vowel in "school", [u]). It has a more open counterpart, the "long" "o", like the vowel in "low" ([o]). There are shorter, and thus more open, counterparts to each of these, with the short close "o" sometimes corresponding with the long open "a". The close back vowels often use the consonant "w" to indicate their quality.
Two basic diphthongs exist: an open vowel followed by "y" ("ay"), and an open vowel followed by "w" ("aw"). These were originally full diphthongs, but many dialects have converted them to "e" and "o" respectively.
The so-called "emphatic" consonants (see the next section) cause all vowels to become mid-centralised.
Consonants.
The various alphabets used for writing Aramaic languages have twenty-two letters (all of which are consonants). Some of these letters, though, can stand for two or three different sounds (usually a plosive and a fricative at the same point of articulation). Aramaic classically uses a series of lightly contrasted plosives and fricatives:
Each member of a certain pair is written with the same letter of the alphabet in most writing systems (that is, "p" and "f" are written with the same letter), and are near allophones.
A distinguishing feature of Aramaic phonology (and that of Semitic languages in general) is the presence of "emphatic" consonants. These are consonants that are pronounced with the root of the tongue retracted, with varying degrees of pharyngealization and velarization. Using their alphabetic names, these emphatics are:
Ancient Aramaic may have had a larger series of emphatics, and some Neo-Aramaic languages definitely do. Not all dialects of Aramaic give these consonants their historic values.
Overlapping with the set of emphatics are the "guttural" consonants. They include Ḥêṯ and ʽAyn from the emphatic set, and add ʼĀlap̄ (a glottal stop) and Hê (as the English "h").
Aramaic classically has a set of four sibilants (Ancient Aramaic may have had six):
In addition to these sets, Aramaic has the nasal consonants "m" and "n", and the approximants "r" (usually an alveolar trill), "l", "y" and "w".
Historical sound changes.
Six broad features of sound change can be seen as dialect differentials:
Grammar.
As with other Semitic languages, Aramaic morphology (the way words are formed) is based on the triliteral root. The root consists of three consonants and has a basic meaning, for example, "k-t-b" has the meaning of 'writing'. This is then modified by the addition of vowels and other consonants to create different nuances of the basic meaning:
Nouns and adjectives.
Aramaic nouns and adjectives are inflected to show gender, number and state. The latter somewhat akin to case in Indo-European languages.
Aramaic has two grammatical genders, masculine and feminine. The feminine absolute singular is usually marked by the ending "-â", which is usually written with an aleph. Jewish varieties, however, often use he instead, following Hebrew orthography.
Nouns can be either singular or plural, but an additional "dual" number exists for nouns that usually come in pairs. The dual number gradually disappeared from Aramaic over time and has little influence in Middle and Modern Aramaic.
Aramaic nouns and adjectives can exist in one of three states; these states correspond in part to the role of cases in other languages.
Whereas other Northwest Semitic languages, like Hebrew, have the absolute and construct states, the emphatic/determined state is a unique feature to Aramaic. Case endings, as in Ugaritic, probably existed in a very early stage of the language, and glimpses of them can be seen in a few compounded proper names. However, as most were short final vowels, they were never written, and the few characteristic long vowels of the masculine plural accusative and genitive are not clearly evidenced in inscriptions. Often, the direct object is marked by a prefixed "l-" (the preposition "to") if it is definite.
Adjectives agree with their nouns in number and gender but agree in state only if attributive. Predicative adjectives are in the absolute state regardless of the state of their noun (a copula may or may not be written). Thus, an attributive adjective to an emphatic noun, as in the phrase "the good king", is written also in the emphatic state "malkâ ṭāḇâ"—king[emph.] good[emph.]. In comparison, the predicative adjective, as in the phrase "the king is good", is written in the absolute state "ṭāḇ malkâ"—good[abs.] king[emph.].
The final "-â" in a number of these suffixes is written with the letter aleph. However, some Jewish Aramaic texts employ the letter he for the feminine absolute singular. Likewise, some Jewish Aramaic texts employ the Hebrew masculine absolute singular suffix "-îm" instead of "-în". The masculine determined plural suffix, "-ayyâ", has an alternative version, "-ê". The alternative is sometimes called the "gentilic plural" for its prominent use in ethnonyms ("yəhûḏāyê", 'the Jews', for example). This alternative plural is written with the letter aleph, and came to be the only plural for nouns and adjectives of this type in Syriac and some other varieties of Aramaic. The masculine construct plural, "-ê", is written with yodh. In Syriac and some other variants this ending is diphthongized to "-ai".
Possessive phrases in Aramaic can either be made with the construct state or by linking two nouns with the relative particle "d[î]-". As use of the construct state almost disappears from the Middle Aramaic period on, the latter method became the main way of making possessive phrases.
For example, the various forms of possessive phrases (for "the handwriting of the queen") are:
In Modern Aramaic, the last form is by far the most common. In Biblical Aramaic, the last form is virtually absent.
Verbs.
The Aramaic verb has gradually evolved in time and place, varying between varieties of the language. Verb forms are marked for person (first, second or third), number (singular or plural), gender (masculine or feminine), tense (perfect or imperfect), mood (indicative, imperative, jussive or infinitive) and voice (active, reflexive or passive). Aramaic also employs a system of conjugations, or verbal stems, to mark intensive and extensive developments in the lexical meaning of verbs.
Aspectual tense.
Aramaic has two proper tenses: perfect and imperfect. These were originally aspectual, but developed into something more like a preterite and future. The perfect is unmarked, while the imperfect uses various preformatives that vary according to person, number and gender. In both tenses the third-person singular masculine is the unmarked form from which others are derived by addition of afformatives (and preformatives in the imperfect). In the chart below (on the root K-T-B, meaning "to write"), the first form given is the usual form in Imperial Aramaic, while the second is Classical Syriac.
Conjugations or verbal stems.
Like other Semitic languages, Aramaic employs a number of conjugations, or verbal stems, to extend the lexical coverage of verbs. The basic conjugation of the verb is called the "ground stem", or "G-stem". Following the tradition of mediaeval Arabic grammarians, it is more often called the Pə‘al (also written Pe‘al), using the form of the triliteral root P-‘-L, meaning "to do". This stem carries the basic lexical meaning of the verb.
By doubling of the second radical, or root letter, the D-stem or Pa‘‘el is formed. This is often an intensive development of the basic lexical meaning. For example, "qəṭal" means "he killed", whereas "qaṭṭel" means "he slew". The precise relationship in meaning between the two stems differs for every verb.
A preformative, which can be "ha-", "a-" or "ša-", creates the C-stem or variously the Hap̄‘el, Ap̄‘el or Šap̄‘el (also spelt Haph‘el, Aph‘el and Shaph‘el). This is often an extensive or causative development of the basic lexical meaning. For example, "ṭə‘â" means "he went astray", whereas "aṭ‘î" means "he deceived". The Šap̄‘el is the least common variant of the C-stem. Because this variant is standard in Akkadian, it is possible that its use in Aramaic represents loanwords from that language. The difference between the variants Hap̄‘el and Ap̄‘el appears to be the gradual dropping of the initial "h" sound in later Old Aramaic. This is noted by the respelling of the older he preformative with aleph.
These three conjugations are supplemented with three derived conjugations, produced by the preformative "hiṯ-" or "eṯ-". The loss of the initial "h" sound occurs similarly to that in the form above. These three derived stems are the Gt-stem, Hiṯpə‘el or Eṯpə‘el (also written Hithpe‘el or Ethpe‘el), the Dt-stem, Hiṯpa‘‘al or Eṯpa‘‘al (also written Hithpa‘‘al or Ethpa‘‘al), and the Ct-stem, Hiṯhap̄‘al, Ettap̄‘al, Hištap̄‘al or Eštap̄‘al (also written Hithhaph‘al, Ettaph‘al, Hishtaph‘al or Eshtaph‘al). Their meaning is usually reflexive, but later became passive. However, as with other conjugations, actual meaning differs from verb to verb.
Not all verbs utilise all of these conjugations, and, in some, the G-stem is not used. In the chart below (on the root K-T-B, meaning "to write"), the first form given is the usual form in Imperial Aramaic, while the second is Classical Syriac.
Aramaic also has two proper tenses: the perfect and the imperfect. In Imperial Aramaic, the participle began to be used for a historical present. Perhaps under influence from other languages, Middle Aramaic developed a system of composite tenses (combinations of forms of the verb with pronouns or an auxiliary verb), allowing for narrative that is more vivid. The syntax of Aramaic (the way sentences are put together) usually follows the order verb–subject–object (VSO). Imperial (Persian) Aramaic, however, tended to follow a S-O-V pattern (similar to Akkadian), which was the result of Persian syntactic influence.
Aramaic word processors.
The World's first Aramaic language word processing software was developed in 1986–1987 in Kuwait by information technology professional Sunil Sivanand (1953– ), who is now Managing Director and Chief Technology Architect at Acette. Sunil Sivanand did most of the character generation and programming work on a first generation, twin disk drive IBM Personal Computer. The project was sponsored by Daniel Benjamin, who was a patron of a group of individuals working worldwide to preserve and revive the Aramaic language.

</doc>
<doc id="2304" url="http://en.wikipedia.org/wiki?curid=2304" title="Saint Titus">
Saint Titus

Titus (; Greek: Τίτος) was an early Christian missionary and Church leader, a companion and disciple of Paul the Apostle, mentioned in several of the Pauline epistles including the Epistle to Titus. He is believed to be a Gentile converted to Christianity by Paul and, according to tradition, was consecrated by him as Bishop of the Island of Crete. Titus brought a fundraising letter from Paul to Corinth, to collect for the poor in Jerusalem. Later, on Crete, Titus appointed presbyters (elders) in every city and remained there into his old age, dying in the city of Candia (modern Heraklion).
Life.
Titus was a Greek, apparently from Antioch, who is said to have studied Greek philosophy and poetry in his early years. He seems to have been converted by Paul, whereupon he served as Paul's secretary and interpreter. In the year 51, Titus accompanied Paul to the council held at Jerusalem, on the subject of the Mosaic rites. Although the apostle had consented to the circumcision of Timothy, in order to render his ministry acceptable among the Jews, he would not allow the same in regard to Titus, so as not to seem in agreement with those who would require it for Gentile converts.
Towards the close of the year 56, Paul sent Titus from Ephesus to Corinth, with full commission to remedy the several subjects of scandal and dissensions in that church. From Corinth, Paul then sent Titus to organize the collections of alms for the Christians at Jerusalem. Titus was a peacemaker, administrator, and missionary. He rejoined Paul in Macedon, and cheered him with the tidings he brought from Corinth.
St. Paul, after his first imprisonment, returning from Rome stopped at the island of Crete to preach. The necessities of other churches requiring his presence elsewhere, he ordained his disciple Titus bishop of that island, and left him to finish the work he had begun. Chrysostom says that this is an indication of the esteem St. Paul held for Titus.
Paul summoned Titus from Crete to join him at Nicopolis in Epirus. Later, Titus travelled to Dalmatia. The New Testament does not record his death.
It has been argued that the name "Titus" in 2 Corinthians and Galatians is nothing more than an informal name used by Timothy, implied already by the fact that even though both are said to be long-term close companions of Paul, they never appear in common scenes. The theory proposes that a number of passages—1 Cor. 4:17, 16.10; 2 Cor. 2:13, 7:6, 13-14, 12:18; and Acts 19.22—all refer to the same journey of a single individual, Titus-Timothy. 2 Timothy seems to dispute this, by claiming that Titus has gone to Dalmatia. () The fact that Paul made a point of circumcising Timothy () but refused to circumcise Titus () indicates that they are different men.
Veneration.
The feast day of Titus was not included in the Tridentine Calendar. When added in 1854, it was assigned to 6 February. In 1969, the Roman Catholic Church assigned the feast to 26 January so as to celebrate the two disciples of Paul, Titus and Timothy, on the day after the feast of the Conversion of St. Paul. The Evangelical Lutheran Church in America celebrates these two, together with Silas, on the same date. The Orthodox Church commemorates him on 25 August and on 4 January.
His relics, now consisting of only his skull, are venerated in the Church of St. Titus, Heraklion, Crete to which it was returned in 1966<ref name="The Orthodox Messenger, v. 8(7/8), July/Aug 1997"></ref> after being removed to Venice during the Turkish occupation.
St. Titus is the patron saint of the United States Army Chaplain Corps. The Corps has established the Order of Titus Award. According to the Department of Defense, the "Order of Titus award is the only award presented by the Chief of Chaplains to recognize outstanding performance of ministry by chaplains and chaplain assistants. The Order of Titus is awarded for meritorious contributions to the unique and highly visible Unit Ministry Team Observer Controller Program. The award recognizes the great importance of realistic, doctrinally guided combat ministry training in ensuring the delivery of prevailing religious support to the American Soldier." 

</doc>
<doc id="2308" url="http://en.wikipedia.org/wiki?curid=2308" title="Actinide">
Actinide

The actinide or actinoid (IUPAC nomenclature) series encompasses the 15 metallic chemical elements with atomic numbers from 89 to 103, actinium through lawrencium.
The actinide series derives its name from the first element in the series, actinium. The informal chemical symbol An is used in general discussions of actinide chemistry to refer to any actinide. All but one of the actinides are f-block elements, corresponding to the filling of the 5f electron shell; lawrencium, a d-block element, is also generally considered an actinide. In comparison with the lanthanides, also mostly f-block elements, the actinides show much more variable valence. They all have very large atomic and ionic radii and exhibit an unusually large range of physical properties. While actinium and the late actinides (from americium onwards) behave similarly to the lanthanides, the elements thorium through neptunium are much more similar to transition metals in their chemistry.
Of the actinides, primordial thorium and uranium occur naturally in substantial quantities and small amounts of persisting natural plutonium have also been identified. The radioactive decay of uranium produces transient amounts of actinium and protactinium, and atoms of neptunium, americium, curium, berkelium and californium are occasionally produced from transmutation reactions in uranium ores. The other actinides are purely synthetic elements. Nuclear weapons tests have released at least six actinides heavier than plutonium into the environment; analysis of debris from a 1952 hydrogen bomb explosion showed the presence of americium, curium, berkelium, californium, einsteinium and fermium.
All actinides are radioactive and release energy upon radioactive decay; naturally occurring uranium and thorium, and synthetically produced plutonium are the most abundant actinides on Earth. These are used in nuclear reactors and nuclear weapons. Uranium and thorium also have diverse current or historical uses, and americium is used in the ionization chambers of most modern smoke detectors.
In presentations of the periodic table, the lanthanides and the actinides are customarily shown as two additional rows below the main body of the table, with placeholders or else a selected single element of each series (either lanthanum or lutetium, and either actinium or lawrencium, respectively) shown in a single cell of the main table, between barium and hafnium, and radium and rutherfordium, respectively. This convention is entirely a matter of aesthetics and formatting practicality; a rarely used wide-formatted periodic table inserts the lanthanide and actinide series in their proper places, as parts of the table's sixth and seventh rows (periods).
Discovery, isolation and synthesis.
Like the lanthanides, the actinides form a family of elements with similar properties. Within the actinides, there are two overlapping groups: transuranium elements, which follow uranium in the periodic table—and transplutonium elements, which follow plutonium. Compared to the lanthanides, which (except for promethium) are found in nature in appreciable quantities, most actinides are rare. The most abundant, or easy to synthesize actinides are uranium and thorium, followed by plutonium, americium, actinium, protactinium and neptunium.
The existence of transuranium elements was suggested by Enrico Fermi based on his experiments in 1934. However, even though four actinides were known by that time, it was not yet understood that they formed a family similar to lanthanides. The prevailing view that dominated early research into transuranics was that they were regular elements in the 7th period, with thorium, protactinium and uranium corresponding to 6th-period hafnium, tantalum and tungsten, respectively. Synthesis of transuranics gradually undermined this point of view. By 1944 an observation that curium failed to exhibit oxidation states above 4 (whereas its supposed 6th period homolog, platinum, can reach oxidation state of 7) prompted Glenn Seaborg to formulate a so-called "actinide hypothesis". Studies of known actinides and discoveries of further transuranic elements provided more data in support of this point of view, but the phrase "actinide hypothesis" (the implication being that "hypothesis" is something that has not been decisively proven) remained in active use by scientists through the late 1950s.
At present, there are two major methods of producing isotopes of transplutonium elements: irradiation of the lighter elements with either neutrons or accelerated charged particles. The first method is most important for applications, as only neutron irradiation using nuclear reactors allows the production of sizeable amounts of synthetic actinides; however, it is limited to relatively light elements. The advantage of the second method is that elements heavier than plutonium, as well as neutron-deficient isotopes, can be obtained, which are not formed during neutron irradiation.
In 1962–1966, there were attempts in the United States to produce transplutonium isotopes using a series of six underground nuclear explosions. Small samples of rock were extracted from the blast area immediately after the test to study the explosion products, but no isotopes with mass number greater than 257 could be detected, despite predictions that such isotopes would have relatively long half-lives of α-decay. This inobservation was attributed to spontaneous fission owing to the large speed of the products and to other decay channels, such as neutron emission and nuclear fission.
From actinium to uranium.
Uranium and thorium were the first actinides discovered. Uranium was identified in 1789 by the German chemist Martin Heinrich Klaproth in pitchblende ore. He named it after the planet Uranus, which had been discovered only eight years earlier. Klaproth was able to precipitate a yellow compound (likely sodium diuranate) by dissolving pitchblende in nitric acid and neutralizing the solution with sodium hydroxide. He then reduced the obtained yellow powder with charcoal, and extracted a black substance that he mistook for metal. Only 60 years later, the French scientist Eugène-Melchior Péligot identified it with uranium oxide. He also isolated the first sample of uranium metal by heating uranium tetrachloride with potassium. The atomic mass of uranium was then calculated as 120, but Dmitri Mendeleev in 1872 corrected it to 240 using his periodicity laws. This value was confirmed experimentally in 1882 by K. Zimmerman.
Thorium oxide was discovered by Friedrich Wöhler in the mineral, which was found in Norway (1827). Jöns Jacob Berzelius characterized this material in more detail by in 1828. By reduction of thorium tetrachloride with potassium, he isolated the metal and named it thorium after the Norse god of thunder and lightning Thor. The same isolation method was later used by Péligot for uranium.
Actinium was discovered in 1899 by André-Louis Debierne, an assistant of Marie Curie, in the pitchblende waste left after removal of radium and polonium. He described the substance (in 1899) as similar to titanium and (in 1900) as similar to thorium. The discovery of actinium by Debierne was however questioned in 1971 and 2000, arguing that Debierne's publications in 1904 contradicted his earlier work of 1899–1900. The name actinium comes from the Greek "aktis, aktinos" (ακτίς, ακτίνος), meaning beam or ray. This metal was discovered not by its own radiation but by the radiation of the daughter products. Owing to the close similarity of actinium and lanthanum and low abundance, pure actinium could only be produced in 1950. The term actinide was probably introduced by Victor Goldschmidt in 1937.
Protactinium was possibly isolated in 1900 by William Crookes. It was first identified in 1913, when Kasimir Fajans and Oswald Helmuth Göhring encountered the short-lived isotope 234mPa (half-life 1.17 minutes) during their studies of the 238U decay. They named the new element "brevium" (from Latin "brevis" meaning brief); the name was changed to "protoactinium" (from Greek πρῶτος + ἀκτίς meaning "first beam element") in 1918 when two groups of scientists, led by the Austrian Lise Meitner and Otto Hahn of Germany and Frederick Soddy and John Cranston of Great Britain, independently discovered 231Pa. The name was shortened to "Protactinium" in 1949. This element was little characterized until 1960, when A. G. Maddock and his co-workers in the U.K. produced 130 grams of protactinium from 60 tonnes of waste left after extraction of uranium from its ore.
Neptunium and above.
Neptunium (named for the planet Neptune, the next planet out from Uranus, after which uranium was named) was discovered by Edwin McMillan and Philip H. Abelson in 1940 in Berkeley, California. They produced the 239Np isotope (half-life = 2.4 days) by bombarding uranium with slow neutrons. It was the first transuranium element produced synthetically.
Transuranium elements do not occur in sizeable quantities in nature and are commonly synthesized via nuclear reactions conducted with nuclear reactors. For example, under irradiation with reactor neutrons, uranium-238 partially converts to plutonium-239:
In this way, Enrico Fermi with collaborators, using the first nuclear reactor Chicago Pile-1, obtained significant amounts of plutonium-239, which were then used in nuclear weapons.
Actinides with the highest mass numbers are synthesized by bombarding uranium, plutonium, curium and californium with ions of nitrogen, oxygen, carbon, neon or boron in a particle accelerator. So, nobelium was produced by bombarding uranium-238 with neon-22 as
Compounds.
Oxides and hydroxides.
Some actinides can exists in several oxide forms such as An2O3, AnO2, An2O5 and AnO3. For all actinides, oxides AnO3 are amphoteric and An2O3, AnO2 and An2O5 are basic, they easily react with water, forming bases:
These bases are poorly soluble in water and by their activity are close to the hydroxides of rare-earth metals. The strongest base is of actinium. All compounds of actinium are colorless, except for black actinium sulfide (Ac2S3). Dioxides of tetravalent actinides crystallize in the cubic system, same as in calcium fluoride.
Thorium reacting with oxygen exclusively forms dioxide:
Thorium dioxide is a refractory material with the highest melting point among any known oxide (3390 °C). Adding 0.8–1% ThO2 to tungsten stabilizes its structure, so the doped filaments have better mechanical stability to vibrations. To dissolve ThO2 in acids, it is heated to 500–600 °C; heating above 600 °C produces a very resistant to acids and other reagents form of ThO2. Small addition of fluoride ions catalyses dissolution of thorium dioxide in acids.
Two protactinium oxides were obtained: PaO2 (black) and Pa2O5(white); the former is isomorphic with ThO2 and the latter is easier to obtain. Both oxides are basic, and Pa(OH)5 is a weak, poorly soluble base.
Decomposition of certain salts of uranium, for example UO2(NO3)·6H2O in air at 400 °C, yields orange or yellow UO3. This oxide is amphoteric and forms several hydroxides, the most stable being UO2(OH)2.
Reaction of uranium(VI) oxide with hydrogen results in uranium dioxide, which is similar in its properties with ThO2. This oxide is also basic and corresponds to the uranium hydroxide (U(OH)4).
Plutonium, neptunium and americium form two basic oxides: An2O3 and AnO2. Neptunium trioxide is unstable; thus, only Np3O8 could be obtained so far. However, the oxides of plutonium and neptunium with the chemical formula AnO2 and An2O3 are well characterized.
Salts.
Actinides easily react with halogens forming salts with the formulas MX3 and MX4 (X = halogen). So the first berkelium compound, BkCl3, was synthesized in 1962 with an amount of 3 nanograms. Like the halogens of rare earth elements, actinide chlorides, bromides, and iodides are water soluble, and fluorides are insoluble. Uranium easily yields a colorless hexafluoride, which sublimates at a temperature of 56.5 °C; because of its volatility, it is used in the separation of uranium isotopes with gas centrifuge or gaseous diffusion. Actinide hexafluorides have properties close to anhydrides. They are very sensitive to moisture and hydrolyze forming AnO2F2. The pentachloride and black hexachloride of uranium were synthesized, but they are both unstable.
Action of acids on actinides yields salts, and if the acids are non-oxidizing then the actinide in the salt is in low-valence state:
However, in these reactions the regenerating hydrogen can react with the metal, forming the corresponding hydride. Uranium reacts with acids and water much more easily than thorium.
Actinide salts can also be obtained by dissolving the corresponding hydroxides in acids. Nitrates, chlorides, sulfates and perchlorates of actinides are water soluble. When crystallizing from aqueous solutions, these salts forming a hydrates, such as Th(NO3)4·6H2O, Th(SO4)2·9H2O and Pu2(SO4)3·7H2O. Salts of high-valence actinides easily hydrolyze. So, colorless sulfate, chloride, perchlorate and nitrate of thorium transform into basic salts with formulas Th(OH)2SO4 and Th(OH)3NO3. The solubility and insolubility of trivalent and tetravalent actinides is like that of lanthanide salts. So phosphates, fluorides, oxalates, iodates and carbonates of actinides are weakly soluble in water; they precipitate as hydrates, such as ThF4·3H2O and Th(CrO4)2·3H2O.
Actinides with oxidation state +6, except for the AnO22+-type cations, form [AnO4]2−, [An2O7]2− and other complex anions. For example, uranium, neptunium and plutonium form salts of the Na2UO4 (uranate) and (NH4)2U2O7 (diuranate) types. In comparison with lanthanides, actinides more easily form coordination compounds, and this ability increases with the actinide valence. Trivalent actinides do not form fluoride coordination compounds, whereas tetravalent thorium forms K2ThF6, KThF5, and even K5ThF9 complexes. Thorium also forms the corresponding sulfates (for example Na2SO4·Th (SO4)2·5H2O), nitrates and thiocyanates. Salts with the general formula An2Th(NO3)6·"n"H2O are of coordination nature, with the coordination number of thorium equal to 12. Even easier is to produce complex salts of pentavalent and hexavalent actinides. The most stable coordination compounds of actinides – tetravalent thorium and uranium – are obtained in reactions with diketones, e.g. acetylacetone.
Applications.
While actinides have some established daily-life applications, such as in smoke detectors (americium) and gas mantles (thorium), they are mostly used in nuclear weapons and use as a fuel in nuclear reactors. The last two areas exploit the property of actinides to release enormous energy in nuclear reactions, which under certain conditions may become self-sustaining chain reaction.
The most important isotope for nuclear power applications is uranium-235. It is used in the thermal reactor, and its concentration in natural uranium does not exceed 0.72%. This isotope strongly absorbs thermal neutrons releasing much energy. One fission act of 1 gram of 235U converts into about 1 MW·day. Of importance, is that 235U emits more neutrons than it absorbs; upon reaching the critical mass, 235U enters into a self-sustaining chain reaction. Typically, uranium nucleus is divided into two fragments with the release of 2–3 neutrons, for example:
Other promising actinide isotopes for nuclear power are thorium-232 and its product from the thorium fuel cycle, uranium-233.
Emission of neutrons during the fission of uranium is important not only for maintaining the nuclear chain reaction, but also for the synthesis of the heavier actinides. Uranium-239 converts via β-decay into plutonium-239, which, like uranium-235, is capable of spontaneous fission. The world's first nuclear reactors were built not for energy, but for producing plutonium-239 for nuclear weapons.
About half of the produced thorium is used as the light-emitting material of gas mantles. Thorium is also added into multicomponent alloys of magnesium and zinc. So the Mg-Th alloys are light and strong, but also have high melting point and ductility and thus are widely used in the aviation industry and in the production of missiles. Thorium also has good electron emission properties, with long lifetime and low potential barrier for the emission. The relative content of thorium and uranium isotopes is widely used to estimate the age of various objects, including stars (see ).
The major application of plutonium has been in nuclear weapons, where the isotope plutonium-239 was a key component due to its ease of fission and availability. Plutonium-based designs allow reducing the critical mass to about a third of that for uranium-235. The "Fat Man"-type plutonium bombs produced during the Manhattan Project used explosive compression of plutonium to obtain significantly higher densities than normal, combined with a central neutron source to begin the reaction and increase efficiency. Thus only 6.2 kg of plutonium was needed for an explosive yield equivalent to 20 kilotons of TNT. (See also Nuclear weapon design.) Hypothetically, as little as 4 kg of plutonium—and maybe even less—could be used to make a single atomic bomb using very sophisticated assembly designs.
Plutonium-238 is potentially more efficient isotope for nuclear reactors, since it has smaller critical mass than uranium-235, but it continues to release much thermal energy (0.56 W/g) by decay even when the fission chain reaction is stopped by control rods. Its application is limited by the high price (about 1000 USD/g). This isotope has been used in thermopiles and water distillation systems of some space satellites and stations. So Galileo and Apollo spacecraft (e.g. Apollo 14) had heaters powered by kilogram quantities of plutonium-238 oxide; this heat is also transformed into electricity with thermopiles. The decay of plutonium-238 produces relatively harmless alpha particles and is not accompanied by gamma-irradiation. Therefore this isotope (~160 mg) is used as the energy source in heart pacemakers where it lasts about 5 times longer than conventional batteries.
Actinium-227 is used as a neutron source. Its high specific energy (14.5 W/g) and the possibility of obtaining significant quantities of thermally stable compounds are attractive for use in long-lasting thermoelectric generators for remote use. 228Ac is used as an indicator of radioactivity in chemical research, as it emits high-energy electrons (2.18 MeV) that can be easily detected. 228Ac-228Ra mixtures are widely used as an intense gamma-source in industry and medicine.
Development of self-glowing actinide-doped materials with durable crystalline matrices is a new area of actinide utilization as the addition of alpha-emitting radionuclides to some glasses and crystals may confer luminescence.
Toxicity.
Radioactive substances can harm human health via (i) local skin contamination, (ii) internal exposure due to ingestion of radioactive isotopes, and (iii) external overexposure by β-activity and γ-radiation. Together with radium and transuranium elements, actinium is one of the most dangerous radioactive poisons with high specific α-activity. The most important feature of actinium is its ability to accumulate and remain in the surface layer of skeletons. At the initial stage of poisoning, actinium accumulates in the liver. Another danger of actinium is that it undergoes radioactive decay faster than being excreted. Adsorption from the digestive tract is much smaller (~0.05%) for actinium than radium.
Protactinium in the body tends to accumulate in the kidneys and bones. The maximum safe dose of protactinium in the human body is 0.03 µCi that corresponds to 0.5 micrograms of 231Pa. This isotope, which might be present in the air as aerosol, is 2.5{{e|8}} times more toxic than hydrocyanic acid.
Plutonium, when entering the body through air, food or blood (e.g. a wound), mostly settles in the lungs, liver and bones with only about 10% going to other organs, and remains there for decades. The long residence time of plutonium in the body is partly explained by its poor solubility in water. Some isotopes of plutonium emit ionizing α-radiation, which damages the surrounding cells. The median lethal dose (LD50) for 30 days in dogs after intravenous injection of plutonium is 0.32 milligram per kg of body mass, and thus the lethal dose for humans is approximately 22 mg for a person weighing 70 kg; the amount for respiratory exposure should be approximately four times greater. Another estimate assumes that plutonium is 50 times less toxic than radium, and thus permissible content of plutonium in the body should be 5 µg or 0.3 µCi. Such amount is nearly invisible in under microscope. After trials on animals, this maximum permissible dose was reduced to 0.65 µg or 0.04 µCi. Studies on animals also revealed that the most dangerous plutonium exposure route is through inhalation, after which 5–25% of inhaled substances is retained in the body. Depending on the particle size and solubility of the plutonium compounds, plutonium is localized either in the lungs or in the lymphatic system, or is absorbed in the blood and then transported to the liver and bones. Contamination via food is the least likely way. In this case, only about 0.05% of soluble 0.01% insoluble compounds of plutonium absorbs into blood, and the rest is excreted. Exposure of damaged skin to plutonium would retain nearly 100% of it.
Using actinides in nuclear fuel, sealed radioactive sources or advanced materials such as self-glowing crystals has many potential benefits. However, a serious concern is the extremely high radiotoxicity of actinides and their migration in the environment. Use of chemically unstable forms of actinides in MOX and sealed radioactive sources is not appropriate by modern safety standards. There is a challenge to develop stable and durable actinide-bearing materials, which provide safe storage, use and final disposal. A key need is application of actinide solid solutions in durable crystalline host phases.

</doc>
<doc id="2310" url="http://en.wikipedia.org/wiki?curid=2310" title="Arthur Miller">
Arthur Miller

Arthur Asher Miller (October 17, 1915 – February 10, 2005) was a prolific American playwright, essayist, and prominent figure in twentieth-century American theatre. Among his most popular plays are "All My Sons" (1947), "Death of a Salesman" (1949), "The Crucible" (1953) and "A View from the Bridge" (1955, revised 1956). He also wrote several screenplays and was most noted for his work on "The Misfits" (1961). The drama "Death of a Salesman" is often numbered on the short list of being among the finest American plays in the 20th century alongside "Long Day's Journey into Night" and "A Streetcar Named Desire".
Miller was often in the public eye, particularly during the late 1940s, 1950s and early 1960s. During this time, he was awarded the Pulitzer Prize for Drama; testified before the House Un-American Activities Committee; and was married to Marilyn Monroe. He received the Prince of Asturias Award and the Praemium Imperiale prize in 2002 and the Jerusalem Prize in 2003, as well as the Dorothy and Lillian Gish Lifetime Achievement Award and the Pulitzer Prize.
Biography.
Early life.
Arthur Asher Miller was born on October 17, 1915, in Harlem, in the New York City borough of Manhattan, the second of three children of Augusta (Barnett) and Isidore Miller. His father was an Austrian Jewish immigrant, and his mother was born in New York, to Austrian Jewish parents. His father owned a women's clothing manufacturing business employing 400 people. He became a wealthy and respected man in the community. The family, including his younger sister Joan, lived on West 110th Street in Manhattan, owned a summer house in Far Rockaway, Queens, and employed a chauffeur. In the Wall Street Crash of 1929, the family lost almost everything and moved to Gravesend, Brooklyn. As a teenager, Miller delivered bread every morning before school to help the family. After graduating in 1932 from Abraham Lincoln High School, he worked at several menial jobs to pay for his college tuition.
At the University of Michigan, Miller first majored in journalism and worked for the student paper, the "Michigan Daily". It was during this time that he wrote his first play, "No Villain". Miller switched his major to English, and subsequently won the Avery Hopwood Award for "No Villain." The award brought him his first recognition and led him to begin to consider that he could have a career as a playwright. Miller enrolled in a playwriting seminar taught by the influential Professor Kenneth Rowe, who instructed him in his early forays into playwriting; Rowe emphasized how a play is built in order to achieve its intended effect, or what Miller called "the dynamics of play construction". Rowe provided realistic feedback along with much-needed encouragement, and became a lifelong friend. Miller retained strong ties to his alma mater throughout the rest of his life, establishing the university's Arthur Miller Award in 1985 and Arthur Miller Award for Dramatic Writing in 1999, and lending his name to the Arthur Miller Theatre in 2000. In 1937, Miller wrote "Honors at Dawn," which also received the Avery Hopwood Award.
After his graduation in 1938, he joined the Federal Theater Project, a New Deal agency established to provide jobs in the theater. He chose the theater project despite the more lucrative offer to work as a scriptwriter for 20th Century Fox. However, Congress, worried about possible Communist infiltration, closed the project in 1939. Miller began working in the Brooklyn Navy Yard while continuing to write radio plays, some of which were broadcast on CBS.
Early career.
In 1940, he married Mary Grace Slattery. The couple had two children, Jane and Robert (born May 31, 1947). Miller was exempted from military service during World War II because of a high-school football injury to his left kneecap.
1940 was also the year his first play was produced; "The Man Who Had All the Luck" won the Theatre Guild's National Award. The play closed after four performances with disastrous reviews.
In 1947, Miller's play "All My Sons", the writing of which had commenced in 1941, was a success on Broadway (earning him his first Tony Award, for Best Author) and his reputation as a playwright was established. Years later, in a 1994 interview with Ron Rifkin, Miller said that most contemporary critics regarded "All My Sons" as "a very depressing play in a time of great optimism" and that positive reviews from Brooks Atkinson of "The New York Times" had saved it from failure.
In 1948, Miller built a small studio in Roxbury, Connecticut. There, in less than a day, he wrote Act I of "Death of a Salesman". Within six weeks, he completed the rest of the play, one of the classics of world theater. "Death of a Salesman" premiered on Broadway on February 10, 1949 at the Morosco Theatre, directed by Elia Kazan, and starring Lee J. Cobb as Willy Loman, Mildred Dunnock as Linda, Arthur Kennedy as Biff, and Cameron Mitchell as Happy. The play was commercially successful and critically acclaimed, winning a Tony Award for Best Author, the New York Drama Circle Critics' Award, and the Pulitzer Prize for Drama. It was the first play to win all three of these major awards. The play was performed 742 times.
In 1949, Miller exchanged letters with Eugene O'Neill regarding Miller's production of All My Sons. O'Neill had sent Miller a congratulatory telegram; in response, he wrote a letter that consisted of a few paragraphs detailing his gratitude for the telegram, apologizing for not responding earlier, and inviting Eugene to the opening of Death of a Salesman. O'Neill replied and accepted the apology, but rejected the invitation citing that his Parkinson's disease made it difficult to travel. He ended the letter with an invitation up to Boston, which never occurred.
The critical years.
In 1956, a one-act version of Miller's verse drama "A View from the Bridge" opened on Broadway in a joint bill with one of Miller's lesser-known plays, "A Memory of Two Mondays". The following year, Miller revised "A View from the Bridge" as a two-act prose drama, which Peter Brook directed in London. A French-Italian co-production "Vu du pont", based on the play, was released in 1962.
In June 1956, Miller left his first wife Mary Slattery and on June 29 he married Marilyn Monroe. Miller and Monroe had met in April 23, 1951, when they had a brief affair, and had remained in contact since then.
Miller began work on "The Misfits", starring his wife. Miller later said that the filming was one of the lowest points in his life; shortly before the film's premiere in 1961, the pair divorced. 19 months later, Monroe died of a possible drug overdose. Miller's future wife Inge Morath worked as a photographer documenting the film's production. The film proved to be the last appearances for both Monroe and Clark Gable, and one of the last for Montgomery Clift.
Miller married photographer Inge Morath on February 17, 1962 and the first of their two children, Rebecca, was born September 15, 1962. Their son Daniel was born with Down syndrome in November 1966; he was institutionalized and excluded from the Millers' personal life at Arthur's insistence. The couple remained together until Inge's death in 2002. Arthur Miller's son-in-law, actor Daniel Day-Lewis, is said to have visited Daniel frequently, and to have persuaded Arthur Miller to reunite with his adult son, Daniel.
HUAC controversy and "The Crucible".
In 1952, Elia Kazan appeared before the House Un-American Activities Committee (HUAC); unwilling to risk his promising career in Hollywood for the Communist cause that he had come to despise, Kazan named eight members of the Group Theatre, including Clifford Odets, Paula Strasberg, Lillian Hellman, J. Edward Bromberg, and John Garfield, who in recent years had been fellow members of the Communist Party. After speaking with Kazan about his testimony, Miller traveled to Salem, Massachusetts to research the witch trials of 1692. "The Crucible", in which Miller likened the situation with the House Un-American Activities Committee to the witch hunt in Salem in 1692, opened at the Beck Theatre on Broadway on January 22, 1953. Though widely considered only somewhat successful at the time of its initial release, today "The Crucible" is Miller's most frequently produced work throughout the world and was adapted into an opera by Robert Ward, which won the Pulitzer Prize for Music in 1962. Miller and Kazan were close friends throughout the late 1940s and early 1950s, but after Kazan's testimony to the HUAC, the pair's friendship ended, and they did not speak to each other for the next ten years. The HUAC took an interest in Miller himself not long after "The Crucible" opened, denying him a passport to attend the play's London opening in 1954. Kazan defended his own actions through his film "On the Waterfront", in which a dockworker heroically testifies against a corrupt union boss.
When Miller applied in 1956 for a routine renewal of his passport, the House Unamerican Activities Committee used this opportunity to subpoena him to appear before the committee. Before appearing, Miller asked the committee not to ask him to name names, to which the chairman, Francis E. Walter (D-PA) agreed.
When Miller attended the hearing, to which Monroe accompanied him, risking her own career, he gave the committee a detailed account of his political activities. Reneging on the chairman's promise, the committee demanded the names of friends and colleagues who had participated in similar activities. Miller refused to comply, saying "I could not use the name of another person and bring trouble on him." As a result, a judge found Miller guilty of contempt of Congress in May 1957. Miller was sentenced to a $500 fine or thirty days in prison, blacklisted, and disallowed a US passport. In 1958, his conviction was overturned by the court of appeals, which ruled that Miller had been misled by the chairman of the HUAC.
Miller's experience with the HUAC affected him throughout his life. In the late 1970s he became very interested in the highly publicized Barbara Gibbons murder case, in which Gibbons' son Peter Reilly was convicted of his mother's murder based on what many felt was a coerced confession and little other evidence. "City Confidential", an A&E Network series, produced an episode about the murder, postulating that part of the reason Miller took such an active interest (including supporting Reilly's defense and using his own celebrity to bring attention to Reilly's plight) was because he had felt similarly persecuted in his run-ins with the HUAC. He sympathized with Reilly, whom he firmly believed to be innocent and to have been railroaded by the Connecticut State Police and the Attorney General who had initially prosecuted the case.
Later career.
In 1964" After the Fall" was produced, and is said to be a deeply personal view of Miller's experiences during his marriage to Monroe. The play reunited Miller with his former friend Kazan: they collaborated on both the script and the direction. "After the Fall" opened on January 23, 1964 at the ANTA Theatre in Washington Square Park amid a flurry of publicity and outrage at putting a Monroe-like character, called Maggie, on stage. Robert Brustein, in a review in the New Republic, called "After the Fall" "a three and one half hour breach of taste, a confessional autobiography of embarrassing explicitness . . . there is a misogynistic strain in the play which the author does not seem to recognize. . . . He has created a shameless piece of tabloid gossip, an act of exhibitionism which makes us all voyeurs, . . . a wretched piece of dramatic writing." That same year, Miller produced "Incident at Vichy". In 1965, Miller was elected the first American president of PEN International, a position which he held for four years. A year later, Miller organized the 1966 PEN congress in New York City. Miller also wrote the penetrating family drama, "The Price", produced in 1968. It was Miller's most successful play since "Death of a Salesman."
In 1969, Miller's works were banned in the Soviet Union after he campaigned for the freedom of dissident writers. Throughout the 1970s, Miller spent much of his time experimenting with the theatre, producing one-act plays such as "Fame" and "The Reason Why", and traveling with his wife, producing "In The Country" and "Chinese Encounters" with her. Both his 1972 comedy "The Creation of the World and Other Business" and its musical adaptation, "Up from Paradise", were critical and commercial failures.
Miller was an unusually articulate commentator on his own work. In 1978 he published a collection of his "Theater Essays", edited by Robert A. Martin and with a foreword by Miller. Highlights of the collection included Miller's introduction to his "Collected Plays", his reflections on the theory of tragedy, comments on the McCarthy Era, and pieces arguing for a publicly supported theater. Reviewing this collection in the "Chicago Tribune," Studs Terkel remarked, "in reading [the "Theater Essays"]...you are exhilaratingly aware of a social critic, as well as a playwright, who knows what he's talking about."
In 1983, Miller traveled to China to produce and direct "Death of a Salesman" at the People's Art Theatre in Beijing. The play was a success in China and in 1984, "Salesman in Beijing," a book about Miller's experiences in Beijing, was published. Around the same time, "Death of a Salesman" was made into a TV movie starring Dustin Hoffman as Willy Loman. Shown on CBS, it attracted 25 million viewers. In late 1987, Miller's autobiographical work,
"Timebends", was published. Before it was published, it was well known that Miller would not talk about Monroe in interviews; in "Timebends" Miller talks about his experiences with Monroe in detail.
During the early-mid 1990s, Miller wrote three new plays: "The Ride Down Mt. Morgan" (1991), "The Last Yankee" (1992), and "Broken Glass" (1994). In 1996, a film of "The Crucible" starring Daniel Day-Lewis, Paul Scofield, Bruce Davison, and Winona Ryder opened. Miller spent much of 1996 working on the screenplay to the film.
"Mr. Peters' Connections" was staged Off-Broadway in 1998, and "Death of a Salesman" was revived on Broadway in 1999 to celebrate its fiftieth anniversary. The play, once again, was a large critical success, winning a Tony Award for best revival of a play.
In 1993, he was awarded the National Medal of Arts. Miller was honored with the PEN/Laura Pels International Foundation for Theater Award for a Master American Dramatist in 1998. In 2001 the National Endowment for the Humanities (NEH) selected Miller for the Jefferson Lecture, the U.S. federal government's highest honor for achievement in the humanities. Miller's lecture was entitled "On Politics and the Art of Acting."
Miller's lecture analyzed political events (including the U.S. presidential election of 2000)
in terms of the "arts of performance," and it drew attacks from some conservatives such as Jay Nordlinger, who called it "a disgrace,"
 and George Will, who argued that Miller was not legitimately a "scholar."
In 1999, Miller was awarded The Dorothy and Lillian Gish Prize, one of the richest prizes in the arts, given annually to "a man or woman who has made an outstanding contribution to the beauty of the world and to mankind’s enjoyment and understanding of life." In 2001, Miller received the National Book Foundation's . On May 1, 2002, Miller was awarded Spain's Principe de Asturias Prize for Literature as "the undisputed master of modern drama." Later that year, Ingeborg Morath died of lymphatic cancer at the age of 78. The following year Miller won the Jerusalem Prize.
In December 2004, the 89-year-old Miller announced that he had been in love with 34-year-old minimalist painter Agnes Barley and had been living with her at his Connecticut farm since 2002, and that they intended to marry. Within hours of her father's death, Rebecca Miller ordered Barley to vacate the premises, having consistently opposed the relationship. Miller's final play, "Finishing the Picture", opened at the Goodman Theatre, Chicago, in the fall of 2004, with one character said to be based on Barley. It was reported to be based on his experience during the filming "The Misfits", though Miller insisted the play is a work of fiction with independent characters that were no more than composite shadows of history.
Death.
Miller died of heart failure after a battle against cancer, pneumonia and congestive heart disease at his home in Roxbury, Connecticut. He had been in hospice care at his sister's apartment in New York since his release from hospital the previous month. He died on the evening of February 10, 2005 (the 56th anniversary of the Broadway debut of "Death of a Salesman"), aged 89, surrounded by Barley, family and friends. He is interred at Roxbury Center Cemetery in Roxbury.
Legacy.
Arthur Miller's career as a writer spanned over seven decades, and at the time of his death, Miller was considered to be one of the greatest dramatists of the twentieth century. After his death, many respected actors, directors, and producers paid tribute to Miller, some calling him the last great practitioner of the American stage, and Broadway theatres darkened their lights in a show of respect.
Miller's Alma Mater, the University of Michigan, opened the Arthur Miller Theatre in March 2007. As per his express wish, it is the only theatre in the world that bears Miller's name.
Other notable arrangements for Miller's legacy are that his letters, notes, drafts and other papers are housed at the Harry Ransom Humanities Research Center at The University of Texas at Austin.
Arthur Miller is also a member of the American Theater Hall of Fame. He was inducted in 1979.
In 1993 he received the Four Freedom Award for Freedom of Speech
Miller's styles, themes, and characters.
Miller successfully diverse dramatic styles and movements in the belief that a play should embody a delicate balance between the individual and society, between the singular personality and the polity, and between the separate and collective elements of life. He thought himself a writer of social plays with a strong emphasis on moral problems in American society and often questioned psychological causes of behavior. He also built on the realist tradition of Henrik Ibsen in his exploration of the individual’s conflict with society but also borrowed Symbolist and expressionist techniques from Bertolt Brecht and others. Some critics attempt to interpret his work from either an exclusively political or an exclusively psychological standpoint but fail to pierce the social veil that Miller creates in his work. Miller often stressed that society made his characters what they are and how it dictated all of their fears and choices.
Themes.
All American Family.
While Miller comes under criticism for his reputation, most critics note him as a dramatist of the family. One of his greatest strengths is his penetrating insight into familial relationships. Often, Miller positions his characters are living in service of their family. The conventions of the family play, such as patterns, setting, and style of representation were set canonically by Eugene O'Neill, Tennessee Williams, and Miller. In these plays, white men are privileged with their family and social responsibility; typically, these men are lower class. Miller maintained that family relationships and families must be immersed in social context.
Social responsibility.
Arthur Miller is known for the consciousness of the characters in his play. In his plays, he confronts a level of banality with the roller coaster of guilt and responsibility. Some strong examples of characters who portray this struggle between their conscious and their social responsibility are Joe Keller in All My Sons and John Proctor in The Crucible. Miller often creates consequences for characters who ignore or violate their social responsibilities.
Life, death, and human purpose.
Miller's determination to deal with the eternal themes of life, death and human purpose is one of his most prominent themes across his works. This theme spans from Willy Lowman's dedication to providing for his family and his inherent belief that his death would leave a legacy, to John Proctor's willingness to die to preserve his name. Mostly all of Miller's protagonists struggle with the mark they leave on life and what it means to die.
Characters.
Willy Loman.
In Death of a Salesman – originally entitled “The Inside of His Head” – Miller brilliantly solves the problem of revealing his main character’s inner discord, rendering Willy Loman as solid as the society in which he tries to sell himself. Indeed, many critics believe that Miller has never surpassed his achievement in this play, which stands as his breakthrough work, distinguished by an extremely long Broadway run, by many revivals, and by many theater awards, including the Pulitzer Prize in 1949. Death of a Salesman seems destined to remain an American classic and a standard text in American classrooms.
Willy Loman desperately wants to believe that he has succeeded, that he is “well liked” as a great salesman, a fine father, and a devoted husband. That he has not really attracted the admiration and popularity at which he has aimed is evident, however, in the weariness that belabors him from the beginning of the play. Nearing retirement he suffers a drastic decrease in sales work, a dissatisfying marriage, and a turbulent relationship with his sons which inexorably leads to his suicide with the justification that the insurance will finally provide for his family.
Eddie Carbone.
Eddie Carbone is the central character in A View From The Bridge and is not positioned as the protagonist or the antogonist. He is a longshoreman who lives with his wife, Beatrice, and his 17 year old niece, Catherine. When his family from Italy, Rodolpho and Marco, migrate illegally and begin to live with him, the small world that he operates in is disrupted. Eddie becomes conflicted and ultimately self-destructive over his sexual attraction to his niece and her involvement with one of his Italian tenants. His character arc culminates as he becomes and informer to the immigration authorities which leads to a confrontation with one of his tenants. Marco labels him as an informer and Eddie perceives this as a permanent blemish on his good name. This confrontation ultimately leads to his death leaves Eddie as one of Miller's examples of tragic figures.
John Proctor.
John Proctor is the protagonist of one of Miller's most controversial works, The Crucible. He is a faithful farmer who lives by a strict moral code that he violates by succumbing to an affair with a young girl, Abigail, who serves in his home. After rejecting her, Abigail spitefully accuses John's wife of witchcraft, involving him in a string of affairs that challenge his beliefs and convictions. In his attempts to save his wife, he is convicted of witchcraft as well, and will only be acquitted if he confesses to his crime and signs his name to a piece of paper. Proctor is a strong, vital man in the prime of his life both in his confession of witchcraft and the subsequent passion with which he defends his name at the cost of his life.
Joe Keller.
Critics have long admired the playwright’s suspenseful handling of the Keller family’s burden in the play All My Sons. The critical character in this work is Joe Keller, who permitted defective parts to remain in warplanes that subsequently crash. Not only does Joe Keller fail to recognize his social responsibility, but also he allows his business partner to take the blame and serve the prison term for the crime. Gradually, events combine to strip Keller of his rationalizations. He argues that he never believed that the cracked engine heads would be installed and that he never admitted his mistake because it would have driven him out of business at the age of sixty-one, when he would not have another chance to “make something” for his family, his highest priority. Joe's irresponsibility is exposed through his son's questioning of his very humanity. Joe's suicide results from the tremendous guilt and self-awareness that arises during the play. This reversal from staunchly defensive over his honorable need to protect his family to discovering his social responsibility had some critics claiming that this was a theatrical trick.
Literary and public criticism.
Christopher Bigsby wrote "Arthur Miller: The Definitive Biography" based on boxes of papers Miller made available to him before his death in 2005. The book was published in November 2008, and is reported to reveal unpublished works in which Miller "bitterly attack[ed] the injustices of American racism long before it was taken up by the civil rights movement".
In his book "Trinity of Passion", author Alan M. Wald conjectures that Miller was "a member of a writer's unit of the Communist Party around 1946," using the pseudonym Matt Wayne, and editing a drama column in the magazine "The New Masses".
Two months after Miller died Peter O'Toole called him a "bore" and Roger Kimball went on record saying that Miller's artistic accomplishments were meager.
The Arthur Miller Foundation.
The Arthur Miller Foundation was founded to honor the legacy of Arthur Miller and his New York City Public School Education. The mission of the foundation is:
"Promoting increased access and equity to theater arts education in our schools and Increasing the number of students receiving theater arts education as an integral part of their academic curriculum". Other initiatives include effecting the certification of new theater teachers and their placement in public schools, increasing the number of theater teachers in the system from the current estimate of 180 teachers in 1800 schools, supporting professional development of all certified theater teachers, providing teaching artists, cultural partners, physical spaces, and theater ticket allocations for students The Foundation's primary purpose is to provide arts education in the New York City School system. The current canceller of the foundation is Carmen Farina, a large proponent of the common core. Alec Baldwin, Ellen Barkin, Katori Hall, Dustin Hoffman, Scarlett Johansson, Tony Kushner, Michael Mayer, Jim McElhinney, Julianne Moore, Liam Neeson, Lynn Nottage, David O. Russell, Liev Schreiber all serve on the Master Arts Council. Son-in-law Daniel Day-Lewis serves on the current board of directors.
Quest to learn program.
The Arthur Miller Foundation currently supports a pilot program in theater and film at the public school Quest to Learn in partnership with the Institute of Play. The model is being used as an in-school elective theater class and lab. The objective is to create a sustainable theater education model to disseminate to teachers at professional development workshop.
References.
Bibliography.
</dl>
Further reading.
Critical Articles

</doc>
<doc id="2313" url="http://en.wikipedia.org/wiki?curid=2313" title="Anton Diabelli">
Anton Diabelli

Anton (or Antonio) Diabelli (5 September 1781 – 7 April 1858) was an Austrian music publisher, editor and composer. Best known in his time as a publisher, he is most familiar today as the composer of the waltz on which Ludwig van Beethoven wrote his set of thirty-three "Diabelli Variations".
Early life.
Diabelli was born in Mattsee near Salzburg. A musical child, he sang in the boys' choir at the Salzburg Cathedral where he is believed to have taken music lessons with Michael Haydn. By age 19, Diabelli had already composed several important compositions, including six masses.
Diabelli was trained to enter the priesthood and in 1800 he joined the monastery at Raitenhaslach, Bavaria. He remained there until 1803 when Bavaria closed all its monasteries.
Career.
In 1803 Diabelli moved to Vienna and began teaching piano and guitar and found work as a proofreader for a music publisher. During this period he learned the music publishing business while continuing to compose. In 1809 he composed his comic opera, "Adam in der Klemme." In 1817 he started a music publishing business and 1818, partnered with Pietro Cappi to create the music publishing firm of Cappi & Diabelli.
The firm, Cappi & Diabelli became well known by arranging popular pieces so they could be played by amateurs at home. A master of promotion, Diabelli selected widely-accessible music such as famous opera tune arrangements, dance music, or hundreds of the latest popular comic theatre songs.
The firm soon established a reputation in more serious music circles by championing the works of Franz Schubert. It was Diabelli who first recognized the composer's potential, become the very first to publish Schubert's work with "Der Erlkönig" in 1821. Diabelli's firm continued to publish Schubert's work until 1823 when an argument between Cappi and Schubert terminated their business. The following year, Diabelli and Cappi parted ways, with Diabelli launching a new publishing house, Diabelli & Co, in 1824.
Following Schubert's early death in 1828, Diabelli purchased a large portion of the composer's massive musical estate from Schubert's brother Ferdinand. As Schubert's total compositions number nearly 1000, Diabelli's firm was able to publish "new" Schubert works for more than 30 years after the composer's death.
Diabelli's publishing house expanded throughout his life, before he retired in 1851, leaving it under the control of Carl Anton Spina. When Diabelli died in 1858, Spina continued to run the firm, and published much music by Johann Strauss II and Josef Strauss. In 1872, the firm was taken over by Friedrich Schreiber, and in 1876 it merged with the firm of August Cranz, who bought the company in 1879 and ran it under his name.
He died in Vienna at the age of 76.
Compositions.
Diabelli produced a number of well known works as a composer, including an operetta called "Adam in der Klemme", several masses and songs and numerous piano and classical guitar pieces. Among these are pieces for piano four hands that are popular among pianists of all ages. His music goes on to be the fundamentals of opera, and is considered by some to have set the fundamental stepping stones for classic jazz.
Diabelli's composition "Pleasures of Youth: Six Sonatinas" is a collection of six sonatinas depicting a struggle between unknown opposing forces. This is suggested by the sharp and frequent change in dynamics from forte to piano. When forte is indicated, the pianist is meant to evoke a sense of wickedness, thus depicting the antagonist. In contrast, the markings of piano represent the protagonist with its softer, more tranquil tones.
Diabelli Variations.
The composition for which Diabelli is now best known was actually written as part of an adventuring story. In 1819, as a promotional idea, he decided to try to publish a volume of variations on a "patriotic" waltz he had penned expressly for this purpose, with one variation by every important Austrian composer living at the time, as well as several significant non-Austrians. The combined contributions would be published in an anthology called "Vaterländischer Künstlerverein". Fifty-one composers responded with pieces, including Beethoven, Schubert, Archduke Rudolph of Austria, F.X. Wolfgang Mozart (jun.), Moritz Count von Dietrichstein, Heinrich Eduard Josef Baron von Lannoy, Ignaz Franz Baron von Mosel, Carl Czerny, Johann Nepomuk Hummel, Ignaz Moscheles, and the eight-year-old Franz Liszt (although it seems Liszt was not invited personally, but his teacher Czerny arranged for him to be involved). Czerny was also enlisted to write a coda. Beethoven, however, instead of providing just one variation, provided 33, and his formed Part I of "Vaterländischer Künstlerverein". They constitute what is generally regarded as one of the greatest of Beethoven's piano pieces and as the greatest set of variations of their time, and are generally known simply as the "Diabelli Variations", Op. 120. The other 50 variations were published as Part II of "Vaterländischer Künstlerverein".
Cultural references.
A sonatina of Diabelli's, presumably Sonatina in F major, Op. 168, No. 1 (I: Moderato cantabile), provides the title and a motif for the French novella "Moderato Cantabile" by Marguerite Duras.

</doc>
<doc id="2314" url="http://en.wikipedia.org/wiki?curid=2314" title="Anita Hill">
Anita Hill

Anita Faye Hill (born July 30, 1956) is an American attorney and academic. She is a professor of social policy, law and women's studies at Brandeis University's Heller School for Social Policy and Management. She became a national figure in 1991 when she accused U.S. Supreme Court nominee Clarence Thomas, her supervisor at the U.S. Department of Education and the Equal Employment Opportunity Commission, of sexual harassment.
Early life and education.
Hill was born in Lone Tree, Oklahoma, the youngest of the 13 children of Albert and Erma Hill, who were farmers. Her family hailed from Arkansas, where her great-grandparents and her maternal grandfather, Henry Eliot, were born into slavery. Hill was raised in the Baptist faith.
After graduating as valedictorian from Morris High School, Hill enrolled at Oklahoma State University, receiving a bachelor's degree with honors, in psychology 1977. She went on to Yale Law School, obtaining her Juris Doctor degree with honors in 1980.
She was admitted to the District of Columbia Bar in 1980 and began her law career as an associate with the Washington, D.C. firm of Wald, Harkrader & Ross. In 1981, she became an attorney-adviser to Clarence Thomas who was then the Assistant Secretary of the U.S. Department of Education's Office for Civil Rights. When Thomas became Chairman of the U.S. Equal Employment Opportunity Commission (EEOC) in 1982, Hill went along to serve as his assistant, leaving the job in 1983.
Hill then became an assistant professor at the Evangelical Christian O. W. Coburn School of Law at Oral Roberts University where she taught from 1983 to 1986. In 1986, she joined the faculty at the University of Oklahoma College of Law where she taught commercial law and contracts.
Clarence Thomas controversy.
In 1991, President George H. W. Bush nominated Clarence Thomas, by then a federal Circuit Judge, to succeed retiring Associate Justice Thurgood Marshall on the Supreme Court. Senate hearings on his confirmation were initially completed with Thomas' good character being presented as a primary qualification for the high court because he had only been a judge for slightly more than one year. There had been little organized opposition to Thomas' nomination, and his confirmation seemed assured until a report of a private interview of Hill by the FBI was leaked to the press. The hearings were then reopened, and Hill was called to publicly testify. Hill said in the October 1991 televised hearings that Thomas had sexually harassed her while he was her supervisor at the Department of Education and the EEOC. When questioned on why she followed Thomas to the second job after he had already allegedly harassed her, she said she had wanted to work in the civil rights field, she had no alternative job, "and at that time, it appeared that the sexual overtures ... had ended."
According to Hill, during her two years of employment as Thomas's assistant, Thomas had asked her out socially many times, and after she refused, he used work situations to discuss sexual subjects. "He spoke about...such matters as women having sex with animals and films showing group sex or rape scenes" she said, adding that on several occasions Thomas graphically described "his own sexual prowess" and the details of his anatomy. Hill also recounted an instance in which Thomas examined a can of Coke on his desk and asked, "Who has put pubic hair on my Coke?"
Four female witnesses waited in the wings to reportedly support Hill's credibility, but they were not called, due to what the "Los Angeles Times" described as a private, compromise deal between "aggressive, gloves-off" Republicans and the Senate Judiciary Committee Chair, Democrat Joe Biden. According to "Time" magazine, one of the witnesses, Angela Wright, may not have been considered credible on the issue of sexual harassment because she had been fired from the EEOC by Thomas.
Hill agreed to take a polygraph test. The results supported the veracity of her statements; Thomas declined the test. He made a vehement and complete denial, saying that he was being subjected to a "high-tech lynching for uppity blacks" by white liberals who were seeking to block a black conservative from taking a seat on the Supreme Court. After extensive debate, the United States Senate confirmed Thomas to the Supreme Court by a vote of 52–48; the narrowest margin since the 19th century.
Thomas's supporters questioned Hill's credibility, claiming she was delusional or had been spurned, leading her to seeking revenge. They cited the time delay of ten years between the alleged behavior by Thomas and Hill's accusations, and noted that Hill had followed Thomas to a second job and later had personal contacts with Thomas, including giving him a ride to an airport—behavior which they said would be inexplicable if Hill's allegations were true. Hill countered that she came forward because she felt an obligation to share information on the character and actions of a person who was being considered for the Supreme Court. She testified that after leaving the EEOC, she had had two "inconsequential" phone conversations with Thomas, and had seen him personally on two occasions; once to get a job reference and the second time when he made a public appearance in Oklahoma where she was teaching.
Doubts about the veracity of Hill's 1991 testimony persisted long after Thomas took his seat on the Court. They were furthered by "American Spectator" writer David Brock in his 1993 book "The Real Anita Hill", though he later recanted the claims he had made, described his book as "character assassination", and apologized to Hill. After interviewing a number of women who alleged that Thomas had frequently subjected them to sexually explicit remarks, "Wall Street Journal" reporters Jane Mayer and Jill Abramson wrote a book which concluded that Thomas had lied during his confirmation process. "Time" magazine remarked in 1994, however, that "Their book doesn't quite nail that conclusion." In 2007, Kevin Merida, a coauthor of another book on Thomas, remarked that what happened between Thomas and Hill was "ultimately unknowable" by others, but that it was clear that "one of them lied, period." Writing in 2007, Neil Lewis of "The New York Times" remarked that, "To this day, each side in the epic he-said, she-said dispute has its unmovable believers".
In 2007, Clarence Thomas published his autobiography, "My Grandfather's Son", in which he revisited the controversy, calling Hill his "most traitorous adversary" and saying that pro-choice liberals, who feared that he would vote to overturn "Roe v. Wade" if he were seated on the Supreme Court, used the scandal against him. He described Hill as touchy and apt to overreact, and her work at the EEOC as mediocre. He acknowledged that three other former EEOC employees had backed Hill's story, but said they had all left the agency on bad terms. He also wrote that Hill "was a left-winger who'd never expressed any religious sentiments whatsoever...and the only reason why she'd held a job in the Reagan administration was because I'd given it to her." Hill denied the accusations in an op-ed in the "New York Times" saying she would not "stand by silently and allow [Justice Thomas], in his anger, to reinvent me".
In October 2010, Thomas's wife Virginia, a conservative activist, left a voicemail at Hill's office asking that Hill apologize for her 1991 testimony. Hill initially believed the call was a hoax and referred the matter to the Brandeis University campus police who alerted the FBI. After being informed that the call was indeed from Virginia Thomas, Hill told the media that she did not believe the message was meant to be conciliatory and said, "I testified truthfully about my experience and I stand by that testimony." Virginia Thomas responded that the call had been intended as an "olive branch".
Effects.
Public interest in, and debate over, Hill's testimony is said to have launched modern-day public awareness and open discussion of the issue of workplace sexual harassment in the United States with the ultimate result that the behavior is less tolerated today. Shortly after the Thomas confirmation hearings, President George H. W. Bush dropped his opposition to a bill giving harassment victims the right to seek federal damage awards, back pay and reinstatement, and the law was passed by Congress. One year later, harassment complaints filed with the EEOC were up 50 percent and public opinion had shifted in Hill's favor. Private companies also started training programs to deter sexual harassment. When journalist Cinny Kennard asked Hill in 1991 if she would testify against Thomas all over again, Hill answered, "I'm not sure if I could have lived with myself if I had answered those questions any differently."
The manner in which the all-male Senate Judiciary Committee challenged and dismissed Hill's accusations of sexual harassment angered women politicians and lawyers. According to D.C. Congressional Delegate Eleanor Holmes Norton, Hill's treatment by the panel also contributed to the large number of women elected to Congress in 1992, "women clearly went to the polls with the notion in mind that you had to have more women in Congress", she said. In their anthology, "All the Women Are White, All the Blacks Are Men, but Some of Us Are Brave", editors Gloria T. Hull, Patricia Bell Scott and Barbara Smith described black feminists mobilizing "a remarkable national response to the Anita Hill-Clarence Thomas controversy.
In 1992 a feminist group began a nationwide fundraising campaign and then obtained matching state funds to endow a professorship at the University of Oklahoma Law School in honor of Hill. Conservative Oklahoma state legislators reacted by demanding Hill's resignation from the university, then introducing a bill to prohibit the university from accepting donations from out-of-state residents, and finally attempting to pass legislation to close down the law school. E. Z. Million, a local conservative activist and business consultant, organized protests and compared Hill to the assassin of President Kennedy. Certain officials at the university attempted to revoke Hill's tenure. After five years of pressure, Hill resigned.
Later career.
Hill accepted a position as a visiting scholar at the Institute for the Study of Social Change at University of California, Berkeley in January 1997, but soon joined the faculty of Brandeis University—first at the Women's Studies Program, later moving to the Heller School for Social Policy and Management. In 2011, she also took a counsel position with the Civil Rights & Employment Practice group of the plaintiffs' law firm Cohen Milstein Sellers & Toll.
Over the years, Hill has provided commentary on gender and race issues on national television programs, including "60 Minutes", "Face the Nation" and Meet the Press She has been a speaker on the topic of commercial law as well as race and women's rights. She is also the author of articles that have been published in the "New York Times" and "Newsweek". and has contributed to many scholarly and legal publications in the areas of international commercial law, bankruptcy, and civil rights.
In 1995 Hill co-edited "Race, Gender and Power in America: The Legacy of the Hill-Thomas Hearings" with Emma Coleman Jordan. In 1997 Hill published her autobiography, "Speaking Truth to Power", in which she chronicled her role in the Clarence Thomas confirmation controversy and wrote that creating a better society had been a motivating force in her life. In 2011 Hill published her second book, "Reimagining Equality: Stories of Gender, Race, and Finding Home", which focuses on the sub-prime lending crisis that resulted in the foreclosure of many homes owned by African-Americans. She calls for a new understanding about the importance of home and its place in the American Dream.
Hill was the subject of the 2013 documentary film "Anita" by director Freida Lee Mock, which chronicles her experience during the Clarence Thomas scandal.
Awards and honors.
In 2005 Hill was selected as a Fletcher Foundation Fellow. In 2008 she was awarded the Louis P. and Evelyn Smith First Amendment Award by the Ford Hall Forum. She also serves on the Board of Trustees for Southern Vermont College in Bennington, Vermont.

</doc>
<doc id="2315" url="http://en.wikipedia.org/wiki?curid=2315" title="August 10">
August 10

August 10 is the day of the year in the Gregorian calendar.
The term 'the 10th of August' is widely used by historians as a shorthand for the Storming of the Tuileries Palace on the 10th of August, 1792, the effective end of the French monarchy until it was restored in 1814.

</doc>
<doc id="2316" url="http://en.wikipedia.org/wiki?curid=2316" title="Audio file format">
Audio file format

An audio file format is a file format for storing digital audio data on a computer system. The bit layout of the audio data (excluding metadata) is called the audio coding format and can be uncompressed, or compressed to reduce the file size, often using lossy compression. The data can be a raw bitstream in an audio coding format, but it is usually embedded in a container format or an audio data format with defined storage layer.
Format types.
It is important to distinguish between the audio coding format, the container containing the raw audio data, and an audio codec. A codec performs the encoding and decoding of the raw audio data while this encoded data is (usually) stored in a container file. Although most audio file formats support only one type of audio coding data (created with an audio coder), a multimedia container format (as Matroska or AVI) may support multiple types of audio and video data.
There are three major groups of audio file formats:
Uncompressed audio format.
There is one major uncompressed audio format, LPCM, which is the same variety of PCM as used in Compact Disc Digital Audio. Although LPCM can be stored on a computer as a raw audio format, it is usually stored in a codice_4 file on Windows or in a codice_5 file on Mac OS. The AIFF format is based on the Interchange File Format (IFF), and the WAV format is based on the similar Resource Interchange File Format (RIFF). WAV and AIFF are not inherently lossless; they're designed to store a wide variety of audio formats, lossless and lossy; they just add a small, metadata-containing header before the audio data to declare the format of the audio data, such as LPCM with a particular sample rate, bit depth, endianness and number of channels. Since WAV and AIFF are widely supported and can store LPCM, they are suitable file formats for storing and archiving an original recording.
BWF (Broadcast Wave Format) is a standard audio format created by the European Broadcasting Union as a successor to WAV. Among other enhancements, BWF allows more robust metadata to be stored in the file. See "European Broadcasting Union: Specification of the Broadcast Wave Format" (EBU Technical document 3285, July 1997). This is the primary recording format used in many professional audio workstations in the television and film industry. BWF files include a standardized timestamp reference which allows for easy synchronization with a separate picture element. Stand-alone, file based, multi-track recorders from AETA, Sound Devices, Zaxcom, HHB Communications Ltd, Fostex, Nagra, Aaton, and TASCAM all use BWF as their preferred format.
Lossless compressed audio format.
A lossless compressed format stores data in less space without losing any information. The original, uncompressed data can be recreated from the compressed version.
Uncompressed audio formats encode both sound and silence with the same number of bits per unit of time. Encoding an uncompressed minute of absolute silence produces a file of the same size as encoding an uncompressed minute of music. In a lossless compressed format, however, the music would occupy a smaller file than an uncompressed format and the silence would take up almost no space at all.
Lossless compression formats include the common FLAC, WavPack, Monkey's Audio, ALAC (Apple Lossless). They provide a compression ratio of about 2:1 (i.e. their files take up half the space of PCM). Development in lossless compression formats aims to reduce processing time while maintaining a good compression ratio.
Lossy compressed audio format.
Lossy compression enables even greater reductions in file size by removing some of the audio information and simplifying the data. This of course results in a reduction in audio quality, but a variety of techniques are used, mainly by exploiting psychoacoustics, to remove the parts of the sound that have the least effect on perceived quality, and to minimize the amount of audible noise added during the process. The popular MP3 format is probably the best-known example, but the AAC format found on the iTunes Music Store is also common. Most formats offer a range of degrees of compression, generally measured in bit rate. The lower the rate, the smaller the file and the more significant the quality loss.

</doc>
<doc id="2319" url="http://en.wikipedia.org/wiki?curid=2319" title="Antipope Victor IV">
Antipope Victor IV

Two antipopes used the regnal name Victor IV:

</doc>
<doc id="2321" url="http://en.wikipedia.org/wiki?curid=2321" title="Area 51">
Area 51

The United States Air Force facility commonly known as Area 51 is a remote detachment of Edwards Air Force Base, within the Nevada Test and Training Range. According to the Central Intelligence Agency (CIA), the correct names for the facility are Homey Airport (ICAO: KXTA) and Groom Lake, though the name Area 51 was used in a CIA document from the Vietnam War. Other names used for the facility include "Dreamland", and nicknames "Paradise Ranch", "Home Base" and "Watertown". The Special use airspace around the field is referred to as a Restricted Area 4808 North (R-4808N).
The base's current primary purpose is publicly unknown; however, based on historical evidence, it most likely supports development and testing of experimental aircraft and weapons systems. The intense secrecy surrounding the base has made it the frequent subject of conspiracy theories and a central component to unidentified flying object (UFO) folklore. Although the base has never been declared a secret base, all research and occurrings in Area 51 are Top Secret/Sensitive Compartmented Information (TS/SCI). In July 2013, following a FOIA request filed in 2005, the CIA publicly acknowledged the existence of the base for the first time, declassifying documents detailing the history and purpose of Area 51.
Area 51 is located in the southern portion of Nevada in the western United States, 83 mi north-northwest of Las Vegas. Situated at its center, on the southern shore of Groom Lake, is a large military airfield. The site was acquired by the United States Air Force in 1955, primarily for the testing of the Lockheed U-2 aircraft. The area around Area 51, including the small town of Rachel on the aptly named "Extraterrestrial Highway", is a popular tourist destination.
Geography.
Area 51.
The original rectangular base of 6 by is now part of the so-called "Groom box", a rectangular area measuring 23 by, of restricted airspace. The area is connected to the internal Nevada Test Site (NTS) road network, with paved roads leading south to Mercury and west to Yucca Flat. Leading northeast from the lake, the wide and well-maintained Groom Lake Road runs through a pass in the Jumbled Hills. The road formerly led to mines in the Groom basin, but has been improved since their closure. Its winding course runs past a security checkpoint, but the restricted area around the base extends further east. After leaving the restricted area, Groom Lake Road descends eastward to the floor of the Tikaboo Valley, passing the dirt-road entrances to several small ranches, before converging with State Route 375, the "Extraterrestrial Highway", south of Rachel.
Area 51 shares a border with the Yucca Flat region of the Nevada Test Site, the location of 739 of the 928 nuclear tests conducted by the United States Department of Energy at NTS. The Yucca Mountain nuclear waste repository is 44 mi southwest of Groom Lake.
Groom Lake.
Groom Lake is a salt flat in Nevada used for runways of the Nellis Bombing Range Test Site airport (KXTA) on the north of the Area 51 USAF military installation. The lake at 4409 ft elevation is approximately 3.7 mi from north to south and 3 mi from east to west at its widest point. Located within the namesake Groom Lake Valley portion of the Tonopah Basin, the lake is 25 mi south of Rachel, Nevada.
History.
The origin of the Area 51 name is unclear. The most accepted comes from a grid numbering system of the area by the Atomic Energy Commission (AEC); while Area 51 isn't part of this system, it is adjacent to Area 15. Another explanation is that 51 was used because it was unlikely that the AEC would use the number.
Groom Lake.
Lead and silver were discovered in the southern part of the Groom Range in 1864, and the English "Groome Lead Mines Limited" company financed the Conception Mines in the 1870s, giving the district its name (nearby mines included Maria, Willow and White Lake). The interests in Groom were acquired by J. B. Osborne and partners and patented in 1876, and his son acquired the interests in the 1890s. Claims were incorporated as two 1916 companies with mining continuing until 1918 and resuming after World War II until the early 1950s.
World War II.
The airfield on the Groom Lake site began service in 1942 as Indian Springs Air Force Auxiliary Field, and consisted of two dirt 5000 feet runways aligned NE/SW, NW/SE . The airfield may have been used for bombing and artillery practice; bomb craters are still visible in the vicinity.
U-2 program.
The Groom Lake test facility was established by the Central Intelligence Agency (CIA) for "Project Aquatone", the development of the Lockheed U-2 strategic reconnaissance aircraft in April 1955.
As part of the project, the director, Richard M. Bissell, Jr., understood that, given the extreme secrecy enveloping the project, the flight test and pilot training programs could not be conducted at Edwards Air Force Base or Lockheed's Palmdale facility. A search for a suitable testing site for the U-2 was conducted under the same extreme security as the rest of the project.
He notified Lockheed, who sent an inspection team out to Groom Lake. According to Lockheed's U-2 designer Kelly Johnson: ... We flew over it and within thirty seconds, you knew that was the place ... it was right by a dry lake. Man alive, we looked at that lake, and we all looked at each other. It was another Edwards, so we wheeled around, landed on that lake, taxied up to one end of it. It was a perfect natural landing field ... as smooth as a billiard table without anything being done to it". Johnson used a compass to lay out the direction of the first runway. The place was called "Groom Lake".
The lakebed made an ideal strip from which they could test aircraft, and the Emigrant Valley's mountain ranges and the NTS perimeter, about 100 miles north of Las Vegas, protected the test site from visitors. The CIA asked the AEC to acquire the land, designated "Area 51" on the map, and add it to the Nevada Test Site.:56–57
Johnson named the area "Paradise Ranch" to encourage workers to move to a place that the CIA's official history of the U-2 project would later describe as "the new facility in the middle of nowhere"; the name became shortened to "the Ranch".:57 On 4 May 1955, a survey team arrived at Groom Lake and laid out a 5000 ft, north-south runway on the southwest corner of the lakebed and designated a site for a base support facility. "The Ranch", also known as Site II, initially consisted of little more than a few shelters, workshops and trailer homes in which to house its small team. In a little over three months, the base consisted of a single, paved runway, three hangars, a control tower, and rudimentary accommodations for test personnel. The base's few amenities included a movie theatre and volleyball court. Additionally, there was a mess hall, several water wells, and fuel storage tanks. By July 1955, CIA, Air Force, and Lockheed personnel began arriving. The Ranch received its first U-2 delivery on 24 July 1955 from Burbank on a C-124 Globemaster II cargo plane, accompanied by Lockheed technicians on a Douglas DC-3. Regular Military Air Transport Service flights were set up between Area 51 and Lockheed's Burbank, California offices. To preserve secrecy, personnel flew to Nevada on Monday mornings and returned to California on Friday evenings.:72
OXCART program.
Project OXCART established in August 1959 for "antiradar studies, aerodynamic structural tests, and engineering designs [and] all later work on the" Lockheed A-12 included testing at Groom Lake, which before improvements for OXCART had inadequate facilities: buildings for only 150 people, a 5000 ft asphalt runway, and limited fuel, hangar, and shop space. Selected for its seclusion and climate, Groom Lake had received a new official name "Area 51" when A-12 test facility construction began in September 1960, including a new 8500 ft runway to replace the existing runway (completed by 15 November 1960 with "expansion joints parallel to the direction of aircraft roll" to limit vibration.)
Four years of "Project 51" construction began on 1 October 1960 by Reynolds Electrical and Engineering Company (REECo) with double-shift construction schedules. The contractor upgraded base facilities and built a new 10000 ft runway (14/32) diagonally across the southwest corner of the lakebed. An Archimedes curve approximately two miles across was marked on the dry lake so that an A-12 pilot approaching the end of the overrun could abort to the playa instead of plunging the aircraft into the sagebrush. Area 51 pilots called it "The Hook". For crosswind landings two unpaved airstrips (runways 9/27 and 03/21) were marked on the dry lakebed.
By August 1961, construction of the essential facilities was completed (3 surplus Navy hangars were erected on the base's north side—hangars 4, 5, and 6.) A fourth, Hangar 7, was new construction. The original U-2 hangars were converted to maintenance and machine shops. Facilities in the main cantonment area included workshops and buildings for storage and administration, a commissary, control tower, fire station, and housing. The Navy also contributed more than 130 surplus Babbitt duplex housing units for long-term occupancy facilities. Older buildings were repaired, and additional facilities were constructed as necessary. A reservoir pond, surrounded by trees, served as a recreational area one mile north of the base. Other recreational facilities included a gymnasium, movie theatre, and a baseball diamond. A permanent aircraft fuel tank farm was constructed by early 1962 for the special JP-7 fuel required by the A-12. Seven tanks were constructed, with a total capacity of 1,320,000 gallons.
For the arrival of OXCART; security was enhanced and the small civilian mine in the Groom basin was closed. In January 1962, the Federal Aviation Administration (FAA) expanded the restricted airspace in the vicinity of Groom Lake. The lakebed became the center of a 600-square-mile addition to restricted area R-4808N.
The CIA facility received eight USAF F-101 Voodoos for training, two T-33 Shooting Star trainers for proficiency flying, a C-130 Hercules for cargo transport, a U-3A for administrative purposes, a helicopter for search and rescue, and a Cessna 180 for liaison use; and Lockheed provided an F-104 Starfighter for use as a chase plane.
The first A-12 test aircraft was covertly trucked from Burbank on 26 February 1962, arrived at Groom Lake on 28 February, was assembled, and made its first flight 26 April 1962 when the base had over 1,000 personnel. Initially, all not connected with a test were herded into the mess hall before each takeoff. This was soon dropped as it disrupted activities and was impractical with the large number of flights. The closed airspace above Groom Lake was within the Nellis Air Force Range airspace, and pilots saw the A-12 20-30 times (at least one signed a secrecy agreement.).
Groom was also the site of the 1st Lockheed D-21 drone test flight on 22 December 1964 (not launched until 5 March 1966). By the end of 1963, nine A-12s were at Area 51, assigned to the CIA operated "1129th Special Activities Squadron".
Although it was decided on 10 January 1967 to phase out the CIA A-12 program, A-12s at Groom Lake occasionally deployed to Kadena AB, Okinawa, for Project Black Shield in 1967 (the 9 A-12s were stored at Palmdale in June 1968 and the 1129th SAS was inactivated.)
D-21 Tagboard.
Following the loss of Gary Powers' U-2 over the Soviet Union, there were several discussions about using the A-12 OXCART as an unpiloted drone aircraft. Although Kelly Johnson had come to support the idea of drone reconnaissance, he opposed the development of an A-12 drone, contending that the aircraft was too large and complex for such a conversion. However, the Air Force agreed to fund the study of a high-speed, high-altitude drone aircraft in October 1962. The Air Force interest seems to have moved the CIA to take action, the project designated "Q-12". By October 1963, the drone's design had been finalized. At the same time, the Q-12 underwent a name change. To separate it from the other A-12-based projects, it was renamed the "D-21". (The "12" was reversed to "21"). "Tagboard" was the project's code name.
The first D-21 was completed in the spring of 1964 by Lockheed. After four more months of checkouts and static tests, the aircraft was shipped to Groom Lake and reassembled. It was to be carried by a two-seat derivative of the A-12, designated the "M-21". When the D-21/M-21 reached the launch point, the first step would be to blow off the D-21's inlet and exhaust covers. With the D-21/M-21 at the correct speed and altitude, the LCO would start the ramjet and the other systems of the D-21. With the D-21's systems activated and running, and the launch aircraft at the correct point, the M-21 would begin a slight pushover, the LCO would push a final button, and the D-21 would come off the pylon".
Difficulties were addressed throughout 1964 and 1965 at Groom Lake with various technical issues. Captive flights showed unforeseen aerodynamic difficulties. By late January 1966, more than a year after the first captive flight, everything seemed ready. The first D-21 launch was made on 5 March 1966 with a successful flight, with the D-21 flying 120 miles with limited fuel. A second D-12 flight was successful in April 1966 with the drone flying 1,200 miles, reaching Mach 3.3 and 90,000 feet. An accident on 30 July 1966 with a fully fueled D-21, on a planned checkout flight suffered from a non-start of the drone after its separation, causing it to collide with the M-21 launch aircraft. The two crewmen ejected and landed in the ocean 150 miles offshore. One crew member was picked up by a helicopter, but the other, having survived the aircraft breakup and ejection, drowned when sea water entered his pressure suit. Kelly Johnson personally cancelled the entire program, having had serious doubts from the start of the feasibility. A number of D-21s had already been produced, and rather than scrapping the whole effort, Johnson again proposed to the Air Force that they be launched from a B-52H bomber.
By late summer of 1967, the modification work to both the D-21 (now designated D-21B) and the B-52Hs were complete. The test program could now resume. The test missions were flown out of Groom Lake, with the actual launches over the Pacific. The first D-21B to be flown was Article 501, the prototype. The first attempt was made on 28 September 1967, and ended in complete failure. As the B-52 was flying toward the launch point, the D-21B fell off the pylon. The B-52H gave a sharp lurch as the drone fell free. The booster fired and was "quite a sight from the ground". The failure was traced to a stripped nut on the forward right attachment point on the pylon. Several more tests were made, none of which met with success. However, the fact is that the resumptions of D-21 tests took place against a changing reconnaissance background. The A-12 had finally been allowed to deploy, and the SR-71 was soon to replace it. At the same time, new developments in reconnaissance satellite technology were nearing operation. Up to this point, the limited number of satellites available restricted coverage to the Soviet Union. A new generation of reconnaissance satellites could soon cover targets anywhere in the world. The satellites' resolution would be comparable to that of aircraft, but without the slightest political risk. Time was running out for the Tagboard.
Several more test flights, including two over China, were made from Beale AFB, California, in 1969 and 1970, to varying degrees of success. On 15 July 1971, Kelly Johnson received a wire canceling the D-21B program. The remaining drones were transferred by a C-5A and placed in dead storage. The tooling used to build the D-21Bs was ordered destroyed. Like the A-12 Oxcart, the D-21B Tagboard drones remained a Black airplane, even in retirement. Their existence was not suspected until August 1976, when the first group was placed in storage at the Davis-Monthan AFB Military Storage and Disposition Center. A second group arrived in 1977. They were labeled "GTD-21Bs" (GT stood for ground training).
Davis-Monthan is an open base, with public tours of the storage area at the time, so the odd-looking drones were soon spotted and photos began appearing in magazines. Speculation about the D-21Bs circulated within aviation circles for years, and it was not until 1982 that details of the Tagboard program were released. However, it was not until 1993 that the B-52/D-21B program was made public. That same year, the surviving D-21Bs were released to museums.
Foreign technology evaluation.
During the Cold War, one of the missions carried out by the United States was the test and evaluation of captured Soviet fighter aircraft. Beginning in the late 1960s, and for several decades, Area 51 played host to an assortment of Soviet-built aircraft. Under the "HAVE DOUGHNUT", "HAVE DRILL" and "HAVE FERRY" programs, the first MiGs flown in the United States were used to evaluate the aircraft in performance, technical, and operational capabilities, pitting the types against U.S. fighters.
This was not a new mission, as testing of foreign technology by the USAF began during World War II. After the war, testing of acquired foreign technology was performed by the Air Technical Intelligence Center (ATIC, which became very influential during the Korean War), under the direct command of the Air Materiel Control Department. In 1961 ATIC became the Foreign Technology Division (FTD), and was reassigned to Air Force Systems Command. ATIC personnel were sent anywhere where foreign aircraft could be found.
The focus of Air Force Systems Command limited the use of the fighter as a tool with which to train the front line tactical fighter pilots. Air Force Systems Command recruited its pilots from the Air Force Flight Test Center at Edwards Air Force Base, California, who were usually graduates from various test pilot schools. Tactical Air Command selected its pilots primarily from the ranks of the Weapons School graduates.
In August 1966, Iraqi Air Force fighter pilot Captain Munir Redfa defected, flying his MiG-21 to Israel after being ordered to attack Iraqi Kurd villages with napalm. His aircraft was transferred to the Groom Lake within a month to study. In 1968 the US Air Force and Navy jointly formed a project known as "Have Doughnut" in which Air Force Systems Command, Tactical Air Command, and the U.S. Navy's Air Test and Evaluation Squadron Four (VX-4) flew this acquired Soviet made aircraft in simulated air combat training. Because U.S. possession of the Soviet MiG-21 was, itself, secret, it was tested at Groom Lake. A joint air force-navy team was assembled for a series of dogfight tests.
Comparisons between the F-4 and the MiG-21 indicated that, on the surface, they were evenly matched. But air combat was not just about technology. In the final analysis, it was the skill of the man in the cockpit. The Have Doughnut tests showed this most strongly. When the Navy or Air Force pilots flew the MiG-21, the results were a draw; the F-4 would win some fights, the MiG-21 would win others. There were no clear advantages. The problem was not with the planes, but with the pilots flying them. The pilots would not fly either plane to its limits. One of the Navy pilots was Marland W. "Doc" Townsend, then commander of VF-121, the F-4 training squadron at NAS Miramar. He was an engineer and a Korean War veteran and had flown almost every navy aircraft. When he flew against the MiG-21, he would outmaneuver it every time. The Air Force pilots would not go vertical in the MiG-21. The Have Doughnut project officer was Tom Cassidy, a pilot with VX-4, the Navy's Air Development Squadron at Point Mugu. He had been watching as Townsend "waxed" the air force MiG-21 pilots. Cassidy climbed into the MiG-21 and went up against Townsend's F-4. This time the result was far different. Cassidy was willing to fight in the vertical, flying the plane to the point where it was buffeting, just above the stall. Cassidy was able to get on the F-4's tail. After the flight, they realized the MiG-21 turned better than the F-4 at lower speeds. The key was for the F-4 to keep its speed up. What had happened in the sky above Groom Lake was remarkable. An F-4 had defeated the MiG-21; the weakness of the Soviet plane had been found. Further test flights confirmed what was learned. It was also clear that the MiG-21 was a formidable enemy. United States pilots would have to fly much better than they had been to beat it. This would require a special school to teach advanced air combat techniques.
On 12 August 1968, two Syrian air force lieutenants, Walid Adham and Radfan Rifai, took off in a pair of MiG-17Fs on a training mission. They lost their way and, believing they were over Lebanon, landed at the Beset Landing Field in northern Israel. (One version has it that they were led astray by an Arabic-speaking Israeli). Prior to the end of 1968 these MiG-17s were transferred from Israeli stocks and added to the Area 51 test fleet. The aircraft were given USAF designations and fake serial numbers so that they could be identified in DOD standard flight logs. As in the earlier program, a small group of Air Force and Navy pilots conducted mock dogfights with the MiG-17s. Selected instructors from the Navy's Top Gun school at NAS Miramar, California, were chosen to fly against the MiGs for familiarization purposes. Very soon, the MiG-17's shortcomings became clear. It had an extremely simple, even crude, control system which lacked the power-boosted controls of American aircraft. The F-4's twin engines were so powerful it could accelerate out of range of the MiG-17's guns in thirty seconds. It was important for the F-4 to keep its distance from the MiG-17. As long as the F-4 was one and a half miles from the MiG-17, it was outside the reach of the Soviet fighter's guns, but the MiG was within reach of the F-4's missiles.
The data from the Have Doughnut and Have Drill tests were provided to the newly formed Top Gun school at NAS Miramar. By 1970, the Have Drill program was expanded; a few selected fleet F-4 crews were given the chance to fight the MiGs. The most important result of Project Have Drill is that no Navy pilot who flew in the project defeated the MiG-17 Fresco in the first engagement. The Have Drill dogfights were by invitation only. The other pilots based at Nellis Air Force Base were not to know about the U.S.-operated MiGs. To prevent any sightings, the airspace above the Groom Lake range was closed. On aeronautical maps, the exercise area was marked in red ink. The forbidden zone became known as "Red Square".
During the remainder of the Vietnam War, the Navy kill ratio climbed to 8.33 to 1. In contrast, the Air Force rate improved only slightly to 2.83 to 1. The reason for this difference was Top Gun. The Navy had revitalized its air combat training, while the Air Force had stayed stagnant. Most of the Navy MiG kills were by Top Gun graduates.
In May 1973, Project "Have Idea" was formed which took over from the older Have Doughnut, Have Ferry and Have Drill projects and the project was transferred to the Tonopah Test Range Airport. At Tonopah testing of foreign technology aircraft continued and expanded throughout the 1970s and 1980s.
Area 51 also hosted another foreign materiel evaluation program called HAVE GLIB. This involved testing Soviet tracking and missile control radar systems. A complex of actual and replica Soviet-type threat systems began to grow around "Slater Lake", a mile northwest of the main base, along with an acquired Soviet "Barlock" search radar placed at Tonopah Air Force Station. They were arranged to simulate a Soviet-style air defense complex.
The Air Force began funding improvements to Area 51 in 1977 under project SCORE EVENT. In 1979, the CIA transferred jurisdiction of the Area 51 site to the Air Force Flight Test Center at Edwards AFB, California. Mr. Sam Mitchell, the last CIA commander of Area 51, relinquished command to USAF Lt. Col. Larry D. McClain.
Have Blue/F-117 program.
The Lockheed Have Blue prototype stealth fighter (a smaller proof-of-concept model of the F-117 Nighthawk) first flew at Groom in December 1977.
In 1978, the Air Force awarded a full-scale development contract for the F-117 to Lockheed Corporation's Advanced Development Projects. On 17 January 1981 the Lockheed test team at Area 51 accepted delivery of the first full Scale Development (FSD) prototype "79–780", designated YF-117A. At 6:05 am on 18 June 1981 Lockheed Skunk Works test pilot Hal Farley lifted the nose of YF-117A "79–780"' off the runway of Area 51.
Meanwhile, Tactical Air Command (TAC) decided to set up a group-level organization to guide the F-117A to an initial operating capability. That organization became the 4450th Tactical Group (Initially designated "A Unit"), which officially activated on 15 October 1979 at Nellis AFB, Nevada, although the group was physically located at Area 51. The 4450th TG also operated the A-7D Corsair II as a surrogate trainer for the F-117A, and these operations continued until 15 October 1982 under the guise of an avionics test mission.
Flying squadrons of the 4450th TG were the 4450th Tactical Squadron (Initially designated "I Unit") activated on 11 June 1981, and 4451st Tactical Squadron (Initially designated "P Unit") on 15 January 1983. The 4450th TS, stationed at Area 51, was the first F-117A squadron, while the 4451st TS was stationed at Nellis AFB and was equipped with A-7D Corsair IIs painted in a dark motif, tail coded "LV". Lockheed test pilots put the YF-117 through its early paces. A-7Ds was used for pilot training before any F-117A's had been delivered by Lockheed to Area 51, later the A-7D's were used for F-117A chase testing and other weapon tests at the Nellis Range.
15 October 1982 is important to the program because on that date Major Alton C. Whitley, Jr. became the first USAF 4450th TG pilot to fly the F-117A.
Although ideal for testing, Area 51 was not a suitable location for an operational group, so a new covert base had to be established for F-117 operations.
Tonopah Test Range Airport was selected for operations of the first USAF F-117 unit, the 4450th Tactical Group (TG). From October 1979, the Tonopah Airport base was reconstructed and expanded. The 6,000 ft runway was lengthened to 10,000 ft. Taxiways, a concrete apron, a large maintenance hangar, and a propane storage tank were added.
By early 1982, four more YF-117A airplanes were operating out of the southern end of the base, known as the "Southend" or "Baja Groom Lake". After finding a large scorpion in their offices, the testing team (Designated "R Unit") adopted it as their mascot and dubbed themselves the "Baja Scorpions". Testing of a series of ultra-secret prototypes continued at Area 51 until mid-1981, when testing transitioned to the initial production of F-117 stealth fighters. The F-117s were moved to and from Area 51 by C-5 under the cloak of darkness, in order to maintain program security. This meant that the aircraft had to be defueled, disassembled, cradled, and then loaded aboard the C-5 at night, flown to Lockheed, and unloaded at night before the real work could begin. Of course, this meant that the reverse actions had to occur at the end of the depot work before the aircraft could be reassembled, flight-tested, and redelivered, again under the cover of darkness. In addition to flight-testing, Groom performed radar profiling, F-117 weapons testing, and was the location for training of the first group of frontline USAF F-117 pilots.
Production FSD airframes from Lockheed were shipped to Area 51 for acceptance testing. As the Baja Scorpions tested the aircraft with functional check flights and L.O. verification, the operational airplanes were then transferred to the 4450th TG.
On 17 May 1982, the move of the 4450th TG from Groom Lake to Tonopah was initiated, with the final components of the move completed in early 1983. Production FSD airframes from Lockheed were shipped to Area 51 for acceptance testing. As the Baja Scorpions tested the aircraft with functional check flights and L.O. verification, the operational airplanes were then transferred to the 4450th TG at Tonopah.
The R-Unit was inactivated on 30 May 1989. Upon inactivation, the unit was reformed as Detachment 1, 57th Fighter Weapons Wing (FWW). In 1990 the last F-117A ("843") was delivered from Lockheed. After completion of acceptance flights at Area 51 of this last new F-117A aircraft, the flight test squadron continued flight test duties of refurbished aircraft after modifications by Lockheed. In February/March 1992 the test unit moved from Area 51 to the USAF Palmdale Plant 42 and was integrated with the Air Force Systems Command 6510th Test Squadron. Some testing, especially RCS verification and other classified activity was still conducted at Area 51 throughout the operational lifetime of the F-117. The recently inactivated (2008) 410th Flight Test Squadron traces its roots, if not its formal lineage to the 4450th TG R-unit.
Later operations.
Since the F-117 became operational in 1983, operations at Groom Lake have continued. The base and its associated runway system were expanded, including expansion of housing and support facilities. In 1995, the federal government expanded the exclusionary area around the base to include nearby mountains that had hitherto afforded the only decent overlook of the base, prohibiting access to 3972 acre of land formerly administered by the Bureau of Land Management.
U.S. government's positions on Area 51.
The amount of information the United States government has been willing to provide regarding Area 51 has generally been minimal.
The USGS topographic map for the area only shows the long-disused Groom Mine. A civil aviation chart published by the Nevada Department of Transportation shows a large restricted area, defined as part of the Nellis restricted airspace. The National Atlas page showing federal lands in Nevada shows the area as lying within the Nellis Air Force Base. Higher resolution (and more recent) images from other satellite imagery providers (including Russian providers and the IKONOS) are commercially available. These show the runway markings, base facilities, aircraft, and vehicles.
Although federal property within the base is exempt from state and local taxes, facilities owned by private contractors are not.
When documents that mention the Nevada Test Site (NTS) and operations at Groom are declassified, mentions of Area 51 and Groom Lake are routinely redacted. One exception is a 1967 memo from CIA director Richard Helms regarding the deployment of three OXCART aircraft from Groom to Kadena Air Base to perform reconnaissance over North Vietnam. Although most mentions of OXCART's home base are redacted in this document, as is a map showing the aircraft's route from there to Okinawa, the redactor appears to have missed one mention: page 15 (page 17 in the PDF), section No. 2 ends "Three OXCART aircraft and the necessary task force personnel will be deployed from Area 51 to Kadena."
In July 2013, CIA released an official history of the U-2 and OXCART projects that officially acknowledged the existence of Area 51. The release was in response to a Freedom of Information Act request submitted in 2005 by Jeffrey T. Richelson of George Washington University's National Security Archives, and contain numerous references to Area 51 and Groom Lake, along with a map of the area..
Security and operations.
The area surrounding the lake is permanently off-limits both to civilian and normal military air traffic. Security clearances are checked regularly; cameras and weaponry are not allowed. Even military pilots training in the NAFR risk disciplinary action if they stray into the exclusionary "box" surrounding Groom's airspace. Surveillance is supplemented using buried motion sensors. Area 51 is a common destination for Janet, the "de facto" name of a small fleet of passenger aircraft operated on behalf of the United States Air Force to transport military personnel, primarily from McCarran International Airport.
Civil Aviation identification.
In December 2007, airline pilots noticed that the base had appeared in their aircraft navigation systems' latest Jeppesen database revision with the ICAO airport identifier code of KXTA and listed as "Homey Airport". The probably inadvertent release of the airport data led to advice by the Aircraft Owners and Pilots Association (AOPA) that student pilots should be explicitly warned about KXTA, not to consider it as a waypoint or destination for any flight even though it now appears in public navigation databases.
Environmental lawsuit.
In 1994, five unnamed civilian contractors and the widows of contractors Walter Kasza and Robert Frost sued the USAF and the United States Environmental Protection Agency. Their suit, in which they were represented by George Washington University law professor Jonathan Turley, alleged they had been present when large quantities of unknown chemicals had been burned in open pits and trenches at Groom. Biopsies taken from the complainants were analyzed by Rutgers University biochemists, who found high levels of dioxin, dibenzofuran, and trichloroethylene in their body fat. The complainants alleged they had sustained skin, liver, and respiratory injuries due to their work at Groom, and that this had contributed to the deaths of Frost and Kasza. The suit sought compensation for the injuries they had sustained, claiming the USAF had illegally handled toxic materials, and that the EPA had failed in its duty to enforce the Resource Conservation and Recovery Act (which governs handling of dangerous materials.) They also sought detailed information about the chemicals to which they were allegedly exposed, hoping this would facilitate the medical treatment of survivors. Congressman Lee H. Hamilton, former chairman of the House Intelligence Committee, told "60 Minutes" reporter Lesley Stahl, "The Air Force is classifying all information about Area 51 in order to protect themselves from a lawsuit."
Citing the State Secrets Privilege, the government petitioned trial judge U.S. District Judge Philip Pro (of the United States District Court for the District of Nevada in Las Vegas) to disallow disclosure of classified documents or examination of secret witnesses, alleging this would expose classified information and threaten national security. When Judge Pro rejected the government's argument, President Bill Clinton issued a Presidential Determination, exempting what it called, "The Air Force's Operating Location Near Groom Lake, Nevada" from environmental disclosure laws. Consequently, Pro dismissed the suit due to lack of evidence. Turley appealed to the U.S. Court of Appeals for the Ninth Circuit, on the grounds that the government was abusing its power to classify material. Secretary of the Air Force Sheila E. Widnall filed a brief that stated that disclosures of the materials present in the air and water near Groom "can reveal military operational capabilities or the nature and scope of classified operations." The Ninth Circuit rejected Turley's appeal, and the U.S. Supreme Court refused to hear it, putting an end to the complainants' case.
The President continues to annually issue a determination continuing the Groom exception. This, and similarly tacit wording used in other government communications, is the only formal recognition the U.S. Government has ever given that Groom Lake is more than simply another part of the Nellis complex.
An unclassified memo on the safe handling of F-117 Nighthawk material was posted on an Air Force web site in 2005. This discussed the same materials for which the complainants had requested information (information the government had claimed was classified). The memo was removed shortly after journalists became aware of it.
1974 Skylab photography.
In January 2006, space historian Dwayne A. Day published an article in online aerospace magazine "The Space Review" titled "Astronauts and Area 51: the Skylab Incident". The article was based on a memo written in 1974 to CIA director William Colby by an unknown CIA official. The memo reported that astronauts on board Skylab 4 had, as part of a larger program, inadvertently photographed a location of which the memo said:
There were specific instructions not to do this. <redacted> was the only location which had such an instruction.
Although the name of the location was obscured, the context led Day to believe that the subject was Groom Lake. As Day noted:
[I]n other words, the CIA considered no other spot on Earth to be as sensitive as Groom Lake.
The memo details debate between federal agencies regarding whether the images should be classified, with Department of Defense agencies arguing that it should, and NASA and the State Department arguing against classification. The memo itself questions the legality of unclassified images to be retroactively classified.
Remarks on the memo, handwritten apparently by DCI (Director of Central Intelligence) Colby himself, read:
[Secretary of State Rusk] did raise it—said State Dept. people felt strongly. But he inclined leave decision to me (DCI)—I confessed some question over need to protect since:
The declassified documents do not disclose the outcome of discussions regarding the Skylab imagery. The behind-the-scenes debate proved moot as the photograph appeared in the Federal Government's Archive of Satellite Imagery along with the remaining Skylab 4 photographs, with no record of anyone noticing until Day identified it in 2007.
Other satellite imagery.
Other satellite imagery is also available, including images that show what appears to be F-16 Fighting Falcon aircraft stationed on the base.
UFO and other conspiracy theories.
Its secretive nature and undoubted connection to classified aircraft research, together with reports of unusual phenomena, have led Area 51 to become a focus of modern UFO and conspiracy theories. Some of the activities mentioned in such theories at Area 51 include:
Many of the hypotheses concern underground facilities at Groom or at Papoose Lake (also known as "S-4 location"), 8.5 mi south, and include claims of a transcontinental underground railroad system, a disappearing airstrip (nicknamed the "Cheshire Airstrip", after Lewis Carroll's Cheshire cat) which briefly appears when water is sprayed onto its camouflaged asphalt, and engineering based on alien technology. Publicly available satellite imagery, however, reveals clearly visible landing strips at Groom Dry Lake, but not at Papoose Lake.
In the mid-1950s, civilian aircraft flew under 20,000 feet while military aircraft flew under 40,000 feet. Once the U-2 began flying at above 60,000 feet, an unexpected side effect was an increasing number of UFO sighting reports. Sightings occurred most often during early evenings hours, when airline pilots flying west saw the U-2's silver wings reflect the setting sun, giving the aircraft a "fiery" appearance. Many sighting reports came to the Air Force's Project Blue Book, which investigated UFO sightings, through air-traffic controllers and letters to the government. The project checked U-2 and later OXCART flight records to eliminate the majority of UFO reports it received during the late 1950s and 1960s, although it could not reveal to the letter writers the truth behind what they saw.:72–73 Similarly, veterans of experimental projects such as OXCART and NERVA at Area 51 agree that their work (including 2,850 OXCART test flights alone) inadvertently prompted many of the UFO sightings and other rumors:
The shape of OXCART was unprecedented, with its wide, disk-like fuselage designed to carry vast quantities of fuel. Commercial pilots cruising over Nevada at dusk would look up and see the bottom of OXCART whiz by at 2,000-plus mph. The aircraft's titanium body, moving as fast as a bullet, would reflect the sun's rays in a way that could make anyone think, "UFO".
They believe that the rumors helped maintain secrecy over Area 51's actual operations. While the veterans deny the existence of a vast underground railroad system, many of Area 51's operations did (and presumably still do) occur underground.
In popular culture.
Novels, films, television programs, and other fictional portrayals of Area 51 describe it—or a fictional counterpart—as a haven for extraterrestrials, time travel, and sinister conspiracies, often linking it with the Roswell UFO incident.
The Las Vegas 51s are a AAA minor league professional baseball team.

</doc>
<doc id="2322" url="http://en.wikipedia.org/wiki?curid=2322" title="Audio signal processing">
Audio signal processing

Audio signal processing, sometimes referred to as audio processing, is the intentional alteration of auditory signals, or sound, often through an audio effect or effects unit. As audio signals may be electronically represented in either digital or analog format, signal processing may occur in either domain. Analog processors operate directly on the electrical signal, while digital processors operate mathematically on the digital representation of that signal.
History.
Audio signals are sound waves—longitudinal waves which travel through air, consisting of compressions and rarefactions. These audio signals are measured in bels or in decibels. Audio processing was necessary for early radio broadcasting, as there were many problems with studio to transmitter links.
Analog signals.
"Analog" indicates something that is mathematically represented by a set of continuous values; for example, the analog clock uses constantly moving hands on a physical clock face, where moving the hands directly alters the information that clock is providing. Thus, an analog signal is one represented by a continuous stream of data, in this case along an electrical circuit in the form of voltage, current or charge changes "(compare with digital signals below)". Analog signal processing (ASP) then involves physically altering the continuous signal by changing the voltage or current or charge via various electrical means.
Historically, before the advent of widespread digital technology, ASP was the only method by which to manipulate a signal. Since that time, as computers and software became more advanced, digital signal processing has become the method of choice.
Digital signals.
A digital representation expresses the pressure wave-form as a sequence of symbols, usually binary numbers. This permits signal processing using digital circuits such as microprocessors and computers. Although such a conversion can be prone to loss, most modern audio systems use this approach as the techniques of digital signal processing are much more powerful and efficient than analog domain signal processing.
Application areas.
Processing methods and application areas include storage, level compression, data compression, transmission, enhancement (e.g., equalization, filtering, noise cancellation, echo or reverb removal or addition, etc.)
Audio broadcasting.
Traditionally the most important audio processing (in audio broadcasting) takes place just before the transmitter. Studio audio processing is limited in the modern era due to digital audio systems (mixers, routers) being pervasive in the studio.
In audio broadcasting, the audio processor must
Techniques.
Audio unprocessed by reverb and delay is metaphorically referred to as "dry", while processed audio is referred to as "wet".

</doc>
<doc id="2323" url="http://en.wikipedia.org/wiki?curid=2323" title="Amdahl's law">
Amdahl's law

Amdahl's law, also known as Amdahl's argument, is used to find the maximum expected improvement to an overall system when only part of the system is improved. It is often used in parallel computing to predict the theoretical maximum speedup using multiple processors. The law is named after computer architect Gene Amdahl, and was presented at the AFIPS Spring Joint Computer Conference in 1967.
The speedup of a program using multiple processors in parallel computing is limited by the time needed for the sequential fraction of the program. For example, if a program needs 20 hours using a single processor core, and a particular portion of the program which takes one hour to execute cannot be parallelized, while the remaining 19 hours (95%) of execution time can be parallelized, then regardless of how many processors are devoted to a parallelized execution of this program, the minimum execution time cannot be less than that critical one hour. Hence the speedup is limited to at most 20×.
Definition.
Given:
The time formula_3 an algorithm takes to finish when being executed on formula_4 thread(s) of execution corresponds to:
formula_5
Therefore, the theoretical speedup formula_6 that can be had by executing a given algorithm on a system capable of executing formula_4 threads of execution is:
formula_8
Description.
Amdahl's law is a model for the expected speedup and the relationship between parallelized implementations of an algorithm and its sequential implementations, under the assumption that the problem size remains the same when parallelized. For example, if for a given problem size a parallelized implementation of an algorithm can run 12% of the algorithm's operations arbitrarily quickly (while the remaining 88% of the operations are not parallelizable), Amdahl's law states that the maximum speedup of the parallelized version is 1/(1 – 0.12) = 1.136 times as fast as the non-parallelized implementation.
More technically, the law is concerned with the speedup achievable from an improvement to a computation that affects a proportion "P" of that computation where the improvement has a speedup of "S". (For example, if 30% of the computation may be the subject of a speed up, "P" will be 0.3; if the improvement makes the portion affected twice as fast, "S" will be 2.) Amdahl's law states that the overall speedup of applying the improvement will be:
To see how this formula was derived, assume that the running time of the old computation was 1, for some unit of time. The running time of the new computation will be the length of time the unimproved fraction takes (which is 1 − "P"), plus the length of time the improved fraction takes. The length of time for the improved part of the computation is the length of the improved part's former running time divided by the speedup, making the length of time of the improved part "P"/"S". The final speedup is computed by dividing the old running time by the new running time, which is what the above formula does.
Here's another example. We are given a sequential task which is split into four consecutive parts: P1, P2, P3 and P4 with the percentages of runtime being 11%, 18%, 23% and 48% respectively. Then we are told that P1 is not sped up, so S1 = 1, while P2 is sped up 5×, P3 is sped up 20×, and P4 is sped up 1.6×. By using the formula
P1/S1 + P2/S2 + P3/S3 + P4/S4, we find the new sequential running time is:
or a little less than 1⁄2 the original running time. Using the formula (P1/S1 + P2/S2 + P3/S3 + P4/S4)−1, the overall speed boost is 1 / 0.4575 = 2.186, or a little more than double the original speed. Notice how the 20× and 5× speedup don't have much effect on the overall speed when P1 (11%) is not sped up, and P4 (48%) is sped up only 1.6 times.
Parallelization.
In the case of parallelization, Amdahl's law states that if "P" is the proportion of a program that can be made parallel (i.e., benefit from parallelization), and (1 − "P") is the proportion that cannot be parallelized (remains serial), then the maximum speedup that can be achieved by using "N" processors is
In the limit, as "N" tends to infinity, the maximum speedup tends to 1 / (1 − "P"). In practice, performance to price ratio falls rapidly as "N" is increased once there is even a small component of (1 − "P").
As an example, if "P" is 90%, then (1 − "P") is 10%, and the problem can be sped up by a maximum of a factor of 10, no matter how large the value of "N" used. For this reason, parallel computing is only useful for either small numbers of processors, or problems with very high values of "P": so-called embarrassingly parallel problems. A great part of the craft of parallel programming consists of attempting to reduce the component (1 – "P") to the smallest possible value.
"P" can be estimated by using the measured speedup ("SU") on a specific number of processors ("NP") using
"P" estimated in this way can then be used in Amdahl's law to predict speedup for a different number of processors.
Relation to law of diminishing returns.
Amdahl's law is often conflated with the law of diminishing returns, whereas only a special case of applying Amdahl's law demonstrates 'law of diminishing returns'. If one picks optimally (in terms of the achieved speed-up) what to improve, then one will see monotonically decreasing improvements as one improves. If, however, one picks non-optimally, after improving a sub-optimal component and moving on to improve a more optimal component, one can see an increase in return. Note that it is often rational to improve a system in an order that is "non-optimal" in this sense, given that some improvements are more difficult or consuming of development time than others.
Amdahl's law does represent the law of diminishing returns if you are considering what sort of return you get by adding more processors to a machine, if you are running a fixed-size computation that will use all available processors to their capacity. Each new processor you add to the system will add less usable power than the previous one. Each time you double the number of processors the speedup ratio will diminish, as the total throughput heads toward the limit of formula_13.
This analysis neglects other potential bottlenecks such as memory bandwidth and I/O bandwidth, if they do not scale with the number of processors; however, taking into account such bottlenecks would tend to further demonstrate the diminishing returns of only adding processors.
Speedup in a sequential program.
The maximum speedup in an improved sequential program, where some part was sped up formula_14 times is limited by inequality
where formula_16 (formula_17) is the fraction of time (before the improvement) spent in the part that was not improved. For example (see picture on right):
Therefore, making A twice as fast is better than making B five times faster. The percentage improvement in speed can be calculated as
Limitations.
Amdahl's law only applies to cases where the problem size is fixed. In practice, as more computing resources become available, they tend to get used on larger problems (larger datasets), and the time spent in the parallelizable part often grows much faster than the inherently sequential work. In this case, Gustafson's law gives a more realistic assessment of parallel performance.

</doc>
<doc id="2326" url="http://en.wikipedia.org/wiki?curid=2326" title="April 27">
April 27

April 27 is the day of the year in the Gregorian calendar.

</doc>
<doc id="2328" url="http://en.wikipedia.org/wiki?curid=2328" title="Ayahuasca">
Ayahuasca

Ayahuasca (usually pronounced or ), also commonly called yagé (), is an entheogenic brew made out of "Banisteriopsis caapi" vine, often in combination with various other plants. It can be mixed with the leaves of Chacruna or Chacropanga, dimethyltryptamine (DMT)-containing plant species. The brew, first described academically in the early 1950s by Harvard ethnobotanist Richard Evans Schultes, who found it employed for divinatory and healing purposes by the native peoples of Amazonian Peru, is known by a number of different names (see below).
It has been reported that some effects can be felt from consuming the caapi vine alone, but that DMT-containing plants (such as "Psychotria") remain inactive when drunk as a brew without a source of monoamine oxidase inhibitor (MAOI) such as "B. caapi". It is unclear how indigenous peoples discovered the hallucinogenic properties of the plants used in the ayahuasca brew. Many indigenous Amazonian people say they received the instructions directly from plants and plant spirits.
Effects.
People who have consumed ayahuasca report having Spiritual revelations regarding their purpose on Earth, the true nature of the Universe as well as deep insight into how to be the best person they possibly can. This is viewed by many as a Spiritual awakening and what is often described as a rebirth. In addition, it is often reported that individuals feel they gain access to higher Spiritual dimensions and make contact with various Spiritual or extra-dimensional beings who can act as guides or healers.
Author Don Jose Campos claims that people may experience profound positive life changes subsequent to consuming ayahuasca. Vomiting can follow ayahuasca ingestion; this purging is considered by many shamans and experienced users of ayahuasca to be an essential part of the experience, as it represents the release of negative energy and emotions built up over the course of one's life. Others report purging in the form of nausea, diarrhea, and hot/cold flashes.
The ingestion of ayahuasca can also cause significant, but temporary, emotional and psychological distress (the "bad trip" experience). Long-term negative effects are not known. However, deaths due to participation in the consumption of ayahuasca have been reported. The deaths may be due to preexisting heart conditions, as ayahuasca may increase pulse rates and blood pressure, or interaction with other medicines taken, such as antidepressants, and in some cases possibly a result of the addition of toé in the brew.
Role of shamans.
Some shamans and experienced users of ayahuasca advise against consuming ayahuasca when not in the presence of one or several well-trained shamans.
In some areas there are purported brujos who masquerade as real shamans and who entice tourists to drink ayahuasca in their presence. Shamans believe one of the purposes for this is to steal one's energy and/or power, of which they believe every person has a stockpile.
Nomenclature.
Ayahuasca is known by many names throughout Northern South America and Brazil.
"Ayahuasca" is the hispanicized style spelling of a word in the Quechua languages, which are spoken in the Andean states of Ecuador, Bolivia, Peru, and Colombia. Speakers of Quechua languages or of the Aymara language may prefer the spelling "ayawaska". This word refers both to the liana "Banisteriopsis caapi", and to the brew prepared from it. In the Quechua languages, "aya" means "spirit, soul", "corpse, dead body", and "waska" means "rope" and "woody vine", "liana". The word "ayahuasca" has been variously translated as "liana of the soul", "liana of the dead", and "spirit liana".
In Brazil, the brew and the liana are informally called either caapi or cipó; the latter is the Portuguese word for liana (or woody climbing vine). In the União do Vegetal of Brazil, an organised spiritual tradition in which people drink ayahuasca, the brew is prepared exclusively from "B. caapi" and "P. viridis". Adherents of União do Vegetal call this brew hoasca or vegetal.
In the Tucanoan languages it is called yagé or yajé (both pronounced ]). The Achuar people and Shuar people of Ecuador and Peru call it natem, whereas the Sharanahua peoples of Peru call it shori.
Chemistry.
Harmala alkaloids are MAO-inhibiting "beta"-carbolines. The three most studied harmala alkaloids in the "B. caapi" vine are harmine, harmaline and tetrahydroharmine. Harmine and harmaline are selective and reversible inhibitors of monoamine oxidase A (MAO-A), while tetrahydroharmine is a weak serotonin reuptake inhibitor (SRI).
This inhibition of MAO-A allows DMT to diffuse unmetabolized past the membranes in the stomach and small intestine, and eventually cross the blood–brain barrier (which, by itself, requires no MAO-A inhibition) to activate receptor sites in the brain. Without RIMAs or the MAOI of MAO-A, DMT would be oxidised (and thus rendered biologically inactive) by monoamine oxidase enzymes in the digestive tract.
Individual polymorphisms in the cytochrome P450-2D6 enzyme affect the ability of individuals to metabolize harmine. Some natural tolerance to habitual use of ayahuasca (roughly once weekly) may develop through upregulation of the serotonergic system. A phase 1 pharmacokinetic study on ayahuasca (as Hoasca) with 15 volunteers was conducted in 1993, during the Hoasca Project. A review of the Hoasca Project has been published.
Preparation.
Sections of "Banisteriopsis caapi" vine are macerated and boiled alone or with leaves from any of a number of other plants, including "Psychotria viridis" ("chacruna") or "Diplopterys cabrerana" (also known as "chaliponga" and "chacropanga"). The resulting brew may contain the powerful psychedelic drug DMT and MAO inhibiting harmala alkaloids, which are necessary to make the DMT orally active.
Brews can also be made with no DMT-containing plants; "Psychotria viridis" being substituted by plants such as "Justicia pectoralis", "Brugmansia", or sacred tobacco, also known as "Mapacho" (Nicotiana rustica), or sometimes left out with no replacement. The potency of this brew varies radically from one batch to the next, both in potency and psychoactive effect, based mainly on the skill of the shaman or brewer, as well as other admixtures sometimes added and the intent of the ceremony. Natural variations in plant alkaloid content and profiles also affect the final concentration of alkaloids in the brew, and the physical act of cooking may also serve to modify the alkaloid profile of harmala alkaloids.
Traditional brew.
Traditional ayahuasca brews are often made with "Banisteriopsis caapi" as an MAOI, although Dimethyltryptamine sources and other admixtures vary from region to region. There are several varieties of caapi, often known as different "colors", with varying effects, potencies, and uses.
DMT admixtures:
Other common admixtures:
Common admixtures with their associated ceremonial values and spirits:
Usage.
Ayahuasca is used largely as a religious sacrament. Users of ayahuasca in non-traditional contexts often align themselves with the philosophies and cosmologies associated with ayahuasca shamanism, as practiced among indigenous peoples like the Urarina of Peruvian Amazonia. While non-native users know of the Spiritual applications of ayahuasca, a less well-known traditional usage focuses on the medicinal properties of ayahuasca. When used for its medicinal purposes, ayahuasca affects the human consciousness for fewer than six hours, beginning half an hour after consumption and peaking after two hours. Ayahuasca also has cardiovascular effects, moderately increasing both heart rate and diastolic blood pressure. In some cases, individuals experience significant psychological stress during the experience. It is for this reason that extreme caution should be taken with those who may be at risk of heart disease.
The psychedelic effects of ayahuasca include visual and auditory stimulation, the mixing of sensory modalities, and psychological introspection that may lead to great elation, fear, or illumination. Its purgative properties are important (known as "la purga" or "the purge"). The intense vomiting and occasional diarrhea it induces can clear the body of worms and other tropical parasites, and harmala alkaloids themselves have been shown to be anthelmintic. Thus, this action is twofold; a direct action on the parasites by these harmala alkaloids (particularly harmine in ayahuasca) works to kill the parasites, and parasites are expelled through the increased intestinal motility that is caused by these alkaloids.
Dietary taboos are often associated with the use of ayahuasca. In the rainforest, these tend towards the purification of one's self – abstaining from spicy and heavily-seasoned foods, excess fat, salt, caffeine, acidic foods (such as citrus) and sex before, after, or during a ceremony. A diet low in foods containing tyramine has been recommended, as the speculative interaction of tyramine and MAOIs could lead to a hypertensive crisis. However, evidence indicates that harmala alkaloids act only on MAO-A, in a reversible way similar to moclobemide (an antidepressant that does not require dietary restrictions). Dietary restrictions are not used by the highly urban Brazilian ayahuasca church União do Vegetal, suggesting the risk is much lower than perceived, and probably non-existent.
Non-traditional usage.
In the late 20th century, the practice of ayahuasca drinking began spreading to Europe, North America and elsewhere. The first ayahuasca Churches, affiliated with the Brazilian Santo Daime, were established in the Netherlands. A legal case was filed against two of the Church's leaders, Hans Bogers (one of the original founders of the Dutch Santo Daime community) and Geraldine Fijneman (the head of the Amsterdam Santo Daime community). Bogers and Fijneman were charged with distributing a controlled substance (DMT); however, the prosecution was unable to prove that the use of ayahuasca by members of the Santo Daime constituted a sufficient threat to public health and order that it warranted denying their rights to religious freedom under ECHR Article 9. The 2001 verdict of the Amsterdam district court is an important precedent. Since then groups that are not affiliated to the Santo Daime have used ayahuasca, and a number of different 'styles' have been developed, including non-religious approaches.
In modern Europe and North America, ayahuasca analogues are often prepared using non-traditional plants which contain the same alkaloids. For example, seeds of the Syrian rue plant can be used as a substitute for the ayahuasca vine, and the DMT-rich "Mimosa hostilis" is used in place of "chakruna". Australia has several indigenous plants which are popular among modern ayahuasqueros there, such as various DMT-rich species of "Acacia".
The name 'ayahuasca' specifically refers to a botanical decoction that contains "Banisteriopsis caapi". A synthetic version, known as pharmahuasca, is a combination of an appropriate MAOI and typically DMT. In this usage, the DMT is generally considered the main psychoactive active ingredient, while the MAOI merely preserves the psychoactivity of orally ingested DMT, which would otherwise be destroyed in the gut before it could be absorbed in the body. Thus, ayahuasqueros and most others working with the brew maintain that the "B. caapi" vine is the defining ingredient, and that this beverage is not ayahuasca unless "B. caapi" is in the brew. The vine is considered to be the "spirit" of ayahuasca, the gatekeeper and guide to the otherworldly realms.
Ayahuasca may be prepared using several plants not traditionally used in South America:
DMT admixtures:
MAOI:
History.
In the 16th century, Christian missionaries from Spain and Portugal first encountered indigenous South Americans using ayahuasca; their earliest reports described it as the work of the devil. In the 20th century, the active chemical constituent of "B. caapi" was named "telepathine", but it was found to be identical to a chemical already isolated from "Peganum harmala" and was given the name harmaline. Beat writer William Burroughs read a paper by Richard Evans Schultes on the subject and sought out "yagé" in the early 1950s while traveling through South America in the hopes that it could relieve or cure opiate addiction (see "The Yage Letters"). Ayahuasca became more widely known when the McKenna brothers published their experience in the Amazon in "True Hallucinations". Dennis McKenna later studied the pharmacology, botany, and chemistry of ayahuasca and oo-koo-he, which became the subject of his master's thesis.
In Brazil, a number of modern religious movements based on the use of ayahuasca have emerged, the most famous of them being Santo Daime and the União do Vegetal (or UDV), usually in an animistic context that may be shamanistic or, more often (as with Santo Daime and the UDV), integrated with Christianity. Both Santo Daime and União do Vegetal now have members and churches throughout the world. Similarly, the US and Europe have started to see new religious groups develop in relation to increased ayahuasca use. Some Westerners have teamed up with shamans in the Amazon rainforest regions, forming ayahuasca healing retreats that claim to be able to cure mental and physical illness and allow communication with the spirit world. Some reports and scientific studies affirm that ritualized use of ayahuasca may improve mental and physical health.
In recent years, the tea has been popularized by Wade Davis ("The Serpent and The Rainbow"), English novelist Martin Goodman in , Chilean novelist Isabel Allende, writer Kira Salak, author Jeremy Narby ("The Cosmic Serpent"), author Jay Griffiths (""), and radio personality Robin Quivers.
In 2008, psychology professor Benny Shanon published a controversial hypothesis that a brew analogous to Ayahuasca was heavily connected to early Judaism, and that the effects of this brew were responsible for some of the most significant events of Moses' life, including his vision of the burning bush.
Research.
Charles Grob directed the first major study of the effects of ayahuasca on humans with the Hoasca Project in 1993. The project studied members of the União do Vegetal (UDV) church in Brazil who use hoasca as a sacrament. As part of the Hoasca Project, Da Silveria et al. (2005) conducted a comparative study of adolescents subscribing to an indigenous Amazonian belief system that sacramentally used ayahuasca and their urban Brazilian counterparts. Da Silveria et al. measured psychiatric diagnoses scores to chose participants who used ayahuasca in a culturally specific manner twice per month and started doing so just at the onset of adolescence. Next, all the participants were scored for substance abuse disorders, anxiety, and depression, body image disorders, and attention deficit hyperactivity disorder using preestablished questionnaires and the DSM-IV. As compared to the control group, ayahuasca-using adolescents scored as much as seven times less in criteria where differences were statistically significant. Those criteria were body image perception, anxiety, and attention disorders, which often trouble Western youth. This data suggests that culturally specific use of ayahuasca could circumvent some of the psychological and cognitive issues adolescents are prone to facing and enhance their ability to self-actuate to the fullest potential.
However, as with research on other entheogens or psychedelics, scientific studies of ayahuasca present some significant challenges to investigators, including philosophical questions relating to ontology, epistemology and objectivity.
Legal status.
Internationally, DMT is a Schedule I drug under the Convention on Psychotropic Substances. The Commentary on the Convention on Psychotropic Substances notes, however, that the plants containing it are not subject to international control:
The cultivation of plants from which psychotropic substances are obtained is not controlled by the Vienna Convention. . . . Neither the crown (fruit, mescal button) of the Peyote cactus nor the roots of the plant Mimosa hostilis nor Psilocybe mushrooms themselves are included in Schedule 1, but only their respective principals, mescaline, DMT and psilocin.
A fax from the Secretary of the International Narcotics Control Board (INCB) to the Netherlands Ministry of Public Health sent in 2001 goes on to state that "Consequently, preparations (e.g. decoctions) made of these plants, including ayahuasca, are not under international control and, therefore, not subject to any of the articles of the 1971 Convention."
Despite the INCB's 2001 affirmation that ayahuasca is not subject to drug control by international convention, in its 2010 Annual Report the Board recommended that governments consider controlling (i.e. criminalizing) ayahuasca at the national level. This recommendation by the INCB has been criticized as an attempt by the Board to overstep its legitimate mandate and as establishing a reason for governments to violate the human rights (i.e., religious freedom) of ceremonial ayahuasca drinkers.
The legal status in the United States of DMT-containing plants is somewhat questionable. Ayahuasca plants and preparations are legal, as they contain no scheduled chemicals. However, brews made using DMT containing plants are illegal since DMT is a Schedule I drug. That said, some people are challenging this, using arguments similar to those used by peyotist religious sects, such as the Native American Church. A court case allowing the União do Vegetal to import and use the tea for religious purposes in the United States, "Gonzales v. O Centro Espirita Beneficente Uniao do Vegetal", was heard by the U.S. Supreme Court on November 1, 2005; the decision, released February 21, 2006, allows the UDV to use the tea in its ceremonies pursuant to the Religious Freedom Restoration Act. In a similar case an Ashland, Oregon-based Santo Daime church sued for their right to import and consume ayahuasca tea. In March 2009, U.S. District Court Judge Panner ruled in favor of the Santo Daime, acknowledging its protection from prosecution under the Religious Freedom Restoration Act.
Religious use in Brazil was legalized after two official inquiries into the tea in the mid-1980s, which concluded that ayahuasca is not a recreational drug and has valid spiritual uses.
In France, Santo Daime won a court case allowing them to use the tea in early 2005; however, they were not allowed an exception for religious purposes, but rather for the simple reason that they did not perform chemical extractions to end up with pure DMT and harmala and the plants used were not scheduled. Four months after the court victory, the common ingredients of ayahuasca as well as harmala were declared "stupéfiants", or narcotic schedule I substances, making the tea and its ingredients illegal to use or possess.
Legal issues.
Ayahuasca has also stirred debate regarding intellectual property protection of traditional knowledge. In 1986 the US Patent and Trademarks Office allowed the granting of a patent on the ayahuasca vine B. Caapi. It allowed this patent based on the assumption that ayahuasca's properties had not been previously described in writing. Several public interest groups, including the Coordinating Body of Indigenous Organizations of the Amazon Basin (COICA) and the Coalition for Amazonian Peoples and Their Environment (Amazon Coalition) objected. In 1999 they brought a legal challenge to this patent which had granted a private US citizen "ownership" of the knowledge of a plant that is well-known and sacred to many indigenous peoples of the Amazon, and used by them in religious and healing ceremonies.
Later that year the PTO issued a decision rejecting the patent, on the basis that the petitioners' arguments that the plant was not "distinctive or novel" were valid. However, the decision did not acknowledge the argument that the plant's religious or cultural values prohibited a patent. In 2001, after an appeal by the patent holder, the US Patent Office reinstated the patent. The law at the time did not allow a third party such as COICA to participate in that part of the reexamination process. The patent, held by US entrepreneur Loren Miller, expired in 2003.
Further reading.
</dl>

</doc>
<doc id="2329" url="http://en.wikipedia.org/wiki?curid=2329" title="Alfonso Leng">
Alfonso Leng

Alfonso Leng Haygus (11 February 1884 – 11 November 1974) was a post-romantic composer of classical music. He was born in Santiago, Chile. He wrote the first important symphonic work in Chilean tradition, "La Muerte de Alcino", a symphonic poem inspired by the novel of Pedro Prado. He composed many art songs in different languages and important piano pieces, like the five "Doloras" (1914), which he later orchestrated and are normally played in concerts in Chile and Latin America. He won the Nacional Art Prize in 1957.
Leng was also an accomplished dentist in Santiago. As a dentist, he was the main founder of the dentistry faculty of the Universidad de Chile, and he was eventually elected as the first dean.
Leng was the nephew of composer Carmela Mackenna.

</doc>
<doc id="2330" url="http://en.wikipedia.org/wiki?curid=2330" title="Abbe number">
Abbe number

In physics and optics, the Abbe number, also known as the V-number or constringence of a transparent material, is a measure of the material's dispersion (variation of refractive index with wavelength) in relation to the refractive index, with high values of "V" indicating low dispersion (low chromatic aberration). It is named after Ernst Abbe (1840–1905), the German physicist who defined it.
The Abbe number, "VD", of a material is defined as
where "n"D, "n"F and "n"C are the refractive indices of the material at the wavelengths of the Fraunhofer D-, F- and C- spectral lines (589.3 nm, 486.1 nm and 656.3 nm respectively). 
Abbe numbers are used to classify glass and other optically transparent materials. For example, flint glass has "V" < 50 and crown glass has "V" > 50. Typical values of "V" range from around 20 for very dense flint glass, around 30 for polycarbonate plastics, and up to 65 for very light crown glass, and up to 85 for fluor-crown glass. Abbe numbers are only a useful measure of dispersion for visible light, and for other wavelengths, or for higher precision work, the group velocity dispersion (the full dispersion relation) is used.
Due to the difficulty and inconvenience in producing sodium and hydrogen lines, alternate definitions of the Abbe number are used in some contexts (ISO 7944). The value "V"d is given by
which defines the Abbe number with respect to the yellow Fraunhofer d (or D3) helium line at 587.5618 nm wavelength. It can also be defined using the green mercury E-line at 546.073 nm:
where F' and C' are the blue and red cadmium lines at 480.0 nm and 643.8 nm, respectively.
An Abbe diagram is produced by plotting the Abbe number "V"d of a material versus its refractive index "n"d. Glasses can then be categorised by their composition and position on the diagram. This can be a letter-number code, as used in the Schott Glass catalogue, or a 6-digit glass code.
Abbe numbers are used to calculate the necessary focal lengths of achromatic doublet lenses to minimize chromatic aberration.
The following table lists standard wavelengths at which n is usually determined, indicated by subscripts. For example, nD is measured at 589.3 nm:

</doc>
<doc id="2331" url="http://en.wikipedia.org/wiki?curid=2331" title="ACN">
ACN

ACN may refer to:

</doc>
<doc id="2332" url="http://en.wikipedia.org/wiki?curid=2332" title="AD (disambiguation)">
AD (disambiguation)

An ad (advertisement) is a form of marketing communication.
AD ("Anno Domini") is a designation used to label years following 1 BC in the Julian and Gregorian calendars.
AD, A.D. or Ad may also refer to:
People.
People nicknamed "AD" or "A.D." include:
"Ad" can also refer to:

</doc>
<doc id="2333" url="http://en.wikipedia.org/wiki?curid=2333" title="Ablative case">
Ablative case

In grammar, ablative case (abbreviated abl) is a grammatical case (a type of noun inflection) in various languages that is used generally to express motion away from something, although the precise meaning may vary by language. The name "ablative" derives from the Latin "ablatus", the (irregular) perfect passive participle of "auferre" "to carry away". There is no ablative case in modern Germanic languages, such as English.
Indo-European languages.
Latin.
The ablative case in Latin ("[casus] ablativus") has various uses, including following various prepositions, in an ablative absolute clause, and adverbially. The ablative case was derived from three Proto-Indo-European cases: ablative (from), instrumental (with), and locative (in/at).
Greek.
In Ancient Greek, there was no ablative case; some of its functions were taken by the genitive and others by the dative; the genitive had functions belonging to the Proto-Indo-European genitive and ablative cases. The genitive case with the prepositions ἀπό "apó" "away from" and ἐκ/ἐξ "ek/ex" "out of" is an example.
German.
German does not have an ablative case in native words, but Latin ablative case-forms were used from the 17th till 19th century after some prepositions, for example after "von" in "von dem Nomine" (ablative of the Latin loanword "Nomen"). Grammarians in that time, like Justus Georg Schottel, Kaspar von Stieler ("der Spate"), Johann Balthasar von Antesperg and Johann Christoph Gottsched, listed an ablative case (as the sixth case after nominative, genitive, dative, accusative and vocative) for German words. They considered the dative case after some prepositions to be an ablative, as in "von dem Mann[e]" ("from the man" or "of the man") and "mit dem Mann[e]" ("with the man"), while they considered the dative case after other prepositions or without a preposition as "dem Mann[e]" to be a dative.
Bosnian, Croatian and Serbian.
As in Ancient Greek, the functions of the ablative case in Bosnian, Croatian and Serbian are performed by the genitive case. Of three forms of genitive in Serbian, as well in Croatian and Bosnian, namely partitive, possessive and ablative, the noun in the ablative genitive marks the origin of something, so as departure or detachment from it.
Albanian.
The ablative case is found in Albanian where it is the fifth case and is called "rasa rrjedhore".
Sanskrit.
The ablative case, known as "apādāna" (अपादान) in Sanskrit, is the fifth case ("panchami") in the grammar, and has similar function to that of Latin.
Sanskrit nouns in this case often refer to a subject "out of" which or "from" whom something (an action, an object) has arisen or occurred—e.g., "patram vṛkṣāt patati" "the leaf falls from the tree".
This case is also used for nouns in several other senses, e.g., where the action occurs "because of" or "without" a certain noun; nouns indicating distance or direction. When it appears with a comparative adjective, e.g. "śreṣṭhatamam," "the best," the ablative is used to refer to that which the adjective is comparing, "better than X".
Armenian.
The modern Armenian ablative has different markers for each main dialect, both originating from Classical Armenian. The Western affix -է "-ē" (definite -էն "-ēn") derives from the Classical singular; the Eastern affix -ից "-ic’" (both indefinite and definite) derives from the Classical plural. For both dialects, the affix is singular with the corresponding plurals being -(ն)երէ(ն) and -(ն)երից.
In Armenian, the ablative case has several uses:
Uralic languages.
Finnish.
In Finnish, the ablative case is the sixth of the locative cases with the meaning "from, off, of", e.g. "pöytä – pöydältä" "table – off from the table". It is an outer locative case, used just as the adessive and allative cases to denote both being on top of something and "being around the place" (as opposed to the inner locative case, the elative, which means "from out of" or "from the inside of"). In the locative meaning, the receding object was near the other place or object, not inside it.
The Finnish ablative is also used in time expressions to indicate start times (e.g. "kymmeneltä" "at ten") as well as with verbs expressing feelings or emotions.
The Finnish ablative has the ending "-lta" or "-ltä" according to the regular rules of vowel harmony.
Hungarian.
The ablative case in Hungarian is used to describe movement away from a solid object. For example, if one is walking away from a friend one could say: 
"a barátomtól jövök" - I am coming (away from) my friend.
Use of this case implies movement from "next to" the solid object, and not from inside it. So "a postától jövök" would mean one had been standing "next to" the post office, and not inside the building.
The application of vowel harmony gives two different suffixes: -tól and -től. These are applied to back- and front-vowel words respectively.
In contrast, the cases used to express movement towards a solid object and for being next to that solid object are the allative case and the adessive case respectively. The cases for movement away from, or out of, something are the delative case (for movement from a surface or from a Hungarian city) and the elative case (for movement out of a container or from out of a foreign city).
Turkic languages.
Azeri.
The ablative in Azeri ("çıxışlıq hal") is expressed through the suffixes "-dan" or "-dən". Examples:
Ev - evdən
<br>"House - from/off the house"
Aparmaq - aparmaqdan
<br>"To carry - from/off carrying"
Turkish.
The ablative in Turkish ("-den hali" or "uzaklaşma hali") is expressed through the suffixes "-den", "-dan", "-ten", or "-tan". Examples:
Ev - evden
<br>"House - from/off the house"
At - attan
<br>"Horse - from/off the horse"
Taşımak - taşımaktan
<br>"To carry - from/off carrying"
Ses - sesten
<br>"Sound/volume - from/off sound/volume"
In some situations simple ablative can have a ”because of” meaning, in these situations ablative can be optionally followed by ”dolayı” (because of) preposition.
Yüksek sesten (dolayı) rahatsız oldum. / "I was uneasy because of high volume. "

</doc>
<doc id="2335" url="http://en.wikipedia.org/wiki?curid=2335" title="Adamic language">
Adamic language

The Adamic language is, according to Jews (as recorded in the "midrashim") and some Christians, the language spoken by Adam (and possibly Eve) in the Garden of Eden. It is variously interpreted as either the language used by God to address Adam (the divine language), or the language invented by Adam with which he named all things (including Eve), as in .
Medieval.
Traditional Jewish exegesis such as Midrash (Genesis Rabbah 38) says that Adam spoke Hebrew because the names he gives Eve – ""Isha" (Book of Genesis 2:23) and "Chava"" (Genesis 3:20) – only make sense in Hebrew. By contrast, Kabbalism assumed an "eternal Torah" which was not identical to the Torah written in Hebrew. Thus, Abulafia in the 13th century assumed that the language spoken in Paradise had been different from Hebrew, and rejected the claim then current also among Christian authors, that a child left unexposed to linguistic stimulus would automatically begin to speak in Hebrew.
Eco (1993) notes that Genesis is ambiguous on whether the language of Adam was preserved by Adam's descendants until the confusion of tongues (Genesis 11:1–9), or if it began to evolve naturally even before Babel (Genesis 10:5).
Dante addresses the topic in his "De Vulgari Eloquentia". He argues that the Adamic language is of divine origin and therefore unchangeable. He also notes that according to Genesis, the first speech act is due to Eve, addressing the serpent, and not to Adam.
In his "Divina Commedia", however, Dante changes his view to another that treats the Adamic language as the product of Adam. This had the consequence that it could not any longer be regarded immutable, and hence Hebrew could not be regarded as identical with the language of Paradise. Dante concludes ("Paradiso" XXVI) that Hebrew is a derivative of the language of Adam. In particular, the chief Hebrew name for God in scholastic tradition, "El", must be derived of a different Adamic name for God, which Dante gives as "I".
Early Modern.
Elizabethan scholar John Dee makes references to an occult or angelic language recorded in his private journals and those of spirit medium Edward Kelley. Dee's journals did not describe the language as "Enochian", instead preferring "Angelical", the "Celestial Speech", the "Language of Angels", the "First Language of God-Christ", the "Holy Language", or "Adamical" because, according to Dee's Angels, it was used by Adam in Paradise to name all things. The language was later dubbed Enochian, due to Dee's assertion that the Biblical Patriarch Enoch had been the last human (before Dee and Kelley) to know the language.
Modern.
Latter Day Saint movement.
Joseph Smith, founder of the Latter Day Saint movement, in his revision of the Bible, declared the Adamic language to have been "pure and undefiled". Some Latter Day Saints believe it to be the language of God. Glossolalia, or speaking in tongues, was commonplace in the early years of the LDS Church, and it was commonly believed that the incomprehensible language spoken during these incidents was the language of Adam though this belief seems to have never been formally or officially adopted.
Some other early Latter Day Saint leaders, including Brigham Young, Orson Pratt, and Elizabeth Ann Whitney, claimed to have received several words in the Adamic language by revelation. Some Latter Day Saints believe that the Adamic language is the "pure language" spoken of by Zephaniah and that it will be restored as the universal language of humankind at the end of the world.
Apostle Orson Pratt declared that "Ahman", part of the name of the settlement "Adam-ondi-Ahman" in Daviess County, Missouri, was the name of God in the Adamic language. An 1832 handwritten page from the Joseph Smith Papers, titled "A Sample of the Pure Language", and reportedly dictated by Smith to "Br. Johnson", asserts that the name of God is "Awmen".
The Latter Day Saint endowment prayer circle once included use of the words "Pay Lay Ale". These untranslated words are no longer used in temple ordinances and have been replaced by an English version, "O God, hear the words of my mouth". Some believe that the "Pay Lay Ale" sentence is derived from the Hebrew phrase "pe le-El", פה לאל "mouth to God".
Other words thought by some Latter Day Saints to derive from the Adamic language include "deseret" ("honey bee"), see Ether and "Ahman" ("God") see Doctrine and Covenants 
The Book of Moses refers to "a book of remembrance" written in the language of Adam.

</doc>
<doc id="2338" url="http://en.wikipedia.org/wiki?curid=2338" title="Rise and Fall of the City of Mahagonny">
Rise and Fall of the City of Mahagonny

Rise and Fall of the City of Mahagonny (German: Aufstieg und Fall der Stadt Mahagonny) is a political-satirical opera composed by Kurt Weill to a German libretto by Bertolt Brecht. It was first performed on 9 March 1930 at the Neues Theater in Leipzig.
Composition history.
The libretto was mainly written in early 1927 and the music was finished in the spring of 1929, although both text and music were partly revised by the authors later. An early by-product, however, was the "Mahagonny-Songspiel", sometimes known as "Das kleine Mahagonny", a concert work for voices and small orchestra commissioned by the Deutsche Kammermusik Festival in Baden-Baden and premiered there on 18 July 1927. The ten numbers, which include the "Alabama Song" and "Benares Song", were duly incorporated into the full opera. The opera had its premiere in Leipzig in March 1930 and played in Berlin in December of the following year. The opera was banned by the Nazis in 1933 and did not have a significant production until the 1960s.
Weill's score uses a number of styles, including rag-time, jazz and formal counterpoint, notably in the "Alabama Song" (covered by multiple artists, notably Ute Lemper, The Doors and David Bowie).
Language.
The lyrics for the "Alabama Song" and another song, the "Benares Song" are in English (albeit specifically idiosyncratic English) and are performed in that language even when the opera is performed in its original (German) language. The name of the city itself is a mix between the English and German word for mahogany, "Mahagoni".
Performance history.
It has played in opera houses around the world. Never achieving the popularity of Weill and Brecht's "The Threepenny Opera," "Mahagonny" is still considered a work of stature with a haunting score. Herbert Lindenberger in his book "Opera in History", for example, views "Mahagonny" alongside Schoenberg's "Moses und Aron" as indicative of the two poles of modernist opera.
Following the Leipzig premiere, the opera was presented in Berlin in December 1931 at the Theater am Schiffbauerdamm conducted by Alexander von Zemlinsky with Lotte Lenya as Jenny, Trude Hesterberg as Begbick, and Harald Paulsen as Jimmy. Another production was presented in January 1934 in Copenhagen at the Det ny Teater.
Other productions within Europe waited until the end of the Second World War, some notable ones being in January 1963 in London at Sadler's Wells Opera conducted by Colin Davis and in Berlin in September 1977 by the Komische Oper.
It was not presented in the United States until 1970, when a short-lived April production at the Phyllis Anderson Theatre off Broadway starred Barbara Harris as Jenny and Estelle Parsons as Begbick.
A full version was presented at the Yale Repertory Theatre in New Haven, Connecticut, in 1974, with Gilbert Price as Jimmy and Stephanie Cotsirilos as Jenny. Kurt Kasznar played Moses. The libretto was performed in an original translation by Michael Feingold; the production was directed by Alvin Epstein.
In October 1978, Yale presented a "chamber version" adapted and directed by Keith Hack, with John Glover as Jimmy and June Gable as Begbick. Mark Lynn-Baker played Fatty; Michael Gross was Trinity Moses.
In November 1979, "Mahagonny" debuted at the Metropolitan Opera in a John Dexter production conducted by James Levine. The cast included Teresa Stratas as Jenny, Astrid Varnay as Begbick, Richard Cassilly as Jimmy, Cornell MacNeil as Moses, Ragnar Ulfung as Fatty and Paul Plishka as Joe. The production was televised in 1979 and was released on DVD in 2010.
The Los Angeles Opera presented the opera in September 1989 under conductor Kent Nagano and with a Jonathan Miller production. Other notable productions in Europe from the 1980s included the March 1986 presentation by the Scottish Opera in Glasgow; a June 1990 production in Florence by the Maggio Musicale Fiorentino. In October 1995 and 1997, the Paris Opera staged by Graham Vick, under the baton of Jeffrey Tate starring Marie McLaughlin as Jenny, Felicity Palmer (1995) and Kathryn Harries (1997) as Begbick, Kim Begley (1995) and Peter Straka (1997) as Jimmy. The July 1998 Salzburg Festival production featured Catherine Malfitano as Jenny, Gwyneth Jones as Begbick, and Jerry Hadley as Jimmy. The Vienna State Opera added it to its repertoire in January 2012 in a production by Jérôme Deschamps conducted by Ingo Metzmacher starring Christopher Ventris as Jimmy and Angelika Kirchschlager as Jenny, notably casting young mezzo-soprano Elisabeth Kulman as Begbick, breaking the tradition of having a veteran soprano (like Varnay or Jones) or musical theater singer (like Patti LuPone) perform the role.
Productions within the US have included those in November 1998 by the Lyric Opera of Chicago directed by David Alden. Catherine Malfitano repeated her role as Jenny, while Felicity Palmer sang Begbick, and Kim Begley sang in the role of Jimmy. The Los Angeles Opera's February 2007 production directed by John Doyle and conducted by James Conlon included Audra McDonald as Jenny, Patti LuPone as Begbick, and Anthony Dean Griffey as Jimmy. This production was recorded on DVD, and subsequently won the 2009 Grammy Awards for "Best Classical Album" and "Best Opera Recording."
In 2014 it was performed using an alternate libretto as a "wrestling opera" at the Oakland Metro by the performers of Hoodslam.
Synopsis.
Act 1.
"Scene 1: A desolate no-man's land"
A truck breaks down. Three fugitives from justice get out: Fatty the Bookkeeper, Trinity Moses, and Leocadia Begbick. Because the federal agents pursuing them will not search this far north, and they are in a good location to attract ships coming south from the Alaskan gold fields, Begbick decides that they can profit by staying where they are and founding a pleasure city, where men can have fun, because there is nothing else in the world to rely on.
"Scene 2"
The news of Mahagonny spreads quickly, and sharks from all over flock to the bait, including the whore Jenny Smith, who is seen, with six other girls, singing the "Alabama Song", in which she waves goodbye to her home and sets out in pursuit of whiskey, dollars and pretty boys.
"Scene 3"
In the big cities, where men lead boring, purposeless lives, Fatty and Moses spread the gospel of Mahagonny, city of gold, among the disillusioned.
"Scene 4"
Four Alaskan Lumberjacks who have shared hard times together in the timberlands and made their fortunes set off together for Mahagonny. Jimmy Mahoney and his three friends – Jacob Schmidt, Bank Account Billy, and Alaska Wolf Joe – sing of the pleasures awaiting them in "Off to Mahagonny", they look forward to the peace and pleasure they will find there.
"Scene 5"
The four friends arrive in Mahagonny, only to find other disappointed travelers already leaving. Begbick, well-informed about their personal tastes, marks down her prices, but for the penurious Billy they still seem too high. Jimmy impatiently calls for the girls of Mahagonny to show themselves, so he can make a choice. Begbick suggests Jenny as the right girl for Jack, who finds her rates too high. She pleads with Jack to reconsider ("Havana Song"), which arouses Jim's interest, and he chooses her. Jenny and the girls sing a tribute to "the Jimmys from Alaska."
"Scene 6"
Jimmy and Jenny get to know one another as she asks him to define the terms of their contact: Does he wish her to wear her hair up or down, to wear fancy underwear or none at all? "What is your wish?" asks Jim, but Jenny evades answering.
"Scene 7"
Begbick, Fatty and Moses meet to discuss the pleasure city's financial crisis: People are leaving in droves, and the price of whiskey is sinking rapidly. Begbick suggests going back to civilization, but Fatty reminds her that the federal agents have been inquiring for her in nearby Pensacola. Money would solve everything, declares Begbick, and she decides to soak the four new arrivals for all they've got.
"Scene 8"
Jimmy, restless, attempts to leave Mahagonny; it is too peaceful for him. His three friends, in close harmony, try to persuade him to stay. Eventually their threats drive Jim, his anger vented, back to the city.
"Scene 9"
In front of the Rich Man's Hotel, Jimmy and the others sit lazily as a pianist plays Tekla Bądarzewska's "A Maiden's Prayer". With growing anger, Jimmy sings of how his hard work and suffering in Alaska have led only to this. Drawing a knife, he shouts for Begbick, while his friends try to disarm him and the other men call to have him thrown out. Calm again, he tells Begbick that Mahagonny can never make people happy: it has too much peace and quiet.
"Scene 10"
As if in answer to Jimmy's complaint, the city is threatened by a typhoon. Everyone sings in horror of the destruction awaiting them.
"Scene 11"
Tensely, people watch for the hurricane's arrival. The men sing a hymn-like admonition not to be afraid. Jim meditatively compares Nature's savagery to the far greater destructiveness of Man. Why do we build, he asks, if not for the pleasure of destroying? Since Man can outdo any hurricane, fear makes no sense. For the sake of human satisfaction, nothing should be forbidden: If you want another man's money, his house or his wife, knock him down and take it; do what you please. As Begbick and the men ponder Jimmy's philosophy, Fatty and Moses rush in with news: The hurricane has unexpectedly struck Pensacola, destroying Begbick’s enemies, the federal agents. Begbick and her cohorts take it as a sign that Jimmy is right; they join him, Jenny, and his three friends in singing a new, defiant song: If someone walks on, then it's me, and if someone gets walked on, then it's you. In the background, the men continue to chant their hymn as the hurricane draws nearer.
Act 2.
"Scene 12"
Magically, the hurricane bypasses Mahagonny, and the people sing in awe of their miraculous rescue. This confirms Begbick's belief in the philosophy of "Do what you want," and she proceeds to put it into effect.
"Scene 13 At the renovated "Do It" tavern."
The men sing of the four pleasures of life: Eating, Lovemaking, Fighting and Drinking. First comes eating: To kitschy cafe music, Jimmy's friend Jacob gorges until he keels over and dies. The men sing a chorale over his body, saluting "a man without fear".
"Scene 14: Loving."
While Begbick collects money and issues tips on behavior, Moses placates the impatient men queuing to make love to Jenny and the other whores. The men sing the "Mandalay Song", warning that love does not last forever, and urging those ahead of them to make it snappy.
"Scene 15: Fighting."
The men flock to see a boxing match between Trinity Moses and Jim's friend Alaska Wolf Joe. While most of the men, including the ever-cautious Billy, bet on the burly Moses, Jim, out of friendship, bets heavily on Joe. The match is manifestly unfair; Moses not only wins but kills Joe in knocking him out.
"Scene 16: Drinking."
In an effort to shake off the gloom of Joe's death, Jimmy invites everyone to have a drink on him. The men sing "Life in Mahagonny", describing how one could live in the city for only five dollars a day, but those who wanted to have fun always needed more. Jim, increasingly drunk, dreams of sailing back to Alaska. He takes down a curtain rod for a mast and climbs on the pool table, pretending it is a ship; Jenny and Billy play along. Jimmy is abruptly sobered up when Begbick demands payment for the whiskey as well as for the damage to her property. Totally broke, he turns in a panic to Jenny, who explains her refusal to help him out in the song "Make your own bed" – an adaptation of the ideas he proclaimed at the end of act 1. Jim is led off in chains as the chorus, singing another stanza of "Life in Mahagonny", returns to its pastimes. Trinity Moses assures the crowd that Jimmy will pay for his crimes with his life.
"Scene 17"
At night, Jim alone and chained to a lamppost, sings a plea for the sun not to rise on the day of his impending trial.
Act 3.
"Scene 18: In the courtroom"
Moses, like a carnival barker, sells tickets to the trials. He serves as prosecutor, Fatty as defense attorney, Begbick as judge. First comes the case of Toby Higgins, accused of premeditated murder for the purpose of testing an old revolver. Fatty invites the injured party to rise, but no one does so, since the dead do not speak. Toby bribes all three, and as a result, Begbick dismisses the case. Next Jimmy's case is called. Chained, he is led in by Billy, from whom he tries to borrow money; Billy of course refuses, despite Jim's plea to remember their time together in Alaska. In virtually the same speech he used to attack Higgins, Moses excoriates him for not paying his bills, for seducing Jenny (who presents herself as a plaintiff) to commit a "carnal act" with him for money, and for inciting the crowd with "an illegal joyous song" on the night of the typhoon. Billy, with the chorus's support, counters that, in committing the latter act, Jimmy discovered the laws by which Mahagonny lives. Moses argues that Jim hastened his friend Joe's death in a prizefight by betting on him, and Billy counters by asking who actually killed Joe. Moses does not reply. But there is no answer for the main count against him. Jim gets short sentences for his lesser crimes, but for having no money, he is sentenced to death. Begbick, Fatty and Moses, rising to identify themselves as the injured parties, proclaim "in the whole human race / there is no greater criminal / than a man without money". As Jim is led off to await execution, everyone sings the "Benares Song", in which they long for that exotic city "where the sun is shining." But Benares has been destroyed by an earthquake. "Where shall we go?" they ask.
"Scene 19: At the gallows"
Jim says a tender goodbye to Jenny, who, dressed in white, declares herself his widow. He surrenders her to Billy, his last remaining companion from Alaska. When he tries to delay the execution by reminding the people of Mahagonny that God exists, they play out for him, under Moses' direction, the story of "God in Mahagonny", in which the Almighty condemns the town and is overthrown by its citizens, who declare that they can not be sent to Hell because they are already in Hell. Jim, chastened, asks only for a glass of water, but is refused even this as Moses gives the signal for the trap to be sprung.
"Scene 20"
A caption advises that, after Jim's death, increasing hostility among the city's various factions has caused the destruction of Mahagonny. To a potpourri of themes from earlier in the opera, groups of protesters are seen on the march, in conflict with one another, while the city burns in the background. Jenny and the whores carry Jim's clothing and accessories like sacred relics; Billy and several men carry his coffin. In a new theme, they and the others declare, "Nothing you can do will help a dead man". Begbick, Fatty and Moses appear with placards of their own, joining the entire company in its march and declaring "Nothing will help him or us or you now," as the opera ends in chaos.
Themes.
Satire of opera.
To an extent, "Mahagonny" is an opera that satirizes operas. Brecht said that "[i]t attacks the society that needs operas of such a sort" and Weill said that it "pays conscious tribute to the irrationality of the operatic form". Both thought operas had become too full of ritual and bereft of substance, and "Mahagonny" in part sought to deflate the pompous arrogance of traditional opera. With this aim, many traditional operatic themes are subverted and made grotesque; love becomes a commodity, the "deus ex machina" tells everyone to go to hell, the law is run by criminals, etc. A traditional opera theme is true love, but in Mahagonny the closest such thing is the love between Jimmy and the prostitute Jenny. Furthermore, when given the choice to pay off Jimmy's debt and save his life, she tearfully regrets that while she loves him and will miss him dearly, she cannot part with her money. This commodification of love is brought to a grotesque apex after the hurricane spares Mahagonny; the residents now feel free to do what they want, and naturally they want to love. Consequently, in act 2 scene 3, the largely male population take turns having sex with the prostitutes. In contrast to the supposed theme of love, the scene portrays a perverse form of love; the prostitutes are carted around like giant slabs of meat and the "love" is regimented by the queue of men each waiting impatiently for his own turn. The "Mandalay Song" also heightens the ongoing tension. At no point is the music entirely tonal, and while the tune is seemingly jazzy and carefree, the tonalities betray an uneasiness about the whole business. In "Mahagonny", operatic love is mutated from a grand aspiration to a mere commodity.
Another trope of operas is the "deus ex machina", in which the protagonist is saved at the last minute by divine intervention. This is a useful technique to quickly wrap up a story and make a happy ending, and has been used in drama many times. In "Mahagonny", though there are no supernatural occurrences for most of the opera, there is in fact a "deus ex machina"; God himself comes to Mahagonny right before Jimmy is executed. The typical opera would have God solving all the problems just in time for the end of the opera, but "Mahagonny"'s god does not. He does not even acknowledge that Jimmy is tied up and ready to be killed, but at least tries to fix the moral problems in Mahagonny. He tries to convince them to give up their degraded way of life, but the residents all refuse the offer. God then tells them literally to go to hell, but the people are not even offended; they proclaim that they already are in hell so that is no punishment. After fixing nothing, God then lets Jimmy have his say. Jimmy realizes that money did not buy him happiness or freedom, and he has learned his lesson. However, God does not spare him even then, and Jimmy is executed off-stage.
Mahagonny as capitalism.
Mahagonny as a city was also intended to be a parable of capitalism stripped of its veneer of bourgeois respectability, as it "arose to meet the needs and desires of the people, and it was these same needs and desires that brought about its destruction". Ultimately, this was also intended as a commentary on the state of Weimar Germany; underneath that facade of prosperity and happiness, lay corruption and savagery. Under Brecht's (and to some extent Weill's) Marxist-influenced view of capitalism, it is created to provide people the goods and services they need, but it does so at the expense of reducing everything to a mere commodity. Furthermore, since obtaining wealth in capitalism is a cutthroat enterprise, the powerful are no better than a gang of bandits, and the law in turn is run by such thugs.
The city of Mahagonny embodies many of these characteristics. Mahagonny was originally created to provide people with useful services; the gold prospectors wanted a relaxation spot, and the three criminals needed to stay there. However, this led to the commodification of everything the tourists desired, especially love. In the end, nobody could buy true happiness; Alaska Wolf Joe and Jacob Schmidt died, the city is burning down, and Jimmy declared before his death that "[t]he happiness I bought was no happiness". His death was also ordered by the court of law, which was run by the three criminals. To make matters even more farcical, they let a murderer bribe his way to freedom while Jimmy is sentenced to death for petty crimes. The parallels between the events of "Mahagonny" and the Marxist view of capitalism are clear.
To make the comparison more obvious, the opera is set in a pseudo-Wild West America, with Mahagonny itself placed somewhere far from the rest of civilization. America was the land of unbridled capitalism, the frontier just as much so. The only difference is that bourgeois civility and civilization has yet to occupy the frontier, and thus there is no hiding the nature of capitalism beneath the facade of gentlemanly conduct. In "Mahagonny", the characters are prostitutes, lumberjacks, criminals, and the like. Not one of them comes from the moneyed class, and yet the same system of exploitation was set up, but in a more naked manner. Instead of seducing a woman's love with power and influence, the residents of Mahagonny pay for a prostitute. But in "Mahagonny", poverty is not just a condition the poor bring upon themselves, but a crime to be punished. Thus, Brecht and Weill tried to display capitalism as the meatgrinder they believed it to be.
Musical and dramatic elements.
Gebrauchsmusik.
Though Kurt Weill was not a vocal proponent of the "Gebrauchsmusik" movement in Germany, many of his works, including the music for "Mahagonny", share many of its characteristics. Loosely defined, "Gebrauchsmusik" is the idea that music can be more than just pure music. For example, music that accompanies a silent film is perfectly respectable, so long as it is done well. Also, simple music to be performed by amateurs is also acceptable. Weill's musical setting of "Mahagonny" exemplifies many of these characteristics. In the first place, this is music composed for the stage and not for the concert hall, and Weill intentionally chose that so. He wished to make his music speak out to as many people as possible, so throughout his career his mostly wrote music for the stage, and all the while in Europe he was considered a real composer and not just some hack pandering to the playwright to make a living.
For example, in act 1, scene 2, the scenario is that Jenny and other girls are walking to Mahagonny. The music is surprisingly simple; just a simple solo with a short chorus and sparse orchestration. The music is not some baroque contrapuntal scheme, nor is it a Romantic forest of sound; rather, the music is very easy to listen to. This music setting matches with the idea of making music accessible to the public, and not just for educated artists. The music style also displays influences from popular music. During this time, American jazz was a sensation in Europe; since opera is set in America, it is not surprising that the tune and the beat have a jazz influence. The orchestration, also includes such non-classical instruments as a saxophone, a decidedly jazz instrument. By using a jazz style in the music, Weill immediately associates the action as happening in America. In addition to making a relatively exotic sound, Weill manages to incorporate the jazz style in the song without making it seem incongruous; the American and European music are seamlessly joined under Weill's hands.
Elsewhere Weill uses other such non-classical instruments as the accordion, and he uses other popular influences, including those of his native Germany. The most enduring feature of "Gebrauchsmusik" in "Mahagonny", however, are the tunes. This reflects Weill's greatest desire to create simple music that would go straight to the heart of the audience. Many of the songs in "Mahagonny" are very simple and accessible. The "Alabama Song", for example, can be picked up absentmindedly and hummed. And while it seems carefree, something seems wrong with it, despite or perhaps because of its simplicity.
Verfremdungseffekt.
Since Mahagonny was co-produced by Brecht, there is a prominent display of the "Verfremdungseffekt", often translated as the "alienation effect". Brecht and Weill wished to replace the old dramatic theater and its emphasis on emotions with epic theatre and its emphasis on reason. In the case of Brecht, it was more as a didactic tool for communist philosophy, but for Weill, it was more of a social scheme, a way to get people involved and thinking. The general scheme was to shake up people's preconceived notions and make them think about what is happening on stage, or to emotionally distance the audience from the action thus making logical evaluation of the play's events easier. Brecht and Weill used different methods to achieve this effect.
One of the most noticeable methods Brecht uses are the inscriptions at the beginning of most of the scenes. Before the majority of the scenes, there is a short summary of that scene recited to the audience. By being already aware of what will happen, the audience can then better concentrate on what is going on in the scene. Often, Brecht will also have seemingly bizarre events occur, seemingly just to keep the audience unable to guess what will happen next. For example, Jimmy is going crazy at having nothing to do, when all of a sudden a hurricane starts heading towards Mahagonny. The audience is forced to give up concentrating on how Jimmy feels and think about what the meaning of this sudden hurricane is.
Weill also contributed greatly to the "Verfremdungseffekt" by his music. Often the music would intentionally be unsuited for the onstage action, preventing the audience from getting carried away by the onstage emotion. For example, in act 2, scene 13, the hurricane has spared Mahagonny, and the people feel free to do whatever makes them happy. For Jacob Schmidt, this means eating a lot. He sings of how he has not had his fill yet with such lines as "Not enough by half! / I may eat myself for supper." And yet, the music betrays the seeming unbridled ecstasy of Jacob; he is singing to a discordant melody, and the accordion accompaniment sounds stark and rather macabre. The intention is that the audience realizes that all this is very wrong; Jacob claims to be having a great time, but the music suggests all may not be well, thus the audience needs to pay attention and think about what is really going on. To further this point, Jacob then dies and the chorus sings of how happy he was while dragging out his corpse. This last twist of welcoming death is unexpected and contributes to the alienation.
Another example of "Verfremdungseffekt" in the music is in the "Alabama Song". This time, instead of the music sounding deeply disturbing compared to the stage action, it is the reverse. When the "Alabama Song" first appears, the women are going to Mahagonny. The second time the song appears is near the end of the opera, after Jimmy has been executed. Mahagonny is in decline, and there are street protests. The entire stage is singing about how rotten the world and man are, when all of a sudden Jenny and the prostitutes come walking through singing the "Alabama Song", a total departure from the previous mood. What is more, they are carrying Jimmy's corpse through the stage. The music refuses to set and keep the audience in a particular mood, and the conflict between the lighthearted "Alabama Song" and the imagery of the funeral procession is confusing. This tension serves to distance the audience from the action, even at an exceptionally powerful moment of the opera, giving the audience one last chance to digest all the contradictions and perversions of Mahagonny.
In other media.
The 2005 movie "Manderlay", directed by Lars von Trier, contains several references to the plot of "Mahagonny". The most notable of these is the threat of a hurricane approaching the city during the first act. Von Trier's earlier movie "Dogville", to which Manderlay is a sequel, was for a large part based on a song from Brecht's "Threepenny Opera" ("Pirate Jenny"). In the brothel scene in act 2 of "Mahagonny", the choir sings a "Song von Mandelay". The play "Happy End" (1929) by Elisabeth Hauptmann, Brecht and Weill, also contains a song called "Der Song von Mandelay", which uses the same refrain as in the brothel scene of "Mahagonny". Brecht's use of the name Mandelay/Mandalay was inspired by Rudyard Kipling's poem "Mandalay".
Recordings.
"Rise and Fall of the City of Mahagonny": Teresa Stratas, Astrid Varnay, Richard Cassilly(MET, Recorded 1979)
Cover versions of songs.
"Alabama Song" (covered by multiple artists, notably Ute Lemper, The Doors and David Bowie).

</doc>
<doc id="2339" url="http://en.wikipedia.org/wiki?curid=2339" title="Avery Hopwood">
Avery Hopwood

James Avery Hopwood (May 28, 1882 - July 1, 1928), was an American playwright, called the most successful playwright of the Jazz Age, having four plays running simultaneously on Broadway in 1920.
Biography.
He was born in Cleveland, Ohio and graduated Phi Beta Kappa from the University of Michigan (1905).
Hopwood started out as a journalist for a Cleveland newspaper as its New York correspondent, but within a year had a play, "Clothes" (1906), produced on Broadway. He became known as "The Playboy Playwright" and specialized in comedies and farces, some of them with material considered risqué at the time. One play, "The Demi-Virgin" in 1921, prompted a court case because of its suggestive subject matter, including a risque game of cards, "Stripping Cupid", where a bevy of showgirls teased the audience in their lingerie. The case was dismissed.
Dramatist.
His many plays included "Nobody's Widow" (1910), starring Blanche Bates; "Fair and Warmer" (1915), starring Madge Kennedy (filmed in 1919); "The Gold Diggers" (1919), starring Ina Claire (filmed in 1923 as "The Gold Diggers", in 1928 as "Gold Diggers of Broadway" and also as "Gold Diggers of 1933"); "Ladies' Night", 1920, starring Charlie Ruggles (filmed in 1928); the famous mystery play "The Bat" (with Mary Roberts Rinehart), 1920 (filmed in 1926 "The Bat", 1930 "The Bat Whispers," and 1959 "The Bat)"; "Getting Gertie's Garter" (with Wilson Collison), 1921, starring Hazel Dawn (filmed in 1927 and 1945); "The Demi-Virgin", 1921, also starring Dawn; "The Alarm Clock", 1923; "The Best People" (with David Gray), 1924 (filmed in 1925 and as "Fast and Loose" in 1930), the song-farce "Naughty Cinderella", 1925, starring Irene Bordoni and "The Garden of Eden" in 1927 (filmed in 1928 as "The Garden of Eden").
Hopwood was asked to write the third act of Mary Roberts Rinehart's play; "The Bat". Hopwood collaborated with Rinehart to then work on the last act of the play in Sewickley and sometimes in New York.
Interestingly, the early sound film, "The Bat Whispers", played an influence on Bob Kane's Batman because the inspiration for Batman's costume came from the "mysterious Bat" character portrayed in the movie from 1930.
A clever, adroit, masterful craftsman who wrote to the tastes of his public, Hopwood was inexhaustible in his work ethic. Although the press reported that he was engaged to vaudeville dancer and choreographer Rose Rolanda in 1924, Hopwood's close friend Carl Van Vechten confirmed in later years that it was all a publicity stunt. Rolanda would later marry caricaturist Miguel Covarrubias.
Death.
While swimming at Juan-les-Pins on the French Riviera, July 1, 1928, he suffered a heart attack and died. He is buried in Riverside Cemetery, Cleveland, Ohio, next to his mother, Jule.
Hopwood Awards.
The terms of Hopwood's will left a substantial portion of his estate to his alma mater, the University of Michigan for the establishment of the Avery Hopwood and Jule Hopwood Creative Writing Awards. The bequest stipulated: "It is especially desired that students competing for prizes shall be allowed the widest possible latitude, and that the new, the unusual, and the radical shall be especially encouraged." Famous Hopwood award winners include Robert Hayden, Marge Piercy, Arthur Miller, Betty Smith, Lawrence Kasdan, John Ciardi, Mary Gaitskill, Edmund White, Nancy Willard, Frank O’Hara, and Steve Hamilton.
Works.
"The Great Bordello".
Throughout his life, Hopwood worked on a novel that he hoped would "expose" the strictures the commercial theater machine imposed on playwrights, but the manuscript was never published. Jack Sharrar recovered the manuscript for this novel in 1982 during his research for "Avery Hopwood, His Life and Plays". The novel was published in July 2011 as "The Great Bordello".

</doc>
<doc id="2340" url="http://en.wikipedia.org/wiki?curid=2340" title="Antipope Felix II">
Antipope Felix II

Antipope Felix II was installed as Pope in 355 AD after the Emperor Constantius II banished the reigning Pope, Liberius, for refusing to subscribe the sentence of condemnation against Saint Athanasius. In May 357 AD the Roman laity, which had remained faithful to Liberius, demanded that Constantius, who was on a visit to Rome, should recall Liberius. The Emperor planned to have Felix and Liberius rule jointly, but when Liberius returned Felix was forced to retire to Porto, near Rome, where, after making an unsuccessful attempt to establish himself again in Rome, he died on 22 November 365 AD.
This Felix was later confused with a Roman martyr named Felix, with the result that he was included in lists of the Popes as Felix II and that the succeeding Popes of the same name (Pope Felix III and Pope Felix IV) were given wrong numerals, as was Antipope Felix V.
The Catholic Encyclopedia (1909) called this confusion a "distortion of the true facts" and suggested that it arose because the "Liber Pontificalis", which at this point may be registering a reliable tradition, says that this Felix built a church on the Via Aurelia, which is where the Roman martyr of an earlier date was buried. However, a more recent source says that of the martyr Felix nothing is known except his name, that he was a martyr, and that he was buried in the cemetery on the Via Portuensis that bears his name.
The Catholic Encyclopedia remarked that "the real story of the antipope was lost and he obtained in local Roman history the status of a saint and a confessor. As such he appears in the Roman Martyrology on 29 July." At that time (1909) the Roman Martyrology had the following text: At Rome, on the Aurelian Way, St. Felix II, pope and martyr. Being expelled from his See by the Arian emperor Constantius for defending the Catholic faith, and being put to the sword privately at Cera in Tuscany, he died gloriously. His body was taken away from that place by clerics, and buried on the Aurelian Way. It was afterwards brought to the Church of the Saints Cosmas and Damian, where, under the Sovereign Pontiff Gregory XIII, it was found beneath the altar with the relics of the holy martyrs Mark, Marcellian, and Tranquillinus, and with the latter was put back in the same place on 31 July. In the same altar were also found the bodies of the holy martyrs Abundius, a priest, and Abundantius, a deacon, which were shortly after solemnly transferred to the church of the Society of Jesus, on the eve of their feast.
 This entry was based on what the Catholic Encyclopedia called later legends that confound the relative positions of Felix and Liberius. More recent editions of the Roman Martyrology have instead: At Rome, at the third milestone on the Via Portuensis, in the cemetery dedicated to his name, Saint Felix, martyr.
The feast day of the Roman martyr Felix is 29 July. The antipope Felix died, as stated above, on a 22 November, and his death was not a martyr's, occurring when the Peace of Constantine had been in force for half a century.
As well as the Roman Martyrology, the Roman Missal identified the Saint Felix of 29 July with the antipope. This identification, still found in the 1920 typical edition, does not appear in the 1962 typical edition. To judge by the Marietti printing of 1952, which omits the numeral "II" and the word "Papae", the correction had already been made by then.

</doc>
<doc id="2341" url="http://en.wikipedia.org/wiki?curid=2341" title="Alkaloid">
Alkaloid

Alkaloids are a group of naturally occurring chemical compounds that contain mostly basic nitrogen atoms. This group also includes some related compounds with neutral and even weakly acidic properties. Some synthetic compounds of similar structure are also termed alkaloids. In addition to carbon, hydrogen and nitrogen, alkaloids may also contain oxygen, sulfur and more rarely other elements such as chlorine, bromine, and phosphorus.
Alkaloids are produced by a large variety of organisms including bacteria, fungi, plants, and animals. They can be purified from crude extracts of these organisms by acid-base extraction. Alkaloids have a wide range of pharmacological activities including antimalarial (e.g. quinine), antiasthma (e.g. ephedrine), anticancer (e.g. homoharringtonine), cholinomimetic (e.g. galantamine), vasodilatory (e.g. vincamine), antiarrhythmic (e.g. quinidine), analgesic (e.g. morphine), antibacterial (e.g. chelerythrine), and antihyperglycemic activities (e.g. piperine). Many have found use in traditional or modern medicine, or as starting points for drug discovery. Other alkaloids possess psychotropic (e.g. psilocin) and stimulant activities (e.g. cocaine, caffeine, nicotine), and have been used in entheogenic rituals or as recreational drugs. Alkaloids can be toxic too (e.g. atropine, tubocurarine). Although alkaloids act on a diversity of metabolic systems in humans and other animals, they almost uniformly invoke a bitter taste.
The boundary between alkaloids and other nitrogen-containing natural compounds is not clear-cut. Compounds like amino acid peptides, proteins, nucleotides, nucleic acid, amines, and antibiotics are usually not called alkaloids. Natural compounds containing nitrogen in the exocyclic position (mescaline, serotonin, dopamine, etc.) are usually classified as amines rather than as alkaloids. Some authors, however, consider alkaloids a special case of amines.
Naming.
The name "alkaloids" (German: "Alkaloide") was introduced in 1819 by the German chemist , and is derived from late Latin root "Latin: "alkali"" (which, in turn, comes from the Arabic "al-qalwī" – "ashes of plants") and the suffix "Greek: -οειδής" – "like". However, the term came into wide use only after the publication of a review article by Oscar Jacobsen in the chemical dictionary of Albert Ladenburg in the 1880s.
There is no unique method of naming alkaloids. Many individual names are formed by adding the suffix "ine" to the species or genus name. For example, atropine is isolated from the plant "Atropa belladonna", strychnine is obtained from the seed of Strychnine tree ("Strychnos nux-vomica" L.). If several alkaloids are extracted from one plant then their names often contain suffixes "idine", "anine", "aline", "inine" etc. There are also at least 86 alkaloids whose names contain the root "vin" because they are extracted from vinca plants such as "Vinca rosea" ("Catharanthus roseus"); these are called vinca alkaloids.
History.
Alkaloid-containing plants have been used by humans since ancient times for therapeutic and recreational purposes. For example, medicinal plants have been known in the Mesopotamia at least around 2000 BC. The "Odyssey" of Homer referred to a gift given to Helen by the Egyptian queen, a drug bringing oblivion. It is believed that the gift was an opium-containing drug. A Chinese book on houseplants written in 1st–3rd centuries BC mentioned a medical use of Ephedra and opium poppies. Also, coca leaves have been used by South American Indians since ancient times.
Extracts from plants containing toxic alkaloids, such as aconitine and tubocurarine, were used since antiquity for poisoning arrows.
Studies of alkaloids began in the 19th century. In 1804, the German chemist Friedrich Sertürner isolated from opium a "soporific principle" (Latin: "principium somniferum"), which he called "morphium" in honor of Morpheus, the Greek god of dreams; in German and some other Central-European languages, this is still the name of the drug. The term "morphine", used in English and French, was given by the French physicist Joseph Louis Gay-Lussac.
A significant contribution to the chemistry of alkaloids in the early years of its development was made by the French researchers Pierre Joseph Pelletier and Joseph Bienaimé Caventou, who discovered quinine (1820) and strychnine (1818). Several other alkaloids were discovered around that time, including xanthine (1817), atropine (1819), caffeine (1820), coniine (1827), nicotine (1828), colchicine (1833), sparteine (1851), and cocaine (1860).
The first complete synthesis of an alkaloid was achieved in 1886 by the German chemist Albert Ladenburg. He produced coniine by reacting 2-methylpyridine with acetaldehyde and reducing the resulting 2-propenyl pyridine with sodium. The development of the chemistry of alkaloids was accelerated by the emergence of spectroscopic and chromatographic methods in the 20th century, so that by 2008 more than 12,000 alkaloids had been identified.
Classifications.
Compared with most other classes of natural compounds, alkaloids are characterized by a great structural diversity and there is no uniform classification of alkaloids. First classification methods have historically combined alkaloids by the common natural source, e.g., a certain type of plants. This classification was justified by the lack of knowledge about the chemical structure of alkaloids and is now considered obsolete.
More recent classifications are based on similarity of the carbon skeleton (e.g., indole-, isoquinoline-, and pyridine-like) or biochemical precursor (ornithine, lysine, tyrosine, tryptophan, etc.). However, they require compromises in borderline cases; for example, nicotine contains a pyridine fragment from nicotinamide and pyrrolidine part from ornithine and therefore can be assigned to both classes.
Alkaloids are often divided into the following major groups:
Some alkaloids do not have the carbon skeleton characteristic of their group. So, galantamine and homoaporphines do not contain isoquinoline fragment, but are, in general, attributed to isoquinoline alkaloids.
Main classes of monomeric alkaloids are listed in the table below:
Properties.
Most alkaloids contain oxygen in their molecular structure; those compounds are usually colorless crystals at ambient conditions. Oxygen-free alkaloids, such as nicotine or coniine, are typically volatile, colorless, oily liquids. Some alkaloids are colored, like berberine (yellow) and sanguinarine (orange).
Most alkaloids are weak bases, but some, such as theobromine and theophylline, are amphoteric. Many alkaloids dissolve poorly in water but readily dissolve in organic solvents, such as diethyl ether, chloroform or 1,2-dichloroethane. Caffeine, cocaine, codeine and nicotine are water soluble (with a solubility of ≥1g/L), whereas others, including morphine and yohimbine are highly water soluble (0.1–1 g/L). Alkaloids and acids form salts of various strengths. These salts are usually soluble in water and ethanol and poorly soluble in most organic solvents. Exceptions include scopolamine hydrobromide, which is soluble in organic solvents, and the water-soluble quinine sulfate.
Most alkaloids have a bitter taste or are poisonous when ingested. Alkaloid production in plants appeared to have evolved in response to feeding by herbivorous animals; however, some animals have evolved the ability to detoxify alkaloids. Some alkaloids can produce developmental defects in the offspring of animals that consume but cannot detoxify the alkaloids. One example is the alkaloid cyclopamine, produced in the leaves of corn lily. During the 1950s, up to 25% of lambs born by sheep that had grazed on corn lily had serious facial deformations. These ranged from deformed jaws to cyclopia (see picture). After decades of research, in the 1980s, the compound responsible for these deformities was identified as the alkaloid 11-deoxyjervine, later renamed to cyclopamine.
Distribution in nature.
Alkaloids are generated by various living organisms, especially by higher plants – about 10 to 25% of those contain alkaloids. Therefore, in the past the term "alkaloid" was associated with plants.
The alkaloids content in plants is usually within a few percent and is inhomogeneous over the plant tissues. Depending on the type of plants, the maximum concentration is observed in the leaves (black henbane), fruits or seeds (Strychnine tree), root (Rauwolfia serpentina) or bark (cinchona). Furthermore, different tissues of the same plants may contain different alkaloids.
Beside plants, alkaloids are found in certain types of fungi, such as psilocybin in the fungus of the genus Psilocybe, and in animals, such as bufotenin in the skin of some toads. Many marine organisms also contain alkaloids. Some amines, such as adrenaline and serotonin, which play an important role in higher animals, are similar to alkaloids in their structure and biosynthesis and are sometimes called alkaloids.
Extraction.
Because of the structural diversity of alkaloids, there is no single method of their extraction from natural raw materials. Most methods exploit the property of most alkaloids to be soluble in organic solvents but not in water, and the opposite tendency of their salts.
Most plants contain several alkaloids. Their mixture is extracted first and then individual alkaloids are separated. Plants are thoroughly ground before extraction. Most alkaloids are present in the raw plants in the form of salts of organic acids. The extracted alkaloids may remain salts or change into bases. Base extraction is achieved by processing the raw material with alkaline solutions and extracting the alkaloid bases with organic solvents, such as 1,2-dichloroethane, chloroform, diethyl ether or benzene. Then, the impurities are dissolved by weak acids; this converts alkaloid bases into salts that are washed away with water. If necessary, an aqueous solution of alkaloid salts is again made alkaline and treated with an organic solvent. The process is repeated until the desired purity is achieved.
In the acidic extraction, the raw plant material is processed by a weak acidic solution (e.g., acetic acid in water, ethanol, or methanol). A base is then added to convert alkaloids to basic forms that are extracted with organic solvent (if the extraction was performed with alcohol, it is removed first, and the remainder is dissolved in water). The solution is purified as described above.
Alkaloids are separated from their mixture using their different solubility in certain solvents and different reactivity with certain reagents or by distillation.
Biosynthesis.
Biological precursors of most alkaloids are amino acids, such as ornithine, lysine, phenylalanine, tyrosine, tryptophan, histidine, aspartic acid, and anthranilic acid. Nicotinic acid can be synthesized from tryptophan or aspartic acid. Ways of alkaloid biosynthesis are too numerous and cannot be easily classified. However, there are a few typical reactions involved in the biosynthesis of various classes of alkaloids, including synthesis of Schiff bases and Mannich reaction.
Synthesis of Schiff bases.
Schiff bases can be obtained by reacting amines with ketones or aldehydes. These reactions are a common method of producing C=N bonds.
In the biosynthesis of alkaloids, such reactions may take place within a molecule, such as in the synthesis of piperidine:
Mannich reaction.
An integral component of the Mannich reaction, in addition to an amine and a carbonyl compound, is a carbanion, which plays the role of the nucleophile in the nucleophilic addition to the ion formed by the reaction of the amine and the carbonyl.
The Mannich reaction can proceed both intermolecularly and intramolecularly:
Dimer alkaloids.
In addition to the described above monomeric alkaloids, there are also dimeric, and even trimeric and tetrameric alkaloids formed upon condensation of two, three, and four monomeric alkaloids. Dimeric alkaloids are usually formed from monomers of the same type through the following mechanisms:
Biological role.
The role of alkaloids for living organisms that produce them is still unclear. It was initially assumed that the alkaloids are the final products of nitrogen metabolism in plants, as urea in mammals. It was later shown that alkaloid concentrations varies over time, and this hypothesis was refuted.
Most of the known functions of alkaloids are related to protection. For example, aporphine alkaloid liriodenine produced by the tulip tree protects it from parasitic mushrooms. In addition, the presence of alkaloids in the plant prevents insects and chordate animals from eating it. However, some animals are adapted to alkaloids and even use them in their own metabolism. Such alkaloid-related substances as serotonin, dopamine and histamine are important neurotransmitters in animals. Alkaloids are also known to regulate plant growth. Another example of an organism that uses alkaloids for protection is the "Utetheisa ornatrix", more commonly known as the ornate moth. Pyrrolizidine alkaloids render these larvae and adult moths unpalatable to many of their natural enemies like coccinelid beetles, green lacewings, insectivorous hemiptera and insectivorous bats.
Applications.
In medicine.
Medical use of alkaloid-containing plants has a long history, and, thus, when the first alkaloids were isolated in the 19th century, they immediately found application in clinical practice. Many alkaloids are still used in medicine, usually in the form of salts, including the following:
Many synthetic and semisynthetic drugs are structural modifications of the alkaloids, which were designed to enhance or change the primary effect of the drug and reduce unwanted side-effects. For example, naloxone, an opioid receptor antagonist, is a derivative of thebaine that is present in opium.
In agriculture.
Prior to the development of a wide range of relatively low-toxic synthetic pesticides, some alkaloids, such as salts of nicotine and anabasine, were used as insecticides. Their use was limited by their high toxicity to humans.
Use as psychoactive drugs.
Preparations of plants containing alkaloids and their extracts, and later pure alkaloids, have long been used as psychoactive substances. Cocaine, caffeine, and cathinone are stimulants of the central nervous system. Mescaline and many of indole alkaloids (such as psilocybin, dimethyltryptamine and ibogaine) have hallucinogenic effect. Morphine and codeine are strong narcotic pain killers.
There are alkaloids that do not have strong psychoactive effect themselves, but are precursors for semi-synthetic psychoactive drugs. For example, ephedrine and pseudoephedrine are used to produce methcathinone and methamphetamine. Thebaine is used in the synthesis of many painkillers such as oxycodone.

</doc>
<doc id="2343" url="http://en.wikipedia.org/wiki?curid=2343" title="Adventism">
Adventism

Adventism is a branch of Protestantism which began in the 19th century in the context of the Second Great Awakening revival in the United States. The name refers to belief in the imminent Second Coming (or "Second Advent") of Jesus Christ. William Miller started the Adventist movement in the 1830s. His followers became known as Millerites.
Although the Adventist churches hold much in common, their theologies differ on whether the intermediate state is unconscious sleep or consciousness, whether the ultimate punishment of the wicked is annihilation or eternal torment, the nature of immortality, whether or not the wicked are resurrected after the millennium, and whether the sanctuary of refers to the one in heaven or one on earth. The movement has encouraged the examination of the whole Bible, leading Seventh-day Adventists and some smaller Adventist groups to observe the Sabbath. The General Conference of Seventh-day Adventists has compiled that church's core beliefs in the 28 Fundamental Beliefs (1980 and 2005), which use Biblical references as justification.
In 2010, Adventism claimed some 22 million believers scattered in various independent churches. The largest church within the movement — the Seventh-day Adventist Church — has more than 18 million members.
History.
Adventism began as an inter-denominational movement. Its most vocal leader was William Miller. Between 50,000 and 100,000 people in the United States supported Miller's predictions of Christ's return. After the "Great Disappointment" of October 22, 1844 many people in the movement gave up on Adventism. Of those remaining Adventist, the majority gave up believing in any prophetic (biblical) significance for the October 22 date, yet they remained expectant of the near Advent (second coming of Jesus).
Of those who retained the October 22 date, many maintained that Jesus had come not literally but "spiritually", and consequently were known as "spiritualizers". A small minority held that something concrete had indeed happened on October 22, but this event had been misinterpreted. This viewpoint later emerged and crystallized with the Seventh-day Adventist Church, the largest remaining body today.
Albany Conference (1845).
The Albany Conference in 1845, attended by 61 delegates, was called to attempt to determine the future course and meaning of the Millerite movement. Following this meeting, the "Millerites" then became known as "Adventists" or "Second Adventists". However, the delegates disagreed on several theological points. Four groups emerged from the conference: The Evangelical Adventists, The Life and Advent Union, the Advent Christian Church, and the Seventh-day Adventist Church.
The largest group was organized as the American Millennial Association, a portion of which was later known as the Evangelical Adventist Church. Unique among the Adventists, they believed in an eternal hell and consciousness in death. They declined in numbers, and by 1916 their name did not appear in the United States Census of Religious Bodies. It has diminished to almost non-existence today. Their main publication was the "Advent Herald", of which Sylvester Bliss was the editor until his death in 1863. It was later called the "Messiah’s Herald".
The Life and Advent Union was founded by George Storrs in 1863. He had established "The Bible Examiner" in 1842. It merged with the Adventist Christian Church in 1964.
The Advent Christian Church officially formed in 1861, and grew rapidly at first. It declined a little during the 20th century. The Advent Christians publish the four magazines "The Advent Christian Witness", "Advent Christian News", "Advent Christian Missions" and "Maranatha". They also operate a liberal arts college at Aurora, Illinois; and a one-year Bible College in Lenox, Massachusetts called Berkshire Institute for Christian Studies. The Primitive Advent Christian Church later separated from a few congregations in West Virginia.
The Seventh-day Adventist Church officially formed in 1863. It believes in the sanctity of the seventh-day Sabbath as a holy day for worship. It published the "Adventist Review, Kids Review, and Sabbath Herald". It has grown to a large worldwide denomination and has a significant network of medical and educational institutions.
Miller did not join any of the movements, and he spent the last few years of his life working for unity, before dying in 1849.
Denominations.
The "Handbook of Denominations in the United States", 12th edn., describes the following churches as "Adventist and Sabbatarian (Hebraic) Churches":
Christadelphians.
The Christadelphians were founded in 1844 by John Thomas and had an estimated 25,000 members in 170 ecclesias, or churches, in 2000 in America.
Advent Christian Church.
The Advent Christian Church was founded in 1860 and had 25,277 members in 302 churches in 2002 in America. It is a "first-day" body of Adventist Christians founded on the teachings of William Miller. It adopted the "conditional immortality" views of Charles F. Hudson and George Storrs who formed the "Advent Christian Association" in Salem, Massachusetts in 1860.
Primitive Advent Christian Church.
The Primitive Advent Christian Church is a small group which separated from the Advent Christian Church. It differs from the parent body mainly on two points. Its members observe foot washing as a rite of the church, and they teach that reclaimed backsliders should be baptized (even though they had formerly been baptized). This is sometimes referred to as rebaptism.
Seventh-day Adventist.
The Seventh-day Adventist Church, founded in 1863, had over 17,210,000 baptized members (not counting children of members) worldwide as of 2011. It is best known for its teaching that Saturday, the seventh day of the week, is the Sabbath and is the appropriate day for worship. However, it is the second coming of Jesus Christ along with the Judgement day, based on the three angels message in Revelation 14: 6-13, that is the main doctrine of SDA.
Seventh Day Adventist Reform Movement.
The Seventh Day Adventist Reform Movement is a small offshoot with an unknown number of members from the Seventh-day Adventist Church caused by disagreement over military service on the Sabbath day during World War I.
Davidian Seventh-day Adventist Association.
The Davidians (originally named Shepherd's Rod) is a small offshoot with an unknown number of members made up primarily of voluntarily disfellowshipped members of the Seventh-day Adventist Church. They were originally known as the Shepherd's Rod and are still sometimes referred to as such. The group derives its name from two books on Bible doctrine written by its founder, Victor Houteff, in 1929.
Branch Davidians.
The Branch Davidians were a split ("branch") from the Davidians. Many of them were killed during the infamous Waco Siege of April 1993.
Church of God (Seventh Day).
The Church of God (Seventh-Day) was founded in 1863 and it had an estimated 11,000 members in 185 churches in 1999 in America. Its founding members separated in 1858 from those Adventists associated with Ellen G. White who later organized themselves as Seventh-day Adventists in 1863. The Church of God (Seventh Day) split in 1933, creating two bodies: one headquartered in Salem, West Virginia, and known as the Church of God (7th day) - Salem Conference and the other one headquartered in Denver, Colorado and known as the General Conference of the Church of God (Seventh-Day). The Worldwide Church of God splintered from this. 
Church of God and Saints of Christ.
The Church of God and Saints of Christ was founded in 1896 and had an estimated 40,000 members in approximately 200 congregations in 1999 in America.
Church of God General Conference.
Many denominations known as "Church of God" have Adventist origins.
The Church of God General Conference was founded in 1921 and had 7,634 members in 162 churches in 2004 in America. It is an Adventist Christian body which is also known as the "Church of God of the Abrahamic Faith" and the "Church of God General Conference (Morrow, GA)".
Creation Seventh-Day Adventist.
Creation Seventh Day Adventist Church
United Seventh-Day Brethren.
The United Seventh-Day Brethren is a small Sabbatarian Adventist body.
In 1947, several individuals and two independent congregations within the Church of God Adventist movement formed the "United Seventh-Day Brethren", seeking to increase fellowship and to combine their efforts in evangelism, publications, and other .
Other relationships.
The Bible Students movement founded by Charles Taze Russell had in its early development close connections with the Millerite movement and stalwarts of the Adventist faith, including George Storrs and Joseph Seiss. The various groupings of Bible Students currently have a cumulative membership of less than 20,000 worldwide. Although Jehovah's Witnesses and Bible Students do not categorize themselves as part of the Millerite Adventist movement (or other denominations, in general), some theologians do categorize the group and schisms as Millerite Adventist because of its teachings regarding an imminent Second Coming and use of specific dates. As of January 2014 there are approximately 8 million Jehovah's Witnesses worldwide.
High Sabbath Adventists are a group of Seventh-day Adventists who believe in the prophetic significance of the High Sabbaths. They are Historic Adventists who believe that God has been giving the light of the fourth angel (of Revelation 18) in the form of the Orion Message since 2010.
See also.
General:

</doc>
<doc id="2345" url="http://en.wikipedia.org/wiki?curid=2345" title="Archbishop of Canterbury">
Archbishop of Canterbury

The Archbishop of Canterbury is the senior bishop and principal leader of the Church of England, the symbolic head of the worldwide Anglican Communion and the diocesan bishop of the Diocese of Canterbury.
The current archbishop is Justin Welby. He is the 105th in a line which goes back more than 1400 years to Augustine of Canterbury, the "Apostle to the English", in the year 597. On 9 November 2012 it was officially announced that Welby, then the Bishop of Durham, had been appointed to succeed Rowan Williams as the 105th Archbishop of Canterbury. His enthronement took place in Canterbury Cathedral on 21 March 2013.
From the time of Augustine until the 16th century, the Archbishops of Canterbury were in full communion with the See of Rome and thus usually received the pallium. During the English Reformation the Church of England broke away from the authority of the Pope and the Roman Catholic Church, at first temporarily under Henry VIII and Edward VI and later permanently during the reign of Elizabeth I.
In the Middle Ages there was considerable variation in the methods of nomination of the Archbishop of Canterbury and other bishops. At various times the choice was made by the canons of Canterbury Cathedral, the Pope, or the King of England. Since the English Reformation, the Church of England has been more explicitly a state church and the choice is legally that of the Crown; today it is made by the Queen on the advice of the Prime Minister, who receives a shortlist of two names from an "ad hoc" committee called the Crown Nominations Commission.
Present roles and status.
Today the archbishop fills four main roles:
In the last two of these functions he has an important ecumenical and interfaith role, speaking on behalf of Anglicans in England and worldwide.
The archbishop's main residence is Lambeth Palace in the London Borough of Lambeth. He also has lodgings in the Old Palace, Canterbury, located beside Canterbury Cathedral, where the Chair of St. Augustine sits.
As holder of one of the "five great sees" (the others being York, London, Durham and Winchester), the Archbishop of Canterbury is "ex officio" one of the Lords Spiritual of the House of Lords. He is one of the highest-ranking men in England and the highest ranking non-royal in the United Kingdom's order of precedence.
Since Henry VIII broke with Rome, the Archbishops of Canterbury have been selected by the English (British since the Act of Union in 1707) monarch. Today the choice is made in the name of the monarch by the prime minister, from a shortlist of two selected by an ad-hoc committee called the Crown Nominations Commission. Since the 20th century, the appointment of Archbishops of Canterbury conventionally alternates between more moderate Anglo-Catholics and Evangelicals.
The current archbishop, Justin Welby, 105th Archbishop of Canterbury, was enthroned at Canterbury Cathedral on 4 February 2013. As archbishop he signed himself as "+ Justin Cantuar". His predecessor, Rowan Williams, 104th Archbishop of Canterbury, was enthroned at Canterbury Cathedral on 27 February 2003. Immediately prior to his appointment to Canterbury he was the Bishop of Monmouth and Archbishop of Wales. On 18 March 2012, Rowan Williams announced he would be stepping down as Archbishop of Canterbury at the end of 2012 to become Master of Magdalene College, Cambridge.
Additional roles.
In addition to his office, the archbishop also holds a number of other positions; for example, he is Joint President of the Council of Christians and Jews in the United Kingdom. Some positions he formally holds "ex officio" and others virtually so (the incumbent of the day, although appointed personally, is appointed because of his office). Amongst these are:
Ecumenical and interfaith.
The Archbishop of Canterbury is also a President of Churches Together in England (an ecumenical organisation). Geoffrey Fisher, 99th Archbishop of Canterbury was the first since 1397 to visit Rome, where he held private talks with Pope John XXIII in 1960. In 2005, Rowan Williams became the first Archbishop of Canterbury to attend a papal funeral since the reformation. He also attended the enthronement of Pope Benedict XVI. The 101st archbishop, Donald Coggan was the first to attend an enthronement, that of Pope John Paul II in 1978.
Since 2002, the Archbishop of Canterbury has co-sponsored the Alexandria Middle East Peace process with the Grand Mufti of Egypt. In July 2008, the Archbishop attended a conference of Christians, Jews and Muslims convened by the king of Saudi Arabia at which the notion of the Clash of the Civilizations was rejected. Delegates agreed "on international guidelines for dialogue among the followers of religions and cultures." Delegates said that "the deepening of moral values and ethical principles, which are common denominators among such followers, would help strengthen stability and achieve prosperity for all humans."
Origins.
It has been suggested that the Roman province of Britannia had four archbishops, seated at London, York, Lincoln and Cirencester. However, in the 5th and 6th centuries Britannia began to be overrun by pagan, Germanic peoples who came to be known collectively as the Anglo-Saxons. Of the kingdoms they created, Kent arguably had the closest links with European politics, trade and culture, because it was conveniently situated for communication with the Continent. In the late 6th century, King Æthelberht of Kent married a Christian Frankish princess named Bertha, possibly before becoming king, and certainly a number of years before the arrival of the first Christian mission to England. He permitted the preaching of Christianity.
The first Archbishop of Canterbury was St Augustine (not to be confused with St Augustine of Hippo), who arrived in Kent in 597 AD, having been sent by Pope Gregory I on a mission to the English. He was accepted by King Æthelbert, on his conversion to Christianity, about the year 598. It seems that Pope Gregory, ignorant of recent developments in the former Roman province, including the spread of the Pelagian heresy, had intended the new archiepiscopal sees for England to be established in London and York. In the event, Canterbury was chosen instead of London, owing to political circumstances. Since then the Archbishops of Canterbury have been referred to as occupying the Chair of St. Augustine.
A Gospel Book believed to be directly associated with St. Augustine's mission survives in the Parker Library, Corpus Christi College, Cambridge University, England. Catalogued as Cambridge "Manuscript 286", it has been positively dated to 6th century Italy and this bound book, the St Augustine Gospels, is still used during the swearing-in ceremony of new archbishops of Canterbury.
Before the break with papal authority in the 16th century, the Church of England was an integral part of the Western European church. Since the break the Church of England, an established national church, still considers itself part of the broader Western Catholic tradition (although this is not accepted by the Catholic Church which regards Anglicanism as schismatic and does not accept Anglican holy orders as valid) as well as being the "mother church" of the worldwide Anglican Communion.
Province and Diocese of Canterbury.
The Archbishop of Canterbury exercises metropolitical (or supervisory) jurisdiction over the Province of Canterbury, which encompasses thirty of the forty-four dioceses of the Church of England, with the rest falling within the Province of York. The four dioceses of Wales were formerly also under the Province of Canterbury until 1920 when they were transferred from the established Church of England to the disestablished Church in Wales.
The Archbishop of Canterbury has a ceremonial provincial "curia", or court, consisting of some of the senior bishops of his province. The Bishop of London—the most senior cleric of the church with the exception of the two archbishops—serves as Canterbury's provincial dean, the Bishop of Winchester as chancellor, the Bishop of Lincoln as vice-chancellor, the Bishop of Salisbury as precentor, the Bishop of Worcester as chaplain and the Bishop of Rochester as cross-bearer.
Along with primacy over the Archbishop of York, the Archbishop of Canterbury also has a precedence of honour over the other bishops of the Anglican Communion. He is recognised as "primus inter pares", or first amongst equals. He does not, however, exercise any direct authority in the provinces outside England, except in certain minor roles dictated by Canon in those provinces (for example, he is the judge in the event of an ecclesiastical prosecution against the Archbishop of Wales). He does hold metropolitical authority over several extra-provincial Anglican churches, and he serves as "ex officio" Bishop of the Falkland Islands.
At present the archbishop has three suffragan bishops:
The Bishop of Maidstone was previously a second "actual" suffragan bishop working in the diocese, until it was decided at the diocesan synod of November 2010 that a new bishop will not be appointed.
Styles and privileges.
The Archbishop of Canterbury and the Archbishop of York are both styled as "The Most Reverend"; retired archbishops are styled as "The Right Reverend". Archbishops are, by convention, appointed to the Privy Council and may, therefore, also use the style of "The Right Honourable" for life (unless they are later removed from the council). In formal documents, the Archbishop of Canterbury is referred to as "The Most Reverend Father in God, Forenames, by Divine Providence Lord Archbishop of Canterbury, Primate of All England and Metropolitan". In debates in the House of Lords, the archbishop is referred to as "The Most Reverend Primate, the Archbishop of Canterbury". "The Right Honourable" is not used in either instance. He may also be formally addressed as "Your Grace"—or, more often these days, simply as "Archbishop", or "Father".
The surname of the Archbishop of Canterbury is not always used in formal documents; often only the first name and see are mentioned. The archbishop is legally entitled to sign his name as "Cantuar" (from the Latin for Canterbury). The right to use a title as a legal signature is only permitted to bishops, Peers of the Realm and peers by courtesy. The current Archbishop of Canterbury usually signs as "+Justin Cantuar:".
In the English and Welsh order of precedence, the Archbishop of Canterbury is ranked above all individuals in the realm, with the exception of the Sovereign and members of the Royal Family. Immediately below him is the Lord Chancellor and then the Archbishop of York.
Residences.
The Archbishop of Canterbury's official residence in London is Lambeth Palace.
He also has a residence, named The Old Palace, next to Canterbury Cathedral on the site of the medieval Archbishop's Palace.
The archbishops had palaces on the periphery of London and on the route between London and Canterbury.
Former palaces of the archbishops include

</doc>
<doc id="2346" url="http://en.wikipedia.org/wiki?curid=2346" title="Albion, Michigan">
Albion, Michigan

Albion is a city in Calhoun County in the south central region of the Lower Peninsula of the U.S. state of Michigan. The population was 8,616 at the 2010 census and is part of the Battle Creek Metropolitan Statistical Area. From the time that the earliest English-speaking settlers arrived, the area has also been known as "The Forks", because it is situated at the confluence of the north and south branches of the Kalamazoo River. The "Festival of the Forks" has been held annually since 1967 to celebrate Albion's ethnic heritage.
The presence of several major manufacturers since the 19th century has given Albion the reputation of a factory town. This has changed with the closure of several manufacturers, and Albion's culture is changing to that of a college town with a strong interest in technology and sustainability issues. Albion College is a private liberal arts college with a student population of about 1,750. Albion is a sister city with Noisy-le-Roi, France.
History.
The first European-American settler, Tenney Peabody, arrived in 1833 along with his brother-in-law Charles Blanchard, and a young man named Clark Dowling. Peabody's family followed soon after. In 1835, the Albion Company, a land development company formed by Jesse Crowell, platted a village and Peabody's wife was asked to name the settlement. She considered the name "Peabodyville", but "Albion" was selected instead, after the former residence of Jesse Crowell. Crowell became the first postmaster in 1838. Albion incorporated as a village in 1855 and as a city in 1885.
In 1835, Methodist Episcopal settlers established Albion College, which was known by a few other names before 1861 when the college was fully authorized to confer four-year degrees on both men and women. The first classes were held in Albion in 1843.
The forks of the Kalamazoo River provided power for mills, and Albion quickly became a mill town as well as an agricultural market. A railroad line arrived in 1852, fostering the development of other industries.
In 1973 Albion was named an All-America City by the National Civic League. It celebrated winning the award on May 15, 1974 when the Governor of Michigan, William Milliken, and many dignitaries came to town. However, in 1975 the closure of a major factory cut the celebration short and new challenges were created overnight.
Since that time citizens have mobilized, with support from the Albion Community Foundation founded in 1968, and the Albion Volunteer Service Organization, founded in the 1980s with support from Albion College, to address the challenge of diminishing economic opportunity.
Key to the City Honor Bestowed:
Law and government.
Albion has a Council-Manager form of government. City residents elect a Mayor and City Council members from six districts. The council in turn selects a City Manager to handle day-to-day affairs of the city. The mayor presides over and is a voting member of the council. Council members are elected to four-year terms, staggered every two years. A mayor is elected every two years.
Geography.
According to the United States Census Bureau, the city has a total area of 4.51 sqmi, of which 4.41 sqmi is land and 0.10 sqmi is water. Albion is positioned 42.24 degrees north of the equator and 84.75 degrees west of the prime meridian.
Transportation.
Rail.
Amtrak, the national passenger rail system, provides daily service to Albion, operating its Wolverine both directions between Chicago, Illinois and Pontiac, Michigan via Detroit.
Bus.
Greyhound Lines provides daily intercity city bus service to Albion between Chicago, Illinois and Detroit.

</doc>
<doc id="2348" url="http://en.wikipedia.org/wiki?curid=2348" title="Anointing of the Sick">
Anointing of the Sick

Anointing of the sick, known also by other names, is a form of religious anointing or "unction" (an older term with the same meaning) for the benefit of a sick person. It is practiced by many Christian churches and denominations. 
Anointing of the sick was a customary practice in many civilizations, including among the ancient Greeks and early Jewish communities. The use of oil for healing purposes is referred to in the writings of Hippocrates.
Anointing of the sick should be distinguished from other religious anointings that occur in relation to other sacraments, in particular baptism, confirmation and ordination, and also in the coronation of a monarch.
Names.
Since 1972, the Roman Catholic Church uses the name "Anointing of the Sick" both in the English translations issued by the Holy See of its official documents in Latin and in the English official documents of Episcopal conferences. It does not, of course, forbid the use of other names, for example the more archaic term "Unction of the Sick" or the term "Extreme Unction". Cardinal Walter Kasper used the latter term in his intervention at the 2005 Assembly of the Synod of Bishops. However, the Church declared that "'Extreme unction' ... may also "and more fittingly" be called 'anointing of the sick'" (emphasis added), and has itself adopted the latter term, while not outlawing the former. This is to emphasize that the sacrament is available, and recommended, to all those suffering from any serious illness, and to dispel the common misconception that it is exclusively for those at or very near the point of death.
Extreme Unction was the usual name for the sacrament in the West from the late twelfth century until 1972, and was thus used at the Council of Trent and in the 1913 Catholic Encyclopedia. Peter Lombard (died 1160) is the first writer known to have used the term, which did not become the usual name in the West till towards the end of the twelfth century, and never became current in the East. The word "extreme" (final) indicated either that it was the last of the sacramental unctions (after the anointings at Baptism, Confirmation and, if received, Holy Orders) or because at that time it was normally administered only when a patient was "in extremis".
Other names used in the West include the unction or blessing of consecrated oil, the unction of God, and the office of the unction. Among some Protestant bodies, who do not consider it a sacrament, but instead as a practice suggested rather than commanded by Scripture, it is called anointing with oil.
In the Greek Church the sacrament is called Euchelaion (Greek Εὐχέλαιον, from εὐχή, "prayer", and ἔλαιον, "oil"). Other names are also used, such as ἅγιον ἔλαιον (holy oil), ἡγιασμένον ἔλαιον (consecrated oil), and χρῖσις or χρῖσμα (anointing).
The Community of Christ uses the term administration to the sick.
The term "last rites" refers to administration to a dying person not only of this sacrament but also of Penance and Holy Communion, the last of which, when administered in such circumstances, is known as "Viaticum", a word whose original meaning in Latin was "provision for the journey". The normal order of administration is: first Penance (if the dying person is physically unable to confess, absolution, conditional on the existence of contrition, is given); next, Anointing; finally, Viaticum (if the person can receive it).
Biblical texts.
The chief Biblical text concerning the rite is : "Is any among you sick? Let him call for the elders of the church, and let them pray over him, anointing him with oil in the name of the Lord; and the prayer of faith will save the sick man, and the Lord will raise him up; and if he has committed sins, he will be forgiven." (RSV)
, and are also quoted in this regard.
Sacramental beliefs.
The Roman Catholic, Eastern Orthodox and Coptic and Old Catholic Churches consider this anointing to be a sacrament. Other Christians too, in particular Anglicans, Lutherans and some Protestant and other Christian communities use a rite of anointing the sick, without necessarily classifying it as a sacrament.
In the Churches mentioned here by name, the oil used (called "oil of the sick" in both West and East) is blessed specifically for this purpose.
Roman Catholic Church.
An extensive account of the teaching of the Catholic Church on Anointing of the Sick is given in 
Anointing of the Sick is one of the seven Sacraments recognized by the Catholic Church, and is associated with not only bodily healing but also forgiveness of sins. Only ordained priests can administer it, and "any priest may carry the holy oil with him, so that in a case of necessity he can administer the sacrament of anointing of the sick."
Sacramental graces.
The Catholic Church sees the effects of the sacrament as follows. As the sacrament of Marriage gives grace for the married state, the sacrament of Anointing of the Sick gives grace for the state into which people enter through sickness. Through the sacrament a gift of the Holy Spirit is given, that renews confidence and faith in God and strengthens against temptations to discouragement, despair and anguish at the thought of death and the struggle of death; it prevents from losing Christian hope in God's justice, truth and salvation.
The special grace of the sacrament of the Anointing of the Sick has as its effects:
Sacramental oil.
The duly blessed oil used in the sacrament is, as laid down in the Apostolic Constitution , pressed from olives or from other plants. It is blessed by the bishop of the diocese at the Chrism Mass he celebrates on Holy Thursday or on a day close to it. If oil blessed by the bishop is not available, the priest administering the sacrament may bless the oil, but only within the framework of the celebration.
Current liturgical form (1972).
The Roman Rite Anointing of the Sick, as revised in 1972, puts greater stress than in the immediately preceding centuries on the sacrament's aspect of healing, and points to the place sickness holds in the normal life of Christians and its part in the redemptive work of the Church. Canon law permits its administration to any Catholic who has reached the use of reason and is beginning to be put in danger by illness or old age, unless the person in question obstinately persists in a manifestly grave sin. "If there is any doubt as to whether the sick person has reached the use of reason, or is dangerously ill, or is dead, this sacrament is to be administered". There is an obligation to administer it to the sick who, when they were in possession of their faculties, at least implicitly asked for it. A new illness or a renewal or worsening of the first illness enables a person to receive the sacrament a further time.
The ritual book on pastoral care of the sick provides three rites: anointing outside Mass, anointing within Mass, and anointing in a hospital or institution. The rite of anointing outside Mass begins with a greeting by the priest, followed by sprinkling of all present with holy water, if deemed desirable, and a short instruction. There follows a penitential act, as at the beginning of Mass. If the sick person wishes to receive the sacrament of penance, it is preferable that the priest make himself available for this during a previous visit; but if the sick person must confess during the celebration of the sacrament of anointing, this confession replaces the penitential rite A passage of Scripture is read, and the priest may give a brief explanation of the reading, a short litany is said, and the priest lays his hands on the head of the sick person and then says a prayer of thanksgiving over the already blessed oil or, if necessary, blesses the oil himself.
The actual anointing of the sick person is done on the forehead, with the prayer "Through this holy anointing may the Lord in his love and mercy help you with the grace of the Holy Spirit", and on the hands, with the prayer "May the Lord who frees you from sin save you and raise you up". To each prayer the sick person, if able, responds: "Amen." It is permitted, in accordance with local culture and traditions and the condition of the sick person, to anoint other parts of the body in addition, such as the area of pain or injury, but without repeating the sacramental form. In case of emergency, a single anointing, not necessarily on the forehead, is sufficient.
Historical liturgical form.
From the early Middle Ages until after the Second Vatican Council the sacrament was administered, within the Latin Church, only when death was approaching and, in practice, bodily recovery was not ordinarily looked for, giving rise, as mentioned above to the name "Extreme Unction" (i.e. final anointing). The form used in the Roman Rite included anointing of seven parts of the body while saying (in Latin): "Through this holy unction and His own most tender mercy may the Lord pardon thee whatever sins or faults thou hast committed [quidquid deliquisti] by sight [by hearing, smell, taste, touch, walking, carnal delectation]", the last phrase corresponding to the part of the body that was touched; however, in the words of the 1913 Catholic Encyclopedia, "the unction of the loins is generally, if not universally, omitted in English-speaking countries, and it is of course everywhere forbidden in case of women". Use of this form is still permitted under the conditions mentioned in article 9 of the 2007 motu proprio "Summorum Pontificum".
Liturgical rites of the Catholic Church, both Western and Eastern, other than the Roman, have a variety of other forms for celebrating the sacrament.
Eastern Orthodox Church.
The teaching of the Eastern Orthodox Church on the Holy Mystery (sacrament) of Unction is similar to that of the Roman Catholic Church. However, the reception of the Mystery is not limited to those who are enduring physical illness. The Mystery is given for healing (both physical and spiritual) and for the forgiveness of sin. For this reason, it is normally required that one go to confession before receiving Unction. Because it is a Sacred Mystery of the Church, only Orthodox Christians may receive it.
The solemn form of Eastern Christian anointing requires the ministry of seven priests. A table is prepared, upon which is set a vessel containing wheat. Into the wheat has been placed an empty shrine-lamp, seven candles, and seven anointing brushes. Candles are distributed for all to hold during the service. The rite begins with reading Psalm 50 (the great penitential psalm), followed by the chanting of a special canon. After this, the senior priest (or bishop) pours pure olive oil and a small amount of wine into the shrine lamp, and says the "Prayer of the Oil", which calls upon God to "...sanctify this Oil, that it may be effectual for those who shall be anointed therewith, unto healing, and unto relief from every passion, every malady of the flesh and of the spirit, and every ill..." Then follow seven series of epistles, gospels, long prayers, Ektenias (litanies) and anointings. Each series is served by one of the seven priests in turn. The afflicted one is anointed with the sign of the cross on seven places: the forehead, the nostrils, the cheeks, the lips, the breast, the palms of both hands, and the back of the hands. After the last anointing, the Gospel Book is opened and placed with the writing down upon the head of the one who was anointed, and the senior priest reads the "Prayer of the Gospel". At the end, the anointed kisses the Gospel, the Cross and the right hands of the priests, receiving their blessing.
Anointing is considered to be a public rather than a private sacrament, and so as many of the faithful who are able are encouraged to attend. It should be celebrated in the church when possible, but if this is impossible, it may be served in the home or hospital room of the afflicted.
Unction in the Greek Orthodox Church and Churches of Hellenic custom (Melkite, Antiochian Orthodox, etc.) is usually given with a minimum of ceremony.
Anointing may also be given during Forgiveness Vespers and Great Week, on Great and Holy Wednesday, to all who are prepared. Those who receive Unction on Holy Wednesday should go to Holy Communion on Maundy Thursday. The significance of receiving Unction on Holy Wednesday is shored up by the hymns in the Triodion for that day, which speak of the sinful woman who anointed the feet of Christ (). Just as her sins were forgiven because of her penitence, so the faithful are exhorted to repent of their sins. In the same narrative, Jesus says, "in that she hath poured this ointment on my body, she did it for my burial" (Id., v. 12), linking the unction with Christ's death and resurrection.
In some dioceses of the Russian Orthodox Church it is customary for the bishop to visit each parish or region of the diocese some time during Great Lent and give Anointing for the faithful, together with the local clergy.
Anglican churches.
The 1552 and later editions of the Book of Common Prayer omitted the form of anointing given in the original (1549) version in its Order for the Visitation of the Sick, but most twentieth-century Anglican prayer books do have anointing of the sick.
Some Anglicans accept that anointing of the sick has a sacramental character and is therefore a channel of God's grace, seeing it as an "outward and visible sign of an inward and spiritual grace" which is the definition of a sacrament. The Catechism of the Episcopal Church of the United States of America includes Unction of the Sick as among the "other sacramental rites" and it states that unction can be done with oil or simply with laying on of hands. The rite of anointing is included in the Episcopal Church's "Ministration to the Sick" 
Article 25 of the Thirty-Nine Articles, which are one of the historical formularies of the Church of England (and as such, the Anglican Communion), speaking of the sacraments, says: "Those five commonly called Sacraments, that is to say, Confirmation, Penance, Orders, Matrimony, and extreme Unction, are not to be counted for Sacraments of the Gospel, being such as have grown partly of the corrupt following of the Apostles, partly are states of life allowed in the Scriptures; but yet have not like nature of Sacraments with Baptism, and the Lord's Supper, for that they have not any visible sign or ceremony ordained of God."
Lutheran churches.
Anointing of the sick has been retained in some Lutheran churches since the Reformation. Although it is not considered a sacrament like baptism and the Eucharist, it is known as a ritual in the same respect as confession, confirmation, holy orders, and matrimony. 
Liturgy.
After the penitent has received absolution following confession, the presiding minister recites . He goes on to recite the following: 
[Name], you have confessed your sins and received Holy Absolution. In remembrance of the grace of God given by the Holy Spirit in the waters of Holy Baptism, I will anoint you with oil. Confident in our Lord and in love for you, we also pray for you that you will not lose faith. Knowing that in Godly patience the Church endures with you and supports you during this affliction. We firmly believe that this illness is for the glory of God and that the Lord will both hear our prayer and work according to His good and gracious will.
He anoints the person on the forehead and says this blessing:
Almighty God, the Father of our Lord Jesus Christ, who has given you the new birth of water and the Spirit and has forgiven you all your sins, strengthen you with His grace to life everlasting. Amen.
Other Protestant communities.
Among Protestants, anointing is provided in a wide variety of formats but, for the most part, however, it has fallen into disuse. Protestant communities generally vary widely on the sacramental character of anointing. Most Mainline Protestants recognize only two sacraments, the Eucharist and baptism (though some Lutherans add confession), deeming Anointing only a humanly-instituted rite. Non-traditional Protestant communities generally use the term "ordinance" rather than "Sacrament".
Mainline beliefs.
Liturgical or Mainline Protestant communities (e.g. Presbyterian, Congregationalist/United Church of Christ, Methodist, etc.) all have official yet often optional liturgical rites for the anointing of the sick partly on the model of Western pre-Reformation rites. Anointing need not be associated with grave illness or imminent danger of death. 
Charismatic and Pentecostal beliefs.
In Charismatic and Pentecostal communities, anointing of the sick is a frequent practice and has been an important ritual in these communities since the respective movements were founded in the 19th and 20th centuries. These communities use extemporaneous forms of administration at the discretion of the minister, who need not be a pastor. There is minimal ceremony attached to its administration. Usually, several people physically touch (laying on of hands) the recipient during the anointing. It may be part of a worship service with the full assembly of the congregation present, but may also be done in more private settings, such as homes or hospital rooms. Some Pentecostals believe that physical healing is within the anointing and so there is often great expectation or at least great hope that a miraculous cure or improvement will occur when someone is being prayed over for healing.
Evangelical and fundamentalist beliefs.
In Evangelical and Fundamentalist communities, anointing of the sick is performed with varying degrees of frequency, although laying on of hands may be more common than anointing. The rite would be similar to that of Pentecostals in its simplicity, but would usually not have the same emotionalism attached to it. Unlike some Pentecostals, Evangelicals and Fundamentalists generally do not believe that physical healing is within the anointing. Therefore, God may or may not grant physical healing to the sick. The healing conferred by anointing is thus a spiritual event that may not result in physical recovery.
The Church of the Brethren practices Anointing with Oil as an ordinance along with Baptism, Communion, Laying on of Hands, and the Love Feast.
Evangelical Protestants who use anointing differ about whether the person doing the anointing must be an ordained member of the clergy, whether the oil must necessarily be olive oil and have been previously specially consecrated, and about other details. Several Evangelical groups reject the practice so as not to be identified with charismatic and Pentecostal groups, which practice it widely.
Use of Catholic rite among Protestants.
Some Protestant US military chaplains carry the Roman Rite version of the Anointing of the Sick with them for use if called upon to assist wounded or dying soldiers who are Catholics. The Catholic and Orthodox Churches consider invalid "as a sacrament" the administration of Anointing of the Sick by such chaplains, who in the eyes of those Churches are not validly ordained priests. The rite performed by them is thus seen as having the same by no means negligible value of any other form of prayer offered for the sick or dying.
Latter Day Saint movement.
The Church of Jesus Christ of Latter-day Saints.
Latter-day Saints, who consider themselves restorationists, also practice ritual anointing of the sick, as well as other forms of anointing. Members of The Church of Jesus Christ of Latter-day Saints (LDS Church) consider anointing to be an ordinance.
Members of the LDS Church who hold the Melchizedek priesthood may use consecrated oil in performing the ordinance of blessing of the "sick or afflicted", though oil is not required if it is unavailable. The priesthood holder anoints the recipient's head with a drop of oil, then lays hands upon that head and declare their act of anointing. Then another priesthood holder joins in, if available, and pronounces a "sealing" of the anointing and other words of blessing, as he feels inspired. Melchizedek priesthood holders are also authorized to consecrate any pure olive oil and often carry a personal supply in case they have need to perform a blessing. Oil is not used in other blessings, such as for people seeking comfort or counsel.
In addition to the reference, the Doctrine and Covenants contains numerous references to the anointing and healing of the sick by those with authority to do so.
Community of Christ.
Administration to the sick is one of the eight sacraments of the Community of Christ, in which it has also been used for people seeking spiritual, emotional or mental healing.
External links.
Western
Eastern

</doc>
<doc id="2349" url="http://en.wikipedia.org/wiki?curid=2349" title="Abstract data type">
Abstract data type

In computer science, an abstract data type (ADT) is a mathematical model for data types where a data type is defined by its behavior (semantics) from the point of view of a "user" of the data, specifically in terms of possible values, possible operations on data of this type, and the behavior of these operations. This contrasts with data structures, which are concrete representations of data, and are the point of view of an implementer, not a user.
Formally, an ADT may be defined as a "class of objects whose logical behavior is defined by a set of values and a set of operations"; this is analogous to an algebraic structure in mathematics. What is meant by "behavior" varies by author, with the two main types of formal specifications for behavior being "axiomatic (algebraic) specification" and an "abstract model;" these correspond to axiomatic semantics and operational semantics of an abstract machine, respectively. Some authors also include the computational complexity ("cost"), both in terms of time (for computing operations) and space (for representing values).
In practice many common data types are not ADTs, as the abstraction is not perfect, and users must be aware of issues like arithmetic overflow that are due to the representation. For example, integers are often implemented as fixed width (32-bit or 64-bit binary numbers), and thus experience integer overflow if the maximum value is exceeded.
ADTs are a theoretical concept in computer science, used in the design and analysis of algorithms, data structures, and software systems, and do not correspond to specific features of computer languages – mainstream computer languages do not directly support formally specified ADTs. However, various language features correspond to certain aspects of ADTs, and are easily confused with ADTs proper; these include abstract types, opaque data types, protocols, and design by contract. ADTs were first proposed by Barbara Liskov and Stephen N. Zilles in 1974, as part of the development of the CLU language.
Examples.
For example, integers are an ADT, defined as the values 0, 1, −1, 2, ..., and by the operations of addition, subtraction, multiplication, and division, together with greater than, less than, etc., which behave according to familiar mathematics (with care for integer division), independently of how the integers are represented by the computer. Explicitly, "behavior" includes obeying various axioms (associativity and commutativity of addition etc.), and preconditions on operations (cannot divide by zero). Typically integers are represented in a data structure as binary numbers, most often as two's complement, but might be binary-coded decimal or in ones' complement, but the user is abstracted from the concrete choice of representation, and can simply use the data as integers.
An ADT consists not only of operations, but also of values of the underlying data and of constraints on the operations. An "interface" typically refers only to the operations, and perhaps some of the constraints on the operations, notably pre-conditions and post-conditions, but not other constraints, such as relations between the operations.
For example, an abstract stack, which is a last-in-first-out structure, could be defined by three operations: push, that inserts some data item onto the structure, pop, that extracts an item from it, and peek or top, that allows data on top of the structure to be examined without removal. An abstract queue data structure, which is a first-in-first-out structure, would also have three operations, enqueue to join the queue; dequeue, to remove the first element from the queue; and front, in order to access and serve the first element in the queue. There would be no way of differentiating these two data types, unless a mathematical constraint is introduced that for a stack specifies that each pop always returns the most recently pushed item that has not been popped yet. When analyzing the efficiency of algorithms that use stacks, one may also specify that all operations take the same time no matter how many items have been pushed into the stack, and that the stack uses a constant amount of storage for each element.
Introduction.
Abstract data types are purely theoretical entities, used (among other things) to simplify the description of abstract algorithms, to classify and evaluate data structures, and to formally describe the type systems of programming languages. However, an ADT may be implemented by specific data types or data structures, in many ways and in many programming languages; or described in a formal specification language. ADTs are often implemented as modules: the module's interface declares procedures that correspond to the ADT operations, sometimes with comments that describe the constraints. This information hiding strategy allows the implementation of the module to be changed without disturbing the client programs.
The term abstract data type can also be regarded as a generalised approach of a number of algebraic structures, such as lattices, groups, and rings. The notion of abstract data types is related to the concept of data abstraction, important in object-oriented programming and design by contract methodologies for software development.
Defining an abstract data type.
An abstract data type is defined as a mathematical model of the data objects that make up a data type as well as the functions that operate on these objects.
There are no standard conventions for defining them. A broad division may be drawn between "imperative" and "functional" definition styles.
Imperative definition style.
In the "imperative" definition style, which is closer to the philosophy of imperative programming languages, an abstract data structure is conceived as an entity that is "mutable" — meaning that it may be in different "states" at different times. Some operations may change the state of the ADT; therefore, the order in which operations are evaluated is important, and the same operation on the same entities may have different effects if executed at different times — just like the instructions of a computer, or the commands and procedures of an imperative language. To underscore this view, it is customary to say that the operations are "executed" or "applied", rather than "evaluated". The imperative style is often used when describing abstract algorithms. This is described by Donald E. Knuth and can be referenced from here The Art of Computer Programming.
Abstract variable.
Imperative ADT definitions often depend on the concept of an "abstract variable", which may be regarded as the simplest non-trivial ADT. An abstract variable "V" is a mutable entity that admits two operations:
with the constraint that
As in so many programming languages, the operation store("V","x") is often written "V" ← "x" (or some similar notation), and fetch("V") is implied whenever a variable "V" is used in a context where a value is required. Thus, for example, "V" ← "V" + 1 is commonly understood to be a shorthand for store("V",fetch("V") + 1).
In this definition, it is implicitly assumed that storing a value into a variable "U" has no effect on the state of a distinct variable "V". To make this assumption explicit, one could add the constraint that
More generally, ADT definitions often assume that any operation that changes the state of one ADT instance has no effect on the state of any other instance (including other instances of the same ADT) — unless the ADT axioms imply that the two instances are connected (aliased) in that sense. For example, when extending the definition of abstract variable to include abstract records, the operation that selects a field from a record variable "R" must yield a variable "V" that is aliased to that part of "R".
The definition of an abstract variable "V" may also restrict the stored values "x" to members of a specific set "X", called the "range" or "type" of "V". As in programming languages, such restrictions may simplify the description and analysis of algorithms, and improve their readability.
Note that this definition does not imply anything about the result of evaluating fetch("V") when "V" is "un-initialized", that is, before performing any store operation on "V". An algorithm that does so is usually considered invalid, because its effect is not defined. (However, there are some important algorithms whose efficiency strongly depends on the assumption that such a fetch is legal, and returns some arbitrary value in the variable's range.)
Instance creation.
Some algorithms need to create new instances of some ADT (such as new variables, or new stacks). To describe such algorithms, one usually includes in the ADT definition a create() operation that yields an instance of the ADT, usually with axioms equivalent to
This axiom may be strengthened to exclude also partial aliasing with other instances. On the other hand, this axiom still allows implementations of create() to yield a previously created instance that has become inaccessible to the program.
Preconditions, postconditions, and invariants.
In imperative-style definitions, the axioms are often expressed by "preconditions", that specify when an operation may be executed; "postconditions", that relate the states of the ADT before and after the execution of each operation; and "invariants", that specify properties of the ADT that are "not" changed by the operations.
Example: abstract stack (imperative).
As another example, an imperative definition of an abstract stack could specify that the state of a stack "S" can be modified only by the operations
with the constraint that
Since the assignment { "V" ← "x" }, by definition, cannot change the state of "S", this condition implies that { "V" ← pop("S") } restores "S" to the state it had before the { push("S","x") }. From this condition and from the properties of abstract variables, it follows, for example, that the sequence
where "x","y", and "z" are any values, and "U", "V", "W" are pairwise distinct variables, is equivalent to
Here it is implicitly assumed that operations on a stack instance do not modify the state of any other ADT instance, including other stacks; that is,
A stack ADT definition usually includes also a Boolean-valued function empty("S") and a create() operation that returns a stack instance, with axioms equivalent to
Single-instance style.
Sometimes an ADT is defined as if only one instance of it existed during the execution of the algorithm, and all operations were applied to that instance, which is not explicitly notated. For example, the abstract stack above could have been defined with operations push("x") and pop(), that operate on "the" only existing stack. ADT definitions in this style can be easily rewritten to admit multiple coexisting instances of the ADT, by adding an explicit instance parameter (like "S" in the previous example) to every operation that uses or modifies the implicit instance.
On the other hand, some ADTs cannot be meaningfully defined without assuming multiple instances. This is the case when a single operation takes two distinct instances of the ADT as parameters. For an example, consider augmenting the definition of the stack ADT with an operation compare("S","T") that checks whether the stacks "S" and "T" contain the same items in the same order.
Functional ADT definitions.
Another way to define an ADT, closer to the spirit of functional programming, is to consider each state of the structure as a separate entity. In this view, any operation that modifies the ADT is modeled as a mathematical function that takes the old state as an argument, and returns the new state as part of the result. Unlike the "imperative" operations, these functions have no side effects. Therefore, the order in which they are evaluated is immaterial, and the same operation applied to the same arguments (including the same input states) will always return the same results (and output states).
In the functional view, in particular, there is no way (or need) to define an "abstract variable" with the semantics of imperative variables (namely, with fetch and store operations). Instead of storing values into variables, one passes them as arguments to functions.
Example: abstract stack (functional).
For example, a complete functional-style definition of a stack ADT could use the three operations:
In a functional-style definition there is no need for a create operation. Indeed, there is no notion of "stack instance". The stack states can be thought of as being potential states of a single stack structure, and two stack states that contain the same values in the same order are considered to be identical states. This view actually mirrors the behavior of some concrete implementations, such as linked lists with hash cons.
Instead of create(), a functional definition of a stack ADT may assume the existence of a special stack state, the "empty stack", designated by a special symbol like Λ or "()"; or define a bottom() operation that takes no arguments and returns this special stack state. Note that the axioms imply that
In a functional definition of a stack one does not need an empty predicate: instead, one can test whether a stack is empty by testing whether it is equal to Λ.
Note that these axioms do not define the effect of top("s") or pop("s"), unless "s" is a stack state returned by a push. Since push leaves the stack non-empty, those two operations are undefined (hence invalid) when "s" = Λ. On the other hand, the axioms (and the lack of side effects) imply that push("s","x") = push("t","y") if and only if "x" = "y" and "s" = "t".
As in some other branches of mathematics, it is customary to assume also that the stack states are only those whose existence can be proved from the axioms in a finite number of steps. In the stack ADT example above, this rule means that every stack is a "finite" sequence of values, that becomes the empty stack (Λ) after a finite number of pops. By themselves, the axioms above do not exclude the existence of infinite stacks (that can be poped forever, each time yielding a different state) or circular stacks (that return to the same state after a finite number of pops). In particular, they do not exclude states "s" such that pop("s") = "s" or push("s","x") = "s" for some "x". However, since one cannot obtain such stack states with the given operations, they are assumed "not to exist".
Whether to include complexity.
Aside from the behavior in terms of axioms, it is also possible to include, in the definition of an ADT's operations, their algorithmic complexity. Alexander Stepanov, designer of the C++ Standard Template Library, included complexity guarantees in the STL's specification, arguing:
The reason for introducing the notion of abstract data types was to allow interchangeable software modules. You cannot have interchangeable modules unless these modules share similar complexity behavior. If I replace one module with another module with the same functional behavior but with different complexity tradeoffs, the user of this code will be unpleasantly surprised. I could tell him anything I like about data abstraction, and he still would not want to use the code. Complexity assertions have to be part of the interface.—Alexander Stepanov
Advantages of abstract data typing.
Abstraction provides a promise that any implementation of the ADT has certain properties and abilities; knowing these is all that is required to make use of an ADT object. The user does not need any technical knowledge of how the implementation works to use the ADT. In this way, the implementation may be complex but will be encapsulated in a simple interface when it is actually used.
Code that uses an ADT object will not need to be edited if the implementation of the ADT is changed. Since any changes to the implementation must still comply with the interface, and since code using an ADT may only refer to properties and abilities specified in the interface, changes may be made to the implementation without requiring any changes in code where the ADT is used.
Different implementations of an ADT, having all the same properties and abilities, are equivalent and may be used somewhat interchangeably in code that uses the ADT. This gives a great deal of flexibility when using ADT objects in different situations. For example, different implementations of an ADT may be more efficient in different situations; it is possible to use each in the situation where they are preferable, thus increasing overall efficiency.
Typical operations.
Some operations that are often specified for ADTs (possibly under other names) are
In imperative-style ADT definitions, one often finds also
The free operation is not normally relevant or meaningful, since ADTs are theoretical entities that do not "use memory". However, it may be necessary when one needs to analyze the storage used by an algorithm that uses the ADT. In that case one needs additional axioms that specify how much memory each ADT instance uses, as a function of its state, and how much of it is returned to the pool by free.
Examples.
Some common ADTs, which have proved useful in a great variety of applications, are
Each of these ADTs may be defined in many ways and variants, not necessarily equivalent. For example, a stack ADT may or may not have a count operation that tells how many items have been pushed and not yet popped. This choice makes a difference not only for its clients but also for the implementation.
Implementation.
Implementing an ADT means providing one procedure or function for each abstract operation. The ADT instances are represented by some concrete data structure that is manipulated by those procedures, according to the ADT's specifications.
Usually there are many ways to implement the same ADT, using several different concrete data structures. Thus, for example, an abstract stack can be implemented by a linked list or by an array.
In order to prevent clients from depending on the implementation, an ADT is often packaged as an "opaque data type" in one or more modules, whose interface contains only the signature (number and types of the parameters and results) of the operations. The implementation of the module — namely, the bodies of the procedures and the concrete data structure used — can then be hidden from most clients of the module. This makes it possible to change the implementation without affecting the clients. If the implementation is exposed, it is known instead as a "transparent data type."
When implementing an ADT, each instance (in imperative-style definitions) or each state (in functional-style definitions) is usually represented by a handle of some sort.
Modern object-oriented languages, such as C++ and Java, support a form of abstract data types. When a class is used as a type, it is an abstract type that refers to a hidden representation. In this model an ADT is typically implemented as a class, and each instance of the ADT is usually an object of that class. The module's interface typically declares the constructors as ordinary procedures, and most of the other ADT operations as methods of that class. However, such an approach does not easily encapsulate multiple representational variants found in an ADT. It also can undermine the extensibility of object-oriented programs.
In a pure object-oriented program that uses interfaces as types, types refer to behaviors not representations.
Example: implementation of the stack ADT.
As an example, here is an implementation of the stack ADT above in the C programming language.
 Imperative-style interface 
An imperative-style interface might be:
This implementation could be used in the following manner:
This interface can be implemented in many ways. The implementation may be arbitrarily inefficient, since the formal definition of the ADT, above, does not specify how much space the stack may use, nor how long each operation should take. It also does not specify whether the stack state "t" continues to exist after a call "s" ← pop("t").
In practice the formal definition should specify that the space is proportional to the number of items pushed and not yet popped; and that every one of the operations above must finish in a constant amount of time, independently of that number. To comply with these additional specifications, the implementation could use a linked list, or an array (with dynamic resizing) together with two integers (an item count and the array size)
Functional-style interface.
Functional-style ADT definitions are more appropriate for functional programming languages, and vice versa. However, one can provide a functional style interface even in an imperative language like C. For example:
The main problem is that C lacks garbage collection, and this makes this style of programming impractical; moreover, memory allocation routines in C are slower than allocation in a typical garbage collector, thus the performance impact of so many allocations is even greater.
ADT libraries.
Many modern programming languages, such as C++ and Java, come with standard libraries that implement several common ADTs, such as those listed above.
Built-in abstract data types.
The specification of some programming languages is intentionally vague about the representation of certain built-in data types, defining only the operations that can be done on them. Therefore, those types can be viewed as "built-in ADTs". Examples are the arrays in many scripting languages, such as Awk, Lua, and Perl, which can be regarded as an implementation of the Map or Table ADT.
References.
</dl>

</doc>
<doc id="2357" url="http://en.wikipedia.org/wiki?curid=2357" title="American Football League">
American Football League

The American Football League (AFL) was a major professional American football league that operated from 1960 until 1969, when it merged with the National Football League (NFL). The upstart AFL operated in direct competition with the more established NFL throughout its existence.
The AFL was created by a number of owners who had been refused NFL expansion franchises or had minor shares of NFL franchises. The AFL's original lineup saw an Eastern division of the New York Titans, Boston Patriots, Buffalo Bills and the Houston Oilers along with a Western division of the Los Angeles Chargers, Denver Broncos, Oakland Raiders, and Dallas Texans. The league first gained attention by signing 75% of the NFL's first-round draft choices in 1960, including Houston's successful signing of All-American Billy Cannon.
While the first years of the AFL saw uneven competition and low attendance, the league was buttressed by a generous television contract with ABC (followed by a contract with NBC for games starting with the 1965 season) that broadcast the more offense-oriented football league nationwide. Continuing to attract top talent from colleges and the NFL by the mid-1960s, as well as successful franchise shifts to San Diego (from LA) and Kansas City (from Dallas), the AFL established a dedicated following. The transformation of the struggling Titans into the New York Jets under new ownership further solidified the league's reputation among the major media.
As fierce competition made player salaries skyrocket in both leagues, especially after a series of "raids," the leagues agreed to a merger in 1966. Among the conditions were a common draft and a championship game played between the two league champions, which would eventually become known as the Super Bowl.
The AFL and NFL operated as separate leagues until 1970, with separate regular season and playoff schedules except for the championship game. During this time the AFL added the Miami Dolphins and Cincinnati Bengals. After losses by Kansas City and Oakland in the first two AFL-NFL Championship Games to the Green Bay Packers, the New York Jets and Kansas City Chiefs won Super Bowls III and IV, cementing the league's claim to being an equal to the NFL.
In 1970, the AFL was absorbed into the NFL, and the ten AFL franchises along with the Baltimore Colts, Cleveland Browns, and Pittsburgh Steelers became the American Football Conference.
League history.
During the 1950s, the National Football League had grown to rival Major League Baseball as one of the most popular professional sports leagues in the United States. One franchise that did not share in this newfound success of the league was the Chicago Cardinals, owned by the Bidwill family, who had become overshadowed by the more popular Chicago Bears. The Bidwills hoped to relocate their franchise, preferably to St. Louis but could not come to terms with the league on a relocation fee. Needing cash, the Bidwills began entertaining offers from would-be investors, and one of the men who approached the Bidwills was Lamar Hunt, son and heir of Texas millionaire oilman H. L. Hunt. Hunt offered to buy the Cardinals and move them to Dallas, Texas, where he had grown up. However, these negotiations came to nothing, since the Bidwills insisted on retaining a controlling interest in the franchise and were unwilling to move their team to a city where a previous NFL franchise had failed in 1952. While Hunt negotiated with Bidwills, similar offers were made by Bud Adams, Bob Howsam, and Max Winter.
When Hunt, Adams, and Howsam were unable to secure a controlling interest in the Chicago Cardinals, they approached NFL commissioner Bert Bell and proposed the addition of expansion teams. Bell, wary of expanding the 12-team league and risking its newfound success, rejected the offer. On his return flight to Dallas, Hunt conceived the idea of an entirely new league and decided to contact the others who had shown interest in purchasing the Cardinals. He contacted Adams, Howsam, and Winter (as well as Winter's business partner, Bill Boyer) to gauge their interest in starting a new league. Hunt's first meeting with Adams was held in March 1959. Hunt, who felt a regional rivalry would be critical for the success of the new league, convinced Adams to join and found his team in Houston. Hunt next secured an agreement from Howsam to bring a team to Denver, Colorado.
After Winter and Boyer agreed to start a team in Minneapolis-Saint Paul, the new league had its first four teams. Hunt then approached Willard Rhodes, who hoped to bring pro football to Seattle, Washington. However, the University of Washington was unwilling to let the fledgling league use Husky Stadium, probably due to the excessive wear and tear that would have caused to the facility's grass surface. With no place for his team to play, Rhodes' effort came to nothing. Hunt also sought franchises in Los Angeles, California; Buffalo and New York City. During the summer of 1959 he sought the blessings of the NFL for his nascent league, as he did not seek a potentially costly rivalry. Within weeks of the July 1959 announcement of the league's formation, Hunt received commitments from Barron Hilton and Harry Wismer to bring teams to Los Angeles and New York, respectively. His initial efforts for Buffalo, However, were rebuffed, when Hunt's first choice of owner, Pat McGroder, declined to take part; McGroder had hoped that the threat of the AFL would be enough to prompt the NFL to expand to Buffalo.
On August 14, 1959, the first league meeting was held in Chicago, Illinois, and charter memberships were given to Dallas, New York, Houston, Denver, Los Angeles, and Minneapolis-Saint Paul. On August 22 the league officially was named the American Football League. The NFL's initial reaction was not as openly hostile as it had been with the earlier All-America Football Conference (Bell had even given his public approval), yet individual NFL owners soon began a campaign to undermine the new league. AFL owners were approached with promises of new NFL franchises or ownership stakes in existing ones. Only the party from Minneapolis accepted, and the Minnesota group joined the NFL the next year in 1961; the Minneapolis group joined Ole Haugsrud in the new NFL team's ownership group, with Haugsrud dubbing the team the Minnesota Vikings. The older league also announced on August 29 that it had conveniently reversed its position against expansion, and planned to bring NFL expansion teams to Houston and Dallas, to start play in 1961. (The NFL did not expand to Houston at that time, the promised Dallas team – the Dallas Cowboys – actually started play in 1960, and the Vikings began play in 1961.) Finally, the NFL quickly came to terms with the Bidwills and allowed them to relocate the struggling Cardinals to St. Louis, eliminating that city as a potential AFL market.
Ralph Wilson, who owned a minority interest in the NFL's Detroit Lions at the time, initially announced he was placing a team in Miami, Florida, but like the Seattle situation, was also rebuffed by local ownership; given five other choices, Wilson negotiated with McGroder and brought the team that would become the Bills to Buffalo. Buffalo was officially awarded its franchise on October 28. During a league meeting on November 22, a 10-man ownership group from Boston, Massachusetts (led by Billy Sullivan) was awarded the AFL's eighth team. On November 30, 1959, Joe Foss, a World War II Marine fighter ace and former governor of South Dakota, was named the AFL's first commissioner. Foss commissioned a friend of Harry Wismer's to develop the AFL's eagle-on-football logo. Hunt was elected President of the AFL on January 26, 1960.
The AFL Draft.
The AFL's first draft took place the same day Boston was awarded its franchise, and lasted 33 rounds. The league held a second draft on December 2, which lasted for 20 rounds. Because the Raiders joined after the AFL draft, they inherited Minnesota's selections. A special "allocation draft" was held in January 1960, to allow the Raiders to stock their team, as some of the other AFL teams had already signed some of Minneapolis' original draft choices.
Crisis and success (1960–61).
In November 1959, Minneapolis owner Max Winter announced his intent to leave the AFL to accept a franchise offer from the NFL. In 1961, his team began play in the NFL as the Minnesota Vikings. Los Angeles Chargers owner Barron Hilton demanded that a replacement for Minnesota be placed in California, to reduce his team's operating costs and to create a rivalry. After a brief search, Oakland was chosen and an ownership group led by F. Wayne Valley and local real estate developer Chet Soda was formed. After initially being called the Oakland "Señores", the Oakland Raiders officially joined the AFL on January 30, 1960.
The AFL's first major success came when the Houston Oilers signed Billy Cannon, the All-American and 1959 Heisman Trophy winner from LSU. Cannon signed a $100,000 contract to play for the Oilers, despite having already signed a $50,000 contract with the NFL's Los Angeles Rams. The Oilers filed suit and claimed that Rams general manager Pete Rozelle had unduly manipulated Cannon. The court upheld the Houston contract, and with Cannon the Oilers appeared in the AFL's first three championship games (winning two).
On June 9, 1960, the league signed a five-year television contract with ABC, which brought in revenues of approximately $2,125,000 per year for the entire league. On June 17, the AFL filed an antitrust lawsuit against the NFL, which was dismissed in 1962 after a two-month trial. The AFL began regular-season play (a night game on Friday, September 9, 1960) with eight teams in the league — the Boston Patriots, Buffalo Bills, Dallas Texans, Denver Broncos, Houston Oilers, Los Angeles Chargers, New York Titans, and Oakland Raiders. Raiders' co-owner Wayne Valley dubbed the AFL ownership "The Foolish Club," a term Lamar Hunt subsequently used on team photographs he sent as Christmas gifts.
The Oilers became the first-ever league champions by defeating the Chargers, 24–16, in the AFL Championship on January 1, 1961. Attendance for the 1960 season was respectable for a new league, but not nearly that of the NFL. Whereas the more popular NFL teams in 1960 regularly saw attendance figures in excess of 50,000 per game, AFL attendance generally hovered between 10,000-20,000 per game. With the low attendance came financial losses. The Raiders, for instance, lost $500,000 in their first year and only survived after receiving a $400,000 loan from Bills owner Ralph Wilson. In an early sign of stability, however, the AFL did not lose any teams after its first year of operation. In fact, the only major change was the relocation of the Chargers from Los Angeles to nearby San Diego.
On August 8, 1961, the AFL challenged the Canadian Football League to an exhibition game that would feature the Hamilton Tiger-Cats and the Buffalo Bills. Playing at Civic Stadium in Hamilton, Ontario, the Ticats defeated the Bills 38–21 playing a mix of AFL and CFL rules.
Movement and instability (1962–63).
While the Oilers found instant success in the AFL, other teams did not fare as well. The Oakland Raiders and New York Titans struggled on and off the field during their first few seasons in the league. Oakland's eight-man ownership group was reduced to just three in 1961, after heavy financial losses their first season. Attendance for home games was poor, partly due to the team playing in the San Francisco Bay Area—which already had an established NFL team (the San Francisco 49ers)—but the product on the field was also to blame. After winning six games their debut season, the Raiders won a total of three times in the 1961 and 1962 seasons. Oakland took part in a 1961 supplemental draft meant to boost the weaker teams in the league, but it did little good. They participated in another such draft in 1962.
The Titans fared a little better on the field but had their own financial troubles. Attendance was so low for home games that team owner Harry Wismer had fans move to seats closer to the field to give the illusion of a fuller stadium on television. Eventually Wismer could no longer afford to meet his payroll, and on November 8, 1962 the AFL took over operations of the team. The Titans were sold to a five-person ownership group headed by Sonny Werblin on March 28, 1963, and in April the new owners changed the team's name to the New York Jets.
The Raiders and Titans both finished last in their respective divisions in the 1962 season. The Texans and Oilers, winners of their divisions, faced each other for the 1962 AFL Championship on December 23. The Texans dethroned the two-time champion Oilers, 20–17, in a double-overtime contest that was, at the time, professional football's longest-ever game.
In 1963, the Texans became the second AFL team to relocate. Lamar Hunt felt that despite winning the league championship in 1962, the Texans could not succeed financially competing in the same market as the Dallas Cowboys, which entered the NFL as an expansion franchise in 1960. After meetings with New Orleans, Atlanta, and Miami, Hunt announced on May 22 that the Texans' new home would be Kansas City, Missouri. Kansas City mayor Harold Roe Bartle (nicknamed "Chief") was instrumental in his city's success in attracting the team. Partly to honor Bartle, the franchise officially became the Kansas City Chiefs on May 26.
The San Diego Chargers, under head coach Sid Gillman, won a decisive 51–10 victory over the Boston Patriots for the 1963 AFL Championship. Confident that his team was capable of beating the NFL-champion Chicago Bears (he had the Chargers' rings inscribed with the phrase "World Champions"), Gillman approached NFL Commissioner Pete Rozelle and proposed a final championship game between the two teams. Rozelle declined the offer; however, the game would be instituted three seasons later.
Watershed years (1964–65).
A series of events throughout the next few years demonstrated the AFL's ability to achieve a greater level of equality with the NFL. On January 29, 1964, the AFL signed a lucrative $36 million television contract with NBC (beginning in the 1965 season), which gave the league money it needed to compete with the NFL for players. An NFL owner was quoted as saying to NFL Commissioner Pete Rozelle that "They don't have to call us 'Mister' anymore". A single-game attendance record was set on November 8, 1964, when 61,929 fans packed Shea Stadium to watch the New York Jets and Buffalo Bills.
The bidding war for players between the AFL and NFL escalated in 1965. The Chiefs drafted University of Kansas star Gale Sayers in the first round of the 1965 AFL draft (held November 28, 1964), while the Chicago Bears did the same in the NFL draft. Sayers eventually signed with the Bears. A similar situation occurred when the New York Jets and the NFL's St. Louis Cardinals both drafted University of Alabama quarterback Joe Namath. In what was viewed as a key victory for the AFL, Namath signed a $427,000 contract with the Jets on January 2, 1965 (the deal included a new car). It was the highest amount of money ever paid to a collegiate football player, and is cited as the strongest contributing factor to the eventual merger between the two leagues.
In early 1965, the AFL considered adding its first expansion team, to begin play in Atlanta in 1966. An AFL franchise was awarded to Rankin Smith of that city. The NFL quickly offered Smith a franchise, which Smith accepted. In March 1965, Joe Robbie had met with Commissioner Foss to inquire about an expansion franchise for Miami, Florida. On May 6, after Atlanta's exit, Robbie secured an agreement with Miami mayor Robert King Higho to bring a team to Miami. League expansion was approved at a meeting held on June 7, and on August 16 the AFL's ninth franchise was officially awarded to Robbie and television star Danny Thomas. The Miami Dolphins joined the league for a fee of $7.5 million and started play in the AFL's Eastern Division in 1966.
Escalation and merger (1966–67).
In 1966, the rivalry between the AFL and NFL reached an all-time peak. On April 7, Joe Foss resigned as AFL commissioner. His successor was Oakland Raiders head coach and general manager Al Davis, who had been instrumental in turning around the fortunes of that franchise. No longer content with trying to outbid the NFL for college talent, the AFL under Davis started to recruit players already on NFL squads. Davis's strategy focused on quarterbacks in particular, and in two months he persuaded seven NFL quarterbacks to sign with the AFL. Although Davis's intention was to help the AFL win the bidding war, some AFL and NFL owners saw the escalation as detrimental to both leagues. Alarmed with the rate of spending in the league, Hilton Hotels forced Barron Hilton to relinquish his stake in the Chargers as a condition of maintaining his leadership role with the hotel chain.
The same month Davis was named commissioner, several NFL owners, along with Dallas Cowboys general manager Tex Schramm, secretly approached Lamar Hunt and other AFL owners and asked the AFL to merge. They held a series of secret meetings in Dallas to discuss their concerns over rapidly increasing player salaries, as well as the practice of player poaching. Hunt and Schramm completed the basic groundwork for a merger of the two leagues by the end of May, and on June 8, 1966, the merger was officially announced. Under the terms of the agreement, the two leagues would hold a common player draft. The agreement also called for a title game to be played between the champions of the respective leagues. The two leagues would be fully merged by 1970, NFL commissioner Pete Rozelle would remain as commissioner of the merged league, and additional expansion teams would eventually be awarded by 1970 or soon thereafter to bring it to a 28-team league. The AFL also agreed to pay indemnities of $18 million to the NFL over 20 years. In protest, Davis resigned as AFL commissioner on July 25 rather than remain until the completion of the merger, and Milt Woodard was named President of the AFL.
On January 15, 1967, the first-ever World Championship Game between the champions of the two separate professional football leagues, the AFL-NFL Championship Game (retroactively referred to as Super Bowl I), was played in Los Angeles. After a close first half, the NFL champion Green Bay Packers overwhelmed the AFL champion Kansas City Chiefs, 35–10. The loss reinforced for many the notion that the AFL was an inferior league. Packers head coach Vince Lombardi stated after the game, "I do not think they are as good as the top teams in the National Football League."
The second AFL-NFL Championship (Super Bowl II) yielded a similar result. The Oakland Raiders—who had easily beaten the Houston Oilers to win their first AFL championship—were overmatched by the Packers, 33–14. The more experienced Packers capitalized on a number of Raiders miscues and never trailed. Green Bay defensive tackle Henry Jordan offered a compliment to Oakland and the AFL, when he said, "... the AFL is becoming much more sophisticated on offense. I think the league has always had good personnel, but the blocks were subtler and better conceived in this game."
The AFL added its tenth and final team on May 24, 1967, when it awarded the league's second expansion franchise to an ownership group from Cincinnati, Ohio, headed by NFL legend Paul Brown. Although Brown had intended to join the NFL, he agreed to join the AFL when he learned that his team would be included in the NFL once the merger was completed. The Cincinnati Bengals began play in the 1968 season, finishing last in the Western Division.
Legitimacy and the end of an era (1968–70).
While many AFL players and observers believed their league was the equal of the NFL, their first two Super Bowl performances did nothing to prove it. However, on November 17, 1968, when NBC cut away from a game between the Jets and Raiders to air the children's movie "Heidi," the ensuing uproar helped disprove the notion that fans still considered the AFL an inferior product. The perception of AFL inferiority forever changed on January 12, 1969, when the AFL Champion New York Jets shocked the heavily favored NFL Champion Baltimore Colts in Super Bowl III. The Colts, who entered the contest favored by as many as 18 points, had completed the 1968 NFL season with a 13–1 record, and won the NFL title with a convincing 34–0 win over the Cleveland Browns. Led by their stalwart defense—which allowed a record-low 144 points—the 1968 Colts were considered one of the best-ever NFL teams.
By contrast, the Jets had allowed 280 points, the highest total for any division winner in the two leagues. They had also only narrowly beaten the favored Oakland Raiders 27–23 in the AFL championship game. Jets quarterback Joe Namath recalled that in the days leading up to the game, he grew increasingly angry when told New York had no chance to beat Baltimore. Three days before the game, a frustrated Namath responded to a heckler at the Touchdown Club in Miami by declaring, "We're going to win Sunday, I'll guarantee you."
Namath and the Jets made good on his guarantee as they held the Colts scoreless until late in the fourth quarter. The Jets won, 16–7, in what is considered one of the greatest upsets in American sports history. With the win, the AFL finally achieved parity with the NFL and legitimized the merger of the two leagues. That notion was reinforced one year later in Super Bowl IV, when the AFL champion Kansas City Chiefs upset the NFL champion Minnesota Vikings, 23–7, in the last championship game to be played between the two leagues. The Vikings, favored by 12½ points, were held to just 67 rushing yards.
The last game in AFL history was the AFL All-Star Game, held in Houston's Astrodome on January 17, 1970. The Western All-Stars, led by Chargers quarterback John Hadl, defeated the Eastern All-Stars, 26–3. Hadl was named the game's Most Valuable Player. Prior to the start of the 1970 NFL season, the merged league was organized into two conferences of three divisions each. All ten AFL teams made up the bulk of the new American Football Conference. To avoid having an inequitable number of teams in each conference, the leagues voted to move three NFL teams to the AFC. Motivated by the prospect of an intrastate rivalry with the Bengals as well as by personal animosity toward Paul Brown, Cleveland Browns owner Art Modell quickly offered to include his team in the AFC. He helped persuade the Pittsburgh Steelers (the Browns' archrivals) and Baltimore Colts (who shared the Baltimore/Washington, D.C. market with the Washington Redskins) to follow suit, and each team received US $3 million to make the switch. All the other NFL squads became part of the National Football Conference.
Pro Football Hall of Fame receiver Charlie Joiner, who started his career with the Houston Oilers (1969), was the last AFL player active in professional football, retiring after the 1986 season, when he played for the San Diego Chargers.
Legacy.
Overview.
The American Football League stands as the only professional football league to successfully compete against the NFL. When the two leagues merged in 1970, all ten AFL franchises and their statistics became part of the new NFL. Every other professional league that had competed against the NFL before the AFL-NFL merger had folded completely: the three previous leagues named "American Football League" and the All-America Football Conference. From an earlier AFL (1936–1937), only the Cleveland Rams (now the St. Louis Rams) joined the NFL and are currently operating, as are the Cleveland Browns and the San Francisco 49ers from the AAFC. A third AAFC team, the Baltimore Colts (not related to the 1953–1983 Baltimore Colts or to the current Indianapolis Colts franchise), played only one year in the NFL, disbanding at the end of the 1950 season. The league resulting from the merger was a 26-team juggernaut (since expanded to 32) with television rights covering all of the Big Three television networks and teams in close proximity to almost all of the top 40 metropolitan areas, a fact that has precluded any other competing league from gaining traction since the merger; failed attempts to mimic the AFL's success included the World Football League (1974–75), United States Football League (1983–85), XFL (2001) and United Football League (2009–2012).
The AFL was also the most successful of numerous upstart leagues of the 1960s and 1970s that attempted to challenge a major professional league's dominance. All nine teams that were in the AFL at the time the merger was agreed upon were accepted into the league intact (as was the tenth team added between the time of the merger's agreement and finalization). For comparison, the World Hockey Association (1972–79) managed to have four of its six remaining teams merged into the National Hockey League, which actually caused the older league to contract a franchise, but WHA teams were forced to disperse the majority of their rosters and restart as expansion teams. The merged WHA teams were also not financially sound, as three of the four were forced to relocate within 20 years. The American Basketball Association (1967–76) managed to have only four of its teams merged into the National Basketball Association, and the rest of the league was forced to fold. The Continental League, a proposed third league for Major League Baseball that was to begin play in 1961, never played a single game.
Rule changes.
The NFL adopted some of the innovations introduced by the AFL immediately and a few others in the years following the merger. One was including the names on player jerseys. The older league also adopted the practice of using the stadium scoreboard clocks to keep track of the official game time, instead of just having a stopwatch used by the referee. The AFL played a 14-game schedule for its entire existence, starting in 1960. The NFL, which had played a 12-game schedule since 1947, changed to a 14-game schedule in 1961, a year after the American Football League instituted it. The AFL also introduced the two-point conversion to professional football thirty-four years before the NFL instituted it in 1994 (college football had adopted the two-point conversion in the late 1950s). All of these innovations pioneered by the AFL, including its more exciting style of play and colorful uniforms, have essentially made today's professional football more like the "AFL" than like the old-line NFL. The AFL's challenge to the NFL also laid the groundwork for the Super Bowl, which has become the standard for championship contests in the United States of America.
Television.
The NFL also adapted how the AFL used the growing power of televised football games, which were bolstered with the help of major network contracts (first with ABC and later with NBC). With that first contract with ABC, the AFL adopted the first-ever cooperative television plan for professional football, in which the proceeds were divided equally among member clubs. It featured many outstanding games, such as the classic 1962 double-overtime American Football League championship game between the Dallas Texans and the defending champion Houston Oilers. At the time it was the longest professional football championship game ever played. The AFL also appealed to fans by offering a flashier style of play (just like the ABA in basketball), compared to the more conservative game of the NFL. Long passes ("bombs") were commonplace in AFL offenses, led by such talented quarterbacks as John Hadl, Daryle Lamonica and Len Dawson.
Despite having a national television contract, the AFL often found itself trying to gain a foothold, only to come up against roadblocks. For example, CBS-TV, which broadcast NFL games, ignored and did not report scores from the innovative AFL, on orders from the NFL. It was only after the merger agreement was announced that CBS began to give AFL scores.
Expanding and reintroducing the sport to more cities.
The AFL took advantage of the burgeoning popularity of football by locating teams in major cities that lacked NFL franchises. Hunt's vision not only brought a new professional football league to California and New York, but introduced the sport to Colorado, restored it to Texas and later to fast-growing Florida, as well as bringing it to New England for the first time in 12 years. Buffalo, having lost its original NFL franchise in 1929 and turned down by the NFL at least twice (1940 and 1950) for a replacement, returned to the NFL with the merger. The return of football to Kansas City was the first time that city had seen professional football since the NFL's Kansas City Blues/Cowboys of the 1920s; the arrival of the Chiefs, and the contemporary arrival of the St. Louis Football Cardinals, brought professional football back to Missouri for the first time since the temporary St. Louis Gunners of 1934.
If not for the AFL, at least 17 of today's NFL teams would probably never have existed: the ten teams from the AFL, and seven clubs that were instigated by the AFL's presence to some degree. Three NFL franchises were awarded as a direct result of the AFL's competition with the older league: the Minnesota Vikings, who were awarded to Max Winter in exchange for dropping his bid to join the AFL; the Atlanta Falcons, whose franchise went to Rankin Smith to dissuade him from purchasing the AFL's Miami Dolphins; and the New Orleans Saints, because of successful anti-trust legislation which let the two leagues merge, and was supported by several Louisiana politicians.
In the case of the Dallas Cowboys, the NFL had long sought to return to the Dallas area after the Dallas Texans folded in 1952, but was originally met with strong opposition by Washington Redskins owner George Preston Marshall, who had enjoyed a monopoly as the only NFL team to represent the American South. Marshall later changed his position after future-Cowboys owner Clint Murchison bought the rights to Washington's fight song "Hail to the Redskins" and threatened to prevent Marshall from playing it at games. By then, the NFL wanted to quickly award the new Dallas franchise to Murchison so the team could immediately begin play and complete with the AFL's Texans. As a result, the Cowboys played its inaugural season in 1960 without the benefit of the NFL draft.
As part of the merger agreement, additional expansion teams would be awarded by 1970 or soon thereafter to bring the league to 28 franchises; this requirement was fulfilled when the Seattle Seahawks and the Tampa Bay Buccaneers began play in 1976. In addition, had it not been for the existence of the Oilers from 1960 to 1996, the Houston Texans also would likely not exist today; the 2002 expansion team restored professional football in Houston after the original charter AFL member Oilers relocated to become the Tennessee Titans.
Kevin Sherrington of "The Dallas Morning News" has argued that the presence of AFL and the subsequent merger radically altered the fortunes of the Pittsburgh Steelers, saving the team "from stinking". Before the merger, the Steelers had long been one of the NFL's worst teams. Constantly lacking the money to build a quality team, the Steelers had only posted eight winning seasons, and just one playoff appearance, since their first year of existence in 1933. They also finished with a 1-13 record in 1969, tied with the Chicago Bears for the worst record in the NFL. The $3 million indemnity that the Steelers received for joining the AFC with the rest of the former AFL teams after the merger helped them rebuild into a contender, drafting eventual-Pro Football Hall of Famers like Terry Bradshaw and Joe Greene, and ultimately winning four Super Bowls in the 1970s. Since the 1970 merger, the Steelers have the NFL's highest winning percentage, the most total victories, the most trips to either conference championship game, are tied with the Dallas Cowboys for the most trips to the Super Bowl, and have won an NFL-record six Super Bowl championships.
Effects on players.
Perhaps the greatest social legacy of the AFL was the domino effect of its policy of being more liberal than the entrenched NFL in offering opportunity for black players. While the NFL was still emerging from thirty years of segregation influenced by Washington Redskins' owner George Preston Marshall, the AFL actively recruited from small and predominantly black colleges. The AFL's color-blindness led not only to the explosion of black talent on the field, but to the eventual entry of blacks into scouting, coordinating, and ultimately head coaching positions, long after the league ceased to exist.
The AFL's free agents came from several sources. Some were players who could not find success playing in the NFL, while another source was the Canadian Football League. In the late 1950s, many players released by the NFL, or un-drafted and unsigned out of college by the NFL, went North to try their luck with the CFL, and later returned to the states to play in the AFL.
In the league's first years, players such as Oilers' George Blanda, Chargers/Bills' Jack Kemp, Texans' Len Dawson, the NY Titans' Don Maynard, Raiders/Patriots/Jets' Babe Parilli, Pats' Bob Dee proved to be AFL standouts. Other players such as the Broncos' Frank Tripucka, the Pats' Gino Cappelletti, the Bills' Cookie Gilchrist and the Chargers' Tobin Rote, Sam DeLuca and Dave Kocourek also made their mark to give the fledgling league badly needed credibility. Rounding out this mix of potential talent were the true "free agents", the walk-ons and the "wanna-be's", who tried out in droves for the chance to play professional American football.
After the AFL-NFL merger agreement in 1966, and after the AFL's Jets defeated the "best team in the history of the NFL", the Colts, a popular misconception fostered by the NFL and spread by media reports was that the AFL defeated the NFL because of the Common Draft instituted in 1967. This apparently was meant to assert that the AFL could not achieve parity as long as it had to compete with the NFL in the draft. But the 1968 Jets had less than a handful of "common draftees". Their stars were honed in the AFL, many of them since the Titans days. As noted below, the AFL got its share of stars long before the "common draft".
Players who chose the AFL to develop their talent included Lance Alworth and Ron Mix of the Chargers, who had also been drafted by the NFL's San Francisco 49ers and Baltimore Colts respectively. Both eventually were elected to the Pro Football Hall of Fame after earning recognition during their careers as being among the best at their positions. Among specific teams, the 1964 Buffalo Bills stood out by holding their opponents to a pro football record 913 yards rushing on 300 attempts, while also recording fifty quarterback sacks in a 14-game schedule.
Another example is cited by the University of Kansas website, which describes the 1961 Bluebonnet Bowl, won by KU, and goes on to say "Two Kansas players, quarterback John Hadl and fullback Curtis McClinton, signed professional contracts on the field immediately after the conclusion of the game. Hadl inked a deal with the "[AFL]" San Diego Chargers, and McClinton went to the "[AFL]" Dallas Texans." Between them, in their careers Hadl and McClinton combined for an American Football League Rookie of the Year award, seven AFL All-Star selections, two Pro Bowl selections, a team MVP award, two AFL All-Star Game MVP awards, two AFL championships, and a World Championship. And these were players selected by the AFL long "before" the "Common Draft".
In 2009, a five-part series, "", on the "Showtime Network", refuted many of the long-held misconceptions about the AFL. In it, Abner Haynes tells of how his father forbade him to accept being drafted by the NFL, after drunken scouts from that league had visited the Haynes home; the NFL Cowboys' Tex Schramm is quoted as saying that if his team had ever agreed to play the AFL's Dallas Texans, they would very likely have lost; George Blanda makes a case for more AFL players being inducted to the Pro Football Hall of Fame by pointing out that Hall of Famer Willie Brown was cut by the Houston Oilers because he couldn't cover Oilers flanker Charlie Hennigan in practice. Later, when Brown was with the Broncos, Hennigan needed nine catches in one game against the Broncos to break Lionel Taylor's Professional Football record of 100 catches in one season. Hennigan caught the nine passes and broke the record, even though he was covered by Brown: Blanda's point being that if Hennigan could do so well against a Hall of Fame db, he deserves induction, as well.
Influence on professional football coaching.
The AFL also spawned coaches whose style and techniques have profoundly affected the play of professional football to this day. In addition to AFL greats like Hank Stram, Lou Saban, Sid Gillman and Al Davis were eventual hall of fame coaches such as Bill Walsh, a protégé of Davis with the AFL Oakland Raiders for one season; and Chuck Noll, who worked for Gillman and the AFL LA/San Diego Chargers from 1960 through 1965. Others include Buddy Ryan (AFL's New York Jets), Chuck Knox (Jets), Walt Michaels (Jets), and John Madden (AFL's Oakland Raiders). Additionally, many prominent coaches began their pro football careers as players in the AFL, including Sam Wyche (Cincinnati Bengals), Marty Schottenheimer (Buffalo Bills), Wayne Fontes (Jets), and two-time Super Bowl winner Tom Flores (Oakland Raiders). Flores also has a Super Bowl ring as a player (1969 Kansas City Chiefs).
AFL 50th Anniversary Celebration.
As the influence of the AFL continues through the present, the 50th anniversary of its launch was celebrated during 2009. The season-long celebration began in August with the 2009 Pro Football Hall of Fame Game in Canton, Ohio between two AFC teams (as opposed to the AFC-vs-NFC format the game first adopted in 1971). The opponents were two of the original AFL franchises, the Buffalo Bills and Tennessee Titans (the former Houston Oilers). Bills' owner Ralph C. Wilson Jr. (a 2009 Hall of Fame inductee) and Titans' owner Bud Adams were the only surviving members of the Foolish Club, the eight original owners of AFL franchises.
The Hall of Fame Game was the first of several "Legacy Weekends," during which each of the "original eight" AFL teams sported uniforms from their AFL era. Each of the 8 teams took part in at least two such "legacy" games. On-field officials also wore red-and-white-striped AFL uniforms during these games.
In the fall of 2009, the Showtime pay-cable network premiered "", a 5-part documentary series produced by NFL Films that features vintage game film and interviews as well as more recent interviews with those associated with the AFL.
The NFL sanctioned a variety of "Legacy" gear to celebrate the AFL anniversary, such as "throwback" jerseys, T-shirts, signs, pennants and banners, including items with the logos and colors of the Dallas Texans, Houston Oilers, and New York Titans, the three of the Original Eight AFL teams which have changed names or venues. A December 5, 2009 story by Ken Belson in the "New York Times" quotes league officials as stating that AFL "Legacy" gear made up twenty to thirty percent of the league's annual $3 billion merchandise income. Fan favorites were the Denver Broncos' vertically striped socks, which could not be re-stocked quickly enough.
AFL franchises.
Today, two of the NFL's eight divisions are composed entirely of former AFL teams, the AFC West (Broncos, Chargers, Chiefs, and Raiders) and the AFC East (Bills, Dolphins, Jets, and Patriots). Additionally, the Bengals now play in the AFC North and the Tennessee Titans (formerly the Oilers) play in the AFC South.
AFL playoffs.
From 1960 to 1968, the AFL determined its champion via a single-elimination playoff game between the winners of its two divisions. The home teams alternated each year by division, so in 1968 the Jets hosted the Raiders, even though Oakland had a better record (this was changed in 1969). In 1963, the Buffalo Bills and Boston Patriots finished tied with identical records of 7–6–1 in the AFL East Division. There was no tie-breaker protocol in place, so a one-game playoff was held in War Memorial Stadium in December. The visiting Patriots defeated the host Bills 26–8. The Patriots traveled to San Diego as the Chargers completed a three-game season sweep over the weary Patriots with a 51–10 victory. A similar situation occurred in the 1968 season, when the Oakland Raiders and the Kansas City Chiefs finished the regular season tied with identical records of 12–2 in the AFL West Division. The Raiders beat the Chiefs 41–6 in a division playoff to qualify for the AFL Championship Game. In 1969, the final year of the independent AFL, Professional Football's first "wild card" playoffs were conducted. A four-team playoff was held, with the second-place teams in each division playing the winner of the other division. The Chiefs upset the Raiders in Oakland 17–7 in the league's Championship, the final AFL game played. The Kansas City Chiefs were the first Super Bowl champion to win two road playoff games and the first wildcard team to win the Super Bowl, although the term "wildcard" was coined by the media, and not used officially until several years later.
AFL Championship Games.
"Italics" – Super Bowl Appearance, Bold - Super Bowl Victory
AFL All-Star games.
The AFL did not play an All-Star game after its first season in 1960, but did stage All-Star games for the 1961 through 1969 seasons. All-Star teams from the Eastern and Western divisions played each other after every season except 1965. That season, the league champion Buffalo Bills played all-stars from the other teams.
After the 1964 season, the AFL All-Star game had been scheduled for early 1965 in New Orleans' Tulane Stadium. After numerous black players were refused service by a number of area hotels and businesses, black and white players alike called for a boycott. Led by Bills players such as Cookie Gilchrist, the players successfully lobbied to have the game moved to Houston's Jeppesen Stadium.
All-Time AFL Team.
As chosen by 1969 AFL Hall of Fame Selection Committee Members:
AFL records.
The following is a sample of some records set during the existence of the league. The NFL considers AFL statistics and records equivalent to its own.

</doc>
<doc id="2358" url="http://en.wikipedia.org/wiki?curid=2358" title="A.S. Roma">
A.S. Roma

Associazione Sportiva Roma (BIT: , LSE: ), commonly referred to as simply Roma ], is a professional Italian football club based in Rome. Founded by a merger in 1927, Roma have participated in the top-tier of Italian football for all of their existence except for 1951–52. For their 63rd season in a row (82nd overall), Roma are competing in Serie A for the 2014–15 season.
Roma have won Serie A three times, first in 1941–42 then in 1982–83 and again in 2000–01, as well as winning nine Coppa Italia titles and two Supercoppa Italiana titles. On the European stage Roma won an Inter-Cities Fairs Cup in 1960–61, coming close to European Cup victory in 1983–84 (lost the one-legged final played at home against Liverpool), and finishing as runners-up in the UEFA Cup for 1990–91 (two-legged aggregate defeat against Inter).
Home games are currently played at the Stadio Olimpico, a venue they share with city rivals Lazio. With a capacity of over 72,000, it is the second largest of its kind in Italy, with only the San Siro able to seat more. In September 2009 the club unveiled plans to build a Stadio della Roma (new 55,000-capacity) in the western suburbs of Rome. Its design was modelled after English football stadiums with the objective being to give fans a closer view of the pitch, and is said to be inspired by the Colosseum. In September 2011, it was announced that the new president, Thomas R. DiBenedetto, had reached an agreement with the mayor of Rome, Gianni Alemanno, to have the new stadium completed by 2016.
History.
A.S. Roma was founded in the summer of 1927 when Italo Foschi, initiated the merger of three older Italian Football Championship clubs from the city of Rome; Roman FC, SS Alba-Audace and Fortitudo-Pro Roma SGS. The purpose of the merger was to give the Italian capital a strong club to rival that of the more dominant Northern Italian clubs of the time. The only major Roman club to resist the merger was S.S. Lazio because of the intervention of the army General Vaccaro, member of the club and executive of Italian Football Federation.
The club played its earliest seasons at the "Motovelodromo Appio" stadium, before settling in the working-class streets of Testaccio, where it built an all-wooden ground "Campo Testaccio"; this was opened in November 1929. An early season in which Roma made a large mark was the 1930–31 championship, the club finished as runners-up behind Juventus. Captain Attilio Ferraris along with Guido Masetti, Fulvio Bernardini and Rodolfo Volk were highly important players during this period.
First title victory and decline.
After a slump in league form and the departure of high key players, Roma eventually rebuilt their squad adding goalscorers such as the Argentine Enrique Guaita. Under the management of Luigi Barbesino, the Roman club came close to their first title in 1935–36; finishing just one point behind champions Bologna.
Roma returned to form after being inconsistent for much of the late 1930s; Roma recorded an unexpected title triumph in the 1941–42 season by winning their first ever" scudetto" title. The eighteen goals scored by local player Amedeo Amadei were essential to the Alfréd Schaffer coached Roma side winning the title. At the time Italy was involved in World War II and Roma were playing at the "Stadio del Partito Nazionale Fascista".
In the years just after the war, Roma were unable to recapture their league stature from the early 1940s. Roma finished in the lower half of Serie A for five seasons in a row, before eventually succumbing to their only ever relegation to Serie B at the end of the 1950–51 season; around a decade after their championship victory. Under future national team manager Giuseppe Viani, promotion straight back up was achieved.
After returning to the Serie A, Roma managed to stabilise themselves as a top half club again with players such as Egisto Pandolfini, Dino Da Costa and Dane Helge Bronée. Their best finish of this period was under the management of Englishman Jesse Carver, when in 1954–55 they finished as runners-up, after Udinese who originally finished second were relegated for corruption.
Although Roma were unable to break into the top four during the following decade, they did achieve some measure of cup success. Their first honour outside of Italy was recorded in 1960–61 when Roma won the Inter-Cities Fairs Cup by beating Birmingham City 4–2 in the finals. A few years later Roma won their first Coppa Italia trophy in 1963–64, by beating Torino 1–0.
Their lowest point came during the 1964–65 season when manager Juan Carlos Lorenzo announced that the club could not pay its players and was unlikely to be able to afford to travel to Vicenza to fulfil its next fixture. Supporters kept the club going with a fundraiser at the Sistine Theatre and bankruptcy was avoided with the election of a new club president Franco Evangelisti.
Their second Coppa Italia trophy was won in 1968–69 when it was competed in a small league like system. Giacomo Losi set a Roma appearance record during 1969 with 450 appearances in all competitions, the record he set would last for 38 years.
Time of mixed fortunes.
Roma were able to add another cup to their collection in 1972, with a 3–1 victory over Blackpool in the Anglo-Italian Cup. During much of the 1970s Roma's appearance in the top half of Serie A was sporadic. The best place the club were able to achieve during the decade was third in 1974–75. Notable players who turned out for the club during this period included midfielders Giancarlo De Sisti and Francesco Rocca.
The dawning of a newly successful era in Roma's footballing history was brought in with another Coppa Italia victory, they beat Torino on penalties to win the 1979–80 cup. Roma would reach heights in the league which they had not touched since the 1940s by narrowly and controversially finishing as runners-up to Juventus in 1980–81. Former Milan player Nils Liedholm was the manager at the time, with players such as Bruno Conti, Agostino Di Bartolomei, Roberto Pruzzo and Falcão.
The second "scudetto" did not elude Roma for much longer; in 1982–83 the Roman club won the title for the first time in 41 years, amidst celebrations in the capital. The following season Roma finished as runners-up in Italy and collected a Coppa Italia title, they also finished as runners-up in the European Cup final of 1984. The European Cup final with Liverpool ended in a 1–1 draw with a goal from Pruzzo, but Roma eventually lost the penalty shoot-out. Roma's successful run in the 1980s would finish with a runners-up spot in 1985–86 and a Coppa Italia victory, beating out Sampdoria 3–2.
After that a comparative decline began in the league, one of the few league highs from the following period being a third-place finish in 1987–88. At the start of the 1990s the club was involved in an all-Italian UEFA Cup final, where they lost 2–1 to Internazionale in 1991; the same season the club won its seventh Coppa Italia trophy and ended runners-up to Sampdoria in the Supercoppa Italiana. Aside from finishing runners-up to Torino in a Coppa Italia final, the rest of the decade was largely sub-par in the history of Roma; especially in the league where the highest they could manage was fourth in 1997–98. The early 1990s also saw the emergence of homegrown striker Francesco Totti who would go on to be an important member of the team and the club's iconic captain.
In the new millennium.
2000–2010.
Roma returned to form in the 2000s, starting the decade in great style by winning their third ever Serie A title in 2000–01; the "scudetto" was won on the last day of the season by beating Parma 3–1, edging out Juventus by two points. The club's captain, Francesco Totti was a large reason for the title victory and he would become one of the main heroes in the club's history, going on to break several club records. Other important players during this period included Aldair, Cafu, Gabriel Batistuta, and Vincenzo Montella.
The club attempted to defend the title in the following season but ended as runners-up to Juventus by just one point. This would be the start of Roma finishing as runners-up many times in both Serie A and Coppa Italia during the 2000s; they lost out 4–2 to AC Milan in the Coppa Italia final of 2003 and lost out to Milan again by finishing second in Serie A for the 2003–04 season. The club also re-capitalized several time in 2003–04 season. In November 2003 €37.5 million was injected by "Roma 2000" to cover the half-year loss and loss carried from previous year. and again on 30 June for €44.57 million. Through stock market, a further €19.850 million of new shares issued, and at the year end, the share capital was €19.878 million, which unchanged as of 2011[ [update]]. The following season also saw the departure of Walter Samuel for €25 million and Emerson for €28 million, which decreased the strength of the squad, thus "Giallorossi" finished as the eighth place, one of the worst of recent season.
A Serie A scandal was revealed during 2006 and Roma were one of the teams not involved; after punishments were handed out, Roma was re-classified as runners-up for 2005–06; the same season in which they finished second in the Coppa Italia losing to Internazionale. In the two following seasons, 2006–07 and 2007–08, Roma finished as Serie A runners-up, meaning that in the 2000s Roma have finished in the top two positions more than any other decade in their history Meanwhile in the UEFA Champions League during both of these seasons, they reached the quarter-finals before going out to Manchester United. Despite the sloppy start in UEFA Champions League 2008–09, Roma managed to reach the knockout stage ahead of Chelsea in their group, thus finishing for the first time in their history as winners of the group stage. However, the "Giallorossi" would lose to Arsenal in the knockout stage on penalty kicks, ending their Champions League campaign.
After a disappointing start to the 2009–10 season, Claudio Ranieri replaced Luciano Spalletti as head coach. At the time of the switch, Roma lay bottom of the Serie A table after losses to Juventus and Genoa. Despite this setback, Roma would later embark on an incredible unbeaten streak of 24 matches in the league – with the last of the 24 being a 2–1 win over rivals Lazio, whereby Roma came from 1–0 down at half-time to defeat their city rivals after Ranieri courageously substituted both Totti and De Rossi at the interval. The Giallorossi were on top of the table at one point, before a loss to U.C. Sampdoria later in the season. Roma would finish runners-up to Inter yet again in both Serie A and the Coppa Italia. This rounded out a highly successful decade in Roma's history, following somewhat mediocre results of the 1990s. During the 2000s, Roma had finally recaptured the Scudetto, two Coppa Italia trophies, and their first two Supercoppa Italiana titles. Other notable contributions to the club's history have included a return to the UEFA Champions League Quarter-finals (in the 2006–2007 and 2007–2008 editions) since 1984, six runners up positions in the league, four Coppa Italia finals and three Supercoppa finals – marking Roma's greatest ever decade.
The "AS Roma SPV LLC" era.
In the summer of 2010, the Sensi family agreed to relinquish their control of AS Roma as part of a debt-settlement agreement. This brought an end to the presidential reign of the Sensi family who had presided over the club since 1993. Until a new owner was appointed, Rosella Sensi would continue her directorial role of the club. The 2010–11 season had once again seen Roma start off with mixed fortunes on both a domestic and European level. These included losses against teams like Cagliari, Brescia and a 2–0 defeat against Bayern Munich in the group stages of the Champions League (a match which saw manager Claudio Ranieri openly criticised by his own players). However, these were accompanied by victories against Inter Milan and a sensational victory against Bayern Munich in the return fixture, which saw Roma fight back from 0–2 down at half-time to emerge as 3–2 winners. Following a series of poor results which saw Roma engage in a winless-streak of five consecutive matches, Claudio Ranieri resigned as head coach in February 2011, and former striker Vincenzo Montella was appointed as caretaker manager until the end of the season. It was also during this season that Roma icon, Francesco Totti, scored his 200th Serie A goal against Fiorentina in March 2011 – becoming only the sixth ever player to achieve such a feat.
On 16 April 2011, the takeover contract was closed with a USA investment group lead by Thomas R. DiBenedetto. "DiBenedetto AS Roma LLC" (later renamed to AS Roma SPV, LLC) consists of 4 other shareholders (or 3 not counting the family trust), namely James Pallotta (25%) (of "Tudor Investment"), Michael Ruane (25%) (director of "TA Realty"; partially own the "AS Roma SPV, LLC" through family trust for 22.5%) and Richard D'Amore (25%) (of "North Bridge Venture Partners" and Veeco). DiBenedetto became the 22nd president of the club, served from 27 September 2011 to 27 August 2012 and was succeeded by James Pallotta. In 2011, "AS Roma SPV, LLC" owned 60% shares on NEEP Roma holding, with the rest (40%) retained by the creditor of Sensi, UniCredit; NEEP in turn owned all shares held previously by Sensi (about 67%) with the rest free float in the stock market.
The new ownership immediately went into effect by making significant changes in the club, hiring Walter Sabatini as director of football and former Spanish international and FC Barcelona B coach Luis Enrique as manager; the first high-profile signings from the duo were attacking midfielder Erik Lamela from River Plate, forward Bojan Krkic from Barcelona, goalkeeper Maarten Stekelenburg from AFC Ajax and unattached defender Gabriel Heinze. The club also sold and released high earner, namely defender John Arne Riise, keeper Doni, forward Jérémy Ménez and Mirko Vucinic. At financial level, the company had recapitalized for more than €100 million, which the last recapitalization was in early 2000s.
However, Roma was eliminated from 2011–12 UEFA Europa League play-off round. After the formal takeover on 18 August, Roma bought forward Pablo Daniel Osvaldo, midfielder Miralem Pjanic, Fernando Gago and defender Simon Kjær, as well as youngster Fabio Borini, made the club costed more than €40 million if the loan deal were successfully turned to definitive deal. In 2012 Pallotta became the new president, which he personally broke the equal partnership by increased the shares holding on NEEP Roma Holding SpA on 1 August 2013 by buying 9% shares from UniCredit (Pallotta held 9% directly plus 15% indirectly on NEEP; in turn NEEP held more than 70% shares on AS Roma SpA, later diluted to 9% directly plus around 12% indirectly due to introduction of the 5th partner in AS Roma SPV, LLC on 4 April 2014; the change in ratio due to UniCredit sold 31% shares on NEEP to AS Roma SPV LCC not known.)
On 12 June 2013, Roma's president James Pallotta announced that Rudi Garcia had been appointed the new manager of Roma. He enjoyed a fantastic start to his Roma career, winning his first ten consecutive games (an all time Serie A record) including a 2–0 derby win against Lazio, a 3–0 victory away to Inter Milan and a 2–0 home win over title rivals Napoli. During this run, Roma scored 24 times while conceding just once, away to Parma.
Colours, badge and nicknames.
Roma's colours of imperial purple with a golden yellow trim represents the traditional colours of Rome, the official seal of the "Comune di Roma" features the same colours. The gold and the purple-red represent Roman imperial dignity. White shorts and black socks are usually worn with the red shirt, however in particularly high key games the shorts and socks are the same colour as the home shirt.
The kit itself was originally worn by "Roman Football Club"; one of the three clubs who merged to form the current incarnation in 1927. Because of the colours they wear, Roma are often nicknamed "i giallorossi" meaning the yellow-reds. Roma's away kit is traditionally white, with a third kit changing colour from time to time. Maybe because of modern sport marketing, the last few years have seen the golden trim and details substituted by light orange. Modern alternate kits have included all orange and orange-maroon versions.
A popular nickname for the club is "i lupi" (the wolves), the animal has always featured on the club's badge in different forms throughout their history. Currently the emblem of the team is the one which was used when the club was first founded. It portrays the female wolf with the two infant brothers Romulus and Remus, illustrating the myth of the founding of Rome, superimposed on a bipartite golden yellow over maroon red shield. In the myth from which the club take their nickname and logo, the twins (sons of Mars and Rhea Silvia) are thrown into the River Tiber by their uncle Amulius, a she-wolf saved the twins and looked after them. Eventually the two twins took revenge on Amulius, before falling out themselves; Romulus killed Remus and as thus was made king of a new city named in his honour, Rome.
Facilities.
Stadiums.
The very first sport facility A.S. Roma used was Motovelodromo Appio which was previously used by Alba-Audace. A.S. Roma only played the 1927–28 season there until they moved to Campo Testaccio the very next season. Campo Testaccio was used through 1929 to 1940. The team moved later to the Stadio Nazionale del PNF where they spent 13 years before moving once again.
In the 1953–54 season A.S. Roma moved to the Olympic arena, Stadio Olimpico. The arena has undergone several changes over the years. The most significant change took place in the nineties when Stadio Olimpico was demolished and then reconstructed to for the Football World Cup 1990, witch took place in Italy. A.S. Roma has played almost every season since 1953–54, with exception of the 1989–90 seasons due to the reconstruction of Stadio Olimpico. That year Roma played its home games at Stadio Flaminio.
30 December 2012 AS Roma president James Pallotta announced the construction of a new stadium in the Tor di Valle area of Rome. The new stadium Stadio della Roma is scheduled for opening in 2016. The new stadium will have a capacity of 60,000 spectators.
Trigoria.
A sports centre located in Trigoria at kilometer 3600 in south-east of Rome, was purchased 22 July 1977 by the then club president Gaetano Anzalone. It was opened in 23 July 1979 and was it the president Anzalones last act of his presidency. The complex had its first expansion in 1984 when the club was handled by Dino Viola and another in 1998 under the chairmanship of Franco Sensi. The sports centre official name is Fulvio Bernardini di Trigoria, named after the club icon Fulvio Bernardini.
The sports centre is also known for hosting the Argentinian football team during Football World Cup 1990.
Supporters and rivalries.
Roma is the fifth most supported football club in Italy behind Juventus, Internazionale, Milan and Napoli with around 7% of Italian football fans supporting the club (according to the Doxa Institute-L'Espresso's research of April 2006). Historically the largest section of Roma supporters in the city of Rome have come from the inner-city, especially Testaccio.
The traditional ultras group of the club was "Commando Ultrà Curva Sud" commonly abbreviated as "CUCS"; this group was founded by the merger of many smaller groups and was considered one of the most historic in the history of European football. However, by the mid-1990s "CUCS" had been usurped by rival factions and ultimately broke up. Since that time, the "Curva Sud" of the Stadio Olimpico has been controlled by more right-wing groups; "A.S. Roma Ultras", "Boys", "Giovinezza" and others. The oldest group "Fedayn" is apolitical however and politics is not the main identity of Roma, just a part of their overall identity. In September 2009 the club unveiled plans to build a new 55,000-capacity stadium in Rome's western suburbs.
The most known club anthem is "Roma (non-si discute, si ama)", also known as "Roma Roma", by singer Antonello Venditti. The title roughly means "Roma is not to be questioned, it is to be loved" and is sung before each match. The song "Grazie Roma", by the same singer, is played at the end of victorious home games. Recently, the main riff of The White Stripes song "Seven Nation Army" has also become widely popular at games.
Rivalries.
In Italian football Roma is a club with many rivalries; first and foremost is their rivalry with Lazio, the club with whom they share the Stadio Olimpico. The derby between the two is called the "Derby della Capitale", it is amongst the most heated and emotional footballing rivalries in the world. The fixture has seen some occasional instances of violence in the past including the death of Lazio fan, Vincenzo Paparelli in 1979–80 as a result of an emergency flare fired from the Curva Sud, and the abandonment of a game in March 2004, following unfounded rumours of a fatality which led to violence outside the stadium.
With Napoli, Roma also compete in the "Derby del Sole" rivalry meaning the "Derby of the Sun". Nowadays fans also consider other Serie A giants like Juventus (rivalry born especially in the 1980s), Milan and Internazionale (increased in recent years) among their rivals as these four compete for the top three spots in the league table to secure a spot in the Champions League.
There have been a number of instances of conflict in recent years between some Roma supporters and fans of English clubs, and the subsequent violence outside the stadium which saw a number of Liverpool fans stabbed. Since then, there have been further instances of some English supporters being attacked and stabbed in Rome, including incidents in 2001 when Liverpool visited Roma twice and subsequent clashes with Middlesbrough fans in 2006 and Manchester United fans in 2007. In March 2009, a coach carrying Arsenal supporters was attacked by a group of Roma "Ultras" just outside the Stadio Olimpico. The coach's windows were smashed and at least one person entered the vehicle, letting off a flare and stabbed a supporter in the knee.
Management staff.
Source: 
</dl>
Presidential history.
Roma have had numerous presidents over the course of their history, some of which have been the owners of the club, others have been honorary presidents. Franco Sensi was the chairman until his death in 2008, with his daughter Rosella Sensi in place as honorary president. Here is a complete list of Roma presidents from 1927 until the present day.
Managerial history.
Roma have had many managers and trainers running the team during their history, here is a chronological list of them from 1927 onwards.
Honours.
National titles.
Serie A
Coppa Italia
Supercoppa Italiana
Serie B
International titles.
European Cup
UEFA Cup
Inter-Cities Fairs Cup
Anglo-Italian Cup
Other titles.
MLS All-Star Game
Hall of Fame.
On 7 October 2012 the Hall of Fame of Roma was announced.
The Hall of Fame players was voted via the clubs official website and a special Hall of Fame panel. In 2013 four players was voted in as well as in 2014, the third year of AS Roma Hall of Fame four more players was voted in.
Club records and statistics.
Francesco Totti holds Roma's official appearance record, having made 610 (as of May 2011) appearances in all competitions, over the course of 19 seasons from 1992 until the present day. He also holds the record for Serie A appearances with 474, as he passed Giacomo Losi on 1 March 2008, during a home match against Parma.
Including all competitions, Francesco Totti is the all-time leading goalscorer for Roma, with 262 goals since joining the club, 207 of which were scored in Serie A (another Roma record). Roberto Pruzzo, who was the all-time topscorer since 1988 comes in second in all competitions with 136. In the 1930–31 season, Rodolfo Volk scored 29 goals in Serie A over the course of a single season, not only was he the league's topscorer that year, but he set a Roma record for most goals scored in a season, which still lasts today.
Its major founders Fortitudo and Alba having been relegated at the end of 1926–27 campaign, new-founded Roma had to take part to Southern First Division championship (Serie B) for its inaugural season; nevertheless FIGC decided a special enlargement of first level division re-admitting AS Roma as SSC Napoli. The first ever official game participated in by Roma was in the National Division, the predecessor of Serie A, of 1927–28, against Livorno; Roma won 2–0. The biggest ever victory recorded by Roma was 9–0 against Cremonese during the Serie A season of 1929–30. The highest defeat Roma have ever suffered is 7–1, this has happened three times; first against Juventus during 1931–32, then against Torino in 1947–48 and most recently against Manchester United in 2006–07.
A.S. Roma as a company.
Since 1999, during Franco Sensi's period in charge, Associazione Sportiva Roma has been a "joint stock company". From 2004 to 2011, Roma's shares are distributed between; 67.1% to Compagnia Italpetroli SpA (the Sensi family "holding") and 32.9% to other shareholders.
In April 2008, after months of speculation, George Soros was confirmed by Rosella Sensi, CEO of Italian Serie A association football club A.S. Roma, to be bidding for a takeover. The takeover bid was successively rejected by the Sensi family, who instead preferred to maintain the club's ownership. On 17 August 2008 club chairman and owner Franco Sensi died after a long illness; his place at the chairmanship of the club was successively taken by his daughter Rosella.
Since the takeover in 2011, NEEP Roma Holding S.p.A. owned all shares Sensi previously hold. NEEP, itself a joint venture, was held by DiBenedetto AS Roma LLC (later renamed to AS Roma SPV, LLC) and Unicredit in 60–40 ratio from 2011 to 2013, which the former had 4 real person shareholders in equal ratio, led by future Roma president Thomas R. DiBenedetto (2011–12). The takeover also activated a mandatory bid of shares from the general public, however not all minority shareholders willing to sell their shares. The mandatory bid had made NEEP held 78.038% of shares of AS Roma (increased from 67.1% of the Sensi). On 1 August 2013, the president of Roma as well as one of the four American shareholder of AS Roma SPV, LLC, James Pallotta, bought an additional 9% shares of NEEP Roma Holding from Unicredit (through Raptor Holdco LLC), as the bank not willing to fully participate in the capital increase of NEEP from €120,000 to €160,008,905. On 4 April 2014 Starwood Capital Group also became the fifth shareholder of AS Roma SPV, as well as forming strategic partnership with AS Roma SpA to develop real estate around the new stadium. The private investment firm was represented by Zsolt Kohalmi in AS Roma SPV, whom was appointed on 4 April as a partner and head of European acquisitions of the firm. On 11 August 2014, UniCredit sold the remain shares on NEEP (of 31%) for €33 million which made AS Roma SPV LLC (91%) and Raptor Holdco LLC (9%) were the sole intermediate holding company of AS Roma SpA.
Along with Lazio and Juventus, Roma is one of only three Italian clubs quotated in Borsa Italiana (Italian stock exchange). According to The Football Money League published by consultants Deloitte, in the season 2010–11, Roma was the 15th highest earning football club in the world with an estimated revenue of €143.5 million.
Since re-capitalization in 2003–04 season, Roma had a short-lived financial self-sustainability. The club had set-up a special amortisation fund using Articolo 18-bis Legge 91/1981 mainly for the abnormal signing prior 2002–03 season, (such as Davide Bombardini for €11 million account value in June 2002, which the flopped player exchange boosted 2001–02 season result) and the tax payment of 2002–03 season was rescheduled. In 2004–05 season Roma made a net profit of €10,091,689 and followed by €804,285 in 2005–06 season. In 2006–07 season the accounting method changed to IFRS, which 2005–06 result was reclassified as net loss of €4,051,905 and 2006–07 season was net income of €10,135,539 (€14.011 million as a group). Moreover, the special fund (€80,189,123) was removed from the asset and co-currently for the equity as scheduled, made Roma group had a negative equity of €8.795 million on 30 June 2007. In 2007–08 season Roma made a net income of €18,699,219. (€19 million as a group) However, in 2008–09 season saw the decrease of gate and TV income, co-currently with finished 6th in Serie A, which saw Roma made a net loss of €1,894,330. (€1.56 million as a group) The gate and TV income further slipped in 2009–10 season, made a net loss of €21,917,292 (already boosted by the sale of Alberto Aquilani; €22 million as a group) despite sporting success (the second in 2009–10 Serie A). Moreover, despite a positive equity as a separate company (€105,142,589), the AS Roma Group had a negative equity on consolidated balance sheet, fell from +€8.8million to negative €13.2 million. In 2010–11 season Roma was administrated by UniCredit as Sensi family failed to repay the bank and the club was put into the market, which also saw Roma did not had major signing in 2010–11 season. Co-currently with no selling profit on the player, Roma net loss was enlarged to €30,589,137 (€30.778 million as a group) and the new owner already planned a re-capitalization after the mandatory bid on the shares. On the good side, the TV income was increased from €75,150,744 to €78,041,642 as well as gate income increased, from €23,821,218 to €31,017,179. It is because Roma entered 2010–11 UEFA Champions League which counter-weight the effect of the new collective agreement of Serie A. In 2011–12, the renewal of squad and participate in 2011–12 UEFA Europa League had worsen the financial result, which the €50 million capital increase (in advance) was counter-weighted totally by the net loss. In 2012–13 season, the participation in domestic league only, not only not harmful to the revenue but increase in gate income as well as decrease in wage bill, however Roma still not yet break-even (€40.130 million net loss in consolidated accounts). NEEP Roma also re-capitalized AS Roma in advance for another €26,550,000 during 2012–13. A proposed capital increase by €100 million for AS Roma was finally announced on 25 June 2014, however until 22 May 2014 NEEP already injected €108 million to AS Roma, which depends on public subscription, more than €8 million would converted to medium-long term loan from shareholder instead of becoming share capital.
One of the subsidiary of Roma (joint venture with SS Lazio, 37.5% x2 and Parma, 25%), Società Diritti Sportivi S.r.l. was in the process of liquidation since 2005. The company was a joint-venture of 4 football clubs including Fiorentina. However after the bankruptcy of old Viola, both Roma and Lazio had increased it shares ratio from 25% to 37.5%.
Superleague Formula.
A.S. Roma had a team in the Superleague Formula race car series where teams are sponsored by football clubs. A.S. Roma's driver was ex IndyCar Series driver Franck Perera. The team had posted 3 podiums and was operated by Alan Docking Racing.

</doc>
<doc id="2360" url="http://en.wikipedia.org/wiki?curid=2360" title="Abu Nidal Organization">
Abu Nidal Organization

The Abu Nidal Organization (ANO) is the most common name for the Palestinian group Fatah–The Revolutionary Council ("Fatah al-Majles al-Thawry"), also known as Black June, the Arab Revolutionary Brigades, the Revolutionary Organization of Socialist Muslims, and sometimes operating as Black September (not to be confused with the Black September Organization).
The ANO is named after its founder Abu Nidal. It was created by a split from Yasser Arafat's Fatah faction of the PLO in 1974. The group has been designated as a terrorist organization by the United States, Israel, and the European Union.
Formation and background.
The ANO was originally formed as a result of the 1974 Rejectionist Front split in the PLO, after Arafat's Fatah had pushed through amendments of the PLO's goals, which were seen as a step towards compromise with Israel. Abu Nidal then moved to Ba'athist Iraq where he set up the ANO, which soon began a vicious string of terrorist attacks.
It has not clearly defined its ideological position, but was clearly opposed to any form of compromise or negotiation with Israel. It is known as one of the most uncompromisingly militant Palestinian groups ever. It had an estimated membership of several hundred, but its strength today is not known.
ANO attacks.
The ANO carried out attacks in 20 countries, killing or injuring almost 900 persons. Targets include the United States, the United Kingdom, France, Israel, moderate Palestinians, the PLO, and various Arab and European countries. The group has not attacked Western targets since the late 1980s.
Major attacks included the Rome and Vienna Airport Attacks in December 1985, the Neve Shalom synagogue in Istanbul and the Pan Am Flight 73 hijacking in Karachi in September 1986, and the "City of Poros" day-excursion ship attack in Greece in July 1988.
The ANO has been especially noted for its uncompromising stance on negotiation with Israel, treating anything less than all-out military struggle against Israel as treachery. This led the group to perform numerous attacks against the PLO, which had made clear it accepted a negotiated solution to the conflict. Fatah-RC is believed to have assassinated PLO deputy chief Abu Iyad and PLO security chief Abu Hul in Tunis in January 1991. It assassinated a Jordanian diplomat in Lebanon in January 1994 and has been linked to the killing of the PLO representative there. Noted PLO moderate Issam Sartawi was killed by the Fatah-RC in 1983. In the late 1970s, the group also made failed assassination attempt on the present Palestinian president and PLO chairman, Mahmoud Abbas. These attacks, and numerous others, led to the PLO issuing a death sentence "in absentia" against Abu Nidal. In the early 1990s, it made an attempt to gain control of a refugee camp in Lebanon, but this was thwarted by PLO organizations.

</doc>
<doc id="2362" url="http://en.wikipedia.org/wiki?curid=2362" title="Antibody">
Antibody

An antibody (AB), also known as an immunoglobulin (Ig), is a large, Y-shape protein produced by plasma cells that is used by the immune system to identify and neutralize pathogens such as bacteria and viruses. The antibody recognizes a unique molecule of the harmful agent, called an antigen, via the variable region. Each tip of the "Y" of an antibody contains a paratope that is specific for one particular epitope (similarly analogous to a key) on an antigen, allowing these two structures to bind together with precision. Using this binding mechanism, an antibody can "tag" a microbe or an infected cell for attack by other parts of the immune system, or can neutralize its target directly (for example, by blocking a part of a microbe that is essential for its invasion and survival). The ability of an antibody to communicate with the other components of the immune system is mediated via its Fc region (located at the base of the "Y"), which contains a conserved glycosylation site involved in these interactions. The production of antibodies is the main function of the humoral immune system.
Antibodies are secreted by cells of the adaptive immune system (B cells), and more specifically, differentiated B cells called plasma cells. Antibodies can occur in two physical forms, a soluble form that is secreted from the cell, and a membrane-bound form that is attached to the surface of a B cell and is referred to as the B cell receptor (BCR). The BCR is found only on the surface of B cells and facilitates the activation of these cells and their subsequent differentiation into either antibody factories called plasma cells or memory B cells that will survive in the body and remember that same antigen so the B cells can respond faster upon future exposure. In most cases, interaction of the B cell with a T helper cell is necessary to produce full activation of the B cell and, therefore, antibody generation following antigen binding. Soluble antibodies are released into the blood and tissue fluids, as well as many secretions to continue to survey for invading microorganisms.
Antibodies are glycoproteins belonging to the immunoglobulin superfamily; the terms "antibody" and "immunoglobulin" are often used interchangeably. Though strictly speaking, an antibody is not the same as an immunoglobulin; B cells can produce two types of immunoglobulins - surface immunoglobulins, which are B cell receptors; and secreted immunoglobulins, which are antibodies. So antibodies are one of two classes of immunoglobulins. Antibodies are typically made of basic structural units—each with two large heavy chains and two small light chains. There are several different types of antibody heavy chains based on five different types of crystallisable fragments (Fc) that may be attached to the antigen-binding fragments. The five different types of Fc regions allow antibodies to be grouped into five "isotypes". Each Fc region of a particular antibody isotype is able to bind to its specific Fc Receptor (except for IgD, which is essentially the BCR), thus allowing the antigen-antibody complex to mediate different roles depending on which FcR it binds. The ability of an antibody to bind to its corresponding FcR is further modulated by the structure of the glycan(s) present at conserved sites within its Fc region. The ability of antibodies to bind to FcRs helps to direct the appropriate immune response for each different type of foreign object they encounter. For example, IgE is responsible for an allergic response consisting mast cell degranulation and histamine release. IgE's Fab paratope binds to allergic antigen, for example house dust mite particles, while its Fc region binds to Fc receptor ε. The allergen-IgE-FcRε interaction mediates allergic signal transduction to induce conditions such as asthma. 
Though the general structure of all antibodies is very similar, a small region at the tip of the protein is extremely variable, allowing millions of antibodies with slightly different tip structures, or antigen-binding sites, to exist. This region is known as the "hypervariable region". Each of these variants can bind to a different antigen. This enormous diversity of antibody paratopes on the antigen-binding fragments allows the immune system to recognize an equally wide variety of antigens. The large and diverse population of antibody paratope is generated by random recombination events of a set of gene segments that encode different antigen-binding sites (or "paratopes"), followed by random mutations in this area of the antibody gene, which create further diversity. This recombinational process that produces clonal antibody paratope diversity is called V(D)J or VJ recombination. Basically, the antibody paratope is polygenic, made up of three genes, V, D, and J. Each paratope locus is also polymorphic, such that during antibody production, one allele of V, one of D, and one of J is chosen. These gene segments are then joined together using random genetic recombination to produce the paratope. The regions where the genes are randomly recombined together is the hyper variable region used to recognise different antigens on a clonal basis. 
Antibody genes also re-organize in a process called class switching that changes the one type of heavy chain Fc fragment to another, creating a different isotype of the antibody that retains the antigen-specific variable region. This allows a single antibody to be used by different types of Fc receptors, expressed on different parts of the immune system.
Forms.
The membrane-bound form of an antibody may be called a "surface immunoglobulin" (sIg) or a "membrane immunoglobulin" (mIg). It is part of the "B cell receptor" (BCR), which allows a B cell to detect when a specific antigen is present in the body and triggers B cell activation. The BCR is composed of surface-bound IgD or IgM antibodies and associated Ig-α and Ig-β heterodimers, which are capable of signal transduction. A typical human B cell will have 50,000 to 100,000 antibodies bound to its surface. Upon antigen binding, they cluster in large patches, which can exceed 1 micrometer in diameter, on lipid rafts that isolate the BCRs from most other cell signaling receptors.
These patches may improve the efficiency of the cellular immune response. In humans, the cell surface is bare around the B cell receptors for several hundred nanometers, which further isolates the BCRs from competing influences.
Antibody–antigen interactions.
The antibody's paratope interacts with the antigen's epitope. An antigen usually contains different epitopes along its surface arranged discontinuously, and dominant epitopes on a given antigen are called determinants. 
Antibody and antigen interact by spatial complementarity (lock and key). The molecular forces involved in the Fab-epitope interaction are weak and non-specific - for example electrostatic forces, hydrogen bonds, hydrophobic interactions, and van der Waals forces. This means binding between antibody and antigen is reversible, and the antibody's affinity towards an antigen is relative rather than absolute. Relatively weak binding also means it is possible for an antibody to cross-react with different antigens of different relative affinities.
Isotypes.
Antibodies can come in different varieties known as isotypes or classes. In placental mammals there are five antibody isotypes known as IgA, IgD, IgE, IgG, and IgM. They are each named with an "Ig" prefix that stands for immunoglobulin, another name for antibody, and differ in their biological properties, functional locations and ability to deal with different antigens, as depicted in the table. The different suffixes of the antibody isotypes denote the different types of heavy chains the antibody contains, with each heavy chain class named alphabetically: α, γ, δ, ε, and μ. This gives rise to IgA, IgG, IgD, IgE, and IgM, respectively. 
The antibody isotype of a B cell changes during cell development and activation. Immature B cells, which have never been exposed to an antigen, express only the IgM+ isotype in a cell surface bound form. The B lymphocyte, in its mature ready-to-respond form, is known as "naive B lymphocyte." The naive B lymphocyte express both surface IgM+ and IgD+. The co-expression of both these immunoglobulin isotypes renders the B cell 'mature' and ready to respond to antigen. B cell activation follows engagement of the cell-bound antibody molecule with an antigen, causing the cell to divide and differentiate into an antibody-producing cell called a plasma cell. In this activated form, the B cell starts to produce antibody in a secreted form rather than a membrane-bound form. Some daughter cells of the activated B cells undergo isotype switching, a mechanism that causes the production of antibodies to change from IgM or IgD to the other antibody isotypes, IgE, IgA, or IgG, that have defined roles in the immune system.
Structure.
Antibodies are heavy (~150 kDa) globular plasma proteins. They have sugar chains (glycans) added to conserved amino acid residues. In other words, antibodies are "glycoproteins". The attached glycans are critically important to the structure and function of the antibody. Among other things the expressed glycans can modulate an antibody's affinity for its corresponding FcR(s). 
The basic functional unit of each antibody is an immunoglobulin (Ig) monomer (containing only one Ig unit); secreted antibodies can also be dimeric with two Ig units as with IgA, tetrameric with four Ig units like teleost fish IgM, or pentameric with five Ig units, like mammalian IgM.
 The variable parts of an antibody are its V regions, and the constant part is its C region.
Immunoglobulin domains.
The Ig monomer is a "Y"-shaped molecule that consists of four polypeptide chains; two identical "heavy chains" and two identical "light chains" connected by disulfide bonds.
Each chain is composed of structural domains called immunoglobulin domains. These domains contain about 70–110 amino acids and are classified into different categories (for example, variable or IgV, and constant or IgC) according to their size and function. They have a characteristic immunoglobulin fold in which two beta sheets create a "sandwich" shape, held together by interactions between conserved cysteines and other charged amino acids.
Heavy chain.
There are five types of mammalian Ig heavy chain denoted by the Greek letters: α, δ, ε, γ, and μ. The type of heavy chain present defines the "class" of antibody; these chains are found in IgA, IgD, IgE, IgG, and IgM antibodies, respectively. Distinct heavy chains differ in size and composition; α and γ contain approximately 450 amino acids, whereas μ and ε have approximately 550 amino acids.
In birds, the major serum antibody, also found in yolk, is called IgY. It is quite different from mammalian IgG. However, in some older literature and even on some commercial life sciences product websites it is still called "IgG", which is incorrect and can be confusing.
Each heavy chain has two regions, the "constant region" and the "variable region". The constant region is identical in all antibodies of the same isotype, but differs in antibodies of different isotypes. Heavy chains γ, α and δ have a constant region composed of "three" tandem (in a line) Ig domains, and a hinge region for added flexibility; heavy chains μ and ε have a constant region composed of "four" immunoglobulin domains. The variable region of the heavy chain differs in antibodies produced by different B cells, but is the same for all antibodies produced by a single B cell or B cell clone. The variable region of each heavy chain is approximately 110 amino acids long and is composed of a single Ig domain.
Light chain.
In mammals there are two types of immunoglobulin light chain, which are called lambda (λ) and kappa (κ). A light chain has two successive domains: one constant domain and one variable domain. The approximate length of a light chain is 211 to 217 amino acids. Each antibody contains two light chains that are always identical; only one type of light chain, κ or λ, is present per antibody in mammals. Other types of light chains, such as the iota (ι) chain, are found in other vertebrates like sharks (Chondrichthyes) and bony fishes (Teleostei).
CDRs, Fv, Fab and Fc regions.
Some parts of an antibody have the same functions. The arms of the Y, for example, contain the sites that can bind to antigens (in general, identical) and, therefore, recognize specific foreign objects. This region of the antibody is called the "Fab (fragment, antigen-binding) region". It is composed of one constant and one variable domain from each heavy and light chain of the antibody.
The paratope is shaped at the amino terminal end of the antibody monomer by the variable domains from the heavy and light chains. The variable domain is also referred to as the FV region and is the most important region for binding to antigens. To be specific, variable loops of β-strands, three each on the light (VL) and heavy (VH) chains are responsible for binding to the antigen. These loops are referred to as the complementarity determining regions (CDRs).
The structures of these CDRs have been clustered and classified by Chothia et al.
and more recently by North et al.
and Nikoloudis et al.
In the framework of the immune network theory, CDRs are also called idiotypes. According to immune network theory, the adaptive immune system is regulated by interactions between idiotypes.
The base of the Y plays a role in modulating immune cell activity. This region is called the "Fc (Fragment, crystallizable) region", and is composed of two heavy chains that contribute two or three constant domains depending on the class of the antibody. Thus, the Fc region ensures that each antibody generates an appropriate immune response for a given antigen, by binding to a specific class of Fc receptors, and other immune molecules, such as complement proteins. By doing this, it mediates different physiological effects including recognition of opsonized particles (binding to FcγR), lysis of cells (binding to complement), and degranulation of mast cells, basophils, and eosinophils (binding to FcεR).
In summary, whilst the Fab region of the antibody determines its antigen specificity, the Fc region of the antibody determines the antibody's class effect. Since only the constant domains of the heavy chains make up the Fc region of an antibody, the classes of heavy chain in antibodies determine their class effects. Possible classes of heavy chains in antibodies include alpha, gamma, delta, epsilon, and mu, and they define the antibody's isotypes IgA, G, D, E, and M, respectively. This infers different isotypes of antibodies have different class effects due to their different Fc regions binding and activating different types of receptors. Possible class effects of antibodies include: Opsonisation, agglutination, haemolysis, complement activation, mast cell degranulation, and neutralisation (though this class effect may be mediated by the Fab region rather than the Fc region). It also implies that Fab-mediated effects are directed at microbes or toxins, whilst Fc mediated effects are directed at effector cells or effector molecules (see below).
Function.
Activated B cells differentiate into either antibody-producing cells called plasma cells that secrete soluble antibody or memory cells that survive in the body for years afterward in order to allow the immune system to remember an antigen and respond faster upon future exposures.
At the prenatal and neonatal stages of life, the presence of antibodies is provided by passive immunization from the mother. Early endogenous antibody production varies for different kinds of antibodies, and usually appear within the first years of life. Since antibodies exist freely in the bloodstream, they are said to be part of the humoral immune system. Circulating antibodies are produced by clonal B cells that specifically respond to only one antigen (an example is a virus capsid protein fragment). Antibodies contribute to immunity in three ways: They prevent pathogens from entering or damaging cells by binding to them; they stimulate removal of pathogens by macrophages and other cells by coating the pathogen; and they trigger destruction of pathogens by stimulating other immune responses such as the complement pathway.Antibodies will also trigger vasoactive amine degranulation to contribute to immunity against certain types of antigens (helminths, allergens). 
Activation of complement.
Antibodies that bind to surface antigens (for example, on bacteria) will attract the first component of the complement cascade with their Fc region and initiate activation of the "classical" complement system. This results in the killing of bacteria in two ways. First, the binding of the antibody and complement molecules marks the microbe for ingestion by phagocytes in a process called opsonization; these phagocytes are attracted by certain complement molecules generated in the complement cascade. Second, some complement system components form a membrane attack complex to assist antibodies to kill the bacterium directly (bacteriolysis). 
Activation of effector cells.
To combat pathogens that replicate outside cells, antibodies bind to pathogens to link them together, causing them to agglutinate. Since an antibody has at least two paratopes, it can bind more than one antigen by binding identical epitopes carried on the surfaces of these antigens. By coating the pathogen, antibodies stimulate effector functions against the pathogen in cells that recognize their Fc region.
Those cells that recognize coated pathogens have Fc receptors, which, as the name suggests, interacts with the Fc region of IgA, IgG, and IgE antibodies. The engagement of a particular antibody with the Fc receptor on a particular cell triggers an effector function of that cell; phagocytes will phagocytose, mast cells and neutrophils will degranulate, natural killer cells will release cytokines and cytotoxic molecules; that will ultimately result in destruction of the invading microbe. The activation of natural killer cells by antibodies initiates a cytotoxic mechanism known as antibody-dependent cell-mediated cytotoxicity (ADCC) - this process may explain the efficacy of monoclonal antibodies used in biological therapies against cancer. The Fc receptors are isotype-specific, which gives greater flexibility to the immune system, invoking only the appropriate immune mechanisms for distinct pathogens.
Natural antibodies.
Humans and higher primates also produce "natural antibodies" that are present in serum before viral infection. Natural antibodies have been defined as antibodies that are produced without any previous infection, vaccination, other foreign antigen exposure or passive immunization. These antibodies can activate the classical complement pathway leading to lysis of enveloped virus particles long before the adaptive immune response is activated. Many natural antibodies are directed against the disaccharide galactose α(1,3)-galactose (α-Gal), which is found as a terminal sugar on glycosylated cell surface proteins, and generated in response to production of this sugar by bacteria contained in the human gut. Rejection of xenotransplantated organs is thought to be, in part, the result of natural antibodies circulating in the serum of the recipient binding to α-Gal antigens expressed on the donor tissue.
Immunoglobulin diversity.
Virtually all microbes can trigger an antibody response. Successful recognition and eradication of many different types of microbes requires diversity among antibodies; their amino acid composition varies allowing them to interact with many different antigens. It has been estimated that humans generate about 10 billion different antibodies, each capable of binding a distinct epitope of an antigen. Although a huge repertoire of different antibodies is generated in a single individual, the number of genes available to make these proteins is limited by the size of the human genome. Several complex genetic mechanisms have evolved that allow vertebrate B cells to generate a diverse pool of antibodies from a relatively small number of antibody genes.
Domain variability.
The chromosomal region that encodes an antibody is large and contains several distinct gene loci for each domain of the antibody—the chromosome region containing heavy chain genes (IGH@) is found on chromosome 14, and the loci containing lambda and kappa light chain genes (IGL@ and IGK@) are found on chromosomes 22 and 2 in humans. One of these domains is called the variable domain, which is present in each heavy and light chain of every antibody, but can differ in different antibodies generated from distinct B cells. Differences, between the variable domains, are located on three loops known as hypervariable regions (HV-1, HV-2 and HV-3) or complementarity determining regions (CDR1, CDR2 and CDR3). CDRs are supported within the variable domains by conserved framework regions. The heavy chain locus contains about 65 different variable domain genes that all differ in their CDRs. Combining these genes with an array of genes for other domains of the antibody generates a large cavalry of antibodies with a high degree of variability. This combination is called V(D)J recombination discussed below.
V(D)J recombination.
Somatic recombination of immunoglobulins, also known as "V(D)J recombination", involves the generation of a unique immunoglobulin variable region. The variable region of each immunoglobulin heavy or light chain is encoded in several pieces—known as gene segments (subgenes). These segments are called variable (V), diversity (D) and joining (J) segments. V, D and J segments are found in Ig heavy chains, but only V and J segments are found in Ig light chains. Multiple copies of the V, D and J gene segments exist, and are tandemly arranged in the genomes of mammals. In the bone marrow, each developing B cell will assemble an immunoglobulin variable region by randomly selecting and combining one V, one D and one J gene segment (or one V and one J segment in the light chain). As there are multiple copies of each type of gene segment, and different combinations of gene segments can be used to generate each immunoglobulin variable region, this process generates a huge number of antibodies, each with different paratopes, and thus different antigen specificities. Interestingly, the rearrangement of several subgenes (i.e. V2 family) for lambda light chain immunoglobulin is coupled with the activation of microRNA miR-650, which further influences biology of B-cells.
After a B cell produces a functional immunoglobulin gene during V(D)J recombination, it cannot express any other variable region (a process known as allelic exclusion) thus each B cell can produce antibodies containing only one kind of variable chain.
Somatic hypermutation and affinity maturation.
Following activation with antigen, B cells begin to proliferate rapidly. In these rapidly dividing cells, the genes encoding the variable domains of the heavy and light chains undergo a high rate of point mutation, by a process called "somatic hypermutation" (SHM). SHM results in approximately one nucleotide change per variable gene, per cell division. As a consequence, any daughter B cells will acquire slight amino acid differences in the variable domains of their antibody chains.
This serves to increase the diversity of the antibody pool and impacts the antibody's antigen-binding affinity. Some point mutations will result in the production of antibodies that have a weaker interaction (low affinity) with their antigen than the original antibody, and some mutations will generate antibodies with a stronger interaction (high affinity). B cells that express high affinity antibodies on their surface will receive a strong survival signal during interactions with other cells, whereas those with low affinity antibodies will not, and will die by apoptosis. Thus, B cells expressing antibodies with a higher affinity for the antigen will outcompete those with weaker affinities for function and survival. The process of generating antibodies with increased binding affinities is called "affinity maturation". Affinity maturation occurs in mature B cells after V(D)J recombination, and is dependent on help from helper T cells.
Class switching.
Isotype or class switching is a biological process occurring after activation of the B cell, which allows the cell to produce different classes of antibody (IgA, IgE, or IgG). The different classes of antibody, and thus effector functions, are defined by the constant (C) regions of the immunoglobulin heavy chain. Initially, naive B cells express only cell-surface IgM and IgD with identical antigen binding regions. Each isotype is adapted for a distinct function; therefore, after activation, an antibody with an IgG, IgA, or IgE effector function might be required to effectively eliminate an antigen. Class switching allows different daughter cells from the same activated B cell to produce antibodies of different isotypes. Only the constant region of the antibody heavy chain changes during class switching; the variable regions, and therefore antigen specificity, remain unchanged. Thus the progeny of a single B cell can produce antibodies, all specific for the same antigen, but with the ability to produce the effector function appropriate for each antigenic challenge. Class switching is triggered by cytokines; the isotype generated depends on which cytokines are present in the B cell environment.
Class switching occurs in the heavy chain gene locus by a mechanism called class switch recombination (CSR). This mechanism relies on conserved nucleotide motifs, called "switch (S) regions", found in DNA upstream of each constant region gene (except in the δ-chain). The DNA strand is broken by the activity of a series of enzymes at two selected S-regions. The variable domain exon is rejoined through a process called non-homologous end joining (NHEJ) to the desired constant region (γ, α or ε). This process results in an immunoglobulin gene that encodes an antibody of a different isotype.
Affinity designations.
A group of antibodies can be called "monovalent" (or "specific") if they have affinity for the same epitope, or for the same antigen (but potentially different epitopes on the molecule), or for the same strain of microorganism (but potentially different antigens on or in it). In contrast, a group of antibodies can be called "polyvalent" (or "unspecific") if they have affinity for various antigens or microorganisms. Intravenous immunoglobulin, if not otherwise noted, consists of polyvalent IgG. In contrast, monoclonal antibodies are monovalent for the same epitope.
Asymmetrical antibodies.
Heterodimeric antibodies, which are also asymmetrical and antibodies, allow for greater flexibility and new formats for attaching a variety of drugs to the antibody arms. One of the general formats for a heterodimeric antibody is the “knobs-into-holes” format. This format is specific to the heavy chain part of the constant region in antibodies. The “knobs” part is engineered by replacing a small amino acid with a larger one. It fits into the “hole”, which is engineered by replacing a large amino acid with a smaller one. What connects the “knobs” to the “holes” are the disulfide bonds between each chain. The “knobs-into-holes” shape facilitates antibody dependent cell mediated cytotoxicity. Single chain variable fragments (scFv) are connected to the variable domain of the heavy and light chain via a short linker peptide. The linker is rich in glycine, which gives it more flexibility, and serine/threonine, which gives it specificity. Two different scFv fragments can be connected together, via a hinge region, to the constant domain of the heavy chain or the constant domain of the light chain. This gives the antibody bispecificity, allowing for the binding specificities of two different antigens. The “knobs-into-holes” format enhances heterodimer formation but doesn’t suppress homodimer formation.
To further improve the function of heterodimeric antibodies, many scientists are looking towards artificial constructs. Artificial antibodies are largely diverse protein motifs that use the functional strategy of the antibody molecule, but aren’t limited by the loop and framework structural constraints of the natural antibody. Being able to control the combinational design of the sequence and three-dimensional space could transcend the natural design and allow for the attachment of different combinations of drugs to the arms.
Heterodimeric antibodies have a greater range in shapes they can take and the drugs that are attached to the arms don’t have to be the same on each arm, allowing for different combinations of drugs to be used in cancer treatment. Pharmaceuticals are able to produce highly functional bispecific, and even multispecific, antibodies. The degree to which they can function is impressive given that such a change shape from the natural form should lead to decreased functionality.
Medical applications.
Disease diagnosis and therapy.
Detection of particular antibodies is a very common form of medical diagnostics, and applications such as serology depend on these methods. For example, in biochemical assays for disease diagnosis, a titer of antibodies directed against Epstein-Barr virus or Lyme disease is estimated from the blood. If those antibodies are not present, either the person is not infected or the infection occurred a "very" long time ago, and the B cells generating these specific antibodies have naturally decayed. In clinical immunology, levels of individual classes of immunoglobulins are measured by nephelometry (or turbidimetry) to characterize the antibody profile of patient. Elevations in different classes of immunoglobulins are sometimes useful in determining the cause of liver damage in patients for whom the diagnosis is unclear. For example, elevated IgA indicates alcoholic cirrhosis, elevated IgM indicates viral hepatitis and primary biliary cirrhosis, while IgG is elevated in viral hepatitis, autoimmune hepatitis and cirrhosis. Autoimmune disorders can often be traced to antibodies that bind the body's own epitopes; many can be detected through blood tests. Antibodies directed against red blood cell surface antigens in immune mediated hemolytic anemia are detected with the Coombs test. The Coombs test is also used for antibody screening in blood transfusion preparation and also for antibody screening in antenatal women.
Practically, several immunodiagnostic methods based on detection of complex antigen-antibody are used to diagnose infectious diseases, for example ELISA, immunofluorescence, Western blot, immunodiffusion, immunoelectrophoresis, and magnetic immunoassay. Antibodies raised against human chorionic gonadotropin are used in over the counter pregnancy tests.
Targeted monoclonal antibody therapy is employed to treat diseases such as rheumatoid arthritis, multiple sclerosis, psoriasis, and many forms of cancer including non-Hodgkin's lymphoma, colorectal cancer, head and neck cancer and breast cancer.
Some immune deficiencies, such as X-linked agammaglobulinemia and hypogammaglobulinemia, result in partial or complete lack of antibodies. These diseases are often treated by inducing a short term form of immunity called passive immunity. Passive immunity is achieved through the transfer of ready-made antibodies in the form of human or animal serum, pooled immunoglobulin or monoclonal antibodies, into the affected individual.
Prenatal therapy.
Rhesus factor, also known as Rhesus D (RhD) antigen, is an antigen found on red blood cells; individuals that are Rhesus-positive (Rh+) have this antigen on their red blood cells and individuals that are Rhesus-negative (Rh–) do not. During normal childbirth, delivery trauma or complications during pregnancy, blood from a fetus can enter the mother's system. In the case of an Rh-incompatible mother and child, consequential blood mixing may sensitize an Rh- mother to the Rh antigen on the blood cells of the Rh+ child, putting the remainder of the pregnancy, and any subsequent pregnancies, at risk for hemolytic disease of the newborn.
Rho(D) immune globulin antibodies are specific for human Rhesus D (RhD) antigen. Anti-RhD antibodies are administered as part of a prenatal treatment regimen to prevent sensitization that may occur when a Rhesus-negative mother has a Rhesus-positive fetus. Treatment of a mother with Anti-RhD antibodies prior to and immediately after trauma and delivery destroys Rh antigen in the mother's system from the fetus. It is important to note that this occurs before the antigen can stimulate maternal B cells to "remember" Rh antigen by generating memory B cells. Therefore, her humoral immune system will not make anti-Rh antibodies, and will not attack the Rhesus antigens of the current or subsequent babies. Rho(D) Immune Globulin treatment prevents sensitization that can lead to Rh disease, but does not prevent or treat the underlying disease itself.
Research applications.
Specific antibodies are produced by injecting an antigen into a mammal, such as a mouse, rat, rabbit, goat, sheep, or horse for large quantities of antibody. Blood isolated from these animals contains "polyclonal antibodies"—multiple antibodies that bind to the same antigen—in the serum, which can now be called antiserum. Antigens are also injected into chickens for generation of polyclonal antibodies in egg yolk. To obtain antibody that is specific for a single epitope of an antigen, antibody-secreting lymphocytes are isolated from the animal and immortalized by fusing them with a cancer cell line. The fused cells are called hybridomas, and will continually grow and secrete antibody in culture. Single hybridoma cells are isolated by dilution cloning to generate cell clones that all produce the same antibody; these antibodies are called "monoclonal antibodies". Polyclonal and monoclonal antibodies are often purified using Protein A/G or antigen-affinity chromatography.
In research, purified antibodies are used in many applications. Antibodies for research applications can be found directly from antibody suppliers, or through use of a specialist search engine. Research antibodies are most commonly used to identify and locate intracellular and extracellular proteins. Antibodies are used in flow cytometry to differentiate cell types by the proteins they express; different types of cell express different combinations of cluster of differentiation molecules on their surface, and produce different intracellular and secretable proteins. They are also used in immunoprecipitation to separate proteins and anything bound to them (co-immunoprecipitation) from other molecules in a cell lysate, in Western blot analyses to identify proteins separated by electrophoresis, and in immunohistochemistry or immunofluorescence to examine protein expression in tissue sections or to locate proteins within cells with the assistance of a microscope. Proteins can also be detected and quantified with antibodies, using ELISA and ELISPOT techniques.
Researchers using antibodies in their work need to record them correctly in order to allow their research to be reproducible (and therefore tested, and qualified by other researchers). Less than half of research antibodies referenced in academic papers can be easily identified. A paper published in F1000 in 2014 provided researchers with a guide for reporting research antibody use.
Regulatory validation of monoclonal antibody products for human use.
Production and testing :
Traditionally, most antibodies are produced by hybridoma cell lines through immortalization of antibody-producing cells by chemically-induced fusion with myeloma cells. In some cases, additional fusions with other lines have created "triomas" and "quadromas". The manufacturing process should be appropriately described and validated. Validation studies should
at least include :
Before clinical trials, studies of product safety and feasibility have to be performed :
Preclinical studies : 
Structure prediction.
The importance of antibodies in health care and the biotechnology industry demands knowledge of their structures at high resolution. This information is used for protein engineering, modifying the antigen binding affinity, and identifying an epitope, of a given antibody. X-ray crystallography is one commonly used method for determining antibody structures. However, crystallizing an antibody is often laborious and time-consuming. Computational approaches provide a cheaper and faster alternative to crystallography, but their results are more equivocal, since they do not produce empirical structures. Online web servers such as "Web Antibody Modeling" (WAM) and "Prediction of Immunoglobulin Structure" (PIGS) enables computational modeling of antibody variable regions. Rosetta Antibody is a novel antibody FV region structure prediction server, which incorporates sophisticated techniques to minimize CDR loops and optimize the relative orientation of the light and heavy chains, as well as homology models that predict successful docking of antibodies with their unique antigen.
The ability to describe the antibody through binding affinity to the antigen is supplemented by information on antibody structure and amino acid sequences for the purpose of patent claims.
History.
The first use of the term "antibody" occurred in a text by Paul Ehrlich. The term "Antikörper" (the German word for "antibody") appears in the conclusion of his article "Experimental Studies on Immunity", published in October 1891, which states that, "if two substances give rise to two different antikörper, then they themselves must be different". However, the term was not accepted immediately and several other terms for antibody were proposed; these included "Immunkörper", "Amboceptor", "Zwischenkörper", "substance sensibilisatrice", "copula", "Desmon", "philocytase", "fixateur", and "Immunisin". The word "antibody" has formal analogy to the word "antitoxin" and a similar concept to "Immunkörper" ("immune body" in English). As such, the original construction of the word contains a logical flaw; the antitoxin is something directed against a toxin, while the antibody is a body directed against something.
The study of antibodies began in 1890 when Kitasato Shibasaburō described antibody activity against diphtheria and tetanus toxins. Kitasato put forward the theory of humoral immunity, proposing that a mediator in serum could react with a foreign antigen. His idea prompted Paul Ehrlich to propose the side-chain theory for antibody and antigen interaction in 1897, when he hypothesized that receptors (described as "side-chains") on the surface of cells could bind specifically to toxins – in a "lock-and-key" interaction – and that this binding reaction is the trigger for the production of antibodies. Other researchers believed that antibodies existed freely in the blood and, in 1904, Almroth Wright suggested that soluble antibodies coated bacteria to label them for phagocytosis and killing; a process that he named opsoninization.
In the 1920s, Michael Heidelberger and Oswald Avery observed that antigens could be precipitated by antibodies and went on to show that antibodies are made of protein. The biochemical properties of antigen-antibody-binding interactions were examined in more detail in the late 1930s by John Marrack. The next major advance was in the 1940s, when Linus Pauling confirmed the lock-and-key theory proposed by Ehrlich by showing that the interactions between antibodies and antigens depend more on their shape than their chemical composition. In 1948, Astrid Fagreaus discovered that B cells, in the form of plasma cells, were responsible for generating antibodies.
Further work concentrated on characterizing the structures of the antibody proteins. A major advance in these structural studies was the discovery in the early 1960s by Gerald Edelman and Joseph Gally of the antibody light chain, and their realization that this protein is the same as the Bence-Jones protein described in 1845 by Henry Bence Jones. Edelman went on to discover that antibodies are composed of disulfide bond-linked heavy and light chains. Around the same time, antibody-binding (Fab) and antibody tail (Fc) regions of IgG were characterized by Rodney Porter. Together, these scientists deduced the structure and complete amino acid sequence of IgG, a feat for which they were jointly awarded the 1972 Nobel Prize in Physiology or Medicine. The Fv fragment was prepared and characterized by David Givol. While most of these early studies focused on IgM and IgG, other immunoglobulin isotypes were identified in the 1960s: Thomas Tomasi discovered secretory antibody (IgA) and David S. Rowe and John L. Fahey identified IgD, and IgE was identified by Kimishige Ishizaka and Teruko Ishizaka as a class of antibodies involved in allergic reactions. In a landmark series of experiments beginning in 1976, Susumu Tonegawa showed that genetic material can rearrange itself to form the vast array of available antibodies.

</doc>
<doc id="2363" url="http://en.wikipedia.org/wiki?curid=2363" title="Alessandro Scarlatti">
Alessandro Scarlatti

Alessandro Scarlatti (2 May 1660 – 22 October 1725) was an Italian Baroque composer, especially famous for his operas and chamber cantatas. He is considered the founder of the Neapolitan school of opera. He was the father of two other composers, Domenico Scarlatti and Pietro Filippo Scarlatti.
Life.
Scarlatti was born in Palermo, then part of the Kingdom of Sicily. He is generally said to have been a pupil of Giacomo Carissimi in Rome, and some theorize that he had some connection with northern Italy because his early works seem to show the influence of Stradella and Legrenzi. The production at Rome of his opera "Gli Equivoci nell sembiante" (1679) gained him the support of Queen Christina of Sweden (who at the time was living in Rome), and he became her "Maestro di Cappella". In February 1684 he became "Maestro di Cappella" to the viceroy of Naples, perhaps through the influence of his sister, an opera singer, who might have been the mistress of an influential Neapolitan noble. Here he produced a long series of operas, remarkable chiefly for their fluency and expressiveness, as well as other music for state occasions.
In 1702 Scarlatti left Naples and did not return until the Spanish domination had been superseded by that of the Austrians. In the interval he enjoyed the patronage of Ferdinando de' Medici, for whose private theatre near Florence he composed operas, and of Cardinal Ottoboni, who made him his "maestro di cappella", and procured him a similar post at the Basilica di Santa Maria Maggiore in Rome in 1703.
After visiting Venice and Urbino in 1707, Scarlatti took up his duties in Naples again in 1708, and remained there until 1717. By this time Naples seems to have become tired of his music; the Romans, however, appreciated it better, and it was at the Teatro Capranica in Rome that he produced some of his finest operas ("Telemaco", 1718; "Marco Attilio Regolò", 1719; "La Griselda", 1721), as well as some noble specimens of church music, including a mass for chorus and orchestra, composed in honor of Saint Cecilia for Cardinal Acquaviva in 1721. His last work on a large scale appears to have been the unfinished serenata for the marriage of the prince of Stigliano in 1723. He died in Naples in 1725.
Scarlatti's music.
Scarlatti's music forms an important link between the early Baroque Italian vocal styles of the 17th century, with their centers in Florence, Venice and Rome, and the classical school of the 18th century. Scarlatti's style, however, is more than a transitional element in Western music; like most of his Naples colleagues he shows an almost modern understanding of the psychology of modulation and also frequently makes use of the ever-changing phrase lengths so typical of the Napoli school. His early operas ("Gli equivoci nel sembiante" 1679; "L'honestà negli amori" 1680, containing the famous aria "Già il sole dal Gange"; "Il Pompeo" 1683, containing the well-known airs "O cessate di piagarmi" and "Toglietemi la vita ancor," and others down to about 1685) retain the older cadences in their recitatives, and a considerable variety of neatly constructed forms in their charming little arias, accompanied sometimes by the string quartet, treated with careful elaboration, sometimes with the continuo alone. By 1686 he had definitely established the "Italian overture" form (second edition of "Dal male il bene"), and had abandoned the ground bass and the binary form air in two stanzas in favour of the ternary form or da capo type of air. His best operas of this period are "La Rosaura" (1690, printed by the Gesellschaft für Musikforschung), and "Pirro e Demetrio" (1694), in which occur the arias "Le Violette", and "Ben ti sta, traditor".
From about 1697 onwards ("La caduta del Decemviri"), influenced partly perhaps by the style of Giovanni Bononcini and probably more by the taste of the viceregal court, his opera arias become more conventional and commonplace in rhythm, while his scoring is hasty and crude, yet not without brilliance ("L'Eraclea", 1700), the oboes and trumpets being frequently used, and the violins often playing in unison. The operas composed for Ferdinando de' Medici are lost; they might have given a more favourable idea of his style as his correspondence with the prince shows that they were composed with a very sincere sense of inspiration.
"Mitridate Eupatore", accounted his masterpiece, composed for Venice in 1707, contains music far in advance of anything that Scarlatti had written for Naples, both in technique and in intellectual power. The later Neapolitan operas ("L'amor volubile e tiranno" 1709; "La principessa fedele" 1710; "Tigrane", 1714, &c.) are showy and effective rather than profoundly emotional; the instrumentation marks a great advance on previous work, since the main duty of accompanying the voice is thrown upon the string quartet, the harpsichord being reserved exclusively for the noisy instrumental ritornelli. In his opera "Teodora" (1697) he originated the use of the orchestral "ritornello".
His last group of operas, composed for Rome, exhibit a deeper poetic feeling, a broad and dignified style of melody, a strong dramatic sense, especially in accompanied recitatives, a device which he himself had been the first to use as early as 1686 ("Olimpia vendicata") and a much more modern style of orchestration, the horns appearing for the first time, and being treated with striking effect.
Besides the operas, oratorios ("Agar et Ismaele esiliati", 1684; "La Maddalena", 1685; "La Giuditta", 1693; "Christmas Oratorio", c. 1705; "S. Filippo Neri", 1714; and others) and serenatas, which all exhibit a similar style, Scarlatti composed upwards of five hundred chamber-cantatas for solo voice. These represent the most intellectual type of chamber-music of their period, and it is to be regretted that they have remained almost entirely in manuscript, since a careful study of them is indispensable to anyone who wishes to form an adequate idea of Scarlatti's development.
His few remaining Masses (the story of his having composed two hundred is hardly credible) and church music in general are comparatively unimportant, except the great "St Cecilia Mass" (1721), which is one of the first attempts at the style which reached its height in the great Masses of Johann Sebastian Bach and Beethoven. His instrumental music, though not without interest, is curiously antiquated as compared with his vocal works.

</doc>
<doc id="2369" url="http://en.wikipedia.org/wiki?curid=2369" title="Aston Martin">
Aston Martin

Aston Martin Lagonda Limited is a British manufacturer of luxury sports cars and grand tourers. It was founded in 1913 by Lionel Martin and Robert Bamford.
The firm became associated with luxury grand touring cars in the 1950s and 1960s, and with the fictional character James Bond following his use of a DB5 model in the 1964 film "Goldfinger".
The company has had a chequered financial history, including bankruptcy in the 1970s, but has also enjoyed long periods of success and stability, including under the ownership of David Brown, from 1947 to 1972 and of the Ford Motor Company from 1994 to 2007.
In March 2007, a consortium of investors, led by David Richards, purchased 92% of Aston Martin for £479 million, with Ford retaining a £40 million stake.
David Richards became chairman of Aston Martin. In December 2012, the Italian private equity fund Investindustrial
signed a deal to buy 37.5% of Aston Martin, investing £150 million as a capital increase.
History.
Founding.
Aston Martin was founded in 1913 by Lionel Martin and Robert Bamford. The two had joined forces as Bamford & Martin the previous year to sell cars made by Singer from premises in Callow Street, London where they also serviced GWK and Calthorpe vehicles. Martin raced specials at Aston Hill near Aston Clinton, and the pair decided to make their own vehicles. The first car to be named "Aston Martin" was created by Martin by fitting a four-cylinder Coventry-Simplex engine to the chassis of a 1908 Isotta-Fraschini.
They acquired premises at Henniker Mews in Kensington and produced their first car in March 1915. Production could not start because of the outbreak of World War I, and Martin joined the Admiralty and Bamford the Royal Army Service Corps. All machinery was sold to the Sopwith Aviation Company.
Inter war years.
After the war, the company was refounded at Abingdon Road, Kensington and a new car designed to carry the Aston-Martin name. Bamford left in 1920 and the company was revitalised with funding from Count Louis Zborowski. In 1922, Bamford & Martin produced cars to compete in the French Grand Prix, which went on to set world speed and endurance records at Brooklands. Three works Team Cars with 16-valve were built for racing and record breaking: chassis number 1914, later developed as the Green Pea; chassis number 1915, the Razor Blade record car; and chassis number 1916, later developed as the Halford Special.
Approximately 55 cars were built for sale in two configurations, and short chassis. The company went bankrupt in 1924 and was bought by Lady Charnwood, who put her son John Benson on the board. The company failed again in 1925 and the factory closed in 1926, with Lionel Martin leaving.
Later that year, Bill Renwick, Augustus (Bert) Bertelli and investors which included Lady Charnwood took control of the company. They renamed it Aston Martin Motors and moved it to the former Whitehead Aircraft Limited works in Feltham. Renwick and Bertelli had been in partnership some years and had developed an overhead-cam four-cylinder engine using Renwick's patented combustion chamber design, which they had tested in an Enfield Allday chassis. The only "Renwick and Bertelli" motor car made, it was known as "Buzzbox" and still survives.
The pair had planned to sell their engine to motor manufacturers, but having heard that the Aston Martin was no longer in production realised they could capitalise on its reputation to jump start the production of a completely new car.
Between 1926 and 1937 Bertelli was both technical director and designer of all new Aston Martins, since known as "Bertelli cars". They included the 1½-litre "T-type", "International", "Le Mans", "MKII" and its racing derivative, the "Ulster", and the 2-litre 15/98 and its racing derivative, the "Speed Model". Most were open two-seater sports cars bodied by Bert Bertelli's brother , with a small number of long-chassis four-seater tourers, dropheads and saloons also produced.
Bertelli was a competent driver keen to race his cars, one of few owner/manufacturer/drivers. The "LM" team cars were very successful in national and international motor racing including at Le Mans and the Mille Miglia.
Financial problems reappeared in 1932. The company was rescued for a year by L. Prideaux Brune before passing it on to Sir Arthur Sutherland. In 1936, Aston Martin decided to concentrate on road cars, producing just 700 until World War II halted work. Production shifted to aircraft components during the war.
David Brown era.
In 1947, tractor manufacturer David Brown Limited bought the company under the leadership of managing director Sir David Brown—its "post-war saviour". The company also acquired Lagonda that year for its 2.6-litre W. O. Bentley-designed engine. Both companies shared resources and workshops, birthing the classic "DB" series of cars. In 1950, the company announced the DB2, followed by the DB2/4 in 1953, the DB2/4 MkII in 1955, the DB Mark III in 1957 and the Italian-styled 3.7 L DB4 in 1958.
While these models helped Aston Martin establish a good racing pedigree, the DB4 stood out and yielded the famous DB5 in 1963. The company stayed true to its emerging "grand touring" style with the DB6 (1965–70), and DBS (1967–1972).
The six-cylinder engines of these cars from 1954 up to 1965 were designed by Tadek Marek.
1970s—changing ownership.
The Aston Martin company was often financially troubled. In 1972, the firm was sold to Company Developments, a Birmingham-based consortium chaired by William Wilson, MBE.
The company was resold in 1975 by its receiver following a further bankruptcy to North American businessmen Peter Sprague and George Minden for £1.05 million. A successful turn-around strategy led to the recruitment of 360 new employees and, by 1977, a trading profit of £750,000. The new owners pushed the company into modernising its line, producing the V8 Vantage in 1977, the convertible Volante in 1978, and the one-off William Towns-styled Bulldog in 1980. Towns also styled the futuristic new Lagonda saloon, based on the V8 model.
In 1980 Aston-Martin sought to buy MG, planning to design a new model and offering their take on an updated 1981 model MGB. The acquisition never developed, as the company was badly hit by the economic contraction of the early 1980s. Worldwide sales shrank to three cars per week, prompting chairman Alan Curtis, Sprague, and Minden to consider shutting down production to concentrate on service and restoration. At this point Curtis attended the 1980 Pace sponsored Stirling Moss benefit day at Brands Hatch, and met fellow Farnham resident Victor Gauntlett.
1980s—Victor Gauntlett.
Gauntlett bought a 12.5% stake in Aston Martin for £500,000 via Pace Petroleum in 1980, with Tim Hearley of CH Industrials taking a similar share. Pace and CHI took over as joint 50/50 owners at the beginning of 1981, with Gauntlett as executive chairman. Gauntlett also led the sales team, and after some development and publicity when it became the world's fastest 4-seater production car, was able to sell the Aston Martin Lagonda in Oman, Kuwait, and Qatar.
In 1982, Aston Martin was granted a Royal Warrant of Appointment by the Prince of Wales. The company holds the warrant to this day.
Understanding that it would take some time to develop new Aston Martin products, they created an engineering service subsidiary to develop automotive products for other companies. It was decided to use the name of the coachbuilding company Tickford which Aston Martin had owned since 1955, the name being already associated with quality cars in the public perception. Products included a Tickford Austin Metro, a Tickford Ford Capri and even Tickford train interiors, particularly on the Jaguar XJS. Pace continued sponsoring racing events, and now sponsored all Aston Martin Owners Club events, taking a Tickford-engined Nimrod Group C car owned by AMOC President Viscount Downe, which came third in the Manufacturers Championship in both 1982 and 1983. It also finished seventh in the 1982 24 Hours of Le Mans race. However, sales of production cars were now at an all-time low of 30 cars produced in 1982.
As trading became tighter in the petroleum market, and Aston Martin was requiring more time and money, Gauntlett agreed to sell Hays/Pace to the Kuwait Investment Office in September 1983. As Aston Martin required greater investment, he also agreed to sell his share holding to American importer and Greek shipping tycoon Peter Livanos, who invested via his joint venture company with Nick and John Papanicolaou, ALL Inc. Gauntlett remained chairman of the AML company 55% owned by ALL, with Tickford a 50/50 venture between ALL and CHI. The uneasy relationship was ended when ALL exercised options to buy a larger share in AML; CHI's residual shares were exchanged for CHI's complete ownership of Tickford, which retained development of existing Aston Martin projects. In 1984, Titan the main shipping company of the Papanicolaou's was in trouble, so Livanos's father George bought out the Papanicolaou's shares in ALL, while Gauntlett again became a shareholder with a 25% holding in AML. The deal valued Aston Martin/AML at £2 million, the year it built its 10,000th car.
Although as a result Aston Martin had to make 60 members of the workforce redundant, Gauntlett bought a stake in Italian styling house Zagato, and resurrected its collaboration with Aston Martin.
In 1986, Gauntlett negotiated the return of fictional British secret agent James Bond to Aston Martin. Cubby Broccoli had chosen to recast the character using actor Timothy Dalton, in an attempt to re-root the Bond-brand back to a more Sean Connery-like feel. Gauntlett supplied his personal pre-production Vantage for use in the filming of "The Living Daylights", and sold a Volante to Broccoli for use at his home in America. Gauntlett turned down the role of a KGB colonel in the film, however: "I would have loved to have done it but really could not afford the time."
The company needed funds to survive in the long term. In May 1987, Gauntlett and Prince Michael of Kent were staying at the home of Contessa Maggi, the wife of the founder of the original Mille Miglia, while watching the revival event. Another house guest was Walter Hayes, vice-President of Ford of Europe. Despite problems over the previous acquisition of AC Cars, Hayes saw the potential of the brand and the discussion resulted in Ford taking a share holding in September 1987. In 1988, having produced some 5,000 cars in 20 years, a revived economy and successful sales of limited edition Vantage, and 52 Volante Zagato coupes at £86,000 each; the company finally retired the ancient V8 and introduced the Virage range—the first new Aston launched in 20 years.
Although Gauntlett was contractually to stay as chairman for two years, his racing interests took Aston back into sports car racing in 1989 with limited European success. However, with engine rule changes for the 1990 season and the launch of the new Aston Martin Volante model, Ford provided the limited supply of Cosworth engines to the Jaguar cars racing team. As the "small Aston" DB7 would require a large engineering input, Ford agreed to take full control of Aston Martin, and Gauntlett handed over the company chairmanship to Hayes in 1991. In 1992, the Vantage version was announced, and the following year the company renewed the DB range by announcing the DB7.
Ford era.
Ford placed Aston in the Premier Automotive Group, invested in new manufacturing and ramped up production. In 1994, Ford opened a new factory at Banbury Road in Bloxham. In 1995, the company produced a record 700 vehicles. Until the Ford era, cars had been produced by hand coachbuilding craft methods, such as the English wheel. In 1998 the 2,000th DB7 was built, and in 2002 the 6,000th, exceeding production of all previous DB models. The DB7 range was boosted by the addition of V12 Vantage models in 1999, and in 2001 the company introduced the V12-engined Aston Martin Vanquish.
At the North American International Auto Show in Detroit, Michigan in 2003, Aston Martin introduced the AMV8 Vantage concept car. Expected to have few changes before its introduction in 2005, the Vantage brought back the classic V8 engine to allow the company to compete in a larger market. 2003 also saw the opening of the Gaydon factory, the first purpose-built factory in Aston Martin's history. Also introduced in 2003 was the DB9 coupé, which replaced the ten-year-old DB7. A convertible version of the DB9, the DB9 Volante, was introduced at the 2004 Detroit Auto Show.
In October 2004, the company set up the dedicated 12500 m2 AMEP engine production plant within the Ford Germany Niehl, Cologne plant. With capacity to produce up to 5,000 engines a year by 100 specially trained personnel, like traditional Aston Martin engine production from Newport Pagnell, assembly of each unit is entrusted to a single technician from a pool of 30, with V8 and V12 variants assembled in under 20 hours. By bringing engine production back to within the company, the promise was that Aston Martin would be able to produce small runs of higher performance variants engines. This expanded engine capacity allowed in 2006, the V8 Vantage sports car to enter production at the Gaydon factory, joining the DB9 and DB9 Volante.
In December 2003 Aston Martin announced it would return to motor racing in 2005. A new division was created, called Aston Martin Racing, which became responsible, together with Prodrive, for the design, development, and management of the DBR9 program. The DBR9 competes in the GT class in sports car races, including the world-famous 24 Hours of Le Mans.
In 2006, an internal audit led Ford to consider divesting itself of parts of its Premier Automotive Group. After suggestions of selling Jaguar Cars, Land Rover, or Volvo Cars were weighed, Ford announced in August 2006 it had engaged UBS AG to sell all or part of Aston Martin at auction.
2007—the Richards era.
On 12 March 2007, a consortium led by Prodrive chairman David Richards purchased Aston Martin for £475m (US$848m). The group included American investment banker John Singers and two Kuwaiti companies, Investment Dar and Adeem Investment; Prodrive had no financial involvement in the deal.
Ford kept a stake in the company valued at £40m (US$70m).
To demonstrate the V8 Vantage's durability across hazardous terrain and promote the car in China, the first east-west crossing of the Asian Highway was undertaken between June and August 2007. A pair of Britons drove 12089 km from Tokyo to Istanbul before joining the European motorway network for another 3259 km to London. The promotion was so successful the company opened dealerships in Shanghai and Beijing within three months.
On 19 July 2007, the Newport Pagnell plant rolled out the last of nearly 13,000 cars made there since 1955, a Vanquish S. The Tickford Street facility was converted to Aston Martin's service and restoration department. UK production is now concentrated at Gaydon on the former RAF V-bomber airfield. In March 2008 the company announced a partnership with Magna Steyr to outsource manufacture of over 2,000 cars annually to Graz, Austria, reassuringly stating: "The continuing growth and success of the company is based upon Gaydon as the focal point and heart of the business, with the design and engineering of all Aston Martin products continuing to be carried out there."
More dealers in Europe and the new pair in China brought the total to 120 in 28 countries.
On 1 September 2008, Aston Martin announced the revival of the Lagonda marque, proposing a concept to be shown in 2009 to coincide with the brand's 100th anniversary. The first production cars are slated for 2012.
In December 2008, Aston Martin announced it would cut its workforce from 1,850 to 1,250.
The first four-door Aston Martin Rapide sports cars rolled out of the Magna Steyr factory in Graz, Austria in 2010. The contract manufacturer provides dedicated facilities to ensure compliance with the exacting standards of Aston Martin and other marques, including Mercedes-Benz. Ulrich Bez has publicly speculated about outsourcing all of Aston Martin's operations with the exception of marketing. In September 2011 it was announced Rapide production would be returned to Gaydon in the second half of 2012, restoring all manufacture there.
2012—Investindustrial stakeholding and new chief executive officer.
In late 2012, Investment Dar reviewed its stake, with Mahindra & Mahindra emerging as a potential bidder for as much as half of Aston Martin. Instead, Italian private equity fund Investindustrial signed a deal on 6 December 2012 to buy 37.5% of Aston Martin, investing £150 million as a capital increase. This was confirmed by Aston Martin in a press release on 7 December 2012. In April 2013 it was reported that Dr Ulrich Bez would be leaving his role as chief executive officer to take up a more ambassadorial position widely seen as the first move by the new shareholders in reviewing the leadership and strategy of the company. On 2 September 2014, Aston Martin announced they had appointed the Nissan executive Andy Palmer as their new CEO with Ulrich Bez retaining a position as Non-Executive Chairman. As sales had been declining, from 2015 Aston Martin sought new customers (particularly wealthy female buyers) with cars like Lagonda and DBX while releasing concepts cars like the Vulcan.
Relationship with Mercedes-AMG.
In 2013 Aston Martin signed a deal with Daimler AG to supply new Mercedes-AMG power plants for the next generation line up. Daimler AG now owns 5% of Aston Martin. Mercedes-AMG will also supply Aston Martin with electrical systems. This technical partnership will support Aston Martin’s launch of a new generation of models that will incorporate new technology and V8s.
Sponsorships.
Aston Martin sponsors 2. Bundesliga club 1860 Munich.
External links.
class="navbox collapsible autocollapse" 
!colspan="70" class="navbox-title"

</doc>
<doc id="2371" url="http://en.wikipedia.org/wiki?curid=2371" title="Albert Pike">
Albert Pike

Albert Pike (December 29, 1809 – April 2, 1891) was an American attorney, Confederate officer, writer, and Freemason.
Early life.
Pike was born in Boston, Massachusetts, son of Ben and Sarah (Andrews) Pike, and spent his childhood in Byfield and Newburyport, Massachusetts. His colonial ancestors included John Pike (1613-1688/1689), the founder of Woodbridge, New Jersey. He attended school in Newburyport and Framingham until he was 15. In August 1825, he passed entrance exams at Harvard University, though when the college requested payment of tuition fees for the first two years which he had successfully challenged by examination, he chose not to attend. He began a program of self-education, later becoming a schoolteacher in Gloucester, North Bedford, Fairhaven and Newburyport.
In 1831, Pike left Massachusetts to travel west, first stopping in St. Louis and later moving on to Independence, Missouri. In Independence, he joined an expedition to Taos, New Mexico, hunting and trading. During the excursion his horse broke and ran, forcing Pike to walk the remaining 500 miles to Taos. After this he joined a trapping expedition to the Llano Estacado in New Mexico and Texas. Trapping was minimal and, after traveling about 1300 miles (650 on foot), he finally arrived at Fort Smith, Arkansas.
Journalist and Lawyer.
Settling in Arkansas in 1833, Pike taught school and wrote a series of articles for the Little Rock "Arkansas Advocate" under the pen name of "Casca." The articles were popular enough that he was asked to join the newspaper's staff. Later, after marrying Mary Ann Hamilton, he purchased part of the newspaper with the dowry. By 1835, he was the "Advocate"'s sole owner. Under Pike's administration the "Advocate" promoted the viewpoint of the Whig Party in a politically volatile and divided Arkansas.
Pike then began to study law and was admitted to the bar in 1837, selling the "Advocate" the same year. He was the first reporter for the Arkansas supreme court and also wrote a book (published anonymously), titled "The Arkansas Form Book", which was a guidebook for lawyers. Additionally, Pike wrote on several legal subjects and continued producing poetry, a hobby he had begun in his youth in Massachusetts. His poems were highly regarded in his day, but are now mostly forgotten. Several volumes of his works were privately published posthumously by his daughter. In 1859, he received an honorary Master of Arts degree from Harvard.
Military career.
When the Mexican–American War started, Pike joined the Regiment of Arkansas Mounted Volunteers (a cavalry regiment) and was commissioned as a troop commander with the rank of captain in June 1846. With his regiment, he fought in the Battle of Buena Vista. Pike was discharged in June 1847. He and his commander, Colonel John Selden Roane, had several differences of opinion. This situation led finally to an "inconclusive" duel between Pike and Roane on July 29, 1847 near Fort Smith, Arkansas. Although several shots were fired in the duel, nobody was injured, and the two were persuaded by their seconds to discontinue it.
After the war, Pike returned to the practice of law, moving to New Orleans for a time beginning in 1853. He wrote another book, "Maxims of the Roman Law and some of the Ancient French Law, as Expounded and Applied in Doctrine and Jurisprudence". Although unpublished, this book increased his reputation among his associates in law. He returned to Arkansas in 1857, gaining some amount of prominence in the legal field and becoming an advocate of slavery, although retaining his affiliation with the Whig Party.
In 1847 Pike became disillusioned when the Whig Party refused to take a stand on slavery. His anti-Catholicism stand led him to join the Know Nothing movement when it was organized in 1856, but was again disappointed when it refused to adopt a strong pro-slavery platform. He joined the other Southern delegates and walked out of the convention. His stand was that state's rights superseded national law and supported the idea of a Southern secession. This stand is made clear in his pamphlet of 1861, "State or Province, Bond or Free?"
When the war started he took the side of the Confederacy. At the Southern Commercial Convention of 1854, Pike said the South should remain in the Union and seek equality with the North, but if the South "were forced into an inferior status, she would be better out of the Union than in it."
He also made several contacts among the Native American tribes in the area, at one time negotiating an $800,000 settlement between the Creeks and other tribes and the federal government. This relationship was to influence the course of his Civil War service. At the beginning of the war, Pike was appointed as Confederate envoy to the Native Americans. In this capacity he negotiated several treaties, one of the most important being with Cherokee chief John Ross, which was concluded in 1861.
Pike was commissioned as a brigadier general on November 22, 1861, and given a command in the Indian Territory. With Gen. Ben McCulloch, Pike trained three Confederate regiments of Indian cavalry, most of whom belonged to the "civilized tribes", whose loyalty to the Confederacy was variable. Although initially victorious at the Battle of Pea Ridge (Elkhorn Tavern) in March, Pike's unit was defeated later in a counterattack, after falling into disarray. Also, as in the previous war, Pike came into conflict with his superior officers, at one time drafting a letter to Jefferson Davis complaining about his direct superior.
After Pea Ridge, Pike was faced with charges that his troops had scalped soldiers in the field. Maj. Gen. Thomas C. Hindman also charged Pike with mishandling of money and material, ordering his arrest. Both these charges were later found to be considerably lacking in evidence; nevertheless Pike, facing arrest, escaped into the hills of Arkansas, sending his resignation from the Confederate Army on July 12. He was at length arrested on November 3 under charges of insubordination and treason, and held briefly in Warren, Texas, but his resignation was accepted on November 11 and he was allowed to return to Arkansas.
Freemasonry.
He first joined the Independent Order of Odd Fellows in 1840 then had in the interim joined a Masonic Lodge and became extremely active in the affairs of the organization, being elected Sovereign Grand Commander of the Scottish Rite's Southern Jurisdiction in 1859. He remained Sovereign Grand Commander for the remainder of his life (a total of thirty-two years), devoting a large amount of his time to developing the rituals of the order. Notably, he published a book called "Morals and Dogma of the Ancient and Accepted Scottish Rite of Freemasonry" in 1871, of which there were several subsequent editions.
Pike is still regarded in America as an eminent and influential Freemason, primarily in the Scottish Rite Southern Jurisdiction.
Death and legacy.
Pike died in Washington, D.C., aged 81, and was buried at Oak Hill Cemetery. Burial was against his wishes; he had left instructions for his body to be cremated. In 1944, his remains were moved to the House of the Temple, headquarters of the Southern Jurisdiction of the Scottish Rite.
Poetry.
As a young man, Pike wrote poetry which he continued to do for the rest of his life. At 23, he published his first poem, “Hymns to the Gods.” Later work was printed in literary journals like Blackwood’s "Edinburgh Magazine" and local newspapers. His first collection of poetry, "Prose Sketches and Poems Written in the Western Country", appeared in 1834. He later gathered many of his poems and republished them in "Hymns to the Gods and Other Poems" (1872). After his death these appeared again in "Gen. Albert Pike’s Poems" (1900) and "Lyrics and Love Songs" (1916).
References.
 #if: 
 #if: A Short Biographical Dictionary of English Literature
 |, 
 #if: 
 }}{{
 #if: 
 #if: 
 | ()
 |{{
 #if: 
 #if: 
 | {{#if:||}}{{
 #if: 
 #if: 
 #if: {{
 #if: A Short Biographical Dictionary of English Literature
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |: {{
 #if: A Short Biographical Dictionary of English Literature
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 
 #if: A Short Biographical Dictionary of English Literature
 |{{
 #if: Cousin
 }} {{Citation/make link
 | 1={{
 #if: 
 #if: 
 #if: 
 |{{
 #if: 
 | 2=" A Short Biographical Dictionary of English Literature
 #if:| []
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 | ( ed.)
 #if: 
 }}{{
 #if: 
 #if: 
 |,
 #if: Cousin
 |{{
 #if: 1910
 |, 1910{{
 #if:
}}{{
 #if: 
 #ifeq: | 1910
 |{{
 #if: 
 #if: Cousin
 | (published )
 |{{
 #if: 
 | (published )
}}{{
 #if: 
 |{{
 #if: {{
 #if: A Short Biographical Dictionary of English Literature
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |, {{
 #if: A Short Biographical Dictionary of English Literature
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
}}{{
 #if:
 | , {{#ifeq: | no
 | {{#if:
 |{{Citation/make link||{{#ifeq:|.|A|a}}rchived}} from the original
 |{{#ifeq:|.|A|a}}rchived
 | {{#ifeq:|.|A|a}}rchived{{#if:
 }}{{#if:| on }}{{
 |. {{citation error|nocat=
 #if: A Short Biographical Dictionary of English Literature
 |, {{
 #if: 
 |
 |, {{
 #if: 
 |
 }}{{
 #if: 
 | {{#ifeq:|,|, r|. R}}etrieved 
}}{{#if:
}}{{#if:
}}{{#if:
}}<span
 class="Z3988"
 title="ctx_ver=Z39.88-2004&rft_val_fmt={{urlencode:info:ofi/fmt:kev:mtx:}}{{
 #if: 
 |journal&rft.genre=article&rft.atitle={{urlencode: A Short Biographical Dictionary of English Literature
 |book{{
 #if: 
 |&rft.genre=bookitem&rft.btitle={{urlencode:}}&rft.atitle={{urlencode: A Short Biographical Dictionary of English Literature
 |&rft.genre=book&rft.btitle={{urlencode: A Short Biographical Dictionary of English Literature
 #if: Cousin |&rft.aulast={{urlencode:Cousin}}{{
 }}{{
 #if: Cousin |&rft.au={{urlencode:Cousin}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: {{
 #if: A Short Biographical Dictionary of English Literature
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |&rft.pages={{urlencode: {{
 #if: A Short Biographical Dictionary of English Literature
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 }}{{
 }}&rfr_id=info:sid/en.wikipedia.org:{{FULLPAGENAMEE}}"> 
 |IncludedWorkTitle = 
 |IncludedWorkURL = 
 |Other = 
 |Edition = 
 |Place = London
 |PublicationPlace = London
 |Publisher = J. M. Dent & Sons. Wikisource
 |PublicationDate = 
 |EditorSurname1 = 
 |EditorSurname2 = 
 |EditorSurname3 = 
 |EditorSurname4 = 
 |EditorGiven1 = 
 |EditorGiven2=
 |EditorGiven3=
 |EditorGiven4=
 |Editorlink1=
 |Editorlink2=
 |Editorlink3=
 |Editorlink4=
 |language = 
 |format = 
 |ARXIV=
 |ASIN=
 |BIBCODE=
 |DOI=
 |DoiBroken=
 |ISBN=
 |ISSN=
 |JFM=
 |JSTOR=
 |LCCN=
 |MR=
 |OCLC=
 |OL=
 |OSTI=
 |PMC=
 |Embargo=1010-10-10
 |PMID=
 |RFC=
 |SSRN=
 |ZBL=
 |ID=
 |AccessDate=
 |DateFormat=none
 |quote = 
 |laysummary = 
 |laydate = 
 |Ref=harv
 |Sep = .
 |PS = 
 |AuthorSep = ; 
 |NameSep = , 
 |Trunc = 8
 |amp = 
External links.
My Personal Views On Pike's Morals and Dogma masonicme.com

</doc>
<doc id="2372" url="http://en.wikipedia.org/wiki?curid=2372" title="ALF Tales">
ALF Tales

ALF Tales is an animated American series that ran on the NBC television network on Saturdays from August 1988 to December 1989. The show was a spinoff from the series "". The show had characters from that series play various characters from fairy tales. The fairy tale was usually altered for comedic effect in a manner akin to Fractured Fairy Tales.
Each story typically spoofs a film genre, such as the "Cinderella" episode done as an Elvis movie. Some episodes featured a "fourth wall" effect where ALF is backstage preparing for the episode, and Rob Cowan would appear drawn as a TV executive (who introduced himself as "Roger Cowan, network executive") to try to brief ALF on how to improve this episode. For instance Cowan once told ALF who was readying for a medieval themed episode that "less than 2% of our audience lives in the Dark Ages".
DVD release.
The first seven episodes were released on DVD on May 30, 2006 in Region 1 from Lions Gate Home Entertainment in a single-disc release entitled "ALF and The Beanstalk and Other Classic Fairy Tales".

</doc>
<doc id="2376" url="http://en.wikipedia.org/wiki?curid=2376" title="Abdul Rashid Dostum">
Abdul Rashid Dostum

Abdul Rashid Dostum (  : ;[] Persian: عبدالرشید دوستم) (born 1954) is an Afghan warlord and ethnic Uzbek who has served as Vice President of Afghanistan since 2014. He was previously part of the leadership council of the National Front of Afghanistan along with Ahmad Zia Massoud and Mohammad Mohaqiq, as well as chairman of his own political party, Junbish-e Milli-yi Islami-yi Afghanistan (National Islamic Movement of Afghanistan). He also served in the past as Chairman Joint Chiefs of Staff of the Afghan National Army, a role often viewed as ceremonial.
During the Soviet war in Afghanistan, Dostum was a general in the Afghan army. He later became an independent warlord and leader of Afghanistan's Uzbek community. He participated in battles against the Mujahideen fighters in the 1980s as well as against the Taliban in the 1990s.
Early life.
Dostum was born in 1954 in Khwaja du koh, Jowzjan Province, Afghanistan. Coming from an impoverished family, he received a very basic traditional education as he was forced to drop out of school at a young age. From there, he took up work in the gas fields.
Careers.
Dostum began working in 1970 in a state-owned gas refinery in Sheberghan, participating in union politics, as the new government started to arm the staff of the workers in the oil and gas refineries. The reason for this was to create "groups for the defense of the revolution". Because of the new communist ideas entering Afghanistan in the 1970s, he enlisted in the army in 1978. Dostum received his basic military training in Jalalabad. His squadron was deployed in the rural areas around Sheberghan, under the auspices of the Ministry of National Security.
Soviet war in Afghanistan.
By the mid-1980s his platoon had grown in stature, reaching company status. He commanded around 20,000 militia men and was considered to be equivalent to a regimental commander. While the unit recruited throughout Jowzjan and had a relatively broad base, many of its early troops and commanders came from Dostum's home village. He left the army after the purge of Parchamis, but returned after the Soviet occupation began.
During the Soviet war in Afghanistan, Dostum was commanding a militia battalion to fight and rout mujahideen forces; he had been appointed an officer due to prior military experience. This eventually became a regiment and later became incorporated into the defense forces as the 53rd Infantry Division. Dostum and his new division reported directly to President Mohammad Najibullah. Later on he became the commander of the military unit 374 in Jowzjan. He defended the Soviet-backed Afghan government against the U.S., Pakistani, and Iranian-backed mujahideen forces throughout the 1980s. While he was only a regional commander, he had largely raised his forces by himself. The Jowzjani militia Dostum controlled was one of the few in the country which was able to be deployed outside its own region. They were deployed in Kandahar in 1988 when Soviet forces were withdrawing from Afghanistan.
Civil war.
Dostum's men would become an important force in the fall of Kabul in 1992. In April 1992, the opposition forces began their march to Kabul against the government of Najibullah. Dostum had allied himself with the opposition commanders Ahmad Shah Massoud and Sayed Jafar Naderi, the head of the Isma'ili community, and together they captured the capital city. He and Massoud fought in a coalition against Gulbuddin Hekmatyar. Massoud and Dostum's forces joined together to defend Kabul against Hekmatyar, with some 4000-5000 of his troops, units of his Shiberghan-based 53rd Division and Balkh-based Guards Division, garrisoning Bala Hissar fort, Maranjan Hill, and Khwaja Rawash International Airport. In 1994, Dostum allied himself with Gulbuddin Hekmatyar against the government of Burhanuddin Rabbani and Ahmad Shah Massoud.
Taliban and Northern Alliance era.
Following the rise of the Taliban and their capture of Kabul, Dostum aligned himself with the Northern Alliance (United Front) against the Taliban. He stationed his troops in the city of Mazar-e-Sharif. The Northern Alliance was assembled in late 1996 by Dostum, Massoud and Karim Khalili against the Taliban. At this point he is said to have had a force of some 50,000 men supported by both aircraft and tanks. He ruled what was, in effect, an independent region. He printed his own Afghan currency and ran a small airline named Balkh Air.
Much like other northern alliance leaders, Dostum also faced infighting within his group and was later forced to surrender his power to General Abdul Malik Pahlawan. Malik entered into secret negotiations with the Taliban, who promised to respect his authority over much of northern Afghanistan, in exchange for Ismail Khan, one of their enemies. Accordingly, on 25 May 1997 Malik arrested Khan and handed him over and let the Taliban enter Mazar-e-Sharif, giving them control over most of northern Afghanistan. Because of this, Dostum was forced to flee to Turkey. However, Malik soon realized that the Taliban were not sincere with their promises as he saw his men being disarmed. He then rejoined the Northern Alliance, and turned against his erstwhile allies, driving them from Mazar-e-Sharif. In October 1997, Dostum returned from exile and retook charge. After Dostum briefly regained control of Mazar-e-Sharif, the Taliban returned in 1998 and he again fled to Turkey.
Operation Enduring Freedom.
Dostum returned in 2001 to join the U.S.-led campaign against the Taliban. Along with General Fahim, Ismail Khan and Mohammad Mohaqiq. In November 2001, with the beginning of the U.S. invasion of Afghanistan, and against the wishes of the CIA who distrusted Dostum, a team including Johnny Micheal Spann landed to set up communications in the Dar-e-Suf. A few hours later 23 men of Operational Detachment Alpha (ODA) 595 landed to begin the war.
On 24 November 2001, 300 Taliban soldiers retreated after the Siege of Kunduz by American and Northern Alliance. The Taliban laid down their weapons a few miles from the city of Mazar-i-Sharif. They eventually surrendered to Dostum. A small group of armed foreign fighters were transferred to the 19th century prison fortress, Qala-i-Jangi. The Taliban used concealed weapons to start the Battle of Qala-i-Jangi against the opposition forces. The uprising was eventually brought under control.
In late 2001, the media began reporting that Dostum's forces, who were fighting the Taliban alongside the US Special Forces, intentionally suffocated as many as 2,000 Taliban prisoners in container trucks in an incident that has become known as the Dasht-i-Leili massacre. In July 2009, The NY Times reported that according to anonymous witnesses they interviewed, "over a three-day period, Taliban prisoners were stuffed into closed metal shipping containers and given no food or water; many suffocated while being trucked to the prison. Other prisoners were killed when guards shot into the containers. The bodies were said to have been buried in a mass grave in Dasht-i-Leili, a stretch of desert just outside Sheberghan. A 2002 declassified U.S. State Department intelligence report states that another source, whose identity is redacted, concluded that about 1,500 Taliban prisoners died. Estimates from other witnesses or human rights groups range from several hundred to several thousand. The report also says that several Afghan witnesses were later tortured or killed." Dostum claimed only 200 were killed. There was satellite evidence that mass graves had been dug up and moved as well as eyewitness statements by survivors. Ultimately no formal investigation was conducted and an official website of General Dostum lays out a timeline of events attempting to refute these numbers. The foundation of the controversy lay in confusion in estimating the number of Taliban that possibly joined the Northern Alliance or simply returned to their villages after the Kunduz surrender.
Karzai administration.
In the aftermath of Taliban's removal from northern Afghanistan, forces loyal to Dostum frequently clashed with Tajik forces loyal to Atta Muhammad Nur. Atta's men kidnapped and killed a number of Dostum's men, and constantly agitated to gain control of Mazar-e-Sharif. Through the political mediations of the Karzai administration, the International Security Assistance Force (ISAF) and the United Nations, the Dostum-Atta feud has gradually declined.
Dostum served as deputy defense minister the early period of the Karzai administration. In March 2003, he established a North Zone of Afghanistan. On 20 May 2003, Dostum narrowly escaped an assassination attempt. He was often residing outside Afghanistan, mainly in Turkey.
On 16 August 2009, Dostum made a requested return from exile to Afghanistan to support President Hamid Karzai in his bid for re-election. He later flew by helicopter to his northern stronghold of Sheberghan, where he was greeted by thousands of his supporters in the local stadium. He subsequently made overtures to the United States, promising he could "destroy the Taliban and al Qaeda" if supported by the U.S., saying that "the U.S. needs strong friends like Dostum."
Ghani administration.
He became Vice President of Afghanistan in the 2014 Afghan presidential election. His running mates were Ashraf Ghani and Sarwar Danish.
Time in Turkey.
Some media reports stated earlier that Dostum was "seeking political asylum" in Turkey <ref name=http://xrl.us/ozw7p>"Dostum seeking asylum in Turkey - media reports," Quqnoos.com, 6 December 2008, retrieved 6 December 2008</ref> while others said he was exiled.<ref name=http://www.earthtimes.org/articles/show/244638,afghan-general-rashid-dostum-flies-to-exile-in-turkey.html>"Afghan general Rashid Dostum flies to exile in Turkey," Deutsche Presse-Agentur via earthtimes.org, 4 December 2008, retrieved 6 December 2008</ref> One Turkish media outlet said Dostum was visiting after flying there with then Turkey's Foreign Minister Ali Babacan during a meeting of the Organization for Security and Cooperation in Europe (OSCE).<ref name=http://www.todayszaman.com/tz-web/detaylar.do?load=detay&link=160690&bolum=102>"Afghan warlord in Turkey but not in exile, official says," Today's Zaman, 5 December 2008, retrieved 6 December 2008</ref>
Political and social views.
While Dostum was ruling northern Afghanistan before the Taliban took over in 1998, women were able to go about unveiled, girls were allowed to go to school and study at the University of Balkh in Mazar-e-Sharif, cinemas showed Indian films and music played on television, activities which were all banned by the Taliban.
He viewed the ISAF forces attempt to crush the Taliban as ineffective and has gone on record saying that he could mop up the Taliban "in six months" if allowed to raise a 10,000 strong army of Afghan veterans. Senior Afghan government officials do not trust Dostum as they are concerned that he might be secretly rearming his forces.

</doc>
